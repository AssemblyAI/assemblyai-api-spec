---
title: "Identifying highlights in audio and video files"
hide-nav-links: true
description: "Identify key phrases spoken in your audio file"
---

The [Key Phrases](/docs/audio-intelligence/key-phrases) model identifies significant words and phrases in your transcript and lets you to extract the most important concepts or highlights from your audio or video file.

For example, if you're a call center, you can analyze highlights from recorded phone calls.

In this step-by-step guide, you'll learn how to apply the model. You'll send the `auto_highlights` parameter in your request, and then use the `auto_highlights_result` property in the response.

## Get started

Before we begin, make sure you have an AssemblyAI account and an API key. You can [sign up](https://assemblyai.com/dashboard/signup) for a free account and get your API key from your dashboard.

The complete source code for this guide can be viewed [here](https://github.com/AssemblyAI-Community/docs-snippets/tree/main/highlights).

Here's an audio sample for this guide:

```bash
https://assembly.ai/wildfires.mp3
```

## Step-by-step instructions

<Steps>
<Step>

<Tabs groupId="language">

<Tab language="python-sdk" title="Python SDK" default>
Install the SDK.

```python
pip install -U assemblyai
```

  </Tab>

  <Tab language="python" title="Python (requests)">
  Create a new file and
request.

```python
import requests
import time
```

  </Tab>

  <Tab language="javascript" title="JavaScript">
  Create a new file and
request.

```javascript
import axios from "axios";
import fs from "fs-extra";
```

  </Tab>

  <Tab language="php" title="PHP">
  Create a new file and
request.

```php
$ch = curl_init();
curl_setopt($ch, CURLOPT_RETURNTRANSFER, true);
```

  </Tab>

  <Tab language="ruby" title="Ruby">
  Create a new file and
request.

<Code src="snippets/guides/identifying-highlights-in-audio-or-video-files/ruby-1.rb" />
  </Tab>

<Tab language="csharp" title="C#">
Create a new file and
request.

```csharp
using System.Net.Http;
using System.Threading;
```

</Tab>

</Tabs>

</Step>
<Step>

<Tabs groupId="language">

<Tab language="python-sdk" title="Python SDK" default>
Import the `assemblyai` package and set the API key.

```python
import assemblyai as aai

aai.settings.api_key = "<YOUR_API_KEY>"
```

  </Tab>

  <Tab language="python" title="Python">
  Set up the API endpoint and headers. The headers should include your API
key.

<Code src="snippets/guides/identifying-highlights-in-audio-or-video-files/python-1.py" />
  </Tab>

  <Tab language="javascript" title="JavaScript">
  Set up the API endpoint and headers. The headers should include your API
key.

<Code src="snippets/guides/identifying-highlights-in-audio-or-video-files/javascript-1.js" />
  </Tab>

  <Tab language="php" title="PHP">
  Set up the API endpoint and headers. The headers should include your API
key.

<Code src="snippets/guides/identifying-highlights-in-audio-or-video-files/php-1.php" />
  </Tab>

  <Tab language="ruby" title="Ruby">
  Set up the API endpoint and headers. The headers should include your API
key.

<Code src="snippets/guides/identifying-highlights-in-audio-or-video-files/ruby-2.rb" />
  </Tab>

  <Tab language="csharp" title="C#">
  Set up the API endpoint and headers. The headers should include your API
key.

```csharp
string apiKey = "<YOUR_API_KEY>";
```

  </Tab>

</Tabs>

</Step>
<Step>

<Tabs groupId="language">

<Tab language="python-sdk" title="Python SDK" default>
Create a `TranscriptionConfig` with `auto_highlights` set to `True`.

```python
# highlight-next-line
config = aai.TranscriptionConfig(auto_highlights=True)
```

  </Tab>

  <Tab language="python" title="Python">
  Upload your local file to the AssemblyAI API.

<Code src="snippets/guides/identifying-highlights-in-audio-or-video-files/python-2.py" />
  </Tab>

  <Tab language="javascript" title="JavaScript">
  Upload your local file to the AssemblyAI API.

<Code src="snippets/guides/identifying-highlights-in-audio-or-video-files/javascript-2.js" />
  </Tab>

  <Tab language="php" title="PHP">
  Upload your local file to the AssemblyAI API.

<Code src="snippets/guides/identifying-highlights-in-audio-or-video-files/php-2.php" />
  </Tab>

  <Tab language="ruby" title="Ruby">
  Upload your local file to the AssemblyAI API.

```ruby
path = "/my_audio.mp3"
response = RestClient.post("#{base_url}/upload", File.read(path), headers)
upload_url = JSON.parse(response.body)["upload_url"]
```

  </Tab>

  <Tab language="csharp" title="C#">
  Upload your local file to the AssemblyAI API.

<Code src="snippets/guides/identifying-highlights-in-audio-or-video-files/csharp-1.cs" />
  </Tab>

</Tabs>

</Step>
<Step>

<Tabs groupId="language">

<Tab language="python-sdk" title="Python SDK" default>
Create a `Transcriber` object and pass in the configuration.

```python
transcriber = aai.Transcriber(config=config)
```

  </Tab>

  <Tab language="python" title="Python">
  Use the `upload_url` returned by the AssemblyAI API to create a JSON payload
containing the `audio_url` parameter and the `auto_highlights` parameter set to
`True`.

<Code src="snippets/guides/identifying-highlights-in-audio-or-video-files/python-3.py" />
  </Tab>

  <Tab language="javascript" title="JavaScript">
  Use the `upload_url` returned by the AssemblyAI API to create a JSON payload
containing the `audio_url` parameter and the `auto_highlights` parameter set to
`True`.

<Code src="snippets/guides/identifying-highlights-in-audio-or-video-files/javascript-3.js" />
  </Tab>

  <Tab language="php" title="PHP">
  Use the `upload_url` returned by the AssemblyAI API to create a JSON payload
containing the `audio_url` parameter and the `auto_highlights` parameter set to
`True`.

<Code src="snippets/guides/identifying-highlights-in-audio-or-video-files/php-3.php" />
  </Tab>

  <Tab language="ruby" title="Ruby">
  Use the `upload_url` returned by the AssemblyAI API to create a JSON payload
containing the `audio_url` parameter and the `auto_highlights` parameter set to
`True`.

<Code src="snippets/guides/identifying-highlights-in-audio-or-video-files/ruby-3.rb" />
  </Tab>

  <Tab language="csharp" title="C#">
  Use the `upload_url` returned by the AssemblyAI API to create a JSON payload
containing the `audio_url` parameter and the `auto_highlights` parameter set to
`True`.

<Code src="snippets/guides/identifying-highlights-in-audio-or-video-files/csharp-2.cs" />
  </Tab>

</Tabs>

</Step>
<Step>

<Tabs groupId="language">

<Tab language="python-sdk" title="Python SDK" default>
Pass the URL or file path to `Transcriber.transcribe()`. You can access the transcript from the returned `Transcript` object.

```python
FILE_URL = "https://assembly.ai/wildfires.mp3"

transcript = transcriber.transcribe(FILE_URL)
```

  </Tab>

  <Tab language="python" title="Python">
  Make a `POST` request to the AssemblyAI API endpoint with the payload and
headers.

```python
url = base_url + "/transcript"
response = requests.post(url, json=data, headers=headers)
```

  </Tab>

  <Tab language="javascript" title="JavaScript">
  Make a `POST` request to the AssemblyAI API endpoint with the payload and
headers.

```javascript
const url = `${baseUrl}/transcript`;
const response = await axios.post(url, data, { headers: headers });
```

  </Tab>

  <Tab language="php" title="PHP">
  Make a `POST` request to the AssemblyAI API endpoint with the payload and
headers.

<Code src="snippets/guides/identifying-highlights-in-audio-or-video-files/php-4.php" />
  </Tab>

  <Tab language="ruby" title="Ruby">
  Make a `POST` request to the AssemblyAI API endpoint with the payload and
headers.

<Code src="snippets/guides/identifying-highlights-in-audio-or-video-files/ruby-4.rb" />
  </Tab>

  <Tab language="csharp" title="C#">
  Make a `POST` request to the AssemblyAI API endpoint with the payload and
headers.

<Code src="snippets/guides/identifying-highlights-in-audio-or-video-files/csharp-3.cs" />
  </Tab>

</Tabs>

</Step>
<Step>

<Tabs groupId="language">

  <Tab language="python-sdk" title="Python SDK" default>
  You can access automatic highlights from `transcript.auto_highlights.results`.

```python
for result in transcript.auto_highlights.results:
  print(f"Highlight: {result.text}, Count: {result.count}, Rank: {result.rank}, Timestamps: {result.timestamps}")
```

  </Tab>

  <Tab language="python" title="Python">
  After making the request, you'll receive an ID for the transcription. Use it
to poll the API every few seconds to check the status of the transcript job.
Once the status is `completed`, you can retrieve the transcript from the API
response, as well as the auto highlight results.

<Code src="snippets/guides/identifying-highlights-in-audio-or-video-files/python-4.py" />
  </Tab>

  <Tab language="javascript" title="JavaScript">
  After making the request, you'll receive an ID for the transcription. Use it
to poll the API every few seconds to check the status of the transcript job.
Once the status is `completed`, you can retrieve the transcript from the API
response, as well as the auto highlight results.

<Code src="snippets/guides/identifying-highlights-in-audio-or-video-files/javascript-4.js" />
  </Tab>

  <Tab language="php" title="PHP">
  After making the request, you'll receive an ID for the transcription. Use it
to poll the API every few seconds to check the status of the transcript job.
Once the status is `completed`, you can retrieve the transcript from the API
response, as well as the auto highlight results.

<Code src="snippets/guides/identifying-highlights-in-audio-or-video-files/php-5.php" />
  </Tab>

  <Tab language="ruby" title="Ruby">
  After making the request, you'll receive an ID for the transcription. Use it
to poll the API every few seconds to check the status of the transcript job.
Once the status is `completed`, you can retrieve the transcript from the API
response, as well as the auto highlight results.

<Code src="snippets/guides/identifying-highlights-in-audio-or-video-files/ruby-5.rb" />
  </Tab>

  <Tab language="csharp" title="C#">
  After making the request, you'll receive an ID for the transcription. Use it
to poll the API every few seconds to check the status of the transcript job.
Once the status is `completed`, you can retrieve the transcript from the API
response, as well as the auto highlight results.

<Code src="snippets/guides/identifying-highlights-in-audio-or-video-files/csharp-4.cs" />
  </Tab>

</Tabs>

</Step>
</Steps>

## Understanding the response

The `auto_highlights_result` key in the response contains a list of all the highlights found in the transcription text. For each entry, the results include the text of the phrase or word detected (`text`), how many times it occurred in the text (`count`), its relevancy score (`rank`), and a list of all the timestamps (`timestamps`), in milliseconds, in the audio where the phrase or word is spoken.

<CodeBlock>
  <JsonViewer
    displayDataTypes={false}
    quotesOnKeys={false}
    displayObjectSize={false}
    src={{
      auto_highlights_result: {
        status: "success",
        results: [
          {
            count: 2,
            rank: 0.04,
            text: "months",
            timestamps: [
              {
                start: 24688,
                end: 24922,
              },
              {
                start: 80408,
                end: 80594,
              },
            ],
          },
          {
            count: 1,
            rank: 0.04,
            text: "first fee",
            timestamps: [
              {
                start: 78948,
                end: 79766,
              },
            ],
          },
        ],
      },
      auto_highlights: true,
    }}
  />
</CodeBlock>

For more information about the API response, see [API/Model reference](/docs/audio-intelligence/key-phrases).

## Conclusion

Automatically highlighting relevant phrases in calls is a great way to focus on important information at a glance. In general, adding AI to Conversation Intelligence tools can augment them by generating actionable summaries to speed up call review, generating insights, monitoring for concerns, increasing engagement, and [more](https://www.assemblyai.com/blog/3-easy-ways-to-add-ai-summarization-to-conversation-intelligence-tools/). Our AI summarization model has several [customizable parameters](/docs/audio-intelligence/summarization#types-and-models) that you can experiment with for other types of recordings.

To learn more about how to use AI summarization for call coaching, see [AssemblyAI blog](https://www.assemblyai.com/blog/build-standout-call-coaching-features-ai-summarization/).
