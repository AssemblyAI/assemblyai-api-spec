---
title: "Migration guide: OpenAI to AssemblyAI"
---

This guide walks through the process of migrating from OpenAI to AssemblyAI for transcribing pre-recorded audio.

### Get Started

Before we begin, make sure you have an AssemblyAI account and an API key. You can [sign up](https://assemblyai.com/dashboard/signup) for a free account and get your API key from your dashboard.

## Side-By-Side Code Comparison

Below is a side-by-side comparison of a basic snippet to transcribe a **local file** by OpenAI and AssemblyAI:

<Tabs groupId="language">
<Tab language="openai" title="OpenAI">

<Code src="../../../../snippets/guides/cookbooks/core-transcription/oai_to_aai/python-1.py" />
</Tab>

<Tab language="aai" title="AssemblyAI">

<Code src="../../../../snippets/guides/cookbooks/core-transcription/oai_to_aai/python-2.py" />
</Tab>
</Tabs>

Here are helpful things to know about our `transcribe` method:

- The SDK handles polling under the hood
- Transcript is directly accessible via `transcript.text`
- English is the default language and Universal is the default speech model if none is specified
- We have a [cookbook for error handling common errors](/docs/guides/common_errors_and_solutions) when using our API.

## Installation

<Tabs groupId="language">
<Tab language="openai" title="OpenAI">

```python
from openai import OpenAI

api_key = "YOUR_OPENAI_API_KEY"
client = OpenAI(api_key)
```

</Tab>
<Tab language="aai" title="AssemblyAI">

```python
import assemblyai as aai

aai.settings.api_key = "YOUR-API-KEY"
transcriber = aai.Transcriber()
```

</Tab>
</Tabs>

When migrating from OpenAI to AssemblyAI, you'll first need to handle authentication and SDK setup:

Get your API key from your [AssemblyAI dashboard](https://www.assemblyai.com/app/api-keys) \
To follow this guide, install AssemblyAI's Python SDK by typing this code into your terminal: \
 `pip install assemblyai`

Things to know:

- Store your API key securely in an environment variable
- API key authentication works the same across all AssemblyAI SDKs

## Audio File Sources

<Tabs groupId="language">
<Tab language="openai" title="OpenAI">

<Code src="../../../../snippets/guides/cookbooks/core-transcription/oai_to_aai/python-3.py" />
</Tab>
<Tab language="aai" title="AssemblyAI">

<Code src="../../../../snippets/guides/cookbooks/core-transcription/oai_to_aai/python-4.py" />
</Tab>
</Tabs>

Here are helpful things to know when migrating your audio input handling:

- AssemblyAI natively supports transcribing publicly accessible audio URLs (for example, S3 URLs), the Whisper API only natively supports transcribing local files.
- There's no need to specify the audio format to AssemblyAI - it's auto-detected. AssemblyAI accepts almost every audio/video file type: [here is a full list of all our supported file types](/docs/faq/what-audio-and-video-file-types-are-supported-by-your-api)
- The Whisper API only supports file sizes up to 25MB, AssemblyAI supports file sizes up to 5GB.

## Adding Features

<Tabs groupId="language">
<Tab language="openai" title="OpenAI">

<Code src="../../../../snippets/guides/cookbooks/core-transcription/oai_to_aai/python-5.py" />
</Tab>
<Tab language="aai" title="AssemblyAI">

<Code src="../../../../snippets/guides/cookbooks/core-transcription/oai_to_aai/python-6.py" />
</Tab>
</Tabs>

Key differences:

- OpenAI does not offer audio intelligence features for their speech-to-text API
- Use `aai.TranscriptionConfig` to specify any extra features that you wish to use
- With AssemblyAI, timestamp granularity is word-level by default
- The results for Speaker Diarization are stored in `transcript.utterances`. To see the full transcript response object, refer to our [API Reference](https://www.assemblyai.com/docs/api-reference).
- Check our [documentation](https://www.assemblyai.com/docs/audio-intelligence) for our full list of available features and their parameters
- If you want to send a custom prompt to an LLM, you can use [LLM Gateway](/docs/llm-gateway/overview) to apply the model to your transcribed audio files.
