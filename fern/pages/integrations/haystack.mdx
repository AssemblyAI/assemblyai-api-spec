---
title: "Haystack Integration for AssemblyAI"
description: "Transcribe, summarize and diarize audio in a Haystack pipeline with Python using the integration with AssemblyAI."
hide-nav-links: true
---

[Haystack (2.x)](https://github.com/deepset-ai/haystack) is an open-source Python framework for building custom LLM applications. The Haystack Integration for AssemblyAI seamlessly integrates with Haystack to use audio files in LLM pipelines.

On top of audio transcription the AssemblyAITranscriber offers summarization and speaker diarization. This makes it possible to not only convert audio to text but also obtain concise summaries and identify speakers in a conversation.

## Quickstart

Install the [assemblyai-haystack package](https://pypi.org/project/assemblyai-haystack/) using pip. This package installs and uses the AssemblyAI Python SDK and Haystack 2.0. You can find more information about the SDK at the [AssemblyAI Python SDK GitHub repository](https://github.com/AssemblyAI/assemblyai-python-sdk).

```bash
pip install assemblyai-haystack
```

## Usage

Add an `AssemblyAITranscriber` component and initialize it by passing your AssemblyAI API key. Once the pipeline is ready to run, make sure to pass at least the `file_path` argument to the `run` function. The `file_path` can be a `URL` or a local file path. In the `run` function, you can also specify whether you want summarization and speaker diarization results.

<Code src="snippets/integrations/haystack/python-1.py" />
<Note>
  Calling `indexing.run()` blocks until the transcription is finished.
</Note>

The results of the transcription, summarization and speaker diarization are returned in separate document lists:

- `transcription`
- `summarization`
- `speaker_labels`

When `AssemblyAITranscriber` is used in a Haystack pipeline, transcription happens by default. In the metadata of the transcription, you will also get the `ID` of the transcription and the `URL` of your audio file.

A bullet point summary of what is being discussed will be returned if `summarization` is set to `TRUE`. The transcription divided into utterances of speakers will be returned if `speaker_labels` is set to `TRUE`.

The output of the `AssemblyAITranscriber` is a Haystack document. When all features are turned on, the created document looks like this:

<Code src="snippets/integrations/haystack/python-2.py" />
## Additional resources

You can learn more about using Haystack with AssemblyAI in these resources:

- [Announcing the AssemblyAI Integration for Haystack](https://www.assemblyai.com/blog/announcing-the-assemblyai-integration-for-haystack/)
- [AssemblyAI integration for Haystack GitHub repository](https://github.com/AssemblyAI/assemblyai-haystack)
