---
title: "ü¶úÔ∏èüîó LangChain Python Integration with AssemblyAI"
description: "Transcribe audio in LangChain Python using the built-in integration with AssemblyAI."
hide-nav-links: true
---

To apply LLMs to speech, you first need to transcribe the audio to text, which is what the AssemblyAI integration for LangChain helps you with.

<Note>

Looking for the LangChain JavaScript integration?<br />
[Go to the LangChain.JS integration](js).

</Note>

## Quickstart

Install [the AssemblyAI package](https://github.com/langchain-ai/langchain) and [the AssemblyAI Python SDK](https://github.com/AssemblyAI/assemblyai-python-sdk):

```bash
pip install langchain
pip install assemblyai
```

Set your AssemblyAI API key as an environment variable named `ASSEMBLYAI_API_KEY`. You can [get a free AssemblyAI API key from the AssemblyAI dashboard](https://www.assemblyai.com/app/api-keys).

<Code src="../../../snippets/integrations/langchain/python/bash.sh" />
Import the `AssemblyAIAudioTranscriptLoader` from `langchain.document_loaders`.

```python
from langchain.document_loaders
```

1. Pass the local file path or URL as the `file_path` argument of the `AssemblyAIAudioTranscriptLoader`.
2. Call the `load` method to get the transcript as LangChain documents.

<Code src="../../../snippets/integrations/langchain/python/python-1.py" />
The `load` method returns an array of documents, but by default, there's only
one document in the array with the full transcript.

The transcribed text is available in the `page_content` attribute:

```python
docs[0].page_content
# Load time, a new president and new congressional makeup. Same old ...
```

The `metadata` contains the full JSON response with more meta information:

<Code src="../../../snippets/integrations/langchain/python/python-2.py" />
## Transcript formats

You can specify the `transcript_format` argument to load the transcript in different formats.

Depending on the format, `load_data()` returns either one or more documents. These are the different `TranscriptFormat` options:

- `TEXT`: One document with the transcription text
- `SENTENCES`: Multiple documents, splits the transcription by each sentence
- `PARAGRAPHS`: Multiple documents, splits the transcription by each paragraph
- `SUBTITLES_SRT`: One document with the transcript exported in SRT subtitles format
- `SUBTITLES_VTT`: One document with the transcript exported in VTT subtitles format

<Code src="../../../snippets/integrations/langchain/python/python-3.py" />
## Transcription config

You can also specify the `config` argument to use different transcript features and audio intelligence models.
Here's an example of using the `config` argument to enable speaker labels, auto chapters, and entity detection:

<Code src="../../../snippets/integrations/langchain/python/python-4.py" />
<Info>
  For the full list of options, see [Transcript API
  reference](https://assemblyai.com/docs/api-reference/transcripts/submit#request).
</Info>

## Pass the AssemblyAI API key as an argument

Instead of configuring the AssemblyAI API key as the `ASSEMBLYAI_API_KEY` environment variable,
you can also pass it as the `api_key` argument.

```python
loader = AssemblyAIAudioTranscriptLoader(
    file_path="./your_file.mp3", api_key="<YOUR_API_KEY>"
)
```

## Additional resources

You can learn more about using LangChain with AssemblyAI in these resources.

- [LangChain docs for the AssemblyAI document loader](https://python.langchain.com/docs/integrations/document_loaders/assemblyai)
- [How to use audio data in LangChain with Python](https://www.assemblyai.com/blog/load-audio-langchain-python/)
- [Retrieval Augmented Generation on audio data with LangChain and Chroma](https://www.assemblyai.com/blog/retrieval-augmented-generation-audio-langchain/)
- [Build LangChain Audio Apps with Python in 5 Minutes](https://www.youtube.com/watch?v=7w7ysaDz2W4)
- [How to use LangChain for RAG over audio files](https://www.youtube.com/watch?v=l9YJrLg61ac)
- [AssemblyAI Python SDK](https://github.com/AssemblyAI/assemblyai-python-sdk)
