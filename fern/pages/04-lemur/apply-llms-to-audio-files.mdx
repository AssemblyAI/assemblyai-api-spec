---
title: "Apply LLMs to audio files"
subtitle: "Learn how to leverage LLMs for speech using LeMUR."
hide-nav-links: true
description: "Learn how to leverage LLMs for speech using LeMUR."
---

## Overview

A Large Language Model (LLM) is a machine learning model that uses natural language processing (NLP) to generate text. [LeMUR](https://assemblyai.com/docs/api-reference/lemur) is a framework that lets you apply LLMs to audio transcripts, for example to ask questions about a call, or to summarize a meeting.

By the end of this tutorial, you'll be able to use LeMUR to summarize an audio file.

Here's the full sample code for what you'll build in this tutorial:

<Tabs groupId="language">
<Tab language="python-sdk" title="Python SDK" default>

```python
import assemblyai as aai

aai.settings.api_key = "<YOUR_API_KEY>"

transcriber = aai.Transcriber()

# You can use a local filepath:
# audio_file = "./example.mp3"

# Or use a publicly-accessible URL:
audio_file = (
  "https://assembly.ai/sports_injuries.mp3"
)
transcript = transcriber.transcribe(audio_file)

prompt = "Provide a brief summary of the transcript."

result = transcript.lemur.task(
  prompt, final_model=aai.LemurModel.claude3_7_sonnet_20250219
)

print(result.response)
```

</Tab>
<Tab language="python" title="Python">

```python
import requests
import time

base_url = "https://api.assemblyai.com"

headers = {
  "authorization": "<YOUR_API_KEY>"
}

# You can use a local filepath:
# with open("./my-audio.mp3", "rb") as f:
# response = requests.post(base_url + "/v2/upload",
# headers=headers,
# data=f)
# upload_url = response.json()["upload_url"]
# Or use a publicly-accessible URL:

upload_url = "https://assembly.ai/sports_injuries.mp3"

data = {
  "audio_url": upload_url
}

response = requests.post(base_url + "/v2/transcript", headers=headers, json=data)

transcript_id = response.json()["id"]
polling_endpoint = base_url + f"/v2/transcript/{transcript_id}"

while True:
transcript = requests.get(polling_endpoint, headers=headers).json()

  if transcript["status"] == "completed":
    break

  elif transcript["status"] == "error":
    raise RuntimeError(f"Transcription failed: {transcript['error']}")

  else:
    time.sleep(3)

prompt = "Provide a brief summary of the transcript."

lemur_data = {
  "prompt": prompt,
  "transcript_ids": [transcript_id],
  "final_model": "anthropic/claude-3-7-sonnet-20250219",
}

result = requests.post(base_url + "/lemur/v3/generate/task", headers=headers, json=lemur_data)
print(result.json()["response"])
```

</Tab>
<Tab language="typescript-sdk" title="TypeScript SDK">

```ts
import { AssemblyAI } from "assemblyai";

const client = new AssemblyAI({
  apiKey: "<YOUR_API_KEY>",
});

// You can use a local filepath:
// const audioFile = "./example.mp3"

// Or use a publicly-accessible URL:
const audioFile = "https://assembly.ai/sports_injuries.mp3";

const run = async () => {
  const transcript = await client.transcripts.transcribe({ audio: audioFile });

  const prompt = "Provide a brief summary of the transcript.";

  const { response } = await client.lemur.task({
    transcript_ids: [transcript.id],
    prompt,
    final_model: "anthropic/claude-3-7-sonnet-20250219",
  });

  console.log(response);
};

run();
```

</Tab>
<Tab language="typescript" title="TypeScript">

```typescript
import axios from "axios";
import fs from "fs-extra";

const base_url = "https://api.assemblyai.com";

const headers = {
  authorization: "<YOUR_API_KEY>",
};

const path = "./my-audio.mp3";
const audioData = await fs.readFile(path);
const uploadResponse = await axios.post(`${base_url}/v2/upload`, audioData, {
  headers,
});

const uploadUrl = uploadResponse.data.upload_url;

const data = {
  audio_url: uploadUrl, // You can also use a URL of an audio or video file on the web
};

const response = await axios.post(base_url + "/v2/transcript", data, {
  headers,
});

const transcript_id = response.data.id;
const polling_endpoint = base_url + `/v2/transcript/${transcript_id}`;

while (true) {
  const transcript = (await axios.get(polling_endpoint, { headers })).data;

  if (transcript.status === "completed") {
    break;
  } else if (transcript.status === "error") {
    throw new Error(`Transcription failed: ${transcript.error}`);
  } else {
    await new Promise((resolve) => setTimeout(resolve, 3000));
  }
}

const prompt = "Provide a brief summary of the transcript.";

const lemur_data = {
  prompt: prompt,
  transcript_ids: [transcript_id],
  final_model: "anthropic/claude-3-7-sonnet-20250219",
};

const result = await axios.post(
  base_url + "/lemur/v3/generate/task",
  lemur_data,
  { headers }
);
console.log(result.data.response);
```

</Tab>
<Tab language="csharp" title="C#">

```csharp
using System;
using System.IO;
using System.Net.Http;
using System.Net.Http.Headers;
using System.Net.Http.Json;
using System.Text;
using System.Text.Json;
using System.Threading.Tasks;

public class Transcript
{
 public string Id { get; set; }
 public string Status { get; set; }
 public string Text { get; set; }

 [JsonPropertyName("language_code")]
 public string LanguageCode { get; set; }

 public string Error { get; set; }
}

public class LemurResponse
{
[JsonPropertyName("request_id")]
public string RequestId { get; set; }

public string Response { get; set; }

public Usage Usage { get; set; }
}

public class Usage
{
[JsonPropertyName("input_tokens")]
public int InputTokens { get; set; }

[JsonPropertyName("output_tokens")]
public int OutputTokens { get; set; }
}

private static async Task<string> UploadFileAsync(string filePath, HttpClient httpClient)
{
  using (var fileStream = File.OpenRead(filePath))
  using (var fileContent = new StreamContent(fileStream))
  {
      fileContent.Headers.ContentType = new MediaTypeHeaderValue("application/octet-stream");

      using (var response = await httpClient.PostAsync("https://api.assemblyai.com/v2/upload", fileContent))
      {
          response.EnsureSuccessStatusCode();
          var jsonDoc = await response.Content.ReadFromJsonAsync<JsonDocument>();
          return jsonDoc.RootElement.GetProperty("upload_url").GetString();
      }
  }
}


private static async Task<Transcript> CreateTranscriptAsync(string audioUrl, HttpClient httpClient)
{
 var data = new { audio_url = audioUrl };
 var content = new StringContent(JsonSerializer.Serialize(data), Encoding.UTF8, "application/json");

 using (var response = await httpClient.PostAsync("https://api.assemblyai.com/v2/transcript", content))
 {
     response.EnsureSuccessStatusCode();
     return await response.Content.ReadFromJsonAsync<Transcript>();
 }
}

private static async Task<Transcript> WaitForTranscriptToProcess(Transcript transcript, HttpClient httpClient)
{
 var pollingEndpoint = $"https://api.assemblyai.com/v2/transcript/{transcript.Id}";

 while (true)
 {
     var pollingResponse = await httpClient.GetAsync(pollingEndpoint);
     transcript = await pollingResponse.Content.ReadFromJsonAsync<Transcript>();
     switch (transcript.Status)
     {
         case "processing":
         case "queued":
             await Task.Delay(TimeSpan.FromSeconds(3));
             break;
         case "completed":
             return transcript;
         case "error":
             throw new Exception($"Transcription failed: {transcript.Error}");
         default:
             throw new Exception("This code shouldn't be reachable.");
     }
 }
}

private static async Task<LemurResponse> GenerateTaskAsync(string prompt, List<string> transcriptIds, HttpClient httpClient)
{
 var data = new
 {
     transcript_ids = transcriptIds,
     prompt,
     final_model = "anthropic/claude-3-7-sonnet-20250219"
 };

 var content = new StringContent(JsonSerializer.Serialize(data), Encoding.UTF8, "application/json");

 using var response = await httpClient.PostAsync("https://api.assemblyai.com/lemur/v3/generate/task", content);
 response.EnsureSuccessStatusCode();
 return await response.Content.ReadFromJsonAsync<LemurResponse>();
}

using (var httpClient = new HttpClient())
{
 httpClient.DefaultRequestHeaders.Authorization =
     new AuthenticationHeaderValue("<YOUR_API_KEY>");

 const string prompt = "Provide a brief summary of the transcript.";

 var uploadUrl = await UploadFileAsync("/my_audio.mp3", httpClient);
 var transcript = await CreateTranscriptAsync(uploadUrl, httpClient); // You can also replace uploadUrl with an audio file URL
 transcript = await WaitForTranscriptToProcess(transcript, httpClient);

 var transcriptIds = new List<string> { transcript.Id };
 var lemurResponse = await GenerateTaskAsync(prompt, transcriptIds, httpClient);

 Console.WriteLine(lemurResponse.Response);
}
```

</Tab>
<Tab language="ruby" title="Ruby">

```ruby
require 'net/http'
require 'json'

base_url = "https://api.assemblyai.com"
headers = {
   "authorization" => "<YOUR_API_KEY>",
   "content-type" => "application/json"
}

path = "/my_audio.mp3"
uri = URI("#{base_url}/v2/upload")
request = Net::HTTP::Post.new(uri, headers)
request.body = File.read(path)

http = Net::HTTP.new(uri.host, uri.port)
http.use_ssl = true
upload_response = http.request(request)
upload_url = JSON.parse(upload_response.body)["upload_url"]

uri = URI("#{base_url}/v2/transcript")
request = Net::HTTP::Post.new(uri, headers)
request.body = { audio_url: upload_url }.to_json # You can also replace upload_url with an audio file URL

response = http.request(request)
transcript_id = JSON.parse(response.body)["id"]
polling_endpoint = "#{base_url}/v2/transcript/#{transcript_id}"

while true
   polling_uri = URI(polling_endpoint)
   polling_request = Net::HTTP::Get.new(polling_uri, headers)
   polling_response = http.request(polling_request)
   transcription_result = JSON.parse(polling_response.body)

   if transcription_result["status"] == "completed"
       break
   elsif transcription_result["status"] == "error"
       raise "Transcription failed: #{transcription_result["error"]}"
   else
       sleep(3)
   end
end

prompt = "Provide a brief summary of the transcript."

lemur_uri = URI("#{base_url}/lemur/v3/generate/task")
lemur_request = Net::HTTP::Post.new(lemur_uri, headers)
lemur_request.body = {
  final_model: "anthropic/claude-3-7-sonnet-20250219",
  prompt: prompt,
  transcript_ids: [transcript_id]
}.to_json

lemur_response = http.request(lemur_request)
lemur_result = JSON.parse(lemur_response.body)
puts lemur_result["response"]
```

</Tab>
<Tab language="php" title="PHP">

```php
<?php
$base_url = "https://api.assemblyai.com";
$headers = array(
    "authorization: <YOUR_API_KEY>",
    "content-type: application/json"
);
$path = "/my_audio.mp3";

$ch = curl_init($base_url . "/v2/upload");
curl_setopt_array($ch, [
    CURLOPT_POST => true,
    CURLOPT_POSTFIELDS => file_get_contents($path),
    CURLOPT_HTTPHEADER => $headers,
    CURLOPT_RETURNTRANSFER => true
]);

$response = curl_exec($ch);
$upload_url = json_decode($response, true)["upload_url"];
curl_close($ch);

$ch = curl_init($base_url . "/v2/transcript");
curl_setopt_array($ch, [
    CURLOPT_POST => true,
    CURLOPT_POSTFIELDS => json_encode(["audio_url" => $upload_url]), // You can also replace upload_url with an audio file URL
    CURLOPT_HTTPHEADER => $headers,
    CURLOPT_RETURNTRANSFER => true
]);

$response = curl_exec($ch);
$transcript_id = json_decode($response, true)['id'];
curl_close($ch);

$polling_endpoint = $base_url . "/v2/transcript/" . $transcript_id;

while (true) {
    $ch = curl_init($polling_endpoint);
    curl_setopt_array($ch, [
        CURLOPT_HTTPHEADER => $headers,
        CURLOPT_RETURNTRANSFER => true
    ]);

    $transcription_result = json_decode(curl_exec($ch), true);
    curl_close($ch);

    if ($transcription_result['status'] === "completed") {
        break;
    } else if ($transcription_result['status'] === "error") {
        throw new Exception("Transcription failed: " . $transcription_result['error']);
    }
    sleep(3);
}

$prompt = 'Provide a brief summary of the transcript.'

$ch = curl_init($base_url . "/lemur/v3/generate/task");
curl_setopt_array($ch, [
    CURLOPT_RETURNTRANSFER => true,
    CURLOPT_POST => true,
    CURLOPT_HTTPHEADER => $headers,
    CURLOPT_POSTFIELDS => json_encode([
        'final_model' => 'anthropic/claude-3-7-sonnet-20250219',
        'prompt' => $prompt,
        'transcript_ids' => [$transcript_id]
    ])
]);

$response = curl_exec($ch);
$result = json_decode($response, true);
echo $result['response'];
curl_close($ch);
```

</Tab>
</Tabs>

If you run the code above, you'll see the following output:

```plain
The transcript describes several common sports injuries - runner's knee,
sprained ankle, meniscus tear, rotator cuff tear, and ACL tear. It provides
definitions, causes, and symptoms for each injury. The transcript seems to be
narrating sports footage and describing injuries as they occur to the athletes.
Overall, it provides an overview of these common sports injuries that can result
from overuse or sudden trauma during athletic activities
```

## Before you begin

To complete this tutorial, you need:

- [Python](https://www.python.org/), [TypeScript](https://www.typescriptlang.org/), [.NET](https://dotnet.microsoft.com/en-us/download), [Ruby](https://www.ruby-lang.org/en/documentation/installation/) or [PHP](https://www.php.net/) installed.
- An <a href="https://www.assemblyai.com/dashboard/signup" target="_blank">AssemblyAI account with a credit card set up</a>.
- Basic understanding of how to [Transcribe an audio file](/docs/getting-started/transcribe-an-audio-file).

## Step 1: Install prerequisites

<Tabs groupId="language">

<Tab language="python-sdk" title="Python SDK" default>

Install the package via pip:

```bash
pip install assemblyai
```

</Tab>

<Tab language="python" title="Python">
Install the package via pip:

```bash
pip install requests
```

</Tab>

<Tab language="typescript-sdk" title="TypeScript SDK">
Install the package via NPM:

```bash
npm install assemblyai
```

</Tab>

<Tab language="typescript" title="TypeScript">
Install the package via NPM:

```bash
npm install axios
```

</Tab>

<Tab language="csharp" title="C#">

No additional packages required - uses standard .NET libraries

</Tab>

<Tab language="ruby" title="Ruby">

No additional gems required - uses standard libraries

</Tab>

<Tab language="php" title="PHP">

No additional packages required - uses built-in cURL functions

</Tab>

</Tabs>

## Step 2: Transcribe an audio file

LeMUR uses one or more transcripts as input to generate text output. In this step, you'll transcribe an audio file that you can later use to create a prompt for.

For more information about transcribing audio, see [Transcribe an audio file](/docs/getting-started/transcribe-an-audio-file).

<Tabs groupId="language">

<Tab language="python-sdk" title="Python SDK" default>

```python
import assemblyai as aai

aai.settings.api_key = "<YOUR_API_KEY>"

transcriber = aai.Transcriber()

# You can use a local filepath:
# audio_file = "./example.mp3"

# Or use a publicly-accessible URL:
audio_file = (
  "https://assembly.ai/sports_injuries.mp3"
)

transcript = transcriber.transcribe(audio_file)
```

</Tab>

<Tab language="python" title="Python" default>

```python
import requests
import time

base_url = "https://api.assemblyai.com"

headers = {"authorization": "<YOUR_API_KEY>"}

# You can use a local filepath:
# with open("./my-audio.mp3", "rb") as f:
#     response = requests.post(base_url + "/v2/upload", headers=headers, data=f)
#     upload_url = response.json()["upload_url"]

# Or use a publicly-accessible URL:
upload_url = "https://assembly.ai/sports_injuries.mp3"

data = {"audio_url": upload_url}

response = requests.post(base_url + "/v2/transcript", headers=headers, json=data)

transcript_id = response.json()["id"]
polling_endpoint = base_url + f"/v2/transcript/{transcript_id}"

while True:
    transcript = requests.get(polling_endpoint, headers=headers).json()

    if transcript["status"] == "completed":
        break

    elif transcript["status"] == "error":
        raise RuntimeError(f"Transcription failed: {transcript['error']}")

    else:
        time.sleep(3)
```

</Tab>

<Tab language="typescript-sdk" title="TypeScript SDK">

```ts
import { AssemblyAI } from "assemblyai";

const client = new AssemblyAI({
  apiKey: "<YOUR_API_KEY>",
});

// You can use a local filepath:
// const audioFile = "./example.mp3"

// Or use a publicly-accessible URL:
const audioUrl = "https://assembly.ai/sports_injuries.mp3";

const run = async () => {
  const transcript = await client.transcripts.transcribe({ audio: audioUrl });
};

run();
```

</Tab>

<Tab language="typescript" title="TypeScript">

```ts
import axios from "axios";
import fs from "fs-extra";

const base_url = "https://api.assemblyai.com";

const headers = {
  authorization: "<YOUR_API_KEY>",
};

const path = "./my-audio.mp3";
const audioData = await fs.readFile(path);
const uploadResponse = await axios.post(`${baseUrl}/v2/upload`, audioData, {
  headers,
});
const uploadUrl = uploadResponse.data.upload_url;

const data = {
  audio_url: uploadUrl, // You can also use a URL of an audio or video file on the web
};

const response = await axios.post(base_url + "/v2/transcript", data, {
  headers,
});

const transcript_id = response.data.id;
const polling_endpoint = base_url + `/v2/transcript/${transcript_id}`;

while (true) {
  const transcript = (await axios.get(polling_endpoint, { headers })).data;

  if (transcript.status === "completed") {
    break;
  } else if (transcript.status === "error") {
    throw new Error(`Transcription failed: ${transcript.error}`);
  } else {
    await new Promise((resolve) => setTimeout(resolve, 3000));
  }
}
```

</Tab>

<Tab language="csharp" title="C#">

```csharp
using System;
using System.IO;
using System.Net.Http;
using System.Net.Http.Headers;
using System.Net.Http.Json;
using System.Text;
using System.Text.Json;
using System.Threading.Tasks;

public class Transcript
{
   public string Id { get; set; }
   public string Status { get; set; }
   public string Text { get; set; }
   [JsonPropertyName("language_code")]
   public string LanguageCode { get; set; }
   public string Error { get; set; }
}

private static async Task<string> UploadFileAsync(string filePath, HttpClient httpClient)
{
    using (var fileStream = File.OpenRead(filePath))
    using (var fileContent = new StreamContent(fileStream))
    {
        fileContent.Headers.ContentType = new MediaTypeHeaderValue("application/octet-stream");
        using (var response = await httpClient.PostAsync("https://api.assemblyai.com/v2/upload", fileContent))
        {
            response.EnsureSuccessStatusCode();
            var jsonDoc = await response.Content.ReadFromJsonAsync<JsonDocument>();
            return jsonDoc.RootElement.GetProperty("upload_url").GetString();
        }
    }
}
private static async Task<Transcript> CreateTranscriptAsync(string audioUrl, HttpClient httpClient)
{
   var data = new { audio_url = audioUrl };
   var content = new StringContent(JsonSerializer.Serialize(data), Encoding.UTF8, "application/json");
   using (var response = await httpClient.PostAsync("https://api.assemblyai.com/v2/transcript", content))
   {
       response.EnsureSuccessStatusCode();
       return await response.Content.ReadFromJsonAsync<Transcript>();
   }
}
private static async Task<Transcript> WaitForTranscriptToProcess(Transcript transcript, HttpClient httpClient)
{
   var pollingEndpoint = $"https://api.assemblyai.com/v2/transcript/{transcript.Id}";
   while (true)
   {
       var pollingResponse = await httpClient.GetAsync(pollingEndpoint);
       transcript = await pollingResponse.Content.ReadFromJsonAsync<Transcript>();
       switch (transcript.Status)
       {
           case "processing":
           case "queued":
               await Task.Delay(TimeSpan.FromSeconds(3));
               break;
           case "completed":
               return transcript;
           case "error":
               throw new Exception($"Transcription failed: {transcript.Error}");
           default:
               throw new Exception("This code shouldn't be reachable.");
       }
   }
}

using (var httpClient = new HttpClient())
{
   httpClient.DefaultRequestHeaders.Authorization =
       new AuthenticationHeaderValue("<YOUR_API_KEY>");

  var uploadUrl = await UploadFileAsync("/my_audio.mp3", httpClient);
   var transcript = await CreateTranscriptAsync(uploadUrl, httpClient); // You can also replace uploadUrl with an audio file URL
   transcript = await WaitForTranscriptToProcess(transcript, httpClient);

}
```

</Tab>
<Tab language="ruby" title="Ruby">

```ruby
require 'net/http'
require 'json'

base_url = "https://api.assemblyai.com"
headers = {
   "authorization" => "<YOUR_API_KEY>",
   "content-type" => "application/json"
}

path = "/my_audio.mp3"
uri = URI("#{base_url}/v2/upload")
request = Net::HTTP::Post.new(uri, headers)
request.body = File.read(path)

http = Net::HTTP.new(uri.host, uri.port)
http.use_ssl = true
upload_response = http.request(request)
upload_url = JSON.parse(upload_response.body)["upload_url"]

uri = URI("#{base_url}/v2/transcript")
request = Net::HTTP::Post.new(uri, headers)
request.body = { audio_url: upload_url }.to_json # You can also replace upload_url with an audio file URL

response = http.request(request)
transcript_id = JSON.parse(response.body)["id"]
polling_endpoint = "#{base_url}/v2/transcript/#{transcript_id}"

while true
   polling_uri = URI(polling_endpoint)
   polling_request = Net::HTTP::Get.new(polling_uri, headers)
   polling_response = http.request(polling_request)
   transcription_result = JSON.parse(polling_response.body)

   if transcription_result["status"] == "completed"
       break
   elsif transcription_result["status"] == "error"
       raise "Transcription failed: #{transcription_result["error"]}"
   else
       sleep(3)
   end
end
```

</Tab>

<Tab language="php" title="PHP">

```php
<?php
$base_url = "https://api.assemblyai.com";
$headers = array(
    "authorization: <YOUR_API_KEY>",
    "content-type: application/json"
);
$path = "/my_audio.mp3";

$ch = curl_init($base_url . "/v2/upload");
curl_setopt_array($ch, [
    CURLOPT_POST => true,
    CURLOPT_POSTFIELDS => file_get_contents($path),
    CURLOPT_HTTPHEADER => $headers,
    CURLOPT_RETURNTRANSFER => true
]);

$response = curl_exec($ch);
$upload_url = json_decode($response, true)["upload_url"];
curl_close($ch);

$ch = curl_init($base_url . "/v2/transcript");
curl_setopt_array($ch, [
    CURLOPT_POST => true,
    CURLOPT_POSTFIELDS => json_encode(["audio_url" => $upload_url]), // You can also replace upload_url with an audio file URL
    CURLOPT_HTTPHEADER => $headers,
    CURLOPT_RETURNTRANSFER => true
]);

$response = curl_exec($ch);
$transcript_id = json_decode($response, true)['id'];
curl_close($ch);

$polling_endpoint = $base_url . "/v2/transcript/" . $transcript_id;

while (true) {
    $ch = curl_init($polling_endpoint);
    curl_setopt_array($ch, [
        CURLOPT_HTTPHEADER => $headers,
        CURLOPT_RETURNTRANSFER => true
    ]);

    $transcription_result = json_decode(curl_exec($ch), true);
    curl_close($ch);

    if ($transcription_result['status'] === "completed") {
        break;
    } else if ($transcription_result['status'] === "error") {
        throw new Exception("Transcription failed: " . $transcription_result['error']);
    }
    sleep(3);
}
```

</Tab>

</Tabs>

<Tip title="Use existing transcript">

If you've already transcribed an audio file you want to use, you can get an existing transcript using its ID. You can find the ID for previously transcribed audio files in the <a href="https://www.assemblyai.com/app/processing-queue" target="_blank">Processing queue</a>.

<Tabs groupId="language">

<Tab language="python-sdk" title="Python SDK" default>

```python
transcript = aai.Transcript.get_by_id("YOUR_TRANSCRIPT_ID")
```

</Tab>

<Tab language="python" title="Python">

```python
transcript = requests.get("https://api.assemblyai.com/v2/transcript/YOUR_TRANSCRIPT_ID", headers=headers).json()
```

</Tab>

<Tab language="typescript-sdk" title="Typescript SDK">

```ts
const transcript = await client.transcripts.get("YOUR_TRANSCRIPT_ID");
```

</Tab>
<Tab language="typescript" title="Typescript">

```ts
const transcript = (
  await axios.get(
    "https://api.assemblyai.com/v2/transcript/YOUR_TRANSCRIPT_ID",
    { headers }
  )
).data;
```

</Tab>

<Tab language="csharp" title="C#">

```csharp
var transcript = await httpClient.GetFromJsonAsync<Transcript>($"https://api.assemblyai.com/v2/transcript/YOUR_TRANSCRIPT_ID");
```

</Tab>
<Tab language="ruby" title="Ruby">

```ruby
transcript = JSON.parse(Net::HTTP.get(URI("#{base_url}/v2/transcript/YOUR_TRANSCRIPT_ID"), headers))
```

</Tab>

<Tab language="php" title="PHP">

```php
$transcription_result = json_decode(file_get_contents($base_url . "/v2/transcript/YOUR_TRANSCRIPT_ID", false, stream_context_create(['http' => ['header' => implode("\r\n", $headers)]])), true);
```

</Tab>

</Tabs>

</Tip>

## Step 3: Prompt LeMUR to generate text output

In this step, you'll create a [Custom task](https://assemblyai.com/docs/api-reference/lemur/task) with LeMUR and use the transcript you created in the previous step as input.

The input to a custom task is called a _prompt_. A prompt is a text string that provides LeMUR with instructions on how to generate the text output.

For more techniques on how to build prompts, see [Improving your prompt](/docs/lemur/improving-your-prompt).

<Steps>

<Step>

<Tabs groupId="language">

<Tab language="python-sdk" title="Python SDK" default>

Write a prompt with instructions on how LeMUR should generate the text output.

```python
prompt = "Provide a brief summary of the transcript."
```

</Tab>

<Tab language="python" title="Python">

Write a prompt with instructions on how LeMUR should generate the text output.

```python
prompt = "Provide a brief summary of the transcript."
```

</Tab>

<Tab language="typescript-sdk" title="TypeScript SDK">

Write a prompt with instructions on how LeMUR should generate the text output.

```ts
const prompt = "Provide a brief summary of the transcript.";
```

</Tab>
<Tab language="typescript" title="TypeScript">

Write a prompt with instructions on how LeMUR should generate the text output.

```ts
const prompt = "Provide a brief summary of the transcript.";
```

</Tab>

<Tab language="csharp" title="C#">

Write a prompt with instructions on how LeMUR should generate the text output.

```csharp
const string prompt = "Provide a brief summary of the transcript.";
```

</Tab>
<Tab language="ruby" title="Ruby">

Write a prompt with instructions on how LeMUR should generate the text output.

```ruby
prompt = 'Provide a brief summary of the transcript.'
```

</Tab>

<Tab language="php" title="PHP">

Write a prompt with instructions on how LeMUR should generate the text output.

```php
$prompt = 'Provide a brief summary of the transcript.'
```

</Tab>
</Tabs>

</Step>
<Step>

<Tabs groupId="language">

<Tab language="python-sdk" title="Python SDK" default>

Create a custom task with LeMUR, using the transcript and prompt as input. The final model defines the LLM to use to process the task. For available models to choose from, see [Change the model type](/docs/lemur/customize-parameters#change-the-model-type).

```python
result = transcript.lemur.task(
    prompt, final_model=aai.LemurModel.claude3_7_sonnet_20250219
)
```

</Tab>

<Tab language="python" title="Python">

Create a custom LeMUR task request, using the transcript and prompt as input. The final model defines the LLM to use to process the task. For available models to choose from, see [Change the model type](/docs/lemur/customize-parameters#change-the-model-type).

```python
lemur_data = {
  "prompt": prompt,
  "transcript_ids": [transcript_id],
  "final_model": "anthropic/claude-3-7-sonnet-20250219",
}

result = requests.post(base_url + "/lemur/v3/generate/task", headers=headers, json=lemur_data)
```

</Tab>

<Tab language="typescript-sdk" title="TypeScript SDK">

Create a custom task with LeMUR, using the transcript and prompt as input. The final model defines the LLM to use to process the task. For available models to choose from, see [Change the model type](/docs/lemur/customize-parameters#change-the-model-type).

```ts
const { response } = await client.lemur.task({
  transcript_ids: [transcript.id],
  prompt,
  final_model: "anthropic/claude-3-7-sonnet-20250219",
});
```

</Tab>
<Tab language="typescript" title="Typescript">

Create a custom LeMUR task request, using the transcript and prompt as input. The final model defines the LLM to use to process the task. For available models to choose from, see [Change the model type](/docs/lemur/customize-parameters#change-the-model-type).

```ts
const lemur_data = {
  prompt: prompt,
  transcript_ids: [transcript_id],
  final_model: "anthropic/claude-3-7-sonnet-20250219",
};

const result = await axios.post(
  base_url + "/lemur/v3/generate/task",
  lemur_data,
  { headers }
);
```

</Tab>

<Tab language="csharp" title="C#">

Create a custom LeMUR task request, using the transcript and prompt as input. The final model defines the LLM to use to process the task. For available models to choose from, see [Change the model type](/docs/lemur/customize-parameters#change-the-model-type).

```csharp
public class LemurResponse
{
  [JsonPropertyName("request_id")]
  public string RequestId { get; set; }

  public string Response { get; set; }

  public Usage Usage { get; set; }
}

public class Usage
{
  [JsonPropertyName("input_tokens")]
  public int InputTokens { get; set; }

  [JsonPropertyName("output_tokens")]
  public int OutputTokens { get; set; }
}

private static async Task<LemurResponse> GenerateTaskAsync(string prompt, List<string> transcriptIds, HttpClient httpClient)
{
   var data = new
   {
       transcript_ids = transcriptIds,
       prompt,
       final_model = "anthropic/claude-3-7-sonnet-20250219"
   };
   var content = new StringContent(JsonSerializer.Serialize(data), Encoding.UTF8, "application/json");

   using var response = await httpClient.PostAsync("https://api.assemblyai.com/lemur/v3/generate/task", content);
   response.EnsureSuccessStatusCode();
   return await response.Content.ReadFromJsonAsync<LemurResponse>();
}

var transcriptIds = new List<string> { transcript.Id };
var lemurResponse = await GenerateTaskAsync(prompt, transcriptIds, httpClient);
```

</Tab>

<Tab language="ruby" title="Ruby">

Create a custom LeMUR task request, using the transcript and prompt as input. The final model defines the LLM to use to process the task. For available models to choose from, see [Change the model type](/docs/lemur/customize-parameters#change-the-model-type).

```ruby
lemur_uri = URI("#{base_url}/lemur/v3/generate/task")
lemur_request = Net::HTTP::Post.new(lemur_uri, headers)
lemur_request.body = {
  final_model: "anthropic/claude-3-7-sonnet-20250219",
  prompt: prompt,
  transcript_ids: [transcript_id]
}.to_json

lemur_response = http.request(lemur_request)
lemur_result = JSON.parse(lemur_response.body)
```

</Tab>

<Tab language="php" title="PHP">

Create a custom LeMUR task request, using the transcript and prompt as input. The final model defines the LLM to use to process the task. For available models to choose from, see [Change the model type](/docs/lemur/customize-parameters#change-the-model-type).

```php
$ch = curl_init($base_url . "/lemur/v3/generate/task");
curl_setopt_array($ch, [
    CURLOPT_RETURNTRANSFER => true,
    CURLOPT_POST => true,
    CURLOPT_HTTPHEADER => $headers,
    CURLOPT_POSTFIELDS => json_encode([
        'final_model' => 'anthropic/claude-3-7-sonnet-20250219',
        'prompt' => $prompt,
        'transcript_ids' => [$transcript_id]
    ])
]);

$response = curl_exec($ch);
$result = json_decode($response, true);
```

</Tab>

</Tabs>
</Step>

<Step>

Print the result.

<Tabs groupId="language">

<Tab language="python-sdk" title="Python SDK" default>

```python
print(result.response)
```

</Tab>

<Tab language="python" title="Python">

```python
print(result.json()["response"])
```

</Tab>
<Tab language="typescript-sdk" title="TypeScript SDK">

```ts
console.log(response);
```

</Tab>
<Tab language="typescript" title="TypeScript">

```ts
console.log(result.data.response);
```

</Tab>

<Tab language="csharp" title="C#">

```csharp
Console.WriteLine(lemurResponse.Response);
```

</Tab>

<Tab language="ruby" title="Ruby">

```ruby
puts lemur_result["response"]
```

</Tab>

<Tab language="php" title="PHP">

```php
echo $result['response'];
curl_close($ch);
```

</Tab>

</Tabs>

The output will look something like this:

```
 The transcript describes several common sports injuries - runner's knee,
 sprained ankle, meniscus tear, rotator cuff tear, and ACL tear. It provides
 definitions, causes, and symptoms for each injury. The transcript seems to be
 narrating sports footage and describing injuries as they occur to the athletes.
 Overall, it provides an overview of these common sports injuries that can
 result from overuse or sudden trauma during athletic activities
```

</Step>

</Steps>

## Next steps

In this tutorial, you've learned how to generate LLM output based on your audio transcripts. The type of output depends on your prompt, so try exploring different prompts to see how they affect the output. Here's a few more prompts to try.

- "Provide an analysis of the transcript and offer areas to improve with exact quotes."
- "What's the main take-away from the transcript?"
- "Generate a set of action items from this transcript."

To learn more about how to apply LLMs to your transcripts, see the following resources:

- [Ask questions about your audio data using LeMUR](/docs/lemur/ask-questions)
- [Writing good prompts](/docs/lemur/improving-your-prompt)

## Need some help?

If you get stuck, or have any other questions, we'd love to help you out. Contact our support team at support@assemblyai.com or create a [support ticket](https://www.assemblyai.com/contact/support).
