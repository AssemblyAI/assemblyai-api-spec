---
title: "Apply LLM Gateway to Audio Transcripts"
subtitle: "Learn how to analyze audio transcripts using LLM Gateway."
hide-nav-links: true
description: "Learn how to analyze audio transcripts using LLM Gateway."
---

## Overview

A Large Language Model (LLM) is a machine learning model that uses natural language processing (NLP) to generate text. [LLM Gateway](https://assemblyai.com/docs/llm-gateway/overview) is a unified API that provides access to 15+ models from Claude, GPT, and Gemini through a single interface. You can use LLM Gateway to analyze audio transcripts, for example to ask questions about a call, or to summarize a meeting.

By the end of this tutorial, you'll be able to use LLM Gateway to summarize an audio file.

Here's the full sample code for what you'll build in this tutorial:

<Tabs groupId="language">
<Tab language="python" title="Python" default>

```python
import requests
import time

# Step 1: Transcribe the audio
base_url = "https://api.assemblyai.com"

headers = {
  "authorization": "<YOUR_API_KEY>"
}

# You can use a local filepath:
# with open("./my-audio.mp3", "rb") as f:
# response = requests.post(base_url + "/v2/upload",
# headers=headers,
# data=f)
# upload_url = response.json()["upload_url"]
# Or use a publicly-accessible URL:

upload_url = "https://assembly.ai/sports_injuries.mp3"

data = {
  "audio_url": upload_url
}

response = requests.post(base_url + "/v2/transcript", headers=headers, json=data)

transcript_id = response.json()["id"]
polling_endpoint = base_url + f"/v2/transcript/{transcript_id}"

while True:
  transcript = requests.get(polling_endpoint, headers=headers).json()

  if transcript["status"] == "completed":
    break

  elif transcript["status"] == "error":
    raise RuntimeError(f"Transcription failed: {transcript['error']}")

  else:
    time.sleep(3)

# Step 2: Send transcript to LLM Gateway
prompt = "Provide a brief summary of the transcript."

llm_gateway_data = {
  "model": "claude-sonnet-4-5-20250929",
  "messages": [
    {"role": "user", "content": f"{prompt}\n\nTranscript: {transcript['text']}"}
  ],
  "max_tokens": 1000
}

response = requests.post(
  "https://llm-gateway.assemblyai.com/v1/chat/completions",
  headers=headers,
  json=llm_gateway_data
)
print(response.json()["choices"][0]["message"]["content"])
```

</Tab>
<Tab language="javascript" title="JavaScript">

```javascript
import axios from "axios";
import fs from "fs-extra";

// Step 1: Transcribe the audio
const base_url = "https://api.assemblyai.com";

const headers = {
  authorization: "<YOUR_API_KEY>",
};

const path = "./my-audio.mp3";
const audioData = await fs.readFile(path);
const uploadResponse = await axios.post(`${base_url}/v2/upload`, audioData, {
  headers,
});

const uploadUrl = uploadResponse.data.upload_url;

const data = {
  audio_url: uploadUrl, // You can also use a URL of an audio or video file on the web
};

const response = await axios.post(base_url + "/v2/transcript", data, {
  headers,
});

const transcript_id = response.data.id;
const polling_endpoint = base_url + `/v2/transcript/${transcript_id}`;

let transcript;
while (true) {
  transcript = (await axios.get(polling_endpoint, { headers })).data;

  if (transcript.status === "completed") {
    break;
  } else if (transcript.status === "error") {
    throw new Error(`Transcription failed: ${transcript.error}`);
  } else {
    await new Promise((resolve) => setTimeout(resolve, 3000));
  }
}

// Step 2: Send transcript to LLM Gateway
const prompt = "Provide a brief summary of the transcript.";

const llm_gateway_data = {
  model: "claude-sonnet-4-5-20250929",
  messages: [
    { role: "user", content: `${prompt}\n\nTranscript: ${transcript.text}` },
  ],
  max_tokens: 1000,
};

const result = await axios.post(
  "https://llm-gateway.assemblyai.com/v1/chat/completions",
  llm_gateway_data,
  { headers }
);
console.log(result.data.choices[0].message.content);
```

</Tab>
<Tab language="csharp" title="C#">

```csharp
using System;
using System.IO;
using System.Net.Http;
using System.Net.Http.Headers;
using System.Net.Http.Json;
using System.Text;
using System.Text.Json;
using System.Threading.Tasks;
using System.Collections.Generic;

public class Transcript
{
 public string Id { get; set; }
 public string Status { get; set; }
 public string Text { get; set; }

 [JsonPropertyName("language_code")]
 public string LanguageCode { get; set; }

 public string Error { get; set; }
}

public class LlmGatewayResponse
{
 public List<Choice> Choices { get; set; }
}

public class Choice
{
 public Message Message { get; set; }
}

public class Message
{
 public string Content { get; set; }
}

private static async Task<string> UploadFileAsync(string filePath, HttpClient httpClient)
{
  using (var fileStream = File.OpenRead(filePath))
  using (var fileContent = new StreamContent(fileStream))
  {
      fileContent.Headers.ContentType = new MediaTypeHeaderValue("application/octet-stream");

      using (var response = await httpClient.PostAsync("https://api.assemblyai.com/v2/upload", fileContent))
      {
          response.EnsureSuccessStatusCode();
          var jsonDoc = await response.Content.ReadFromJsonAsync<JsonDocument>();
          return jsonDoc.RootElement.GetProperty("upload_url").GetString();
      }
  }
}

private static async Task<Transcript> CreateTranscriptAsync(string audioUrl, HttpClient httpClient)
{
 var data = new { audio_url = audioUrl };
 var content = new StringContent(JsonSerializer.Serialize(data), Encoding.UTF8, "application/json");

 using (var response = await httpClient.PostAsync("https://api.assemblyai.com/v2/transcript", content))
 {
     response.EnsureSuccessStatusCode();
     return await response.Content.ReadFromJsonAsync<Transcript>();
 }
}

private static async Task<Transcript> WaitForTranscriptToProcess(Transcript transcript, HttpClient httpClient)
{
 var pollingEndpoint = $"https://api.assemblyai.com/v2/transcript/{transcript.Id}";

 while (true)
 {
     var pollingResponse = await httpClient.GetAsync(pollingEndpoint);
     transcript = await pollingResponse.Content.ReadFromJsonAsync<Transcript>();
     switch (transcript.Status)
     {
         case "processing":
         case "queued":
             await Task.Delay(TimeSpan.FromSeconds(3));
             break;
         case "completed":
             return transcript;
         case "error":
             throw new Exception($"Transcription failed: {transcript.Error}");
         default:
             throw new Exception("This code shouldn't be reachable.");
     }
 }
}

private static async Task<LlmGatewayResponse> SendToLlmGatewayAsync(string prompt, string transcriptText, HttpClient httpClient)
{
 var data = new
 {
     model = "claude-sonnet-4-5-20250929",
     messages = new[]
     {
         new { role = "user", content = $"{prompt}\n\nTranscript: {transcriptText}" }
     },
     max_tokens = 1000
 };

 var content = new StringContent(JsonSerializer.Serialize(data), Encoding.UTF8, "application/json");

 using var response = await httpClient.PostAsync("https://llm-gateway.assemblyai.com/v1/chat/completions", content);
 response.EnsureSuccessStatusCode();
 return await response.Content.ReadFromJsonAsync<LlmGatewayResponse>();
}

using (var httpClient = new HttpClient())
{
 httpClient.DefaultRequestHeaders.Authorization =
     new AuthenticationHeaderValue("<YOUR_API_KEY>");

 const string prompt = "Provide a brief summary of the transcript.";

 // Step 1: Transcribe the audio
 var uploadUrl = await UploadFileAsync("/my_audio.mp3", httpClient);
 var transcript = await CreateTranscriptAsync(uploadUrl, httpClient); // You can also replace uploadUrl with an audio file URL
 transcript = await WaitForTranscriptToProcess(transcript, httpClient);

 // Step 2: Send transcript to LLM Gateway
 var llmGatewayResponse = await SendToLlmGatewayAsync(prompt, transcript.Text, httpClient);

 Console.WriteLine(llmGatewayResponse.Choices[0].Message.Content);
}
```

</Tab>
<Tab language="ruby" title="Ruby">

```ruby
require 'net/http'
require 'json'

# Step 1: Transcribe the audio
base_url = "https://api.assemblyai.com"
headers = {
   "authorization" => "<YOUR_API_KEY>",
   "content-type" => "application/json"
}

path = "/my_audio.mp3"
uri = URI("#{base_url}/v2/upload")
request = Net::HTTP::Post.new(uri, headers)
request.body = File.read(path)

http = Net::HTTP.new(uri.host, uri.port)
http.use_ssl = true
upload_response = http.request(request)
upload_url = JSON.parse(upload_response.body)["upload_url"]

uri = URI("#{base_url}/v2/transcript")
request = Net::HTTP::Post.new(uri, headers)
request.body = { audio_url: upload_url }.to_json # You can also replace upload_url with an audio file URL

response = http.request(request)
transcript_id = JSON.parse(response.body)["id"]
polling_endpoint = "#{base_url}/v2/transcript/#{transcript_id}"

while true
   polling_uri = URI(polling_endpoint)
   polling_request = Net::HTTP::Get.new(polling_uri, headers)
   polling_response = http.request(polling_request)
   transcription_result = JSON.parse(polling_response.body)

   if transcription_result["status"] == "completed"
       break
   elsif transcription_result["status"] == "error"
       raise "Transcription failed: #{transcription_result["error"]}"
   else
       sleep(3)
   end
end

# Step 2: Send transcript to LLM Gateway
prompt = "Provide a brief summary of the transcript."

llm_gateway_uri = URI("https://llm-gateway.assemblyai.com/v1/chat/completions")
llm_gateway_request = Net::HTTP::Post.new(llm_gateway_uri, headers)
llm_gateway_request.body = {
  model: "claude-sonnet-4-5-20250929",
  messages: [
    { role: "user", content: "#{prompt}\n\nTranscript: #{transcription_result['text']}" }
  ],
  max_tokens: 1000
}.to_json

llm_gateway_http = Net::HTTP.new(llm_gateway_uri.host, llm_gateway_uri.port)
llm_gateway_http.use_ssl = true
llm_gateway_response = llm_gateway_http.request(llm_gateway_request)
llm_gateway_result = JSON.parse(llm_gateway_response.body)
puts llm_gateway_result["choices"][0]["message"]["content"]
```

</Tab>
<Tab language="php" title="PHP">

```php
<?php
// Step 1: Transcribe the audio
$base_url = "https://api.assemblyai.com";
$headers = array(
    "authorization: <YOUR_API_KEY>",
    "content-type: application/json"
);
$path = "/my_audio.mp3";

$ch = curl_init($base_url . "/v2/upload");
curl_setopt_array($ch, [
    CURLOPT_POST => true,
    CURLOPT_POSTFIELDS => file_get_contents($path),
    CURLOPT_HTTPHEADER => $headers,
    CURLOPT_RETURNTRANSFER => true
]);

$response = curl_exec($ch);
$upload_url = json_decode($response, true)["upload_url"];
curl_close($ch);

$ch = curl_init($base_url . "/v2/transcript");
curl_setopt_array($ch, [
    CURLOPT_POST => true,
    CURLOPT_POSTFIELDS => json_encode(["audio_url" => $upload_url]), // You can also replace upload_url with an audio file URL
    CURLOPT_HTTPHEADER => $headers,
    CURLOPT_RETURNTRANSFER => true
]);

$response = curl_exec($ch);
$transcript_id = json_decode($response, true)['id'];
curl_close($ch);

$polling_endpoint = $base_url . "/v2/transcript/" . $transcript_id;

while (true) {
    $ch = curl_init($polling_endpoint);
    curl_setopt_array($ch, [
        CURLOPT_HTTPHEADER => $headers,
        CURLOPT_RETURNTRANSFER => true
    ]);

    $transcription_result = json_decode(curl_exec($ch), true);
    curl_close($ch);

    if ($transcription_result['status'] === "completed") {
        break;
    } else if ($transcription_result['status'] === "error") {
        throw new Exception("Transcription failed: " . $transcription_result['error']);
    }
    sleep(3);
}

// Step 2: Send transcript to LLM Gateway
$prompt = 'Provide a brief summary of the transcript.';

$ch = curl_init("https://llm-gateway.assemblyai.com/v1/chat/completions");
curl_setopt_array($ch, [
    CURLOPT_RETURNTRANSFER => true,
    CURLOPT_POST => true,
    CURLOPT_HTTPHEADER => $headers,
    CURLOPT_POSTFIELDS => json_encode([
        'model' => 'claude-sonnet-4-5-20250929',
        'messages' => [
            ['role' => 'user', 'content' => $prompt . "\n\nTranscript: " . $transcription_result['text']]
        ],
        'max_tokens' => 1000
    ])
]);

$response = curl_exec($ch);
$result = json_decode($response, true);
echo $result['choices'][0]['message']['content'];
curl_close($ch);
```

</Tab>
</Tabs>

If you run the code above, you'll see the following output:

```plain
The transcript describes several common sports injuries - runner's knee,
sprained ankle, meniscus tear, rotator cuff tear, and ACL tear. It provides
definitions, causes, and symptoms for each injury. The transcript seems to be
narrating sports footage and describing injuries as they occur to the athletes.
Overall, it provides an overview of these common sports injuries that can result
from overuse or sudden trauma during athletic activities
```

## Before you begin

To complete this tutorial, you need:

- [Python](https://www.python.org/), [Node](https://nodejs.org/en), [.NET](https://dotnet.microsoft.com/en-us/download), [Ruby](https://www.ruby-lang.org/en/documentation/installation/) or [PHP](https://www.php.net/) installed.
- An <a href="https://www.assemblyai.com/dashboard/signup" target="_blank">AssemblyAI account with a credit card set up</a>.
- Basic understanding of how to [Transcribe an audio file](/docs/getting-started/transcribe-an-audio-file).

## Step 1: Install prerequisites

<Tabs groupId="language">

<Tab language="python" title="Python" default>
Install the package via pip:

```bash
pip install requests
```

</Tab>

<Tab language="javascript" title="JavaScript">
Install the package via NPM:

```bash
npm install axios
```

</Tab>

<Tab language="csharp" title="C#">

No additional packages required - uses standard .NET libraries

</Tab>

<Tab language="ruby" title="Ruby">

No additional gems required - uses standard libraries

</Tab>

<Tab language="php" title="PHP">

No additional packages required - uses built-in cURL functions

</Tab>

</Tabs>

## Step 2: Transcribe an audio file

LLM Gateway uses transcript text as input to generate text output. In this step, you'll transcribe an audio file that you can later use with LLM Gateway.

For more information about transcribing audio, see [Transcribe an audio file](/docs/getting-started/transcribe-an-audio-file).

<Tabs groupId="language">

<Tab language="python" title="Python" default>

```python
import requests
import time

base_url = "https://api.assemblyai.com"

headers = {"authorization": "<YOUR_API_KEY>"}

# You can use a local filepath:
# with open("./my-audio.mp3", "rb") as f:
#     response = requests.post(base_url + "/v2/upload", headers=headers, data=f)
#     upload_url = response.json()["upload_url"]

# Or use a publicly-accessible URL:
upload_url = "https://assembly.ai/sports_injuries.mp3"

data = {"audio_url": upload_url}

response = requests.post(base_url + "/v2/transcript", headers=headers, json=data)

transcript_id = response.json()["id"]
polling_endpoint = base_url + f"/v2/transcript/{transcript_id}"

while True:
    transcript = requests.get(polling_endpoint, headers=headers).json()

    if transcript["status"] == "completed":
        break

    elif transcript["status"] == "error":
        raise RuntimeError(f"Transcription failed: {transcript['error']}")

    else:
        time.sleep(3)
```

</Tab>

<Tab language="javascript" title="JavaScript">

```javascript
import axios from "axios";
import fs from "fs-extra";

const base_url = "https://api.assemblyai.com";

const headers = {
  authorization: "<YOUR_API_KEY>",
};

const path = "./my-audio.mp3";
const audioData = await fs.readFile(path);
const uploadResponse = await axios.post(`${baseUrl}/v2/upload`, audioData, {
  headers,
});
const uploadUrl = uploadResponse.data.upload_url;

const data = {
  audio_url: uploadUrl, // You can also use a URL of an audio or video file on the web
};

const response = await axios.post(base_url + "/v2/transcript", data, {
  headers,
});

const transcript_id = response.data.id;
const polling_endpoint = base_url + `/v2/transcript/${transcript_id}`;

while (true) {
  const transcript = (await axios.get(polling_endpoint, { headers })).data;

  if (transcript.status === "completed") {
    break;
  } else if (transcript.status === "error") {
    throw new Error(`Transcription failed: ${transcript.error}`);
  } else {
    await new Promise((resolve) => setTimeout(resolve, 3000));
  }
}
```

</Tab>

<Tab language="csharp" title="C#">

```csharp
using System;
using System.IO;
using System.Net.Http;
using System.Net.Http.Headers;
using System.Net.Http.Json;
using System.Text;
using System.Text.Json;
using System.Threading.Tasks;

public class Transcript
{
   public string Id { get; set; }
   public string Status { get; set; }
   public string Text { get; set; }
   [JsonPropertyName("language_code")]
   public string LanguageCode { get; set; }
   public string Error { get; set; }
}

private static async Task<string> UploadFileAsync(string filePath, HttpClient httpClient)
{
    using (var fileStream = File.OpenRead(filePath))
    using (var fileContent = new StreamContent(fileStream))
    {
        fileContent.Headers.ContentType = new MediaTypeHeaderValue("application/octet-stream");
        using (var response = await httpClient.PostAsync("https://api.assemblyai.com/v2/upload", fileContent))
        {
            response.EnsureSuccessStatusCode();
            var jsonDoc = await response.Content.ReadFromJsonAsync<JsonDocument>();
            return jsonDoc.RootElement.GetProperty("upload_url").GetString();
        }
    }
}
private static async Task<Transcript> CreateTranscriptAsync(string audioUrl, HttpClient httpClient)
{
   var data = new { audio_url = audioUrl };
   var content = new StringContent(JsonSerializer.Serialize(data), Encoding.UTF8, "application/json");
   using (var response = await httpClient.PostAsync("https://api.assemblyai.com/v2/transcript", content))
   {
       response.EnsureSuccessStatusCode();
       return await response.Content.ReadFromJsonAsync<Transcript>();
   }
}
private static async Task<Transcript> WaitForTranscriptToProcess(Transcript transcript, HttpClient httpClient)
{
   var pollingEndpoint = $"https://api.assemblyai.com/v2/transcript/{transcript.Id}";
   while (true)
   {
       var pollingResponse = await httpClient.GetAsync(pollingEndpoint);
       transcript = await pollingResponse.Content.ReadFromJsonAsync<Transcript>();
       switch (transcript.Status)
       {
           case "processing":
           case "queued":
               await Task.Delay(TimeSpan.FromSeconds(3));
               break;
           case "completed":
               return transcript;
           case "error":
               throw new Exception($"Transcription failed: {transcript.Error}");
           default:
               throw new Exception("This code shouldn't be reachable.");
       }
   }
}

using (var httpClient = new HttpClient())
{
   httpClient.DefaultRequestHeaders.Authorization =
       new AuthenticationHeaderValue("<YOUR_API_KEY>");

  var uploadUrl = await UploadFileAsync("/my_audio.mp3", httpClient);
   var transcript = await CreateTranscriptAsync(uploadUrl, httpClient); // You can also replace uploadUrl with an audio file URL
   transcript = await WaitForTranscriptToProcess(transcript, httpClient);

}
```

</Tab>
<Tab language="ruby" title="Ruby">

```ruby
require 'net/http'
require 'json'

base_url = "https://api.assemblyai.com"
headers = {
   "authorization" => "<YOUR_API_KEY>",
   "content-type" => "application/json"
}

path = "/my_audio.mp3"
uri = URI("#{base_url}/v2/upload")
request = Net::HTTP::Post.new(uri, headers)
request.body = File.read(path)

http = Net::HTTP.new(uri.host, uri.port)
http.use_ssl = true
upload_response = http.request(request)
upload_url = JSON.parse(upload_response.body)["upload_url"]

uri = URI("#{base_url}/v2/transcript")
request = Net::HTTP::Post.new(uri, headers)
request.body = { audio_url: upload_url }.to_json # You can also replace upload_url with an audio file URL

response = http.request(request)
transcript_id = JSON.parse(response.body)["id"]
polling_endpoint = "#{base_url}/v2/transcript/#{transcript_id}"

while true
   polling_uri = URI(polling_endpoint)
   polling_request = Net::HTTP::Get.new(polling_uri, headers)
   polling_response = http.request(polling_request)
   transcription_result = JSON.parse(polling_response.body)

   if transcription_result["status"] == "completed"
       break
   elsif transcription_result["status"] == "error"
       raise "Transcription failed: #{transcription_result["error"]}"
   else
       sleep(3)
   end
end
```

</Tab>

<Tab language="php" title="PHP">

```php
<?php
$base_url = "https://api.assemblyai.com";
$headers = array(
    "authorization: <YOUR_API_KEY>",
    "content-type: application/json"
);
$path = "/my_audio.mp3";

$ch = curl_init($base_url . "/v2/upload");
curl_setopt_array($ch, [
    CURLOPT_POST => true,
    CURLOPT_POSTFIELDS => file_get_contents($path),
    CURLOPT_HTTPHEADER => $headers,
    CURLOPT_RETURNTRANSFER => true
]);

$response = curl_exec($ch);
$upload_url = json_decode($response, true)["upload_url"];
curl_close($ch);

$ch = curl_init($base_url . "/v2/transcript");
curl_setopt_array($ch, [
    CURLOPT_POST => true,
    CURLOPT_POSTFIELDS => json_encode(["audio_url" => $upload_url]), // You can also replace upload_url with an audio file URL
    CURLOPT_HTTPHEADER => $headers,
    CURLOPT_RETURNTRANSFER => true
]);

$response = curl_exec($ch);
$transcript_id = json_decode($response, true)['id'];
curl_close($ch);

$polling_endpoint = $base_url . "/v2/transcript/" . $transcript_id;

while (true) {
    $ch = curl_init($polling_endpoint);
    curl_setopt_array($ch, [
        CURLOPT_HTTPHEADER => $headers,
        CURLOPT_RETURNTRANSFER => true
    ]);

    $transcription_result = json_decode(curl_exec($ch), true);
    curl_close($ch);

    if ($transcription_result['status'] === "completed") {
        break;
    } else if ($transcription_result['status'] === "error") {
        throw new Exception("Transcription failed: " . $transcription_result['error']);
    }
    sleep(3);
}
```

</Tab>

</Tabs>

<Tip title="Use existing transcript">

If you've already transcribed an audio file you want to use, you can get an existing transcript using its ID. You can find the ID for previously transcribed audio files in the <a href="https://www.assemblyai.com/app/processing-queue" target="_blank">Processing queue</a>.

<Tabs groupId="language">

<Tab language="python" title="Python" default>

```python
transcript = requests.get("https://api.assemblyai.com/v2/transcript/YOUR_TRANSCRIPT_ID", headers=headers).json()
```

</Tab>

<Tab language="javascript" title="JavaScript">

```javascript
const transcript = (
  await axios.get(
    "https://api.assemblyai.com/v2/transcript/YOUR_TRANSCRIPT_ID",
    { headers }
  )
).data;
```

</Tab>

<Tab language="csharp" title="C#">

```csharp
var transcript = await httpClient.GetFromJsonAsync<Transcript>($"https://api.assemblyai.com/v2/transcript/YOUR_TRANSCRIPT_ID");
```

</Tab>
<Tab language="ruby" title="Ruby">

```ruby
transcript = JSON.parse(Net::HTTP.get(URI("#{base_url}/v2/transcript/YOUR_TRANSCRIPT_ID"), headers))
```

</Tab>

<Tab language="php" title="PHP">

```php
$transcription_result = json_decode(file_get_contents($base_url . "/v2/transcript/YOUR_TRANSCRIPT_ID", false, stream_context_create(['http' => ['header' => implode("\r\n", $headers)]])), true);
```

</Tab>

</Tabs>

</Tip>

## Step 3: Send transcript to LLM Gateway

In this step, you'll send the transcript text to LLM Gateway along with a prompt to generate text output.

The prompt is a text string that provides the LLM with instructions on how to generate the text output. You'll combine the prompt with the transcript text and send it to LLM Gateway using the chat completions API.

<Steps>

<Step>

<Tabs groupId="language">

<Tab language="python" title="Python" default>

Write a prompt with instructions on how the LLM should generate the text output.

```python
prompt = "Provide a brief summary of the transcript."
```

</Tab>

<Tab language="javascript" title="JavaScript">

Write a prompt with instructions on how the LLM should generate the text output.

```javascript
const prompt = "Provide a brief summary of the transcript.";
```

</Tab>

<Tab language="csharp" title="C#">

Write a prompt with instructions on how the LLM should generate the text output.

```csharp
const string prompt = "Provide a brief summary of the transcript.";
```

</Tab>
<Tab language="ruby" title="Ruby">

Write a prompt with instructions on how the LLM should generate the text output.

```ruby
prompt = 'Provide a brief summary of the transcript.'
```

</Tab>

<Tab language="php" title="PHP">

Write a prompt with instructions on how the LLM should generate the text output.

```php
$prompt = 'Provide a brief summary of the transcript.'
```

</Tab>
</Tabs>

</Step>
<Step>

<Tabs groupId="language">

<Tab language="python" title="Python" default>

Send the transcript text and prompt to LLM Gateway. The model parameter defines which LLM to use. For available models, see [LLM Gateway Overview](/docs/llm-gateway/overview).

```python
llm_gateway_data = {
  "model": "claude-sonnet-4-5-20250929",
  "messages": [
    {"role": "user", "content": f"{prompt}\n\nTranscript: {transcript['text']}"}
  ],
  "max_tokens": 1000
}

result = requests.post(
  "https://llm-gateway.assemblyai.com/v1/chat/completions",
  headers=headers,
  json=llm_gateway_data
)
```

</Tab>

<Tab language="javascript" title="JavaScript">

Send the transcript text and prompt to LLM Gateway. The model parameter defines which LLM to use. For available models, see [LLM Gateway Overview](/docs/llm-gateway/overview).

```javascript
const llm_gateway_data = {
  model: "claude-sonnet-4-5-20250929",
  messages: [
    { role: "user", content: `${prompt}\n\nTranscript: ${transcript.text}` },
  ],
  max_tokens: 1000,
};

const result = await axios.post(
  "https://llm-gateway.assemblyai.com/v1/chat/completions",
  llm_gateway_data,
  { headers }
);
```

</Tab>

<Tab language="csharp" title="C#">

Send the transcript text and prompt to LLM Gateway. The model parameter defines which LLM to use. For available models, see [LLM Gateway Overview](/docs/llm-gateway/overview).

```csharp
public class LlmGatewayResponse
{
  public List<Choice> Choices { get; set; }
}

public class Choice
{
  public Message Message { get; set; }
}

public class Message
{
  public string Content { get; set; }
}

private static async Task<LlmGatewayResponse> SendToLlmGatewayAsync(string prompt, string transcriptText, HttpClient httpClient)
{
   var data = new
   {
       model = "claude-sonnet-4-5-20250929",
       messages = new[]
       {
           new { role = "user", content = $"{prompt}\n\nTranscript: {transcriptText}" }
       },
       max_tokens = 1000
   };
   var content = new StringContent(JsonSerializer.Serialize(data), Encoding.UTF8, "application/json");

   using var response = await httpClient.PostAsync("https://llm-gateway.assemblyai.com/v1/chat/completions", content);
   response.EnsureSuccessStatusCode();
   return await response.Content.ReadFromJsonAsync<LlmGatewayResponse>();
}

var llmGatewayResponse = await SendToLlmGatewayAsync(prompt, transcript.Text, httpClient);
```

</Tab>

<Tab language="ruby" title="Ruby">

Send the transcript text and prompt to LLM Gateway. The model parameter defines which LLM to use. For available models, see [LLM Gateway Overview](/docs/llm-gateway/overview).

```ruby
llm_gateway_uri = URI("https://llm-gateway.assemblyai.com/v1/chat/completions")
llm_gateway_request = Net::HTTP::Post.new(llm_gateway_uri, headers)
llm_gateway_request.body = {
  model: "claude-sonnet-4-5-20250929",
  messages: [
    { role: "user", content: "#{prompt}\n\nTranscript: #{transcription_result['text']}" }
  ],
  max_tokens: 1000
}.to_json

llm_gateway_http = Net::HTTP.new(llm_gateway_uri.host, llm_gateway_uri.port)
llm_gateway_http.use_ssl = true
llm_gateway_response = llm_gateway_http.request(llm_gateway_request)
llm_gateway_result = JSON.parse(llm_gateway_response.body)
```

</Tab>

<Tab language="php" title="PHP">

Send the transcript text and prompt to LLM Gateway. The model parameter defines which LLM to use. For available models, see [LLM Gateway Overview](/docs/llm-gateway/overview).

```php
$ch = curl_init("https://llm-gateway.assemblyai.com/v1/chat/completions");
curl_setopt_array($ch, [
    CURLOPT_RETURNTRANSFER => true,
    CURLOPT_POST => true,
    CURLOPT_HTTPHEADER => $headers,
    CURLOPT_POSTFIELDS => json_encode([
        'model' => 'claude-sonnet-4-5-20250929',
        'messages' => [
            ['role' => 'user', 'content' => $prompt . "\n\nTranscript: " . $transcription_result['text']]
        ],
        'max_tokens' => 1000
    ])
]);

$response = curl_exec($ch);
$result = json_decode($response, true);
```

</Tab>

</Tabs>
</Step>

<Step>

Print the result.

<Tabs groupId="language">

<Tab language="python" title="Python" default>

```python
print(result.json()["choices"][0]["message"]["content"])
```

</Tab>
<Tab language="javascript" title="JavaScript">

```javascript
console.log(result.data.choices[0].message.content);
```

</Tab>

<Tab language="csharp" title="C#">

```csharp
Console.WriteLine(llmGatewayResponse.Choices[0].Message.Content);
```

</Tab>

<Tab language="ruby" title="Ruby">

```ruby
puts llm_gateway_result["choices"][0]["message"]["content"]
```

</Tab>

<Tab language="php" title="PHP">

```php
echo $result['choices'][0]['message']['content'];
curl_close($ch);
```

</Tab>

</Tabs>

The output will look something like this:

```
 The transcript describes several common sports injuries - runner's knee,
 sprained ankle, meniscus tear, rotator cuff tear, and ACL tear. It provides
 definitions, causes, and symptoms for each injury. The transcript seems to be
 narrating sports footage and describing injuries as they occur to the athletes.
 Overall, it provides an overview of these common sports injuries that can
 result from overuse or sudden trauma during athletic activities
```

</Step>

</Steps>

## Next steps

In this tutorial, you've learned how to generate LLM output based on your audio transcripts using LLM Gateway. The type of output depends on your prompt, so try exploring different prompts to see how they affect the output. Here's a few more prompts to try.

- "Provide an analysis of the transcript and offer areas to improve with exact quotes."
- "What's the main take-away from the transcript?"
- "Generate a set of action items from this transcript."

To learn more about LLM Gateway and working with different models, see the following resources:

- [LLM Gateway Overview](/docs/llm-gateway/overview)
- [Basic Chat Completions](/docs/llm-gateway/chat-completions)
- [Multi-turn Conversations](/docs/llm-gateway/conversations)

## Need some help?

If you get stuck, or have any other questions, we'd love to help you out. Contact our support team at support@assemblyai.com or create a [support ticket](https://www.assemblyai.com/contact/support).
