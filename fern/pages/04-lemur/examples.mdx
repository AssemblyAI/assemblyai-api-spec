---
title: 'Create custom LLM prompts'
subtitle: 'Learn about different use cases for LeMUR with these examples.'
description: 'Learn about different use cases for LeMUR with these examples.'
---






  
<Tip>
If you want a Quickstart, see [Apply LLMs to audio files](/docs/getting-started/apply-ll-ms-to-audio-files).
</Tip>

<Note title="Before you start">
To use LeMUR, you need an <a href="https://www.assemblyai.com/dashboard/signup" target="_blank">AssemblyAI account</a> with a credit card set up.
</Note>





## Custom prompt example

If you want to send a custom prompt to the LLM, you can use the [LeMUR Task](https://assemblyai.com/docs/api-reference/lemur/task) and apply the model to your transcribed audio files.

<Tabs groupId="language">
  <Tab value="python" title="Python" default>

```python {12-13,15-18}
import assemblyai as aai

aai.settings.api_key = "<YOUR_API_KEY>"

# Step 1: Transcribe an audio file.
# audio_file = "./local_file.mp4"
audio_file = "https://assembly.ai/call.mp4"

transcriber = aai.Transcriber()
transcript = transcriber.transcribe(audio_file)

# Step 2: Define your prompt.
prompt = "What was the emotional sentiment of the phone call?"

# Step 3: Apply LeMUR.
result = transcript.lemur.task(
    prompt, final_model=aai.LemurModel.claude3_5_sonnet
)

print(result.response)
```

  </Tab>
  <Tab value="typescript" title="TypeScript">

```ts {13-14,16-21}
import { AssemblyAI } from 'assemblyai'

const client = new AssemblyAI({
  apiKey: '<YOUR_API_KEY>'
})

const run = async () => {
  // Step 1: Transcribe an audio file.
  // const audioFile = './local_file.mp4'
  const audioFile = 'https://assembly.ai/call.mp4'
  const transcript = await client.transcripts.transcribe({ audio: audioFile })

  // Step 2: Define your prompt.
  const prompt = 'What was the emotional sentiment of the phone call?'

  // Step 3: Apply LeMUR.
  const { response } = await client.lemur.task({
    transcript_ids: [transcript.id],
    prompt,
    final_model: 'anthropic/claude-3-5-sonnet'
  })

  console.log(response)
}

run()
```

  </Tab>
  <Tab value="golang" title="Go">

```go {19-20,22-28}
package main

import (
    "context"
    "fmt"

    aai "github.com/AssemblyAI/assemblyai-go-sdk"
)

func main() {
    ctx := context.Background()

    client := aai.NewClient("<YOUR_API_KEY>")

    // Step 1: Transcribe an audio file. For local files see our Getting Started guides.
    audioURL := "https://assembly.ai/call.mp4"
    transcript, _ := client.Transcripts.TranscribeFromURL(ctx, audioURL, nil)

    // Step 2: Define your prompt.
    prompt := "What was the emotional sentiment of the phone call?"

    // Step 3: Apply LeMUR.
    var params aai.LeMURTaskParams
    params.Prompt = aai.String(prompt)
    params.TranscriptIDs = []string{aai.ToString(transcript.ID)}
    params.FinalModel = "anthropic/claude-3-5-sonnet"

    result, _ := client.LeMUR.Task(ctx, params)

    fmt.Println(*result.Response)
}
```

  </Tab>
  <Tab value="java" title="Java">

```java {17-18,20-25}
import com.assemblyai.api.AssemblyAI;
import com.assemblyai.api.resources.transcripts.types.*;
import com.assemblyai.api.resources.lemur.requests.*;
import java.util.List;

public final class App {
    public static void main(String[] args) {

        AssemblyAI client = AssemblyAI.builder()
                .apiKey("<YOUR_API_KEY>")
                .build();

        // Step 1: Transcribe an audio file. For local files see our Getting Started guides.
        String audioUrl = "https://assembly.ai/call.mp4";
        Transcript transcript = client.transcripts().transcribe(audioUrl);

        // Step 2: Define your prompt.
        String prompt = "What was the emotional sentiment of the phone call?";

        // Step 3: Apply LeMUR.
        var params = LemurTaskParams.builder()
                .prompt(prompt)
                .transcriptIds(List.of(transcript.getId()))
                .finalModel(LemurModel.ANTHROPIC_CLAUDE3_5_SONNET)
                .build();

        var response = client.lemur().task(params);

        System.out.println(response.getResponse());
    }
}
```

  </Tab>
  <Tab value="csharp" title="C#">

```csharp {13-14,16-22}
using AssemblyAI;
using AssemblyAI.Lemur;
using AssemblyAI.Transcripts;

var client = new AssemblyAIClient("<YOUR_API_KEY>");

// Step 1: Transcribe an audio file. For local files see our Getting Started guides.
var transcript = await client.Transcripts.TranscribeAsync(new TranscriptParams
{
    AudioUrl = "https://assembly.ai/call.mp4"
});

// Step 2: Define your prompt.
const string prompt = "What was the emotional sentiment of the phone call?";

// Step 3: Apply LeMUR.
var lemurTaskParams = new LemurTaskParams
{
    Prompt = prompt,
    TranscriptIds = [transcript.Id],
    FinalModel = LemurModel.AnthropicClaude3_5_Sonnet
};

var response = await client.Lemur.TaskAsync(lemurTaskParams);

Console.WriteLine(response.Response);
```

  </Tab>
  <Tab value="ruby" title="Ruby">

```ruby {9-10,12-17}
require 'assemblyai'

client = AssemblyAI::Client.new(api_key: '<YOUR_API_KEY>')

# Step 1: Transcribe audio file. For local files see our Getting Started guides.
audio_url = 'https://assembly.ai/call.mp4'
transcript = client.transcripts.transcribe(audio_url: audio_url)

# Step 2: Define your prompt.
prompt = "What was the emotional sentiment of the phone call?"

# Step 3: Apply LeMUR.
response = client.lemur.task(
  prompt: prompt,
  transcript_ids: [transcript.id],
  final_model: AssemblyAI::Lemur::LemurModel::ANTHROPIC_CLAUDE3_5_SONNET
)

puts response.response
```

  </Tab>
</Tabs>




  
## Ideas to get you started


| Use case | Example prompt |
| --- | --- |
| Question & Answer | <i>"Identify any patterns or trends based on the transcript"</i> |
| Quote or Citation | <i>"List the timestamp X topic was discussed, provide specific citations"</i> |
| Closed-ended questions | <i>"Did the customer express a positive sentiment in the phone call?"</i> |
| Sentiment analysis | <i>"What was the emotional sentiment of the phone call?"</i> |
| Summaries | <i>"Summarize key decisions and important points from the phone call transcript"</i> |
| Summarize audio segments | <i>"Summarize the key events of each chapter"</i> |
| Generate titles and descriptions | <i>"Generate an attention-grabbing YouTube title based on the video transcript"</i> |
| Generate tags | <i>"Generate keywords that can be used to describe the key themes of the conversation"</i> |
| Action items | <i>"What action items were assigned to each participant?"</i> |
| Generate content | <i>"Generate a blog post with key information presented in bullet points from the transcript"</i> |
| Paraphrasing | <i>"Rephrase X segment from the transcript in a different way"</i> |

You can find more ideas and code examples in the [AssemblyAI Cookbook repo](https://github.com/AssemblyAI/cookbook) on Github.





