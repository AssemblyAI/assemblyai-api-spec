---
title: "Create custom LLM prompts"
subtitle: "Learn about different use cases for LeMUR with these examples."
description: "Learn about different use cases for LeMUR with these examples."
---

<Tip>

If you want a Quickstart, see [Apply LLMs to audio files](/docs/lemur/apply-llms-to-audio-files).

</Tip>

<Note title="Before you start">

To use LeMUR, you need an <a href="https://www.assemblyai.com/dashboard/signup" target="_blank"> AssemblyAI account </a> with a credit card set up.

</Note>

## Custom prompt example

If you want to send a custom prompt to the LLM, you can use the [LeMUR Task](https://assemblyai.com/docs/api-reference/lemur/task) and apply the model to your transcribed audio files.

<Tabs groupId="language">
<Tab language="python-sdk" title="Python SDK" default>

```python {13-14,16-19}
import assemblyai as aai

aai.settings.api_key = "<YOUR_API_KEY>"

# Step 1: Transcribe an audio file.
# audio_file = "./local_file.mp4"
# Or use a publicly-accessible URL:
audio_file = "https://assembly.ai/call.mp4"

transcriber = aai.Transcriber()
transcript = transcriber.transcribe(audio_file)

# Step 2: Define your prompt.
prompt = "What was the emotional sentiment of the phone call?"

# Step 3: Apply LeMUR.
result = transcript.lemur.task(
    prompt, final_model=aai.LemurModel.claude3_5_sonnet
)

print(result.response)
```

</Tab>
<Tab language="python" title="Python">

```python {42-43,45-52}
import requests
import time

base_url = "https://api.assemblyai.com"

headers = {
  "authorization": "<YOUR_API_KEY>"
}

# Step 1: Transcribe an audio file.
# You can use a local filepath:
# with open("./my-audio.mp3", "rb") as f:
# response = requests.post(base_url + "/v2/upload",
#                         headers=headers,
#                         data=f)
# upload_url = response.json()["upload_url"]

# Or use a publicly-accessible URL:
upload_url = "https://assembly.ai/call.mp4"

data = {
  "audio_url": upload_url
}

response = requests.post(base_url + "/v2/transcript", headers=headers, json=data)

transcript_id = response.json()["id"]
polling_endpoint = base_url + f"/v2/transcript/{transcript_id}"

while True:
  transcript = requests.get(polling_endpoint, headers=headers).json()

  if transcript["status"] == "completed":
    break

  elif transcript["status"] == "error":
    raise RuntimeError(f"Transcription failed: {transcript['error']}")

  else:
    time.sleep(3)

# Step 2: Define your prompt.
prompt = "What was the emotional sentiment of the phone call?"

# Step 3: Apply LeMUR.
lemur_data = {
  "prompt": prompt,
  "transcript_ids": [transcript_id],
  "final_model": "anthropic/claude-3-5-sonnet",
}

result = requests.post(base_url + "/lemur/v3/generate/task", headers=headers, json=lemur_data)
print(result.json()["response"])
```

</Tab>
<Tab language="typescript-sdk" title="Typescript SDK">

```ts {14-15,17-22}
import { AssemblyAI } from "assemblyai";

const client = new AssemblyAI({
  apiKey: "<YOUR_API_KEY>",
});

const run = async () => {
  // Step 1: Transcribe an audio file.
  // const audioFile = './local_file.mp4'
  // Or use a publicly-accessible URL:
  const audioFile = "https://assembly.ai/call.mp4";
  const transcript = await client.transcripts.transcribe({ audio: audioFile });

  // Step 2: Define your prompt.
  const prompt = "What was the emotional sentiment of the phone call?";

  // Step 3: Apply LeMUR.
  const { response } = await client.lemur.task({
    transcript_ids: [transcript.id],
    prompt,
    final_model: "anthropic/claude-3-5-sonnet",
  });

  console.log(response);
};

run();
```

</Tab>
<Tab language="typescript" title="Typescript">

```ts {43-44,46-53}
import axios from "axios";

const base_url = "https://api.assemblyai.com";

const headers = {
  authorization: "<YOUR_API_KEY>",
};

// Step 1: Transcribe an audio file.
// import fs from 'fs-extra';
// const path = './my-audio.mp3';
// const audioData = await fs.readFile(path)
// const uploadResponse = await axios.post(`${baseUrl}/v2/upload`, audioData, {
// headers
// })
// const uploadUrl = uploadResponse.data.upload_url

// Or use a publicly-accessibly URL:
const uploadUrl = "https://assembly.ai/call.mp4";

const data = {
  audio_url: uploadUrl,
};

const response = await axios.post(base_url + "/v2/transcript", data, {
  headers,
});

const transcript_id = response.data.id;
const polling_endpoint = base_url + `/v2/transcript/${transcript_id}`;

while (true) {
  const transcript = (await axios.get(polling_endpoint, { headers })).data;

  if (transcript.status === "completed") {
    break;
  } else if (transcript.status === "error") {
    throw new Error(`Transcription failed: ${transcript.error}`);
  } else {
    await new Promise((resolve) => setTimeout(resolve, 3000));
  }
}

// Step 2: Define your prompt.
const prompt = "What was the emotional sentiment of the phone call?";

// Step 3: Apply LeMUR.
const lemur_data = {
  prompt: prompt,
  transcript_ids: [transcript_id],
  final_model: "anthropic/claude-3-5-sonnet",
};

const result = await axios.post(
  base_url + "/lemur/v3/generate/task",
  lemur_data,
  { headers }
);
console.log(result.data.response);
```

</Tab>
<Tab language="csharp" title="C#">

```csharp {122-123,125-127}
using System;
using System.IO;
using System.Net.Http;
using System.Net.Http.Headers;
using System.Net.Http.Json;
using System.Text;
using System.Text.Json;
using System.Threading.Tasks;

public class Transcript
{
   public string Id { get; set; }
   public string Status { get; set; }
   public string Text { get; set; }

   [JsonPropertyName("language_code")]
   public string LanguageCode { get; set; }

   public string Error { get; set; }
}

public class LemurResponse
{
  [JsonPropertyName("request_id")]
  public string RequestId { get; set; }

  public string Response { get; set; }

  public Usage Usage { get; set; }
}

public class Usage
{
  [JsonPropertyName("input_tokens")]
  public int InputTokens { get; set; }

  [JsonPropertyName("output_tokens")]
  public int OutputTokens { get; set; }
}

private static async Task<string> UploadFileAsync(string filePath, HttpClient httpClient)
{
    using (var fileStream = File.OpenRead(filePath))
    using (var fileContent = new StreamContent(fileStream))
    {
        fileContent.Headers.ContentType = new MediaTypeHeaderValue("application/octet-stream");

        using (var response = await httpClient.PostAsync("https://api.assemblyai.com/v2/upload", fileContent))
        {
            response.EnsureSuccessStatusCode();
            var jsonDoc = await response.Content.ReadFromJsonAsync<JsonDocument>();
            return jsonDoc.RootElement.GetProperty("upload_url").GetString();
        }
    }
}


private static async Task<Transcript> CreateTranscriptAsync(string audioUrl, HttpClient httpClient)
{
   var data = new { audio_url = audioUrl };
   var content = new StringContent(JsonSerializer.Serialize(data), Encoding.UTF8, "application/json");

   using (var response = await httpClient.PostAsync("https://api.assemblyai.com/v2/transcript", content))
   {
       response.EnsureSuccessStatusCode();
       return await response.Content.ReadFromJsonAsync<Transcript>();
   }
}

private static async Task<Transcript> WaitForTranscriptToProcess(Transcript transcript, HttpClient httpClient)
{
   var pollingEndpoint = $"https://api.assemblyai.com/v2/transcript/{transcript.Id}";

   while (true)
   {
       var pollingResponse = await httpClient.GetAsync(pollingEndpoint);
       transcript = await pollingResponse.Content.ReadFromJsonAsync<Transcript>();
       switch (transcript.Status)
       {
           case "processing":
           case "queued":
               await Task.Delay(TimeSpan.FromSeconds(3));
               break;
           case "completed":
               return transcript;
           case "error":
               throw new Exception($"Transcription failed: {transcript.Error}");
           default:
               throw new Exception("This code shouldn't be reachable.");
       }
   }
}

private static async Task<LemurResponse> GenerateTaskAsync(string prompt, List<string> transcriptIds, HttpClient httpClient)
{
   var data = new
   {
       transcript_ids = transcriptIds,
       prompt,
       final_model = "anthropic/claude-3-5-sonnet"
   };

   var content = new StringContent(JsonSerializer.Serialize(data), Encoding.UTF8, "application/json");

   using var response = await httpClient.PostAsync("https://api.assemblyai.com/lemur/v3/generate/task", content);
   response.EnsureSuccessStatusCode();
   return await response.Content.ReadFromJsonAsync<LemurResponse>();
}

using (var httpClient = new HttpClient())
{
   httpClient.DefaultRequestHeaders.Authorization =
       new AuthenticationHeaderValue("<YOUR_API_KEY>");

   // Step 1: Transcribe an audio file.
   // var uploadUrl = await UploadFileAsync("/my_audio.mp3", httpClient);
   // Or use a publicly-accessible URL.
   var uploadUrl = "https://assembly.ai/call.mp4";
   var transcript = await CreateTranscriptAsync(uploadUrl, httpClient);
   transcript = await WaitForTranscriptToProcess(transcript, httpClient);

   // Step 2: Define your prompt.
   const string prompt = "What was the emotional sentiment of the phone call?";

   // Step 3: Apply LeMUR.
   var transcriptIds = new List<string> { transcript.Id };
   var lemurResponse = await GenerateTaskAsync(prompt, transcriptIds, httpClient);

   Console.WriteLine(lemurResponse.Response);
}
```

</Tab>
<Tab language="ruby" title="Ruby">

```ruby {47-48,50-59}
require 'net/http'
require 'json'

base_url = "https://api.assemblyai.com"
headers = {
   "authorization" => "<YOUR_API_KEY>",
   "content-type" => "application/json"
}

# Step 1: Transcribe an audio file.
# path = "/my_audio.mp3"
# uri = URI("#{base_url}/v2/upload")
# request = Net::HTTP::Post.new(uri, headers)
# request.body = File.read(path)

# http = Net::HTTP.new(uri.host, uri.port)
# http.use_ssl = true
# upload_response = http.request(request)
# upload_url = JSON.parse(upload_response.body)["upload_url"]

# Or use a publicly-accessible URL:
upload_url = "https://assembly.ai/call.mp4"

uri = URI("#{base_url}/v2/transcript")
request = Net::HTTP::Post.new(uri, headers)
request.body = { audio_url: upload_url }.to_json

response = http.request(request)
transcript_id = JSON.parse(response.body)["id"]
polling_endpoint = "#{base_url}/v2/transcript/#{transcript_id}"

while true
   polling_uri = URI(polling_endpoint)
   polling_request = Net::HTTP::Get.new(polling_uri, headers)
   polling_response = http.request(polling_request)
   transcription_result = JSON.parse(polling_response.body)

   if transcription_result["status"] == "completed"
       break
   elsif transcription_result["status"] == "error"
       raise "Transcription failed: #{transcription_result["error"]}"
   else
       sleep(3)
   end
end

# Step 2: Define your prompt.
prompt = "What was the emotional sentiment of the phone call?"

# Step 3: Apply LeMUR.
lemur_uri = URI("#{base_url}/lemur/v3/generate/task")
lemur_request = Net::HTTP::Post.new(lemur_uri, headers)
lemur_request.body = {
  final_model: "anthropic/claude-3-5-sonnet",
  prompt: prompt,
  transcript_ids: [transcript_id]
}.to_json

lemur_response = http.request(lemur_request)
lemur_result = JSON.parse(lemur_response.body)
puts lemur_result["response"]
```

</Tab>
<Tab language="php" title="PHP">

```php {57-58,60-73}
<?php
$base_url = "https://api.assemblyai.com";
$headers = array(
    "authorization: <YOUR_API_KEY>",
    "content-type: application/json"
);

// Step 1: Transcribe an audio file.
// $path = "/my_audio.mp3";
// $ch = curl_init($base_url . "/v2/upload");
// curl_setopt_array($ch, [
//     CURLOPT_POST => true,
//     CURLOPT_POSTFIELDS => file_get_contents($path),
//     CURLOPT_HTTPHEADER => $headers,
//     CURLOPT_RETURNTRANSFER => true
// ]);

// $response = curl_exec($ch);
// $upload_url = json_decode($response, true)["upload_url"];
// curl_close($ch);

// Or use a publicly-accessible URL:
$upload_url = "https://assembly.ai/call.mp4"

$ch = curl_init($base_url . "/v2/transcript");
curl_setopt_array($ch, [
    CURLOPT_POST => true,
    CURLOPT_POSTFIELDS => json_encode(["audio_url" => $upload_url]), // You can also replace upload_url with an audio file URL
    CURLOPT_HTTPHEADER => $headers,
    CURLOPT_RETURNTRANSFER => true
]);

$response = curl_exec($ch);
$transcript_id = json_decode($response, true)['id'];
curl_close($ch);

$polling_endpoint = $base_url . "/v2/transcript/" . $transcript_id;

while (true) {
    $ch = curl_init($polling_endpoint);
    curl_setopt_array($ch, [
        CURLOPT_HTTPHEADER => $headers,
        CURLOPT_RETURNTRANSFER => true
    ]);

    $transcription_result = json_decode(curl_exec($ch), true);
    curl_close($ch);

    if ($transcription_result['status'] === "completed") {
        break;
    } else if ($transcription_result['status'] === "error") {
        throw new Exception("Transcription failed: " . $transcription_result['error']);
    }
    sleep(3);
}

// Step 2: Define your prompt.
$prompt = 'What was the emotional sentiment of the phone call?'

// Step 3: Apply LeMUR.
$ch = curl_init($base_url . "/lemur/v3/generate/task");
curl_setopt_array($ch, [
    CURLOPT_RETURNTRANSFER => true,
    CURLOPT_POST => true,
    CURLOPT_HTTPHEADER => $headers,
    CURLOPT_POSTFIELDS => json_encode([
        'final_model' => 'anthropic/claude-3-5-sonnet',
        'prompt' => $prompt,
        'transcript_ids' => [$transcript_id]
    ])
]);

$response = curl_exec($ch);
$result = json_decode($response, true);
echo $result['response'];
curl_close($ch);
```

  </Tab>
</Tabs>

## Popular Use Cases

<CardGroup cols={3}>
  <Card
    title="Speaker Identification"
    href="https://github.com/AssemblyAI/cookbook/blob/master/lemur/speaker-identification.ipynb"
  >
    _Assign Speaker Names With LeMUR_
  </Card>
  <Card
    title="Custom Topic Tags"
    href="https://github.com/AssemblyAI/cookbook/blob/master/lemur/custom-topic-tags.ipynb"
  >
    _Label content with custom topic tags using LeMUR_
  </Card>
  <Card
    title="Boost Transcription Accuracy"
    href="https://github.com/AssemblyAI/cookbook/blob/master/lemur/custom-vocab-lemur.ipynb"
  >
    _Boost Custom Vocabulary List with LeMUR_
  </Card>
  <Card
    title="Sentiment Analysis"
    href="https://github.com/AssemblyAI/cookbook/blob/master/lemur/call-sentiment-analysis.ipynb"
  >
    _Analyze the sentiment of a phone call with LeMUR_
  </Card>
  <Card
    title="SOAP Note Generation"
    href="https://github.com/AssemblyAI/cookbook/blob/master/lemur/soap-note-generation.ipynb"
  >
    _Generate SOAP notes with LeMUR_
  </Card>
  <Card
    title="Action Items"
    href="https://github.com/AssemblyAI/cookbook/blob/master/lemur/task-endpoint-action-items.ipynb"
  >
    _Generate action items with LeMUR_
  </Card>
</CardGroup>

## Ideas to get you started

| Use case                         | Example prompt                                                                                    |
| -------------------------------- | ------------------------------------------------------------------------------------------------- |
| Question & Answer                | <i>"Identify any patterns or trends based on the transcript"</i>                                  |
| Quote or Citation                | <i>"List the timestamp X topic was discussed, provide specific citations"</i>                     |
| Closed-ended questions           | <i>"Did the customer express a positive sentiment in the phone call?"</i>                         |
| Sentiment analysis               | <i>"What was the emotional sentiment of the phone call?"</i>                                      |
| Summaries                        | <i>"Summarize key decisions and important points from the phone call transcript"</i>              |
| Summarize audio segments         | <i>"Summarize the key events of each chapter"</i>                                                 |
| Generate titles and descriptions | <i>"Generate an attention-grabbing YouTube title based on the video transcript"</i>               |
| Generate tags                    | <i>"Generate keywords that can be used to describe the key themes of the conversation"</i>        |
| Action items                     | <i>"What action items were assigned to each participant?"</i>                                     |
| Generate content                 | <i>"Generate a blog post with key information presented in bullet points from the transcript"</i> |
| Paraphrasing                     | <i>"Rephrase X segment from the transcript in a different way"</i>                                |

You can find more ideas and code examples in the [AssemblyAI Cookbook repo](https://github.com/AssemblyAI/cookbook) on Github.
