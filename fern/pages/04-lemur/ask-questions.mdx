---
title: "Ask Questions About Your Audio Transcripts"
description: "Ask questions about your audio transcripts using LLM Gateway."
---

In this guide, you'll learn how to use LLM Gateway to ask questions and get answers about your audio transcripts.

<Tip>

If you want a Quickstart, see [Apply LLM Gateway to Audio Transcripts](/docs/lemur/apply-llms-to-audio-files).

</Tip>

## Basic Q&A example

To ask a question about your audio transcript, define a prompt with your questions and send it to LLM Gateway along with the transcript text using the chat completions API.

<Tabs groupId="language">
<Tab language="python" title="Python" default>

```python {42-43,45-53}
import requests
import time

# Step 1: Transcribe an audio file.
base_url = "https://api.assemblyai.com"

headers = {
  "authorization": "<YOUR_API_KEY>"
}

# You can use a local filepath:
# with open("./my-audio.mp3", "rb") as f:
# response = requests.post(base_url + "/v2/upload",
#                         headers=headers,
#                         data=f)
# upload_url = response.json()["upload_url"]

# Or use a publicly-accessible URL:
upload_url = "https://assembly.ai/sports_injuries.mp3"

data = {
  "audio_url": upload_url
}

response = requests.post(base_url + "/v2/transcript", headers=headers, json=data)

transcript_id = response.json()["id"]
polling_endpoint = base_url + f"/v2/transcript/{transcript_id}"

while True:
  transcript = requests.get(polling_endpoint, headers=headers).json()

  if transcript["status"] == "completed":
    break

  elif transcript["status"] == "error":
    raise RuntimeError(f"Transcription failed: {transcript['error']}")

  else:
    time.sleep(3)

# Step 2: Define a prompt with your question(s).
prompt = "What is a runner's knee?"

# Step 3: Send to LLM Gateway.
llm_gateway_data = {
  "model": "claude-sonnet-4-5-20250929",
  "messages": [
    {"role": "user", "content": f"{prompt}\n\nTranscript: {transcript['text']}"}
  ],
  "max_tokens": 1000
}

result = requests.post(
  "https://llm-gateway.assemblyai.com/v1/chat/completions",
  headers=headers,
  json=llm_gateway_data
)
print(result.json()["choices"][0]["message"]["content"])
```

</Tab>
<Tab language="javascript" title="JavaScript">
  
```javascript {44-45,47-52}
import axios from "axios";

// Step 1: Transcribe an audio file.
const base_url = "https://api.assemblyai.com";

const headers = {
authorization: "<YOUR_API_KEY>",
};

// import fs from 'fs-extra';
// const path = './my-audio.mp3';
// const audioData = await fs.readFile(path)
// const uploadResponse = await axios.post(`${baseUrl}/v2/upload`, audioData, {
// headers
// })
// const uploadUrl = uploadResponse.data.upload_url

// Or use a publicly-accessibly URL:
const uploadUrl = "https://assembly.ai/sports_injuries.mp3";

const data = {
audio_url: uploadUrl,
};

const response = await axios.post(base_url + "/v2/transcript", data, {
headers,
});

const transcript_id = response.data.id;
const polling_endpoint = base_url + `/v2/transcript/${transcript_id}`;

let transcript;
while (true) {
transcript = (await axios.get(polling_endpoint, { headers })).data;

if (transcript.status === "completed") {
break;
} else if (transcript.status === "error") {
throw new Error(`Transcription failed: ${transcript.error}`);
} else {
await new Promise((resolve) => setTimeout(resolve, 3000));
}
}

// Step 2: Define a prompt with your question(s).
const prompt = "What is a runner's knee?";

// Step 3: Send to LLM Gateway.
const llm_gateway_data = {
model: "claude-sonnet-4-5-20250929",
messages: [
{ role: "user", content: `${prompt}\n\nTranscript: ${transcript.text}` }
],
max_tokens: 1000
};

const result = await axios.post(
"https://llm-gateway.assemblyai.com/v1/chat/completions",
llm_gateway_data,
{ headers }
);
console.log(result.data.choices[0].message.content);

````
</Tab>

<Tab language="csharp" title="C#">

```csharp {122-123,125-127}
using System;
using System.IO;
using System.Net.Http;
using System.Net.Http.Headers;
using System.Net.Http.Json;
using System.Text;
using System.Text.Json;
using System.Threading.Tasks;
using System.Collections.Generic;

public class Transcript
{
   public string Id { get; set; }
   public string Status { get; set; }
   public string Text { get; set; }

   [JsonPropertyName("language_code")]
   public string LanguageCode { get; set; }

   public string Error { get; set; }
}

public class LlmGatewayResponse
{
  public List<Choice> Choices { get; set; }
}

public class Choice
{
  public Message Message { get; set; }
}

public class Message
{
  public string Content { get; set; }
}

private static async Task<string> UploadFileAsync(string filePath, HttpClient httpClient)
{
    using (var fileStream = File.OpenRead(filePath))
    using (var fileContent = new StreamContent(fileStream))
    {
        fileContent.Headers.ContentType = new MediaTypeHeaderValue("application/octet-stream");

        using (var response = await httpClient.PostAsync("https://api.assemblyai.com/v2/upload", fileContent))
        {
            response.EnsureSuccessStatusCode();
            var jsonDoc = await response.Content.ReadFromJsonAsync<JsonDocument>();
            return jsonDoc.RootElement.GetProperty("upload_url").GetString();
        }
    }
}

private static async Task<Transcript> CreateTranscriptAsync(string audioUrl, HttpClient httpClient)
{
   var data = new { audio_url = audioUrl };
   var content = new StringContent(JsonSerializer.Serialize(data), Encoding.UTF8, "application/json");

   using (var response = await httpClient.PostAsync("https://api.assemblyai.com/v2/transcript", content))
   {
       response.EnsureSuccessStatusCode();
       return await response.Content.ReadFromJsonAsync<Transcript>();
   }
}

private static async Task<Transcript> WaitForTranscriptToProcess(Transcript transcript, HttpClient httpClient)
{
   var pollingEndpoint = $"https://api.assemblyai.com/v2/transcript/{transcript.Id}";

   while (true)
   {
       var pollingResponse = await httpClient.GetAsync(pollingEndpoint);
       transcript = await pollingResponse.Content.ReadFromJsonAsync<Transcript>();
       switch (transcript.Status)
       {
           case "processing":
           case "queued":
               await Task.Delay(TimeSpan.FromSeconds(3));
               break;
           case "completed":
               return transcript;
           case "error":
               throw new Exception($"Transcription failed: {transcript.Error}");
           default:
               throw new Exception("This code shouldn't be reachable.");
       }
   }
}

private static async Task<LlmGatewayResponse> SendToLlmGatewayAsync(string prompt, string transcriptText, HttpClient httpClient)
{
   var data = new
   {
       model = "claude-sonnet-4-5-20250929",
       messages = new[]
       {
           new { role = "user", content = $"{prompt}\n\nTranscript: {transcriptText}" }
       },
       max_tokens = 1000
   };

   var content = new StringContent(JsonSerializer.Serialize(data), Encoding.UTF8, "application/json");

   using var response = await httpClient.PostAsync("https://llm-gateway.assemblyai.com/v1/chat/completions", content);
   response.EnsureSuccessStatusCode();
   return await response.Content.ReadFromJsonAsync<LlmGatewayResponse>();
}

using (var httpClient = new HttpClient())
{
   httpClient.DefaultRequestHeaders.Authorization =
       new AuthenticationHeaderValue("<YOUR_API_KEY>");

   // Step 1: Transcribe an audio file.
   // var uploadUrl = await UploadFileAsync("/my_audio.mp3", httpClient);
   // Or use a publicly-accessible URL.
   var uploadUrl = "https://assembly.ai/sports_injuries.mp3";
   var transcript = await CreateTranscriptAsync(uploadUrl, httpClient);
   transcript = await WaitForTranscriptToProcess(transcript, httpClient);

   // Step 2: Define a prompt with your question(s).
   const string prompt = "What is a runner's knee?";

   // Step 3: Send to LLM Gateway.
   var llmGatewayResponse = await SendToLlmGatewayAsync(prompt, transcript.Text, httpClient);

   Console.WriteLine(llmGatewayResponse.Choices[0].Message.Content);
}
````

</Tab>
<Tab language="ruby" title="Ruby">

```ruby {47-48,50-59}
require 'net/http'
require 'json'

# Step 1: Transcribe an audio file.
base_url = "https://api.assemblyai.com"
headers = {
   "authorization" => "<YOUR_API_KEY>",
   "content-type" => "application/json"
}

# path = "/my_audio.mp3"
# uri = URI("#{base_url}/v2/upload")
# request = Net::HTTP::Post.new(uri, headers)
# request.body = File.read(path)

# http = Net::HTTP.new(uri.host, uri.port)
# http.use_ssl = true
# upload_response = http.request(request)
# upload_url = JSON.parse(upload_response.body)["upload_url"]

# Or use a publicly-accessible URL:
upload_url = "https://assembly.ai/sports_injuries.mp3"

uri = URI("#{base_url}/v2/transcript")
request = Net::HTTP::Post.new(uri, headers)
request.body = { audio_url: upload_url }.to_json

http = Net::HTTP.new(uri.host, uri.port)
http.use_ssl = true
response = http.request(request)
transcript_id = JSON.parse(response.body)["id"]
polling_endpoint = "#{base_url}/v2/transcript/#{transcript_id}"

while true
   polling_uri = URI(polling_endpoint)
   polling_request = Net::HTTP::Get.new(polling_uri, headers)
   polling_response = http.request(polling_request)
   transcription_result = JSON.parse(polling_response.body)

   if transcription_result["status"] == "completed"
       break
   elsif transcription_result["status"] == "error"
       raise "Transcription failed: #{transcription_result["error"]}"
   else
       sleep(3)
   end
end

# Step 2: Define a prompt with your question(s).
prompt = "What is a runner's knee?"

# Step 3: Send to LLM Gateway.
llm_gateway_uri = URI("https://llm-gateway.assemblyai.com/v1/chat/completions")
llm_gateway_request = Net::HTTP::Post.new(llm_gateway_uri, headers)
llm_gateway_request.body = {
  model: "claude-sonnet-4-5-20250929",
  messages: [
    { role: "user", content: "#{prompt}\n\nTranscript: #{transcription_result['text']}" }
  ],
  max_tokens: 1000
}.to_json

llm_gateway_http = Net::HTTP.new(llm_gateway_uri.host, llm_gateway_uri.port)
llm_gateway_http.use_ssl = true
llm_gateway_response = llm_gateway_http.request(llm_gateway_request)
llm_gateway_result = JSON.parse(llm_gateway_response.body)
puts llm_gateway_result["choices"][0]["message"]["content"]
```

</Tab>
<Tab language="php" title="PHP">

```php {57-58,60-73}
<?php
// Step 1: Transcribe an audio file.
$base_url = "https://api.assemblyai.com";
$headers = array(
    "authorization: <YOUR_API_KEY>",
    "content-type: application/json"
);

// $path = "/my_audio.mp3";
// $ch = curl_init($base_url . "/v2/upload");
// curl_setopt_array($ch, [
//     CURLOPT_POST => true,
//     CURLOPT_POSTFIELDS => file_get_contents($path),
//     CURLOPT_HTTPHEADER => $headers,
//     CURLOPT_RETURNTRANSFER => true
// ]);

// $response = curl_exec($ch);
// $upload_url = json_decode($response, true)["upload_url"];
// curl_close($ch);

// Or use a publicly-accessible URL:
$upload_url = "https://assembly.ai/sports_injuries.mp3";

$ch = curl_init($base_url . "/v2/transcript");
curl_setopt_array($ch, [
    CURLOPT_POST => true,
    CURLOPT_POSTFIELDS => json_encode(["audio_url" => $upload_url]), // You can also replace upload_url with an audio file URL
    CURLOPT_HTTPHEADER => $headers,
    CURLOPT_RETURNTRANSFER => true
]);

$response = curl_exec($ch);
$transcript_id = json_decode($response, true)['id'];
curl_close($ch);

$polling_endpoint = $base_url . "/v2/transcript/" . $transcript_id;

while (true) {
    $ch = curl_init($polling_endpoint);
    curl_setopt_array($ch, [
        CURLOPT_HTTPHEADER => $headers,
        CURLOPT_RETURNTRANSFER => true
    ]);

    $transcription_result = json_decode(curl_exec($ch), true);
    curl_close($ch);

    if ($transcription_result['status'] === "completed") {
        break;
    } else if ($transcription_result['status'] === "error") {
        throw new Exception("Transcription failed: " . $transcription_result['error']);
    }
    sleep(3);
}

// Step 2: Define a prompt with your question(s).
$prompt = "What is a runner's knee?";

// Step 3: Send to LLM Gateway.
$ch = curl_init("https://llm-gateway.assemblyai.com/v1/chat/completions");
curl_setopt_array($ch, [
    CURLOPT_RETURNTRANSFER => true,
    CURLOPT_POST => true,
    CURLOPT_HTTPHEADER => $headers,
    CURLOPT_POSTFIELDS => json_encode([
        'model' => 'claude-sonnet-4-5-20250929',
        'messages' => [
            ['role' => 'user', 'content' => $prompt . "\n\nTranscript: " . $transcription_result['text']]
        ],
        'max_tokens' => 1000
    ])
]);

$response = curl_exec($ch);
$result = json_decode($response, true);
echo $result['choices'][0]['message']['content'];
curl_close($ch);
```

</Tab>
</Tabs>

#### Example output

```plain
Based on the transcript, runner's knee is a condition characterized
by pain behind or around the kneecap. It is caused by overuse,
muscle imbalance and inadequate stretching. Symptoms include pain
under or around the kneecap and pain when walking.
```

## Structured Q&A with LLM Gateway

You can achieve structured question-and-answer outputs by crafting specific prompts that guide the LLM to format responses in a consistent way. Here's how to create structured Q&A responses using LLM Gateway:

<Tabs groupId="language">
<Tab language="python" title="Python" default>

```python
import requests
import time

# Step 1: Transcribe the audio
base_url = "https://api.assemblyai.com"
headers = {"authorization": "<YOUR_API_KEY>"}

audio_url = "https://assembly.ai/meeting.mp4"
data = {"audio_url": audio_url}
response = requests.post(base_url + "/v2/transcript", headers=headers, json=data)
transcript_id = response.json()["id"]
polling_endpoint = base_url + f"/v2/transcript/{transcript_id}"

while True:
    transcript = requests.get(polling_endpoint, headers=headers).json()
    if transcript["status"] == "completed":
        break
    elif transcript["status"] == "error":
        raise RuntimeError(f"Transcription failed: {transcript['error']}")
    else:
        time.sleep(3)

# Step 2: Create structured Q&A prompt
questions = [
    "What are the top level KPIs for engineering? (KPI stands for key performance indicator)",
    "How many days has it been since the data team has gotten updated metrics? (Choose from: 1, 2, 3, 4, 5, 6, 7, more than 7)"
]

prompt = f"""Answer the following questions based on the meeting transcript. Format your response as:
Q1: [question]
A1: [answer]
Q2: [question]
A2: [answer]

Questions:
{". ".join([f"{i+1}. {q}" for i, q in enumerate(questions)])}

Context: This is a GitLab meeting to discuss logistics."""

# Step 3: Send to LLM Gateway
llm_gateway_data = {
    "model": "claude-sonnet-4-5-20250929",
    "messages": [
        {"role": "user", "content": f"{prompt}\n\nTranscript: {transcript['text']}"}
    ],
    "max_tokens": 1000
}

result = requests.post(
    "https://llm-gateway.assemblyai.com/v1/chat/completions",
    headers=headers,
    json=llm_gateway_data
)
print(result.json()["choices"][0]["message"]["content"])
```

</Tab>
<Tab language="javascript" title="JavaScript">

```javascript
import axios from "axios";

// Step 1: Transcribe the audio
const base_url = "https://api.assemblyai.com";
const headers = { authorization: "<YOUR_API_KEY>" };

const audio_url = "https://assembly.ai/meeting.mp4";
const data = { audio_url };

const response = await axios.post(base_url + "/v2/transcript", data, {
  headers,
});
const transcript_id = response.data.id;
const polling_endpoint = base_url + `/v2/transcript/${transcript_id}`;

let transcript;
while (true) {
  transcript = (await axios.get(polling_endpoint, { headers })).data;
  if (transcript.status === "completed") break;
  if (transcript.status === "error")
    throw new Error(`Transcription failed: ${transcript.error}`);
  await new Promise((resolve) => setTimeout(resolve, 3000));
}

// Step 2: Create structured Q&A prompt
const questions = [
  "What are the top level KPIs for engineering? (KPI stands for key performance indicator)",
  "How many days has it been since the data team has gotten updated metrics? (Choose from: 1, 2, 3, 4, 5, 6, 7, more than 7)",
];

const prompt = `Answer the following questions based on the meeting transcript. Format your response as:
Q1: [question]
A1: [answer]
Q2: [question] 
A2: [answer]

Questions:
${questions.map((q, i) => `${i + 1}. ${q}`).join("\n")}

Context: This is a GitLab meeting to discuss logistics.`;

// Step 3: Send to LLM Gateway
const llm_gateway_data = {
  model: "claude-sonnet-4-5-20250929",
  messages: [
    { role: "user", content: `${prompt}\n\nTranscript: ${transcript.text}` },
  ],
  max_tokens: 1000,
};

const result = await axios.post(
  "https://llm-gateway.assemblyai.com/v1/chat/completions",
  llm_gateway_data,
  { headers }
);
console.log(result.data.choices[0].message.content);
```

</Tab>
</Tabs>

## Advanced Q&A with LLM Gateway

For more sophisticated question-answering scenarios, you can create detailed prompts that guide the LLM to produce highly structured and context-aware responses using LLM Gateway's flexible chat completions API.

## More Q&A prompt examples

Try any of these prompts to get started:

| Use case               | Example prompt                                                            |
| ---------------------- | ------------------------------------------------------------------------- |
| Question and answer    | <i>"Identify any patterns or trends based on the transcript"</i>          |
| Closed-ended questions | <i>"Did the customer express a positive sentiment in the phone call?"</i> |
| Sentiment analysis     | <i>"What was the emotional sentiment of the phone call?"</i>              |

For more examples and techniques, experiment with different prompt structures and try various LLM models available through LLM Gateway.

## API reference

- [LLM Gateway Overview](/docs/llm-gateway/overview)
- [Basic Chat Completions](/docs/llm-gateway/chat-completions)

## Improve the results

To improve your Q&A results with LLM Gateway:

- **Experiment with different models**: Try Claude, GPT, or Gemini models to find the best fit for your use case
- **Refine your prompts**: Use clear, specific instructions and examples to guide the model's responses
- **Add context**: Provide relevant background information to help the model understand the domain
- **Structure your questions**: Use consistent formatting to get more predictable outputs
