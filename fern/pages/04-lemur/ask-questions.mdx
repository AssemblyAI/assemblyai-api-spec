---
title: 'Ask questions about your audio data'
description: 'Ask questions about your audio data with Large Language Models.'
---


  





  
In this guide, you'll learn how to use LeMUR to ask questions and get answers about your audio data.

<Tip>
If you want a Quickstart, see [Apply LLMs to audio files](/docs/getting-started/apply-ll-ms-to-audio-files).
</Tip>

<Note title="Before you start">
To use LeMUR, you need an <a href="https://www.assemblyai.com/dashboard/signup" target="_blank">AssemblyAI account</a> with a credit card set up.
</Note>





## Basic Q&A example

If you want to send a custom prompt to the LLM, you can use the [LeMUR Task](https://assemblyai.com/docs/api-reference/lemur/task) and apply the model to your transcribed audio files.

<Tabs groupId="language">
  <Tab language="python" title="Python" default>
  
  To ask question about your audio data, define a prompt with your questions and call `transcript.lemur.task()`. The underlying `transcript` is automatically used as additional context for the model.

```python {12-13,15-18}
import assemblyai as aai

aai.settings.api_key = "<YOUR_API_KEY>"

# Step 1: Transcribe an audio file.
# audio_file = "./local_file.mp3"
audio_file = "https://assembly.ai/sports_injuries.mp3"

transcriber = aai.Transcriber()
transcript = transcriber.transcribe(audio_file)

# Step 2: Define a prompt with your question(s).
prompt = "What is a runner's knee?"

# Step 3: Apply LeMUR.
result = transcript.lemur.task(
    prompt, final_model=aai.LemurModel.claude3_5_sonnet
)

print(result.response)
```

  </Tab>
  <Tab language="typescript" title="TypeScript">
  
  To ask question about your audio data, define a prompt with your questions and call `client.lemur.task()`. Use the `transcript_ids` parameter to send one or more transcripts as additional context for the model.

```ts {14-15,17-22}
import { AssemblyAI } from 'assemblyai'

const client = new AssemblyAI({
  apiKey: '<YOUR_API_KEY>'
})

const run = async () => {
  // Step 1: Transcribe an audio file.
  //const audioFile = './local_file.mp3'
  const audioFile =
    'https://assembly.ai/sports_injuries.mp3'
  const transcript = await client.transcripts.transcribe({ audio: audioFile })

  // Step 2: Define a prompt with your question(s).
  const prompt = "What is a runner's knee?"

  // Step 3: Apply LeMUR.
  const { response } = await client.lemur.task({
    transcript_ids: [transcript.id],
    prompt,
    final_model: 'anthropic/claude-3-5-sonnet'
  })

  console.log(response)
}

run()
```

  </Tab>
  <Tab language="golang" title="Go">
  
  To summarize the content in your audio data, define a summarization prompt and call `client.LeMUR.Task()`. Use the `TranscriptIDs` parameter to send one or more transcripts as additional context for the model.

```go {19-20,22-28}
package main

import (
    "context"
    "fmt"

    aai "github.com/AssemblyAI/assemblyai-go-sdk"
)

func main() {
    ctx := context.Background()

    client := aai.NewClient("<YOUR_API_KEY>")

    // Step 1: Transcribe an audio file. For local files see our Getting Started guides.
    audioURL := "https://assembly.ai/sports_injuries.mp3"
    transcript, _ := client.Transcripts.TranscribeFromURL(ctx, audioURL, nil)

    // Step 2: Define a prompt with your question.
    prompt := "What is a runner's knee?"

    // Step 3: Apply LeMUR.
    var params aai.LeMURTaskParams
    params.Prompt = aai.String(prompt)
    params.TranscriptIDs = []string{aai.ToString(transcript.ID)}
    params.FinalModel = "anthropic/claude-3-5-sonnet"

    result, _ := client.LeMUR.Task(ctx, params)

    fmt.Println(*result.Response)
}
```

  </Tab>
  <Tab language="java" title="Java">
  
  To ask question about your audio data, define a prompt with your questions and call `client.lemur().task()`. Use the `transcriptIds` parameter to send one or more transcripts as additional context for the model.

```java {17-18,20-25}
import com.assemblyai.api.AssemblyAI;
import com.assemblyai.api.resources.transcripts.types.*;
import com.assemblyai.api.resources.lemur.requests.*;
import java.util.List;

public final class App {
    public static void main(String[] args) {

        AssemblyAI client = AssemblyAI.builder()
                .apiKey("<YOUR_API_KEY>")
                .build();

        // Step 1: Transcribe an audio file. For local files see our Getting Started guides.
        String audioUrl = "https://assembly.ai/sports_injuries.mp3";
        Transcript transcript = client.transcripts().transcribe(audioUrl);

        // Step 2: Define a prompt with your question(s).
        String prompt = "What is a runner's knee?";

        // Step 3: Apply LeMUR.
        var params = LemurTaskParams.builder()
                .prompt(prompt)
                .transcriptIds(List.of(transcript.getId()))
                .finalModel(LemurModel.ANTHROPIC_CLAUDE3_5_SONNET)
                .build();

        var response = client.lemur().task(params);

        System.out.println(response.getResponse());
    }
}
```

  </Tab>
  <Tab language="csharp" title="C#">
  
  
To ask question about your audio data, define a prompt with your questions and call `client.Lemur.TaskAsync()`. Use the `TranscriptIds` parameter to send one or more transcripts as additional context for the model.

```csharp {13-14,16-22}
using AssemblyAI;
using AssemblyAI.Lemur;
using AssemblyAI.Transcripts;

var client = new AssemblyAIClient("<YOUR_API_KEY>");

// Step 1: Transcribe an audio file. For local files see our Getting Started guides.
var transcript = await client.Transcripts.TranscribeAsync(new TranscriptParams
{
    AudioUrl = "https://assembly.ai/sports_injuries.mp3"
});

// Step 2: Define a prompt with your question(s).
const string prompt = "What is a runner's knee?";

// Step 3: Apply LeMUR.
var lemurTaskParams = new LemurTaskParams
{
    Prompt = prompt,
    TranscriptIds = [transcript.Id],
    FinalModel = LemurModel.AnthropicClaude3_5_Sonnet
};

var response = await client.Lemur.TaskAsync(lemurTaskParams);

Console.WriteLine(response.Response);
```

  </Tab>
  <Tab language="ruby" title="Ruby">
  
  To ask question about your audio data, define a prompt with your questions and call `client.lemur.task()`. Use the `transcript_ids` parameter to send one or more transcripts as additional context for the model.

```ruby {9-10,12-17}
require 'assemblyai'

client = AssemblyAI::Client.new(api_key: '<YOUR_API_KEY>')

# Step 1: Transcribe an audio file. For local files see our Getting Started guides.
audio_url = 'https://assembly.ai/sports_injuries.mp3'
transcript = client.transcripts.transcribe(audio_url: audio_url)

# Step 2: Define a prompt with your question(s).
prompt = "What is a runner's knee?"

# Step 3: Apply LeMUR.
response = client.lemur.task(
  prompt: prompt,
  transcript_ids: [transcript.id],
  final_model: AssemblyAI::Lemur::LemurModel::ANTHROPIC_CLAUDE3_5_SONNET
)

puts response.response
```

  </Tab>
</Tabs>

#### Example output

```plain
Based on the transcript, runner's knee is a condition characterized
by pain behind or around the kneecap. It is caused by overuse,
muscle imbalance and inadequate stretching. Symptoms include pain
under or around the kneecap and pain when walking.
```





## Q&A with specialized endpoint

The [LeMUR Question & Answer function](https://www.assemblyai.com/docs/api-reference/lemur/question-answer) requires no prompt engineering and facilitates more deterministic and structured outputs. See the code examples below for more information on how to use this endpoint.

<Tabs groupId="language">
  <Tab language="python" title="Python" default>

  To use it, define a list of `aai.LemurQuestion` objects. For each question, you can define additional `context` and specify either a `answer_format` or a list of `answer_options`. Additionally, you can define an overall `context`.


```python {8-16,18-22}
import assemblyai as aai

aai.settings.api_key = "<YOUR_API_KEY>"

audio_url = "https://assembly.ai/meeting.mp4"
transcript = aai.Transcriber().transcribe(audio_url)

questions = [
    aai.LemurQuestion(
        question="What are the top level KPIs for engineering?",
        context="KPI stands for key performance indicator",
        answer_format="short sentence"),
    aai.LemurQuestion(
        question="How many days has it been since the data team has gotten updated metrics?",
        answer_options=["1", "2", "3", "4", "5", "6", "7", "more than 7"]),
]

result = transcript.lemur.question(
    final_model=aai.LemurModel.claude3_5_sonnet,
    questions,
    context="A GitLab meeting to discuss logistics"
)

for qa_response in result.response:
    print(f"Question: {qa_response.question}")
    print(f"Answer: {qa_response.answer}")
```

  </Tab>
  <Tab language="typescript" title="TypeScript">

  To use it, define a list of `questions`. For each question, you can define additional `context` and specify either a `answer_format` or a list of `answer_options`. Additionally, you can define an overall `context`.


```ts {12-23,25-30}
import { AssemblyAI } from 'assemblyai'

const client = new AssemblyAI({
  apiKey: '<YOUR_API_KEY>'
})

const audioUrl = 'https://assembly.ai/meeting.mp4'

const run = async () => {
  const transcript = await client.transcripts.transcribe({ audio: audioUrl })

  const questions = [
    {
      question: 'What are the top level KPIs for engineering?',
      context: 'KPI stands for key performance indicator',
      answer_format: 'short sentence'
    },
    {
      question:
        'How many days has it been since the data team has gotten updated metrics?',
      answer_options: ['1', '2', '3', '4', '5', '6', '7', 'more than 7']
    }
  ]

  const { response: qas } = await client.lemur.questionAnswer({
    transcript_ids: [transcript.id],
    final_model: 'anthropic/claude-3-5-sonnet',
    context: 'A GitLab meeting to discuss logistics',
    questions: questions
  })

  for (const { question, answer } of qas) {
    console.log('Question', question)
    console.log('Answer', answer)
  }
}

run()
```

  </Tab>
  <Tab language="golang" title="Go">

  To use it, define a list of `questions`. For each question, you can define additional `context` and specify either a `answer_format` or a list of `answer_options`. Additionally, you can define an overall `context`.


```go {18-28,30-34}
package main

import (
    "context"
    "fmt"

    aai "github.com/AssemblyAI/assemblyai-go-sdk"
)

func main() {
    ctx := context.Background()

    client := aai.NewClient("<YOUR_API_KEY>")

    audioURL := "https://assembly.ai/meeting.mp4"
    transcript, err := client.Transcripts.TranscribeFromURL(ctx, audioURL, nil)

    questions := []aai.LemurQuestion{
        {
            Question: "What are the top level KPIs for engineering?",
            Context:  aai.String("KPI stands for key performance indicator"),
            AnswerFormat: aai.String("short sentence"),
        },
        {
            Question: "How many days has it been since the data team has gotten updated metrics?",
            AnswerOptions: &[]string{"1", "2", "3", "4", "5", "6", "7", "more than 7"},
        },
    }

    var params aai.LemurQuestionParams
    params.Questions = questions
    params.TranscriptIDs = []string{aai.ToString(transcript.ID)}
    params.Context = aai.String("A GitLab meeting to discuss logistics")
    params.FinalModel = aai.String("anthropic/claude-3-5-sonnet")

    result, err := client.LeMUR.Question(ctx, params)


    for _, response := range result.Response {
        fmt.Printf("Question: %s\n", response.Question)
        fmt.Printf("Answer: %s\n\n", response.Answer)
    }
}
```

  </Tab>
  <Tab language="java" title="Java">

  To use it, define a list of `LemurQuestion` objects. For each question, you can define additional `context` and specify either a `answerFormat` or a list of `answerOptions`. Additionally, you can define an overall `context`.


```java {17-31}
import com.assemblyai.api.AssemblyAI;
import com.assemblyai.api.resources.transcripts.types.*;
import com.assemblyai.api.resources.lemur.requests.*;
import java.util.List;

public final class App {
    public static void main(String[] args) {

        AssemblyAI client = AssemblyAI.builder()
                .apiKey("<YOUR_API_KEY>")
                .build();

        String audioUrl = "https://assembly.ai/meeting.mp4";

        Transcript transcript = client.transcripts().transcribe(audioUrl);

        var question1 = LemurQuestion.builder()
                .question("What are the top level KPIs for engineering?")
                .context(LemurQuestionContext.of("KPI stands for key performance indicator"))
                .answerFormat("short sentence").build();

        var question2 = LemurQuestion.builder()
                .question("How many days has it been since the data team has gotten updated metrics?")
                .answerOptions(List.of("1", "2", "3", "4", "5", "6", "7", "more than 7")).build();

        var response = client.lemur().questionAnswer(LemurQuestionAnswerParams.builder()
                .transcriptIds(List.of(transcript.getId()))
                .finalModel(LemurModel.ANTHROPIC_CLAUDE3_5_SONNET)
                .context(LemurBaseParamsContext.of("A GitLab meeting to discuss logistic"))
                .questions(List.of(question1, question2))
                .build());

        for (var qa : response.getResponse()) {
            System.out.println("Question: " + qa.getQuestion());
            System.out.println("Answer: " + qa.getAnswer());
        }
    }
}
```

  </Tab>
  <Tab language="csharp" title="C#">

  To use it, define a list of `LemurQuestion` objects. For each question, you can define additional `Context` and specify either a `AnswerFormat` or a list of `AnswerOptions`. Additionally, you can define an overall `Context`.


```csharp {12-32}
using AssemblyAI;
using AssemblyAI.Lemur;
using AssemblyAI.Transcripts;

var client = new AssemblyAIClient("<YOUR_API_KEY>");

var transcript = await client.Transcripts.TranscribeAsync(new TranscriptParams
{
    AudioUrl = "https://assembly.ai/meeting.mp4"
});

var lemurTaskParams = new LemurQuestionAnswerParams
{
    TranscriptIds = [transcript.Id],
    FinalModel = LemurModel.AnthropicClaude3_5_Sonnet,
    Context = "A GitLab meeting to discuss logistic",
    Questions =
    [
        new LemurQuestion
        {
            Question = "What are the top level KPIs for engineering?",
            Context = "KPI stands for key performance indicator",
            AnswerFormat = "short sentence"
        },
        new LemurQuestion
        {
            Question = "How many days has it been since the data team has gotten updated metrics?",
            Context = "KPI stands for key performance indicator",
            AnswerOptions = ["1", "2", "3", "4", "5", "6", "7", "more than 7"]
        }
    ]
};

var response = await client.Lemur.QuestionAnswerAsync(lemurTaskParams);

foreach (var qa in response.Response)
{
    Console.WriteLine($"Question: {qa.Question}");
    Console.WriteLine($"Answer: {qa.Answer}");
}
```

  </Tab>
  <Tab language="ruby" title="Ruby">

  To use it, define a list of `questions`. For each question, you can define additional `context` and specify either a `answer_format` or a list of `answer_options`. Additionally, you can define an overall `context`.


```ruby {9-25}
require 'assemblyai'

client = AssemblyAI::Client.new(api_key: '<YOUR_API_KEY>')

audio_url = 'https://assembly.ai/meeting.mp4'

transcript = client.transcripts.transcribe(audio_url: audio_url)

response = client.lemur.question_answer(
  transcript_ids: [transcript.id],
  final_model: AssemblyAI::Lemur::LemurModel::ANTHROPIC_CLAUDE3_5_SONNET,
  context: 'A GitLab meeting to discuss logistic',
  questions: [
    {
      question: 'What are the top level KPIs for engineering?',
      context: 'KPI stands for key performance indicator',
      answer_format: 'short sentence'
    },
    {
      question: 'How many days has it been since the data team has gotten updated metrics?',
      context: 'KPI stands for key performance indicator',
      answer_options: ['1', '2', '3', '4', '5', '6', '7', 'more than 7']
    }
  ]
)

response.response.each do |qa|
  printf("Question: %<question>s\n", question: qa.question)
  printf("Answer: %<answer>s\n", answer: qa.answer)
end
```

  </Tab>
</Tabs>





## Custom Q&A example (Advanced)

This example shows how you can run a custom LeMUR task with an advanced prompt to create custom Q&A responses:

<Card icon="book" title="Cookbook: Custom Q&A with LeMUR Task" href="https://github.com/AssemblyAI/cookbook/blob/master/lemur/task-endpoint-structured-QA.ipynb"/>




## More Q&A prompt examples

Try any of these prompts to get started:

| Use case | Example prompt |
| --- | --- |
| Question and answer | <i>"Identify any patterns or trends based on the transcript"</i> |
| Closed-ended questions | <i>"Did the customer express a positive sentiment in the phone call?"</i> |
| Sentiment analysis | <i>"What was the emotional sentiment of the phone call?"</i> |

For more use cases and prompt examples, see [LeMUR examples](/docs/lemur/create-custom-llm-prompts).





## API reference

- [LeMUR Task endpoint](https://assemblyai.com/docs/api-reference/lemur/task)
- [LeMUR Question & Answer endpoint](https://www.assemblyai.com/docs/api-reference/lemur/question-answer)





## Improve the results

To improve the results, see the following resources:

- Optimize your prompt with the [prompt engineering guide](/docs/lemur/prompt-engineering).
- To alter the outcome, see [Change model and parameters](/docs/lemur/change-model-and-parameters).




