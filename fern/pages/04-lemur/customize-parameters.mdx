---
title: "Change model and parameters"
subtitle: "Learn how you can customize LeMUR parameters to alter the outcome."
description: "Analyze your audio files with Large Language Models."
---

## Change the model type

LeMUR features the following LLMs:

- Claude 3.7 Sonnet
- Claude 3.5 Sonnet
- Claude 3.5 Haiku
- Claude 3 Opus
- Claude 3 Haiku
- Claude 3 Sonnet (_Legacy - Sunsetting on 7/21/25_)

You can switch the model by specifying the `final_model` parameter.

<Tabs groupId="language">
  <Tab language="python-sdk" title="Python SDK" default>

```python {3}
result = transcript.lemur.task(
    prompt,
    final_model=aai.LemurModel.claude3_7_sonnet_20250219
)
```

| Model                                                    | SDK Parameter                              | Description                                                                                                                             | Region Availability |
| -------------------------------------------------------- | ------------------------------------------ | --------------------------------------------------------------------------------------------------------------------------------------- | ------------------- |
| **Claude 3.7 Sonnet**                                    | `aai.LemurModel.claude3_7_sonnet_20250219` | The newest and most advanced model featuring enhanced reasoning capabilities. Strong at complex reasoning tasks.                        | US & EU             |
| **Claude 3.5 Sonnet**                                    | `aai.LemurModel.claude3_5_sonnet`          | A mid-tier upgrade balancing power and performance. This uses Anthropic's Claude 3.5 Sonnet model version `claude-3-5-sonnet-20240620`. | US & EU             |
| **Claude 3.5 Haiku**                                     | `aai.LemurModel.claude3_5_haiku_20241022`  | The fastest model in the family, optimized for quick responses while maintaining good reasoning.                                        | US & EU             |
| **Claude 3.0 Opus**                                      | `aai.LemurModel.claude3_opus`              | The most powerful legacy Claude 3 model, excels at complex writing and analysis.                                                        | US only             |
| **Claude 3.0 Haiku**                                     | `aai.LemurModel.claude3_haiku`             | An entry-level, fast legacy model for everyday tasks.                                                                                   | US only             |
| **Claude 3.0 Sonnet** (_Legacy - Sunsetting on 7/21/25_) | `aai.LemurModel.claude3_sonnet`            | A legacy mid-tier model balancing power and speed.                                                                                      | US only             |

  </Tab>
  <Tab language="python" title="Python">

```python {4}
data = {
  "prompt": prompt,
  "transcript_ids": [transcript_id],
  "final_model": "anthropic/claude-3-7-sonnet-20250219"
}

result = requests.post("https://api.assemblyai.com/lemur/v3/generate/task", headers=headers, json=data)
```

| Model                                                    | API Parameter                          | Description                                                                                                                             | Region Availability |
| -------------------------------------------------------- | -------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------- | ------------------- |
| **Claude 3.7 Sonnet**                                    | `anthropic/claude-3-7-sonnet-20250219` | The newest and most advanced model featuring enhanced reasoning capabilities. Strong at complex reasoning tasks.                        | US & EU             |
| **Claude 3.5 Sonnet**                                    | `anthropic/claude-3-5-sonnet`          | A mid-tier upgrade balancing power and performance. This uses Anthropic's Claude 3.5 Sonnet model version `claude-3-5-sonnet-20240620`. | US & EU             |
| **Claude 3.5 Haiku**                                     | `anthropic/claude-3-5-haiku-20241022`  | The fastest model in the family, optimized for quick responses while maintaining good reasoning.                                        | US & EU             |
| **Claude 3.0 Opus**                                      | `anthropic/claude-3-opus`              | The most powerful legacy Claude 3 model, excels at complex writing and analysis.                                                        | US only             |
| **Claude 3.0 Haiku**                                     | `anthropic/claude-3-haiku`             | An entry-level, fast legacy model for everyday tasks.                                                                                   | US only             |
| **Claude 3.0 Sonnet** (_Legacy - Sunsetting on 7/21/25_) | `anthropic/claude-3-sonnet`            | A legacy mid-tier model balancing power and speed.                                                                                      | US only             |

  </Tab>
  <Tab language="typescript-sdk" title="Typescript SDK">

```ts {4}
const { response } = await client.lemur.task({
  transcript_ids: [transcript.id],
  prompt,
  final_model: "anthropic/claude-3-7-sonnet-20250219",
});
```

| Model                                                    | SDK Parameter                          | Description                                                                                                                             | Region Availability |
| -------------------------------------------------------- | -------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------- | ------------------- |
| **Claude 3.7 Sonnet**                                    | `anthropic/claude-3-7-sonnet-20250219` | The newest and most advanced model featuring enhanced reasoning capabilities. Strong at complex reasoning tasks.                        | US & EU             |
| **Claude 3.5 Sonnet**                                    | `anthropic/claude-3-5-sonnet`          | A mid-tier upgrade balancing power and performance. This uses Anthropic's Claude 3.5 Sonnet model version `claude-3-5-sonnet-20240620`. | US & EU             |
| **Claude 3.5 Haiku**                                     | `anthropic/claude-3-5-haiku-20241022`  | The fastest model in the family, optimized for quick responses while maintaining good reasoning.                                        | US & EU             |
| **Claude 3.0 Opus**                                      | `anthropic/claude-3-opus`              | The most powerful legacy Claude 3 model, excels at complex writing and analysis.                                                        | US only             |
| **Claude 3.0 Haiku**                                     | `anthropic/claude-3-haiku`             | An entry-level, fast legacy model for everyday tasks.                                                                                   | US only             |
| **Claude 3.0 Sonnet** (_Legacy - Sunsetting on 7/21/25_) | `anthropic/claude-3-sonnet`            | A legacy mid-tier model balancing power and speed.                                                                                      | US only             |

  </Tab>
  <Tab language="typescript" title="Typescript">

```ts {4}
const data = {
  prompt: prompt,
  transcript_ids: [transcript_id],
  final_model: "anthropic/claude-3-7-sonnet-20250219",
};

const result = await axios.post(
  "https://api.assemblyai.com/lemur/v3/generate/task",
  data,
  { headers }
);
```

| Model                                                    | API Parameter                          | Description                                                                                                                             | Region Availability |
| -------------------------------------------------------- | -------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------- | ------------------- |
| **Claude 3.7 Sonnet**                                    | `anthropic/claude-3-7-sonnet-20250219` | The newest and most advanced model featuring enhanced reasoning capabilities. Strong at complex reasoning tasks.                        | US & EU             |
| **Claude 3.5 Sonnet**                                    | `anthropic/claude-3-5-sonnet`          | A mid-tier upgrade balancing power and performance. This uses Anthropic's Claude 3.5 Sonnet model version `claude-3-5-sonnet-20240620`. | US & EU             |
| **Claude 3.5 Haiku**                                     | `anthropic/claude-3-5-haiku-20241022`  | The fastest model in the family, optimized for quick responses while maintaining good reasoning.                                        | US & EU             |
| **Claude 3.0 Opus**                                      | `anthropic/claude-3-opus`              | The most powerful legacy Claude 3 model, excels at complex writing and analysis.                                                        | US only             |
| **Claude 3.0 Haiku**                                     | `anthropic/claude-3-haiku`             | An entry-level, fast legacy model for everyday tasks.                                                                                   | US only             |
| **Claude 3.0 Sonnet** (_Legacy - Sunsetting on 7/21/25_) | `anthropic/claude-3-sonnet`            | A legacy mid-tier model balancing power and speed.                                                                                      | US only             |

  </Tab>
  <Tab language="csharp" title="C#">

```csharp {5}
var data = new
{
  transcript_ids = transcriptIds,
  prompt = prompt,
  final_model = "anthropic/claude-3-7-sonnet-20250219"
};

var content = new StringContent(JsonSerializer.Serialize(data), Encoding.UTF8, "application/json");
using var response = await httpClient.PostAsync("https://api.assemblyai.com/lemur/v3/generate/task", content);
```

| Model                                                    | API Parameter                          | Description                                                                                                                             | Region Availability |
| -------------------------------------------------------- | -------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------- | ------------------- |
| **Claude 3.7 Sonnet**                                    | `anthropic/claude-3-7-sonnet-20250219` | The newest and most advanced model featuring enhanced reasoning capabilities. Strong at complex reasoning tasks.                        | US & EU             |
| **Claude 3.5 Sonnet**                                    | `anthropic/claude-3-5-sonnet`          | A mid-tier upgrade balancing power and performance. This uses Anthropic's Claude 3.5 Sonnet model version `claude-3-5-sonnet-20240620`. | US & EU             |
| **Claude 3.5 Haiku**                                     | `anthropic/claude-3-5-haiku-20241022`  | The fastest model in the family, optimized for quick responses while maintaining good reasoning.                                        | US & EU             |
| **Claude 3.0 Opus**                                      | `anthropic/claude-3-opus`              | The most powerful legacy Claude 3 model, excels at complex writing and analysis.                                                        | US only             |
| **Claude 3.0 Haiku**                                     | `anthropic/claude-3-haiku`             | An entry-level, fast legacy model for everyday tasks.                                                                                   | US only             |
| **Claude 3.0 Sonnet** (_Legacy - Sunsetting on 7/21/25_) | `anthropic/claude-3-sonnet`            | A legacy mid-tier model balancing power and speed.                                                                                      | US only             |

  </Tab>

  <Tab language="ruby" title="Ruby">

```ruby {3}
request = Net::HTTP::Post.new("https://api.assemblyai.com/lemur/v3/generate/task", headers)
request.body = {
  final_model: "anthropic/claude-3-7-sonnet-20250219",
  prompt: prompt,
  transcript_ids: [transcript_id]
}.to_json

response = http.request(lemur_request)
```

| Model                                                    | API Parameter                          | Description                                                                                                                             | Region Availability |
| -------------------------------------------------------- | -------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------- | ------------------- |
| **Claude 3.7 Sonnet**                                    | `anthropic/claude-3-7-sonnet-20250219` | The newest and most advanced model featuring enhanced reasoning capabilities. Strong at complex reasoning tasks.                        | US & EU             |
| **Claude 3.5 Sonnet**                                    | `anthropic/claude-3-5-sonnet`          | A mid-tier upgrade balancing power and performance. This uses Anthropic's Claude 3.5 Sonnet model version `claude-3-5-sonnet-20240620`. | US & EU             |
| **Claude 3.5 Haiku**                                     | `anthropic/claude-3-5-haiku-20241022`  | The fastest model in the family, optimized for quick responses while maintaining good reasoning.                                        | US & EU             |
| **Claude 3.0 Opus**                                      | `anthropic/claude-3-opus`              | The most powerful legacy Claude 3 model, excels at complex writing and analysis.                                                        | US only             |
| **Claude 3.0 Haiku**                                     | `anthropic/claude-3-haiku`             | An entry-level, fast legacy model for everyday tasks.                                                                                   | US only             |
| **Claude 3.0 Sonnet** (_Legacy - Sunsetting on 7/21/25_) | `anthropic/claude-3-sonnet`            | A legacy mid-tier model balancing power and speed.                                                                                      | US only             |

  </Tab>

  <Tab language="php" title="PHP">

```php {7}
$ch = curl_init("https://api.assemblyai.com/lemur/v3/generate/task");
curl_setopt_array($ch, [
    CURLOPT_RETURNTRANSFER => true,
    CURLOPT_POST => true,
    CURLOPT_HTTPHEADER => $headers,
    CURLOPT_POSTFIELDS => json_encode([
        'final_model' => 'anthropic/claude-3-7-sonnet-20250219',
        'prompt' => $prompt,
        'transcript_ids' => [$transcript_id]
    ])
]);

$response = curl_exec($ch);
```

| Model                                                    | API Parameter                          | Description                                                                                                                             | Region Availability |
| -------------------------------------------------------- | -------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------- | ------------------- |
| **Claude 3.7 Sonnet**                                    | `anthropic/claude-3-7-sonnet-20250219` | The newest and most advanced model featuring enhanced reasoning capabilities. Strong at complex reasoning tasks.                        | US & EU             |
| **Claude 3.5 Sonnet**                                    | `anthropic/claude-3-5-sonnet`          | A mid-tier upgrade balancing power and performance. This uses Anthropic's Claude 3.5 Sonnet model version `claude-3-5-sonnet-20240620`. | US & EU             |
| **Claude 3.5 Haiku**                                     | `anthropic/claude-3-5-haiku-20241022`  | The fastest model in the family, optimized for quick responses while maintaining good reasoning.                                        | US & EU             |
| **Claude 3.0 Opus**                                      | `anthropic/claude-3-opus`              | The most powerful legacy Claude 3 model, excels at complex writing and analysis.                                                        | US only             |
| **Claude 3.0 Haiku**                                     | `anthropic/claude-3-haiku`             | An entry-level, fast legacy model for everyday tasks.                                                                                   | US only             |
| **Claude 3.0 Sonnet** (_Legacy - Sunsetting on 7/21/25_) | `anthropic/claude-3-sonnet`            | A legacy mid-tier model balancing power and speed.                                                                                      | US only             |

  </Tab>
</Tabs>

You can find more information on pricing for each model <a href="https://www.assemblyai.com/pricing" target="_blank">here</a>.

## Change the maximum output size

You can change the maximum output size in tokens by specifying the `max_output_size` parameter.

| Model                                                    | API Parameter                          | Max Tokens Allowed |
| -------------------------------------------------------- | -------------------------------------- | ------------------ |
| **Claude 3.7 Sonnet**                                    | `anthropic/claude-3-7-sonnet-20250219` | 64000              |
| **Claude 3.5 Sonnet**                                    | `anthropic/claude-3-5-sonnet`          | 4000               |
| **Claude 3.5 Haiku**                                     | `anthropic/claude-3-5-haiku-20241022`  | 8192               |
| **Claude 3.0 Opus**                                      | `anthropic/claude-3-opus`              | 4000               |
| **Claude 3.0 Haiku**                                     | `anthropic/claude-3-haiku`             | 4000               |
| **Claude 3.0 Sonnet** (_Legacy - Sunsetting on 7/21/25_) | `anthropic/claude-3-sonnet`            | 4000               |

<br />
<br />

<Tabs groupId="language">
  <Tab language="python-sdk" title="Python SDK" default>
  
```python {4}
result = transcript.lemur.task(
    prompt,
    final_model,
    max_output_size=1000
)
```

  </Tab>

  <Tab language="python" title="Python">

```python {5}
data = {
  "prompt": prompt,
  "transcript_ids": [transcript_id],
  "final_model": final_model,
  "max_output_size": 1000
}

result = requests.post("https://api.assemblyai.com/lemur/v3/generate/task", headers=headers, json=data)
```

  </Tab>
  <Tab language="typescript-sdk" title="Typescript SDK">

```ts {5}
const { response } = await client.lemur.task({
  prompt,
  transcript_ids: [transcript.id],
  final_model,
  max_output_size: 1000,
});
```

  </Tab>
  <Tab language="typescript" title="Typescript">

```ts {5}
const data = {
  transcript_ids: [transcript_id],
  prompt: prompt,
  final_model: final_model,
  max_output_size: 1000,
};

const result = await axios.post(
  "https://api.assemblyai.com/lemur/v3/generate/task",
  data,
  { headers }
);
```

  </Tab>
  <Tab language="csharp" title="C#">

```csharp {6}
var data = new
{
  transcript_ids = transcriptIds,
  prompt = prompt,
  final_model = final_model,
  max_output_size = 1000
};

var content = new StringContent(JsonSerializer.Serialize(data), Encoding.UTF8, "application/json");
using var response = await httpClient.PostAsync("https://api.assemblyai.com/lemur/v3/generate/task", content);
```

  </Tab>
  <Tab language="ruby" title="Ruby">

```ruby {6}
request = Net::HTTP::Post.new("https://api.assemblyai.com/lemur/v3/generate/task", headers)
request.body = {
  transcript_ids: [transcript_id],
  prompt: prompt,
  final_model: final_model,
  max_output_size: 1000
}.to_json

response = http.request(lemur_request)
```

  </Tab>
  <Tab language="php" title="PHP">

```php {10}
$ch = curl_init("https://api.assemblyai.com/lemur/v3/generate/task");
curl_setopt_array($ch, [
    CURLOPT_RETURNTRANSFER => true,
    CURLOPT_POST => true,
    CURLOPT_HTTPHEADER => $headers,
    CURLOPT_POSTFIELDS => json_encode([
        'transcript_ids' => [$transcript_id]
        'prompt' => $prompt,
        'final_model' => $final_model,
        'max_output_size' => 1000
    ])
]);

$response = curl_exec($ch);
```

  </Tab>
</Tabs>

## Change the temperature

You can change the temperature by specifying the `temperature` parameter, ranging from 0.0 to 1.0.

Higher values result in answers that are more creative, lower values are more conservative.

<Tabs groupId="language">
  <Tab language="python-sdk" title="Python SDK" default>

```python {4}
result = transcript.lemur.task(
    prompt,
    final_model,
    temperature=0.7
)
```

  </Tab>

  <Tab language="python" title="Python">

```python {5}
data = {
  "prompt": prompt,
  "transcript_ids": [transcript_id],
  "final_model": final_model,
  "temperature": 0.7
}

result = requests.post("https://api.assemblyai.com/lemur/v3/generate/task", headers=headers, json=data)
```

  </Tab>

  <Tab language="typescript-sdk" title="Typescript SDK">

```ts {5}
const { response } = await client.lemur.task({
  prompt,
  transcript_ids: [transcript.id],
  final_model,
  temperature: 0.7,
});
```

  </Tab>
  <Tab language="typescript" title="Typescript">

```ts {5}
const data = {
  transcript_ids: [transcript_id],
  prompt: prompt,
  final_model: final_model,
  temperature: 0.7,
};

const result = await axios.post(
  "https://api.assemblyai.com/lemur/v3/generate/task",
  data,
  { headers }
);
```

  </Tab>
  <Tab language="csharp" title="C#">

```csharp {6}
var data = new
{
  transcript_ids = transcriptIds,
  prompt,
  final_model = final_model,
  temperature = 0.7
};

var content = new StringContent(JsonSerializer.Serialize(data), Encoding.UTF8, "application/json");
using var response = await httpClient.PostAsync("https://api.assemblyai.com/lemur/v3/generate/task", content);
```

  </Tab>
  <Tab language="ruby" title="Ruby">

```ruby {6}
request = Net::HTTP::Post.new("https://api.assemblyai.com/lemur/v3/generate/task", headers)
request.body = {
  transcript_ids: [transcript_id],
  prompt: prompt,
  final_model: final_model,
  temperature: 0.7
}.to_json

response = http.request(lemur_request)

```

  </Tab>
  <Tab language="php" title="PHP">

```php {10}
$ch = curl_init("https://api.assemblyai.com/lemur/v3/generate/task");
curl_setopt_array($ch, [
    CURLOPT_RETURNTRANSFER => true,
    CURLOPT_POST => true,
    CURLOPT_HTTPHEADER => $headers,
    CURLOPT_POSTFIELDS => json_encode([
        'transcript_ids' => [$transcript_id]
        'prompt' => $prompt,
        'final_model' => $final_model,
        'temperature' => 0.7
    ])
]);

$response = curl_exec($ch);
```

  </Tab>
</Tabs>

## Send customized input

You can submit custom text inputs to LeMUR without transcript IDs. This allows you to customize the input, for example, you could include the speaker labels for the LLM.

To submit custom text input, use the `input_text` parameter

<Tabs groupId="language">
  <Tab language="python-sdk" title="Python SDK" default>

```python {8}
text_with_speaker_labels = ""
for utt in transcript.utterances:
    text_with_speaker_labels += f"Speaker {utt.speaker}:\n{utt.text}\n"

result = aai.Lemur().task(
    prompt,
    final_model,
    input_text=text_with_speaker_labels
)
```

  </Tab>

  <Tab language="python" title="Python">

```python {8}
text_with_speaker_labels = ""
for utt in transcript["utterances"]:
  text_with_speaker_labels += f"Speaker {utt["speaker"]}:\n{utt["text"]}\n"

data = {
  "prompt": prompt,
  "final_model": final_model,
  "input_text": text_with_speaker_labels
}

result = requests.post("https://api.assemblyai.com/lemur/v3/generate/task", headers=headers, json=data)
```

  </Tab>

  <Tab language="typescript-sdk" title="Typescript SDK">

```ts {9}
let textWithSpeakerLabels = "";
for (const utt of transcript.utterances) {
  textWithSpeakerLabels += `Speaker ${utt.speaker}:\n${utt.text}\n`;
}

const { response } = await client.lemur.task({
  prompt: prompt,
  final_model: final_model,
  input_text: textWithSpeakerLabels,
});
```

  </Tab>
  <Tab language="typescript" title="Typescript">

```ts {9}
let textWithSpeakerLabels = "";
for (const utt of transcript.utterances) {
  textWithSpeakerLabels += `Speaker ${utt.speaker}:\n${utt.text}\n`;
}

const data = {
  prompt: prompt,
  final_model: final_model,
  input_text: textWithSpeakerLabels,
};

const result = await axios.post(
  "https://api.assemblyai.com/lemur/v3/generate/task",
  data,
  { headers }
);
```

  </Tab>
  
  <Tab language="csharp" title="C#">

```csharp {11}
string textWithSpeakerLabels = "";
foreach (var utt in transcript.utterances)
{
  textWithSpeakerLabels += $"Speaker {utt.speaker}:\n{utt.text}\n";
}

var data = new
{
  prompt,
  final_model = final_model,
  input_text = textWithSpeakerLabels
};

var content = new StringContent(JsonSerializer.Serialize(data), Encoding.UTF8, "application/json");
using var response = await httpClient.PostAsync("https://api.assemblyai.com/lemur/v3/generate/task", content);
```

  </Tab>
  <Tab language="ruby" title="Ruby">

```ruby {10}
text_with_speaker_labels = ""
transcript["utterances"].each do |utt|
  text_with_speaker_labels += "Speaker #{utt.speaker}:\n#{utt.text}\n"
end

request = Net::HTTP::Post.new("https://api.assemblyai.com/lemur/v3/generate/task", headers)
request.body = {
  prompt: prompt,
  final_model: final_model,
  input_text: text_with_speaker_labels
}.to_json

response = http.request(lemur_request)
```

  </Tab>

  <Tab language="php" title="PHP">

```php {14}
$text_with_speaker_labels = "";
foreach ($transcript['utterances'] as $utt) {
  $text_with_speaker_labels .= "Speaker {$utt['speaker']}:\n{$utt['text']}\n";
}

$ch = curl_init("https://api.assemblyai.com/lemur/v3/generate/task");
curl_setopt_array($ch, [
    CURLOPT_RETURNTRANSFER => true,
    CURLOPT_POST => true,
    CURLOPT_HTTPHEADER => $headers,
    CURLOPT_POSTFIELDS => json_encode([
        'prompt' => $prompt,
        'final_model' => $final_model,
        'input_text' => $text_with_speaker_labels
    ])
]);

$response = curl_exec($ch);
```

  </Tab>
</Tabs>

## Submit multiple transcripts

LeMUR can easily ingest multiple transcripts in a single API call.

You can feed in up to a maximum of 100 files or 100 hours, whichever is lower.

<Tabs groupId="language">
  <Tab language="python-sdk" title="Python SDK" default>

```python {1-7}
transcript_group = transcriber.transcribe_group(
    [
        "https://example.org/customer1.mp3",
        "https://example.org/customer2.mp3",
        "https://example.org/customer3.mp3",
    ],
)

# Or use existing transcripts:
# transcript_group = aai.TranscriptGroup.get_by_ids([id1, id2, id3])

result = transcript_group.lemur.task(
  prompt="Provide a summary of these customer calls."
)
```

  </Tab>

  <Tab language="python" title="Python">

```python {3}
data = {
  "prompt": prompt,
  "transcript_ids": [id1, id2, id3],
  "final_model": final_model,
}

result = requests.post("https://api.assemblyai.com/lemur/v3/generate/task", headers=headers, json=data)
```

  </Tab>
  <Tab language="typescript-sdk" title="Typescript SDK">

```ts {2}
const { response } = await client.lemur.task({
  transcript_ids: [id1, id2, id3],
  prompt: "Provide a summary of these customer calls.",
});
```

  </Tab>
  <Tab language="typescript" title="Typescript">

```ts {2}
const data = {
  transcript_ids: [id1, id2, id3],
  prompt: prompt,
  final_model: final_model,
};

const result = await axios.post(
  "https://api.assemblyai.com/lemur/v3/generate/task",
  data,
  { headers }
);
```

  </Tab>

  <Tab language="csharp" title="C#">

```csharp {3}
var data = new
{
  transcript_ids = new List<string> { id1, id2, id3 },
  prompt = prompt,
  final_model = final_model,
};

var content = new StringContent(JsonSerializer.Serialize(data), Encoding.UTF8, "application/json");
using var response = await httpClient.PostAsync("https://api.assemblyai.com/lemur/v3/generate/task", content);
```

  </Tab>
  <Tab language="ruby" title="Ruby">

```ruby {3}
request = Net::HTTP::Post.new("https://api.assemblyai.com/lemur/v3/generate/task", headers)
request.body = {
  transcript_ids: [id1, id2, id3],
  prompt: prompt,
  final_model: final_model
}.to_json

response = http.request(request)
```

  </Tab>
  <Tab language="php" title="PHP">

```php {7}
$ch = curl_init("https://api.assemblyai.com/lemur/v3/generate/task");
curl_setopt_array($ch, [
    CURLOPT_RETURNTRANSFER => true,
    CURLOPT_POST => true,
    CURLOPT_HTTPHEADER => $headers,
    CURLOPT_POSTFIELDS => json_encode([
        'transcript_ids' => [$id1, $id2, $id3],
        'prompt' => $prompt,
        'final_model' => $final_model
    ])
]);

$response = curl_exec($ch);
```

  </Tab>
</Tabs>

## Delete data

You can delete the data for a previously submitted LeMUR request.

Response data from the LLM, as well as any context provided in the original request will be removed.

<Tabs groupId="language">
  <Tab language="python-sdk" title="Python SDK" default>

```python {3}
result = transcript.lemur.task(prompt)

deletion_response = aai.Lemur.purge_request_data(result.request_id)
```

  </Tab>
  <Tab language="python" title="Python">

```python {5}
# First get the request_id from a previous LeMUR task response
request_id = result.json()["request_id"]

delete_url = f"https://api.assemblyai.com/lemur/v3/{request_id}"
deletion_response = requests.delete(delete_url, headers=headers)
```

  </Tab>
  <Tab language="typescript-sdk" title="TypeScript SDK">

```ts {6}
const { response, request_id } = await client.lemur.task({
  transcript_ids: [transcript.id],
  prompt,
});

const deletionResponse = await client.lemur.purgeRequestData(request_id);
```

  </Tab>
  <Tab language="typescript" title="TypeScript">

```ts {5}
// First get the request_id from a previous LeMUR task response
const request_id = result.data.request_id;

const delete_url = `https://api.assemblyai.com/lemur/v3/${request_id}`;
const deletion_response = await axios.delete(delete_url, { headers });
```

  </Tab>
  <Tab language="csharp" title="C#">

```csharp {5}
// First get the request_id from a previous LeMUR task response
string request_id = lemurResponse.RequestId;

string delete_url = $"https://api.assemblyai.com/lemur/v3/{request_id}";
using var deletion_response = await httpClient.DeleteAsync(delete_url);
```

  </Tab>
  <Tab language="ruby" title="Ruby">

```ruby {6}
# First get the request_id from a previous LeMUR task response
request_id = lemur_result["request_id"]

delete_uri = URI("#{base_url}/lemur/v3/#{request_id}")
delete_request = Net::HTTP::Delete.new(delete_uri, headers)
deletion_response = http.request(delete_request)
```

  </Tab>
  <Tab language="php" title="PHP">

```php {12}
// First get the request_id from a previous LeMUR task response
$request_id = $result['request_id'];

$delete_url = "https://api.assemblyai.com/lemur/v3/{$request_id}";
$ch = curl_init($delete_url);
curl_setopt_array($ch, [
    CURLOPT_RETURNTRANSFER => true,
    CURLOPT_CUSTOMREQUEST => "DELETE",
    CURLOPT_HTTPHEADER => $headers
]);

$deletion_response = curl_exec($ch);
curl_close($ch);
```

  </Tab>
</Tabs>

## API reference

You can find detailed information about all LeMUR API endpoints and parameters in the [LeMUR API reference](https://assemblyai.com/docs/api-reference/lemur).
