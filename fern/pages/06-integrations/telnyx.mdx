---
title: "Integrate Telnyx with AssemblyAI"
description: "Build voice agents with Telnyx and AssemblyAI using Pipecat or LiveKit."
hide-nav-links: true
---

Telnyx is a global connectivity platform that provides programmable voice, messaging, and wireless services. By combining Telnyx with AssemblyAI, you can build real-time voice agents with industry-leading speech recognition accuracy and advanced turn detection.

This guide shows you how to integrate Telnyx with AssemblyAI using two popular voice agent orchestrators: LiveKit and Pipecat.

## LiveKit Telephony Integration

[LiveKit](https://livekit.io/) is a real-time communication platform for building voice, video, and data applications. You can integrate Telnyx SIP trunking with LiveKit to enable phone calls to your voice agents that use AssemblyAI for speech recognition.

### How it works

Telnyx SIP trunks bridge phone calls into LiveKit rooms as special SIP participants. Your LiveKit agent (configured with AssemblyAI STT) connects to the room and interacts with the caller. The flow is:

1. **Phone call** â†’ Telnyx SIP trunk
2. **Telnyx** â†’ LiveKit room (creates SIP participant)
3. **LiveKit agent** (with AssemblyAI STT) â†’ joins room and handles conversation

### Before you begin

- **Telnyx account**: Create an account and purchase a phone number at [telnyx.com](https://telnyx.com)
- **LiveKit project**: Get your SIP URI from your [LiveKit project settings](https://cloud.livekit.io)
- **LiveKit CLI**: Install the [LiveKit CLI](https://docs.livekit.io/home/cli/cli-setup/) on your computer
- **Environment variables**: Configure `LIVEKIT_URL`, `LIVEKIT_API_KEY`, `LIVEKIT_API_SECRET`, and `ASSEMBLYAI_API_KEY`

### Step 1: Configure Telnyx SIP connection

Configure your Telnyx SIP connection to route calls to LiveKit. Follow the detailed setup guide:

[Telnyx LiveKit SIP Configuration Guide](https://developers.telnyx.com/docs/voice/sip-trunking/livekit-configuration-guide)

Key steps:
1. Create a SIP connection in Telnyx Mission Control Portal
2. Set connection type to FQDN and provide your LiveKit SIP URI
3. Configure outbound call authentication (username/password)
4. Assign your phone number(s) to the SIP connection

### Step 2: Configure LiveKit SIP trunks

Create inbound and outbound SIP trunks in LiveKit using the LiveKit CLI.

#### Inbound trunk

Create `inboundTrunk.json`:

```json
{
  "trunk": {
    "name": "Telnyx Inbound Trunk",
    "numbers": ["YOUR_TELNYX_NUMBER"]
  }
}
```

Create the trunk:

```bash
lk sip inbound create inboundTrunk.json
```

Save the returned `SIPTrunkID` for the next step.

#### Dispatch rule

Create `dispatchRule.json` to route incoming calls to your agent:

```json
{
  "name": "Agent Dispatch Rule",
  "trunk_ids": ["YOUR_TRUNK_ID"],
  "rule": {
    "dispatchRuleIndividual": {
      "roomPrefix": "call-"
    }
  },
  "roomConfig": {
    "agents": [{
      "agentName": "my-telephony-agent"
    }]
  }
}
```

Create the dispatch rule:

```bash
lk sip dispatch create dispatchRule.json
```

This automatically dispatches your agent to each incoming call in a new room.

#### Outbound trunk (optional)

For outbound calling, create `outboundTrunk.json`:

```json
{
  "trunk": {
    "name": "Telnyx Outbound Trunk",
    "address": "sip.telnyx.com",
    "numbers": ["YOUR_TELNYX_NUMBER"],
    "auth_username": "YOUR_OUTBOUND_USER",
    "auth_password": "YOUR_OUTBOUND_PASS"
  }
}
```

Create the trunk:

```bash
lk sip outbound create outboundTrunk.json
```

### Step 3: Build your agent with AssemblyAI

Create a LiveKit agent that uses AssemblyAI for speech recognition. Once your SIP trunks and dispatch rules are configured, no special telephony code is requiredâ€”the agent simply joins the room when a call comes in.

#### Prerequisites

Setup and activate a virtual environment:

```bash
python -m venv venv
source venv/bin/activate
```

Install the required dependencies:

```bash
pip install livekit-agents livekit-plugins-assemblyai livekit-plugins-openai livekit-plugins-silero livekit-plugins-rime
```

Download model files:

```bash
python agent.py download-files
```

#### Agent code

Here's a minimal agent using AssemblyAI STT:

```python
import asyncio
from dotenv import load_dotenv
from livekit import rtc
from livekit.agents import AutoSubscribe, JobContext, WorkerOptions, cli, llm
from livekit.agents.voice_assistant import VoiceAssistant
from livekit.plugins import assemblyai, openai, silero, rime

load_dotenv()

async def entrypoint(ctx: JobContext):
    initial_ctx = llm.ChatContext().append(
        role="system",
        text=(
            "You are a helpful voice assistant. Your interface with users will be voice. "
            "Use short and concise responses, avoiding unpronounceable punctuation."
        ),
    )

    await ctx.connect(auto_subscribe=AutoSubscribe.AUDIO_ONLY)

    assistant = VoiceAssistant(
        vad=silero.VAD.load(),
        stt=assemblyai.STT(),
        llm=openai.LLM(),
        tts=rime.TTS(),
        chat_ctx=initial_ctx,
    )

    assistant.start(ctx.room)

    await asyncio.sleep(1)
    await assistant.say("Hello! How can I help you today?", allow_interruptions=True)


if __name__ == "__main__":
    cli.run_app(WorkerOptions(entrypoint_fnc=entrypoint))
```

#### Environment variables

Set the following environment variables:

```bash
export LIVEKIT_URL=<your LiveKit server URL>
export LIVEKIT_API_KEY=<your API Key>
export LIVEKIT_API_SECRET=<your API Secret>
export ASSEMBLYAI_API_KEY=<your AssemblyAI API key>
export OPENAI_API_KEY=<your OpenAI API key>
export RIME_API_KEY=<your Rime API key>
```

#### Run the agent

Start your agent:

```bash
python agent.py dev
```

Now dial your Telnyx phone number to test the integration. The call will be routed through Telnyx â†’ LiveKit â†’ your agent with AssemblyAI speech recognition.

### Testing outbound calls

To test an outbound call, create `sipParticipant.json`:

```json
{
  "sip_trunk_id": "YOUR_OUTBOUND_TRUNK_ID",
  "sip_call_to": "+15105551234",
  "room_name": "test-outbound-call",
  "participant_identity": "outbound-test",
  "participant_name": "Test Call"
}
```

Place the call:

```bash
lk sip participant create sipParticipant.json
```

### Troubleshooting

**Call connects but agent never speaks**: Verify your dispatch rule includes `roomConfig.agents` with the correct `agentName`. Without this, the agent won't be automatically dispatched to the room.

**Audio quality issues**: Check your Telnyx SIP connection settings and ensure proper codec configuration. See the [Telnyx troubleshooting guide](https://developers.telnyx.com/docs/voice/sip-trunking/livekit-configuration-guide#troubleshooting).

### Additional resources

- [LiveKit Telephony Quickstart](https://docs.livekit.io/agents/start/telephony/) - Complete guide to LiveKit telephony integration
- [LiveKit Agent Dispatch](https://docs.livekit.io/agents/server/agent-dispatch/) - Detailed documentation on agent dispatch rules
- [Telnyx SIP Trunk Setup](https://developers.telnyx.com/docs/voice/sip-trunking/get-started) - Full Telnyx SIP trunk documentation

## Pipecat Integration

[Pipecat](https://github.com/pipecat-ai/pipecat) is an open-source framework for building voice and multimodal conversational AI agents. The following example demonstrates how to build a Telnyx voice agent with AssemblyAI's streaming speech-to-text.

### Prerequisites

Install the required dependencies:

```bash
pip install pipecat-ai python-dotenv loguru
```

Set up your environment variables:

```bash
TELNYX_API_KEY=your_telnyx_api_key
ASSEMBLYAI_API_KEY=your_assemblyai_api_key
OPENAI_API_KEY=your_openai_api_key
RIME_API_KEY=your_rime_api_key
```

### Basic Example

Here's a complete example of a Telnyx voice agent using AssemblyAI for speech recognition:

```python
import os
import asyncio
import json

from dotenv import load_dotenv
from loguru import logger

from pipecat.audio.vad.silero import SileroVADAnalyzer
from pipecat.frames.frames import EndFrame, TextFrame, UserStartedSpeakingFrame, UserStoppedSpeakingFrame
from pipecat.pipeline.pipeline import Pipeline
from pipecat.pipeline.runner import PipelineRunner
from pipecat.pipeline.task import PipelineParams, PipelineTask
from pipecat.processors.aggregators.openai_llm_context import (
    OpenAILLMContext,
    OpenAILLMContextFrame,
)
from pipecat.serializers.telnyx import TelnyxFrameSerializer
from pipecat.services.assemblyai.stt import AssemblyAISTTService
from pipecat.services.openai.llm import OpenAILLMService
from pipecat.services.rime.tts import RimeTTSService
from pipecat.transports.websocket.fastapi import (
    FastAPIWebsocketTransport,
    FastAPIWebsocketParams,
)

load_dotenv(override=True)


async def run_bot(websocket):
    """Run the voice agent bot with AssemblyAI STT, Rime TTS, and OpenAI LLM."""

    logger.info("Bot starting, waiting for Telnyx stream info...")

    # Read messages until we get the start event
    stream_id = None
    call_control_id = None
    encoding = "PCMU"

    while not (stream_id and call_control_id):
        try:
            msg_text = await asyncio.wait_for(websocket.receive_text(), timeout=10.0)
            msg_data = json.loads(msg_text)
            event = msg_data.get("event")

            logger.info(f"Received event: {event}")

            if event == "connected":
                logger.info("WebSocket connected to Telnyx")
                continue

            elif event == "start":
                stream_id = msg_data.get("stream_id")
                start_info = msg_data.get("start", {})
                call_control_id = start_info.get("call_control_id")
                media_format = start_info.get("media_format", {})
                encoding = media_format.get("encoding", "PCMU")

                logger.info(f"Got stream info - stream_id: {stream_id}, call_control_id: {call_control_id}, encoding: {encoding}")
                break

            elif event == "media":
                stream_id = msg_data.get("stream_id")
                if stream_id:
                    logger.warning("Got media before start event, using stream_id from media")
                    logger.error("Missing call_control_id - cannot proceed")
                    await websocket.close()
                    return

        except asyncio.TimeoutError:
            logger.error("Timeout waiting for Telnyx start event")
            await websocket.close()
            return
        except Exception as e:
            logger.error(f"Error reading WebSocket message: {e}")
            await websocket.close()
            return

    if not (stream_id and call_control_id):
        logger.error("Failed to get required stream information")
        await websocket.close()
        return

    logger.info(f"Initializing Pipecat with stream_id: {stream_id}")

    # Create Telnyx serializer
    serializer = TelnyxFrameSerializer(
        stream_id=stream_id,
        call_control_id=call_control_id,
        api_key=os.getenv("TELNYX_API_KEY"),
        outbound_encoding=encoding,
        inbound_encoding=encoding,
    )

    logger.info("Creating transport...")

    # Create transport
    transport = FastAPIWebsocketTransport(
        websocket=websocket,
        params=FastAPIWebsocketParams(
            audio_in_enabled=True,
            audio_out_enabled=True,
            add_wav_header=False,
            audio_in_passthrough=True,
            vad_analyzer=SileroVADAnalyzer(),
            serializer=serializer,
        ),
    )

    logger.info("Creating AI services...")

    # STT - AssemblyAI
    stt = AssemblyAISTTService(
        api_key=os.getenv("ASSEMBLYAI_API_KEY")
    )

    # LLM - OpenAI
    llm = OpenAILLMService(
        api_key=os.getenv("OPENAI_API_KEY"),
        model="gpt-4o-mini"
    )

    # TTS - Rime (using mistv2 model with luna voice)
    tts = RimeTTSService(
        api_key=os.getenv("RIME_API_KEY"),
        voice_id="luna",
        model_id="mistv2",
    )

    messages = [
        {
            "role": "system",
            "content": (
                "You are a friendly voice assistant. "
                "Your responses will be read aloud, so keep them concise and conversational. "
                "Avoid special characters or formatting. "
                "Begin by saying: 'Hello! This is an automated call. How can I help you today?' "
            ),
        },
    ]

    # Create OpenAI LLM context
    context = OpenAILLMContext(messages)
    context_aggregator = llm.create_context_aggregator(context)

    logger.info("Building pipeline...")

    pipeline = Pipeline(
        [
            transport.input(),
            stt,
            context_aggregator.user(),
            llm,
            tts,
            transport.output(),
            context_aggregator.assistant(),
        ]
    )

    task = PipelineTask(
        pipeline,
        params=PipelineParams(
            allow_interruptions=True,
            enable_metrics=True,
            enable_usage_metrics=True,
        ),
    )

    @transport.event_handler("on_client_disconnected")
    async def on_client_disconnected(transport, client):
        logger.info("ðŸ“ž Call ended")
        await task.queue_frame(EndFrame())

    async def send_initial_greeting():
        """Send greeting after pipeline is ready."""
        await asyncio.sleep(1.5)  # Wait for pipeline to be fully ready
        logger.info("ðŸŽ¤ Sending initial greeting...")
        await task.queue_frames([
            UserStartedSpeakingFrame(),
            TextFrame("Hello"),  # Simple greeting to trigger response
            UserStoppedSpeakingFrame()
        ])

    logger.info("ðŸš€ Starting voice agent pipeline...")
    runner = PipelineRunner()

    try:
        # Start the greeting task in the background
        asyncio.create_task(send_initial_greeting())
        await runner.run(task)
        logger.info("âœ… Pipeline completed")
    except Exception as e:
        logger.error(f"âŒ Error running pipeline: {e}", exc_info=True)


async def bot(websocket):
    """Main bot entry point."""
    try:
        await run_bot(websocket)
    except Exception as e:
        logger.error(f"Fatal error in bot: {e}", exc_info=True)
        import traceback
        logger.error(f"Traceback: {traceback.format_exc()}")
        try:
            await websocket.close()
        except:
            pass
```

### Advanced Configuration

For production use cases, you can customize AssemblyAI's turn detection and add keyterms for improved accuracy:

```python
from pipecat.services.assemblyai.stt import AssemblyAISTTService, AssemblyAIConnectionParams
from pipecat.processors.audio.audio_buffer_processor import AudioBufferProcessor

# Configure AssemblyAI with custom parameters
stt_params = AssemblyAIConnectionParams(
    encoding="pcm_s16le",  # Linear PCM encoding
    sample_rate=8000,
    end_of_turn_confidence_threshold=0.4,
    min_end_of_turn_silence_when_confident=400,
    max_turn_silence=1280,
    keyterms_prompt=["NPI", "TIN", "CMS", "PTAN", "CPT", "CDT", "DOB", "SSN"]
)

stt = AssemblyAISTTService(
    api_key=os.getenv("ASSEMBLYAI_API_KEY"),
    vad_force_turn_endpoint=False,
    connection_params=stt_params,
)

# Add audio buffer to accumulate chunks for AssemblyAI
# AssemblyAI requires >= 50ms chunks
audio_buffer = AudioBufferProcessor(
    sample_rate=8000,
    num_channels=1,
    buffer_size=1600,  # 100ms worth of 16-bit PCM audio
)

# Update pipeline to include audio buffer
pipeline = Pipeline(
    [
        transport.input(),
        audio_buffer,  # Buffer audio chunks
        stt,
        context_aggregator.user(),
        llm,
        tts,
        transport.output(),
        context_aggregator.assistant(),
    ]
)

# Update task params for 8kHz sample rate
task = PipelineTask(
    pipeline,
    params=PipelineParams(
        allow_interruptions=True,
        enable_metrics=True,
        enable_usage_metrics=True,
        audio_in_sample_rate=8000,
        audio_out_sample_rate=8000,
    ),
)
```

### Key Configuration Notes

When using AssemblyAI with Telnyx and Pipecat:

1. **Audio Encoding**: Use `pcm_s16le` (16-bit linear PCM) for best compatibility with AssemblyAI. Telnyx typically sends audio in PCMU (Î¼-law) format, so the audio buffer processor helps convert and batch the audio appropriately.

2. **Turn Detection**: AssemblyAI has built-in VAD and turn detection. You can either:
   - Use AssemblyAI's turn detection by setting `vad_force_turn_endpoint=False`
   - Use Silero VAD by including `vad_analyzer=SileroVADAnalyzer()` in the transport params

3. **Audio Buffering**: AssemblyAI requires audio chunks of at least 50ms. Use `AudioBufferProcessor` to accumulate Telnyx's 20ms chunks into larger buffers.

4. **Keyterms**: Add domain-specific terms to improve recognition accuracy for specialized vocabulary.

## Resources

- [LiveKit Documentation](https://docs.livekit.io/)
- [Telnyx LiveKit Integration Guide](https://developers.telnyx.com/docs/inference/livekit)
- [Pipecat GitHub Repository](https://github.com/pipecat-ai/pipecat)
- [Pipecat Telnyx Examples](https://github.com/pipecat-ai/pipecat-examples/tree/main/telnyx-chatbot)
- [AssemblyAI Streaming Documentation](/docs/speech-to-text/streaming)
- [AssemblyAI Turn Detection Guide](/docs/speech-to-text/universal-streaming/turn-detection)
