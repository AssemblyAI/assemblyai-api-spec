---
title: "ü¶úÔ∏èüîó LangChain JavaScript Integration with AssemblyAI"
description: "Transcribe audio in LangChain.JS using the built-in integration with AssemblyAI."
hide-nav-links: true
---

To apply LLMs to speech, you first need to transcribe the audio to text, which is what the AssemblyAI integration for LangChain helps you with.

<Note>

Looking for the Python integration?<br />
[Go to the LangChain Python integration](python).

</Note>

## Quickstart

Add [the AssemblyAI SDK](https://github.com/AssemblyAI/assemblyai-node-sdk) to your project:

<Tabs>
  <Tab title="npm">

```bash
npm install langchain @langchain/community
```

  </Tab>
  <Tab title="yarn">

```bash
yarn add langchain @langchain/community
```

  </Tab>
  <Tab title="pnpm">

```bash
pnpm add langchain @langchain/community
```

  </Tab>
  <Tab title="bun">

```bash
bun add langchain @langchain/community
```

  </Tab>
</Tabs>

To use the loaders, you need an [AssemblyAI account](https://www.assemblyai.com/dashboard/signup) and get your AssemblyAI API key from the [dashboard](https://www.assemblyai.com/app/api-keys).
Configure the API key as the `ASSEMBLYAI_API_KEY` environment variable or the `apiKey` options parameter.

```typescript

  AudioTranscriptLoader,
  // AudioTranscriptParagraphsLoader,
  // AudioTranscriptSentencesLoader
} from "@langchain/community/document_loaders/web/assemblyai";

// You can also use a local file path and the loader will upload it to AssemblyAI for you.
const audioUrl = "https://assembly.ai/espn.m4a";

// Use `AudioTranscriptParagraphsLoader` or `AudioTranscriptSentencesLoader` for splitting the transcript into paragraphs or sentences
const loader = new AudioTranscriptLoader(
  {
    audio: audioUrl,
    // any other parameters as documented here: https://www.assemblyai.com/docs/api-reference/transcript#create-a-transcript
  },
  {
    apiKey: "<ASSEMBLYAI_API_KEY>", // or set the `ASSEMBLYAI_API_KEY` env variable
  }
);
const docs = await loader.load();
console.dir(docs, { depth: Infinity });
```

<Info>
  - You can use the `AudioTranscriptParagraphsLoader` or
  `AudioTranscriptSentencesLoader` to split the transcript into paragraphs or
  sentences. - If the `audio_file` is a local file path, the loader will upload
  it to AssemblyAI for you. - The `audio_file` can also be a video file. See the
  [list of supported file types in the FAQ
  doc](https://support.assemblyai.com/articles/2616970375-what-audio-and-video-file-types-are-supported-by-your-api).
  - If you don't pass in the `apiKey` option, the loader will use the
  `ASSEMBLYAI_API_KEY` environment variable. - You can add more properties in
  addition to `audio`. Find the full list of request parameters in the
  [AssemblyAI API docs](https://www.assemblyai.com/docs/api-reference/overview).
</Info>

<br />

You can also use the `AudioSubtitleLoader` to get `srt` or `vtt` subtitles as a document.

```typescript
// You can also use a local file path and the loader will upload it to AssemblyAI for you.
const audioUrl = "https://assembly.ai/espn.m4a";

const loader = new AudioSubtitleLoader(
  {
    audio: audioUrl,
    // any other parameters as documented here: https://www.assemblyai.com/docs/api-reference/transcript#create-a-transcript
  },
  "srt", // srt or vtt
  {
    apiKey: "<ASSEMBLYAI_API_KEY>", // or set the `ASSEMBLYAI_API_KEY` env variable
  }
);

const docs = await loader.load();
console.dir(docs, { depth: Infinity });
```

## Additional resources

You can learn more about using LangChain with AssemblyAI in these resources:

- [The LangChain docs for the AssemblyAI document loader](https://js.langchain.com/docs/integrations/document_loaders/web_loaders/assemblyai_audio_transcription)
- [How to integrate spoken audio into LangChain.js using AssemblyAI](https://www.assemblyai.com/blog/integrate-audio-langchainjs/)
- [Integrate Audio into LangChain.js apps in 5 Minutes](https://www.youtube.com/watch?v=hNpUSaYZIzs)
- [AssemblyAI JavaScript SDK](https://github.com/AssemblyAI/assemblyai-node-sdk)
