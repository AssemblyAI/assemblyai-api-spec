---
title: "Transcribe streaming audio"
subtitle: "Learn how to transcribe streaming audio."
hide-nav-links: true
description: "Learn how to transcribe streaming audio."
---

## Overview

By the end of this tutorial, you'll be able to transcribe audio from your microphone.

<Note>
  By default, Universal-Streaming is set to transcribe English audio. If you'd
  like to enable multilingual streaming (support for English, Spanish, French,
  German, Italian, and Portuguese), enable [multilingual
  transcription](/docs/speech-to-text/universal-streaming/multilingual-transcription)
  instead.
</Note>

<Note>
  Streaming is now available in EU-West via `streaming.eu.assemblyai.com`. To
  use the EU streaming endpoint, replace `streaming.assemblyai.com` with
  `streaming.eu.assemblyai.com` in your connection configuration.
</Note>

## Before you begin

To complete this tutorial, you need:

- [Python](https://www.python.org/) or [Node](https://nodejs.org).

Here's the full sample code of what you'll build in this tutorial:

<Tabs groupId="language">
<Tab language="python-sdk" title="Python SDK" default>

<Code src="snippets/getting-started/transcribe-streaming-audio/python-sdk-1.py" />
</Tab>

<Tab language="python" title="Python">

<Code src="snippets/getting-started/transcribe-streaming-audio/python-1.py" />
</Tab>

<Tab language="javascript-sdk" title="JavaScript SDK" default>

<Code src="snippets/getting-started/transcribe-streaming-audio/javascript-sdk-1.js" />
</Tab>

<Tab language="javascript" title="JavaScript">

<Code src="snippets/getting-started/transcribe-streaming-audio/javascript-1.js" />
</Tab>
</Tabs>

## Step 1: Install and import dependencies

<Tabs groupId="language">
<Tab language="python-sdk" title="Python SDK">

<Steps>
  <Step>

Install the AssemblyAI Python SDK via PIP:

```bash
pip install assemblyai
```

  </Step>
  <Step>

Create a file called `main.py` and import the following packages at the top of your file:

<Code src="snippets/getting-started/transcribe-streaming-audio/python-sdk-2.py" />
  </Step>
</Steps>

</Tab>
<Tab language="python" title="Python">

<Steps>
  <Step>

Install the required Python packages:

```bash
pip install pyaudio websocket-client
```

  </Step>
  <Step>

Create a file called `main.py` and import the following packages at the top of your file:

<Code src="snippets/getting-started/transcribe-streaming-audio/python-2.py" />
  </Step>
</Steps>

</Tab>

<Tab language="javascript-sdk" title="JavaScript SDK" default>

<Steps>
  <Step>

Run `npm init` to create an NPM package, and then install the necessary packages via NPM:

```bash
npm install assemblyai node-record-lpcm16
```

  <Note>
    The module `node-record-lpcm16` requires [SoX](http://sox.sourceforge.net/) and it must be available in your `$PATH`.

    For Mac OS:

    ```bash
    brew install sox
    ```

    For most linux disto's:

    ```bash
    sudo apt-get install sox libsox-fmt-all
    ```

    For Windows:

    [download the binaries](http://sourceforge.net/projects/sox/files/latest/download)

  </Note>

  </Step>
  <Step>

Create a file called `main.js` and import the packages at the top of your file:

```javascript
import { Readable } from "stream";
import { AssemblyAI } from "assemblyai";
import recorder from "node-record-lpcm16";
```

  </Step>
</Steps>

</Tab>

<Tab language="javascript" title="JavaScript">

<Steps>
  <Step>
    Run `npm init` to create an NPM package, and then install the following packages via NPM:

    ```bash
    npm install ws mic
    ```

  </Step>
  <Step>

Create a file called `main.js` and import the packages at the top of your file:

<Code src="snippets/getting-started/transcribe-streaming-audio/javascript-2.js" />
  </Step>
</Steps>

</Tab>
</Tabs>

## Step 2: Configure the API key

In this step, you’ll configure your AssemblyAI API key to authenticate your application and enable access to the streaming transcription service.

<Steps>
<Step>

Browse to <a href="https://www.assemblyai.com/app/api-keys" target="_blank">API Keys</a> in your dashboard, and then copy your API key.

</Step>
<Step>

<Tabs groupId="language">
<Tab language="python-sdk" title="Python SDK">

Configure the SDK to use your API key. Replace `<YOUR_API_KEY>` with your copied API key.

```python

api_key = "<YOUR_API_KEY>"
```

</Tab>
<Tab language="python" title="Python">

Store your API key in a variable. Replace `<YOUR_API_KEY>` with your copied API key.

```python
YOUR_API_KEY = "<YOUR_API_KEY>"
```

</Tab>

<Tab language="javascript-sdk" title="JavaScript SDK" default>

In your file, define an async function and create an SDK client within the function. Configure the client to use your API key by replacing `<YOUR_API_KEY>` with your copied API key.

<Code src="snippets/getting-started/transcribe-streaming-audio/javascript-sdk-2.js" />
</Tab>

<Tab language="javascript" title="JavaScript">

Store your API key in a variable. Replace `<YOUR_API_KEY>` with your copied API key.

```javascript
const API_KEY = "<YOUR_API_KEY>";
```

</Tab>
</Tabs>

</Step>
</Steps>

<Note title="Authenticate with a temporary token">
  If you need to authenticate on the client, you can avoid exposing your API key
  by using [temporary authentication
  tokens](/docs/speech-to-text/universal-streaming#authenticate-with-a-temporary-token).
</Note>

## Step 3: Set up audio and websocket configuration

<Tabs groupId="language">
<Tab language="python-sdk" title="Python SDK">

The Python SDK handles audio configuration automatically. You'll specify the sample rate when connecting to the transcriber. If you don’t set a sample rate, it defaults to 16 kHz.

</Tab>
<Tab language="python" title="Python">
<Steps>
<Step>
Set the parameters that control how your client connects to AssemblyAI’s streaming transcription API. These options determine things like audio sample rate and whether you want punctuation and formatting in your final transcripts.

<Code src="snippets/getting-started/transcribe-streaming-audio/python-3.py" />
</Step>

<Step>
Prepare your audio input settings and recording logic. This configuration controls how microphone data is streamed in real-time:

<Code src="snippets/getting-started/transcribe-streaming-audio/python-4.py" />
</Step>
</Steps>

</Tab>
<Tab language="javascript-sdk" title="JavaScript SDK" default>

Create a new streaming service from the AssemblyAI client and add it to your async function. If you don't set a sample rate, it defaults to 16 kHz.

<Code src="snippets/getting-started/transcribe-streaming-audio/javascript-sdk-3.js" />
For the JavaScript SDK, we will set up the audio configuration in [Step
5](#step-5-connect-and-start-transcription) of this guide.

</Tab>

<Tab language="javascript" title="JavaScript">

<Steps>
<Step>
Set the parameters that control how your client connects to AssemblyAI’s streaming transcription API. These options determine things like audio sample rate and whether you want punctuation and formatting in your final transcripts.

<Code src="snippets/getting-started/transcribe-streaming-audio/javascript-3.js" />
</Step>
<Step>
Prepare your audio input settings and recording logic. This configuration controls how microphone data is streamed in real-time:

<Code src="snippets/getting-started/transcribe-streaming-audio/javascript-4.js" />
</Step>
</Steps>

</Tab>
</Tabs>

## Step 4: Create event handlers

In this step, you’ll define event handlers to manage the different types of events emitted during the streaming session.
The handlers will respond to session lifecycle events, transcription turns, errors, and session termination.

<Tabs groupId="language">

<Tab language="python-sdk" title="Python SDK">
Implement basic event handlers. These handlers let your app respond to key streaming events:

- `on_begin` – Logs when the session starts.
- `on_turn` – Handles each transcription turn and optionally enables formatted turns.
- `on_terminated` – Logs when the session ends and how much audio was processed.
- `on_error` – Captures and prints any errors during streaming.

<Code src="snippets/getting-started/transcribe-streaming-audio/python-sdk-3.py" />
</Tab>
<Tab language="python" title="Python">

Implement basic event handlers. These handlers let your app respond to key streaming events:

- `on_open` – Starts streaming microphone audio in a background thread.
- `on_message` – Handles transcription events like `Begin`, `Turn`, and `Termination`.
- `on_error` – Logs any connection or streaming errors and triggers cleanup.
- `on_close` – Cleans up audio resources and saves a WAV recording when the session ends.

<Code src="snippets/getting-started/transcribe-streaming-audio/python-5.py" />
</Tab>

<Tab language="javascript-sdk" title="JavaScript SDK" default>

Add basic event handlers to your async function. These handlers let your app respond to key streaming events:

- `open` – Triggered when the session starts; logs the session ID.
- `error` – Logs any errors that occur during the session.
- `close` – Triggered when the session ends; logs the close code and reason.
- `turn` – Handles each transcription turn and logs the transcript if available.

<Code src="snippets/getting-started/transcribe-streaming-audio/javascript-sdk-4.js" />
</Tab>

<Tab language="javascript" title="JavaScript">

Create an async function. Within it you'll initialize the the WebSocket and set the event handlers:

- `open` – Triggered when the WebSocket connection is established; starts the microphone stream.
- `message` – Handles incoming messages like `Begin`, `Turn`, and `Termination`, and displays transcripts in real time.
- `error` – Logs connection or message errors and triggers cleanup.
- `close` – Called when the connection closes; logs status and reason, and cleans up resources.

<Code src="snippets/getting-started/transcribe-streaming-audio/javascript-5.js" />
</Tab>
</Tabs>

<Tip title="Message sequence and turn events">
  To get a better understanding of the turn event and the message sequences,
  check out our [Message Sequence
  Breakdown](/docs/speech-to-text/universal-streaming/message-sequence) page.
  This object is how you'll receive your transcripts.
</Tip>

## Step 5: Connect and start transcription

Streaming Speech-to-Text uses [WebSockets](https://developer.mozilla.org/en-US/docs/Web/API/WebSockets_API) to stream audio to AssemblyAI. This requires first establishing a connection to the API.

<Tabs groupId="language">
<Tab language="python-sdk" title="Python SDK">
<Steps>
  <Step>
  In the `main` function create a `client` and connect to the streaming service:

<Code src="snippets/getting-started/transcribe-streaming-audio/python-sdk-4.py" />
  </Step>
  <Step>
  Next, create a microphone stream and begin transcribing audio. Make sure the `sample_rate` matches the value you specified in the `StreamingParameters` when initializing the streaming client.

<Code src="snippets/getting-started/transcribe-streaming-audio/python-sdk-5.py" />
  </Step>
</Steps>

</Tab>
<Tab language="python" title="Python">

<Steps>
<Step>
Create a main execution function and initialize the audio stream.

<Code src="snippets/getting-started/transcribe-streaming-audio/python-6.py" />
</Step>

<Step>
Next, create a WebSocket connection to the streaming service:
<Code src="snippets/getting-started/transcribe-streaming-audio/python-7.py" />
</Step>
</Steps>

</Tab>
<Tab language="javascript-sdk" title="JavaScript SDK" default>

In your async function, connect to the transcriber. Create a new microphone stream and set up the audio configuration after the transcriber connects. The `sampleRate` needs to be the same value used in the [streaming service setting](#step-3-set-up-audio-and-websocket-configuration).

<Code src="snippets/getting-started/transcribe-streaming-audio/javascript-sdk-5.js" />
</Tab>

<Tab language="javascript" title="JavaScript">
<Steps>
<Step>

<Note title="Initializing WebSocket">
  The WebSocket was initialized in at the beginning of the `main` function in
  [Step 4](#step-4-create-event-handlers).
</Note>

</Step>
<Step>
Create the function that initializes the audio stream. This function is called within the `main` function from [Step 4](#step-4-create-event-handlers).

<Code src="snippets/getting-started/transcribe-streaming-audio/javascript-6.js" />
</Step>
</Steps>

</Tab>
</Tabs>

## Step 6: Close the connection

<Tabs groupId="language">
<Tab language="python-sdk" title="Python SDK">

Disconnect the client when you're done:

```python
    finally:
        client.disconnect(terminate=True)
```

The connection will also close automatically when you press Ctrl+C. In both cases, the `.disconnect()` handler will clean up the audio resources.

</Tab>
<Tab language="python" title="Python">

Close the WebSocket connection when you're done:

<Code src="snippets/getting-started/transcribe-streaming-audio/python-8.py" />
The connection will also close automatically when you press Ctrl+C. In both
cases, the `.close()` handler will clean up the audio resources.

</Tab>
<Tab language="javascript-sdk" title="JavaScript SDK" default>
Terminate the session when you're done:

<Code src="snippets/getting-started/transcribe-streaming-audio/javascript-sdk-6.js" />
</Tab>

<Tab language="javascript" title="JavaScript">

Terminate the session when you're done:

<Code src="snippets/getting-started/transcribe-streaming-audio/javascript-7.js" />
The connection will also close automatically when you press Ctrl+C. In both
cases, the `cleanup` function will clean up the audio resources.

</Tab>
</Tabs>

<Warning>
  Note: Pricing is based on session duration so it is very important to close
  sessions properly to avoid unexpected usage and cost.
</Warning>

## Next steps

To learn more about Streaming Speech-to-Text, see the following resources:

- [Streaming Speech-to-Text](/docs/speech-to-text/universal-streaming)
- [WebSocket API reference](https://assemblyai.com/docs/api-reference/streaming-api/streaming-api)

## Need some help?

If you get stuck, or have any other questions, we'd love to help you out. Contact our support team at support@assemblyai.com or create a [support ticket](https://www.assemblyai.com/contact/support).
