---
title: "Transcribe a pre-recorded audio file"
subtitle: "Learn how to transcribe and analyze an audio file."
hide-nav-links: true
description: "Learn how to transcribe and analyze an audio file."
---

## Overview

This guide walks you through transcribing your first audio file with AssemblyAI. You will learn how to submit an audio file for transcription and retrieve the results using the AssemblyAI API.

When transcribing an audio file, there are three main things you will want to specify:

1. The speech models you would like to use (required).
2. The region you would like to use (optional).
3. Other models you would like to use like Speaker Diarization or PII Redaction (optional).

## Prerequisites

Before you begin, make sure you have:

<Tabs groupId="language">
<Tab language="python-sdk" title="Python SDK" default>

- An AssemblyAI API key (get one by signing up at [assemblyai.com](https://assemblyai.com))
- Python 3.8 or later installed
- The `assemblyai` package (`pip install assemblyai`)

</Tab>
<Tab language="python" title="Python">

- An AssemblyAI API key (get one by signing up at [assemblyai.com](https://assemblyai.com))
- Python 3.6 or later installed
- The `requests` library (`pip install requests`)

</Tab>
<Tab language="javascript-sdk" title="JavaScript SDK">

- An AssemblyAI API key (get one by signing up at [assemblyai.com](https://assemblyai.com))
- Node.js 18 or later installed
- The `assemblyai` package (`npm install assemblyai`)

</Tab>
<Tab language="javascript" title="JavaScript">

- An AssemblyAI API key (get one by signing up at [assemblyai.com](https://assemblyai.com))
- Node.js 18 or later installed
- The `axios` and `fs-extra` packages (`npm install axios fs-extra`)

</Tab>
</Tabs>

## Step 1: Set up your API credentials

First, configure your API endpoint and authentication:

<Tabs groupId="language">
<Tab language="python-sdk" title="Python SDK" default>

```python
import assemblyai as aai

aai.settings.base_url = "https://api.assemblyai.com"
aai.settings.api_key = "YOUR_API_KEY"
```

Replace `YOUR_API_KEY` with your actual AssemblyAI API key.

<Info title="Need EU data residency?">
  Use our EU endpoint by changing `base_url` to
  `"https://api.eu.assemblyai.com"`.
</Info>

</Tab>
<Tab language="python" title="Python">

<Code src="snippets/getting-started/transcribe-an-audio-file2/python-1.py" />
Replace `YOUR_API_KEY` with your actual AssemblyAI API key.

<Info title="Need EU data residency?">
  Use our EU endpoint by changing `base_url` to
  `"https://api.eu.assemblyai.com"`.
</Info>

</Tab>
<Tab language="javascript-sdk" title="JavaScript SDK">

<Code src="snippets/getting-started/transcribe-an-audio-file2/javascript-sdk-1.js" />
Replace `YOUR_API_KEY` with your actual AssemblyAI API key.

<Info title="Need EU data residency?">
  Use our EU endpoint by changing `baseUrl` to
  `"https://api.eu.assemblyai.com"`.
</Info>

</Tab>
<Tab language="javascript" title="JavaScript">

<Code src="snippets/getting-started/transcribe-an-audio-file2/javascript-1.js" />
Replace `YOUR_API_KEY` with your actual AssemblyAI API key.

<Info title="Need EU data residency?">
  Use our EU endpoint by changing `baseUrl` to
  `"https://api.eu.assemblyai.com"`.
</Info>

</Tab>
</Tabs>

## Step 2: Specify your audio source

You can transcribe audio files in two ways:

<Tabs groupId="language">
<Tab language="python-sdk" title="Python SDK" default>

**Option A: Use a publicly accessible URL**

```python
audio_file = "https://assembly.ai/wildfires.mp3"
```

**Option B: Use a local file**

```python
audio_file = "./example.mp3"
```

The SDK handles local file uploads automatically.

</Tab>
<Tab language="python" title="Python">

**Option A: Use a publicly accessible URL**

```python
audio_file = "https://assembly.ai/wildfires.mp3"
```

**Option B: Upload a local file**

If your audio file is stored locally, upload it to AssemblyAI first:

<Code src="snippets/getting-started/transcribe-an-audio-file2/python-2.py" />
</Tab>
<Tab language="javascript-sdk" title="JavaScript SDK">

**Option A: Use a publicly accessible URL**

```javascript
const audioFile = "https://assembly.ai/wildfires.mp3";
```

**Option B: Use a local file**

```javascript
const audioFile = "./example.mp3";
```

The SDK handles local file uploads automatically.

</Tab>
<Tab language="javascript" title="JavaScript">

**Option A: Use a publicly accessible URL**

```javascript
const audioFile = "https://assembly.ai/wildfires.mp3";
```

**Option B: Upload a local file**

If your audio file is stored locally, upload it to AssemblyAI first:

<Code src="snippets/getting-started/transcribe-an-audio-file2/javascript-2.js" />
</Tab>
</Tabs>

## Step 3: Submit the transcription request

Create a request with your audio URL and desired configuration options:

<Tabs groupId="language">
<Tab language="python-sdk" title="Python SDK" default>

<Code src="snippets/getting-started/transcribe-an-audio-file2/python-sdk-1.py" />
</Tab>
<Tab language="python" title="Python">

<Code src="snippets/getting-started/transcribe-an-audio-file2/python-3.py" />
</Tab>
<Tab language="javascript-sdk" title="JavaScript SDK">

<Code src="snippets/getting-started/transcribe-an-audio-file2/javascript-sdk-2.js" />
</Tab>
<Tab language="javascript" title="JavaScript">

<Code src="snippets/getting-started/transcribe-an-audio-file2/javascript-3.js" />
</Tab>
</Tabs>

This configuration:

- Uses both the `universal-3-pro` and `universal-2` models for broad language coverage. Learn more about our different speech recognition models [here](/docs/getting-started/models).
- Uses [our Automatic Language Detection model](/docs/pre-recorded-audio/language-detection) to detect the dominant language in the spoken audio.
- Uses [our Speaker Diarization model](/docs/pre-recorded-audio/speaker-diarization) to create turn-by-turn utterances.

<Warning title="Model Pricing">
Pricing can vary based on the speech model used in the request.

If you already have an account with us, you can find your specific pricing on [the Billing page](https://www.assemblyai.com/dashboard/account/billing) of your dashboard. If you are a new customer, you can find general pricing information [here](https://www.assemblyai.com/pricing).

</Warning>

## Step 4: Poll for the transcription result

Transcription happens asynchronously. Poll the API until the transcription is complete:

<Tabs groupId="language">
<Tab language="python-sdk" title="Python SDK" default>

The SDK handles polling automatically. Check the result:

```python
if transcript.status == aai.TranscriptStatus.error:
    raise RuntimeError(f"Transcription failed: {transcript.error}")

print(f"\nFull Transcript:\n\n{transcript.text}")
```

</Tab>
<Tab language="python" title="Python">

<Code src="snippets/getting-started/transcribe-an-audio-file2/python-4.py" />
The polling loop checks the transcription status every 3 seconds and prints the
full transcript once processing is complete.

</Tab>
<Tab language="javascript-sdk" title="JavaScript SDK">

The SDK handles polling automatically. Check the result:

<Code src="snippets/getting-started/transcribe-an-audio-file2/javascript-sdk-3.js" />
</Tab>
<Tab language="javascript" title="JavaScript">

<Code src="snippets/getting-started/transcribe-an-audio-file2/javascript-4.js" />
The polling loop checks the transcription status every 3 seconds and prints the
full transcript once processing is complete.

</Tab>
</Tabs>

## Step 5: Access speaker diarization (optional)

If you enabled speaker labels, you can access the speaker-separated utterances:

<Tabs groupId="language">
<Tab language="python-sdk" title="Python SDK" default>

```python
for utterance in transcript.utterances:
    print(f"Speaker {utterance.speaker}: {utterance.text}")
```

</Tab>
<Tab language="python" title="Python">

```python
for utterance in transcript['utterances']:
    print(f"Speaker {utterance['speaker']}: {utterance['text']}")
```

</Tab>
<Tab language="javascript-sdk" title="JavaScript SDK">

```javascript
for (const utterance of transcript.utterances) {
  console.log(`Speaker ${utterance.speaker}: ${utterance.text}`);
}
```

</Tab>
<Tab language="javascript" title="JavaScript">

```javascript
for (const utterance of transcript.utterances) {
  console.log(`Speaker ${utterance.speaker}: ${utterance.text}`);
}
```

</Tab>
</Tabs>

## Complete example

Here is the full working code:

<Tabs groupId="language">
<Tab language="python-sdk" title="Python SDK" default>

<Code src="snippets/getting-started/transcribe-an-audio-file2/python-sdk-2.py" />
</Tab>
<Tab language="python" title="Python">

<Code src="snippets/getting-started/transcribe-an-audio-file2/python-5.py" />
</Tab>
<Tab language="javascript-sdk" title="JavaScript SDK">

<Code src="snippets/getting-started/transcribe-an-audio-file2/javascript-sdk-4.js" />
</Tab>
<Tab language="javascript" title="JavaScript">

<Code src="snippets/getting-started/transcribe-an-audio-file2/javascript-5.js" />
</Tab>
</Tabs>

## Next steps

Now that you have transcribed your first audio file:

- Learn how you can do even more with Universal-3-Pro with [prompting](https://www.assemblyai.com/docs/getting-started/universal-3-pro#prompting)
- Explore [our Speech Understanding features](https://www.assemblyai.com/products/speech-understanding) for more ways to analyze your audio data
- Learn more about searching, summarizing, or asking questions on your transcript with [our LLM Gateway feature](/docs/llm-gateway/overview)
- Find out how to use [webhooks](/docs/deployment/webhooks) to get notified when your transcripts are ready

For more information, check out the full [API reference documentation](https://www.assemblyai.com/docs).
