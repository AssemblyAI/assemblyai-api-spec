---
title: "Best Practices for Building Medical Scribes"
description: "Complete guide for building medical scribes with AssemblyAI"
---

## Introduction

Building a robust medical scribe requires careful consideration of accuracy, latency, speaker identification, and real-time capabilities while maintaining HIPAA compliance and clinical documentation standards. This guide addresses common questions and provides practical solutions for both post-visit and live encounter transcription scenarios.

## Why AssemblyAI for Medical Scribes?

AssemblyAI stands out as the premier choice for medical scribes with several key advantages:

### Industry-Leading Accuracy with Pre-recorded Audio

- **Slam-1 model** delivers exceptional accuracy for medical terminology and clinical documentation
- **2.9% speaker diarization error rate** for precise attribution between provider and patient
- Comprehensive LLM Gateway integration for intelligent post-processing into structured clinical notes

### Real-Time Streaming Advantages

As medical scribes evolve toward real-time documentation, AssemblyAI's Universal-Streaming model offers significant benefits:

- **Ultra-low latency (~300ms)** enables live transcription during patient encounters
- **Format turns** feature provides structured, speaker-aware output in real-time
- **Keyterms prompt** allows providing medical context and patient history to improve accuracy

### End-to-End Voice AI Platform

Unlike fragmented solutions, AssemblyAI provides a unified API for:

- Transcription with speaker diarization (provider vs. patient)
- Medical terminology recognition and contextual understanding
- HIPAA-compliant PII redaction on both text and audio
- Post-processing workflows with LLM Gateway - from SOAP notes to completely custom clinical documentation
- Real-time and batch processing in a single platform
- Compliance and Security built for medical workloads (BAA, HIPAA, DPA, etc.)

## When Should I Use Pre-recorded vs Streaming for Medical Scribes?

Understanding when to use async (pre-recorded) versus streaming is critical for clinical workflows.

### Use Pre-recorded (Slam-1) when:

**Post-visit documentation** - Encounter already happened, need highest accuracy

- **Maximum accuracy required** - Slam-1 has highest medical terminology accuracy
- **Complex medical terminology** - Rare medications, genetic conditions, specialized procedures
- **HIPAA compliance critical** - Full PII redaction with audio de-identification
- **Structured note generation** - SOAP notes, H&P, discharge summaries via LLM Gateway
- **Quality assurance** - Review and editing workflow needed
- **Specialty documentation** - Oncology, cardiology, neurology with complex terminology
- **Speaker diarization needed** - Automatic provider vs. patient separation

**Best for:** Post-visit SOAP notes, specialist consultations, hospital discharge summaries, quality review

### Use Streaming (Universal-Streaming) When:

**Live encounter documentation** - Real-time transcription during patient visit

- **Immediate documentation** - No delay between encounter and note
- **Telemedicine visits** - Document while seeing patient virtually
- **Emergency department** - Fast-paced, immediate documentation needed
- **Primary care visits** - Standard encounters with common terminology
- **Real-time review** - Provider can review and correct during visit
- **Ambient documentation** - Microphone running throughout encounter

**Best for:** Telemedicine, primary care visits, ED encounters, real-time clinical decision support

### Hybrid Approach (Recommended)

Many medical scribes use **both**:

1. **Streaming during visit** - Real-time documentation, immediate review by provider
2. **Slam-1 post-processing** - Run audio through Slam-1 after visit for:
   - Highest accuracy verification
   - Complex terminology correction
   - Complete HIPAA compliance workflow
   - Final structured note generation
   - Speaker diarization (provider vs. patient)

**Example workflow:**

- Provider sees patient â†’ Streaming captures real-time notes
- Visit ends â†’ Audio sent to Slam-1 for final high-accuracy transcription
- LLM Gateway generates structured SOAP note from high-accuracy transcript
- Provider reviews and signs final note

This gives real-time utility during visits while ensuring maximum accuracy for official documentation.

## What Languages and Features for a Medical Scribe?

### Pre-Recorded doctor patient visits (Slam-1)

**Languages:**
For post-visit documentation, Slam-1 supports English for the highest accuracy transcription. If you want to use other languages, Universal is a suitable alternative.

**Core Features**:

- Speaker diarization (provider-patient separation)
- Automatic formatting, punctuation, and capitalization
- Keyterms Prompting for medical specialties and conditions
- Ability to prompt on related medical terms and improve the accuracy of others (for example, `ibuprofen` improving `naproxen`)

**Speech Understanding Models**:

- Entity detection for medications, conditions, and procedures
- Sentiment analysis for patient experience insights
- Speaker identification for separating doctor and patient in a visit

**Guardrails**:

- PII redaction on text and audio for HIPAA compliance

### Real-Time Streaming (Universal-Streaming)

**Languages**:
For live encounter transcription, Universal-Streaming supports:

- English model optimized for medical contexts
- Multilingual model for visits in other languages or with code switching (English, Spanish, German, French, Portuguese, Italian)
- Post-processing LLM Gateway tight integration for increasing medical accuracy

**Streaming-Specific Features**:

- Partial and final transcripts for responsive documentation
- Format turns for structured provider-patient dialogue
- Keyterms Prompt for patient history and current medications
- End-of-utterance detection for natural clinical conversation flow
- Post-processing LLM Gateway integration for increasing medical accuracy

**Recommended approach:** Use streaming for real-time documentation, then run through Slam-1 post-visit for accurate speaker-labeled final notes.

### Coming Soon

- Medical model which packages up the best ways to contextually influence transcript output
- Multilingual Slam-1, especially important for multilingual medical conversations to improve accuracy

## How Can I Get Started Building a Post-Visit Medical Scribe?

Here's a complete example implementing async transcription with Slam-1:

```python
import assemblyai as aai
import asyncio
from typing import Dict, List
from assemblyai.types import (
    SpeakerOptions,
    PIIRedactionPolicy,
    PIISubstitutionPolicy,
)

# Configure API key
aai.settings.api_key = "your_api_key_here"

async def transcribe_encounter_async(audio_source: str) -> Dict:
    """
    Asynchronously transcribe a medical encounter with Slam-1

    Args:
        audio_source: Either a local file path or publicly accessible URL
    """
    # Configure comprehensive medical transcription
    config = aai.TranscriptionConfig(
        speech_model=aai.SpeechModel.slam_1,

        # Diarize provider and patient
        speaker_labels=True,
        speakers_expected=2,  # Typically provider and patient

        # Punctuation and Formatting
        punctuate=True,
        format_text=True,

        # Boost accuracy of medical terminology
        keyterms_prompt=[
            # Patient-specific context
            "hypertension", "diabetes mellitus type 2", "metformin",

            # Specialty-specific terms
            "auscultation", "palpation", "differential diagnosis",
            "chief complaint", "review of systems", "physical examination",

            # Common medications
            "lisinopril", "atorvastatin", "levothyroxine",

            # Procedure terms
            "electrocardiogram", "complete blood count", "hemoglobin A1c"
        ],

        # Speech understanding for medical documentation
        entity_detection=True,  # Extract medications, conditions, procedures
        redact_pii=True,  # HIPAA compliance
        redact_pii_policies=[
            PIIRedactionPolicy.person_name,
            PIIRedactionPolicy.date_of_birth,
            PIIRedactionPolicy.phone_number,
            PIIRedactionPolicy.email_address,
        ],
        redact_pii_sub=PIISubstitutionPolicy.hash,
        redact_pii_audio=True  # Create HIPAA-compliant audio
    )

    # Create async transcriber
    transcriber = aai.Transcriber()

    try:
        # Submit transcription job - works with both file paths and URLs
        transcript = await asyncio.to_thread(
            transcriber.transcribe,
            audio_source,
            config=config
        )

        # Check status
        if transcript.status == aai.TranscriptStatus.error:
            raise Exception(f"Transcription failed: {transcript.error}")

        # Process speaker-labeled utterances
        print("\n=== PROVIDER-PATIENT DIALOGUE ===\n")

        for utterance in transcript.utterances:
            # Format timestamp
            start_time = utterance.start / 1000  # Convert to seconds
            end_time = utterance.end / 1000

            # Identify speaker role
            speaker_label = "Provider" if utterance.speaker == "A" else "Patient"

            # Print formatted utterance
            print(f"[{start_time:.1f}s - {end_time:.1f}s] {speaker_label}:")
            print(f"  {utterance.text}")
            print(f"  Confidence: {utterance.confidence:.2%}\n")

        # Extract clinical entities
        if transcript.entities:
            print("\n=== CLINICAL ENTITIES DETECTED ===\n")
            medications = [e for e in transcript.entities if e.entity_type == "medication"]
            conditions = [e for e in transcript.entities if e.entity_type == "medical_condition"]
            procedures = [e for e in transcript.entities if e.entity_type == "medical_procedure"]

            if medications:
                print("Medications:", ", ".join([m.text for m in medications]))
            if conditions:
                print("Conditions:", ", ".join([c.text for c in conditions]))
            if procedures:
                print("Procedures:", ", ".join([p.text for p in procedures]))

        return {
            "transcript": transcript,
            "utterances": transcript.utterances,
            "entities": transcript.entities,
            "redacted_audio_url": transcript.redacted_audio_url
        }

    except Exception as e:
        print(f"Error during transcription: {e}")
        raise

async def main():
    """
    Example usage for medical encounter
    """
    # Can use either local file or URL
    audio_source = "path/to/patient_encounter.mp3"  # Or use URL
    # audio_source = "https://your-secure-storage.com/encounter.mp3"

    try:
        result = await transcribe_encounter_async(audio_source)

        # Additional processing
        print(f"\nEncounter duration: {result['transcript'].audio_duration} seconds")

        # Could send to LLM Gateway for SOAP note generation here

    except Exception as e:
        print(f"Failed to process encounter: {e}")

if __name__ == "__main__":
    asyncio.run(main())
```

## How Can I Get Started Building a Real-Time Medical Scribe?

Here's a complete example for real-time streaming transcription with LLM post-processing:

```python
import os
import json
import time
import threading
from datetime import datetime
from urllib.parse import urlencode

import pyaudio
import websocket
import requests
from dotenv import load_dotenv
from simple_term_menu import TerminalMenu

# Load environment variables from .env if present
try:
    load_dotenv()
except Exception:
    pass

"""
Medical Scribe â€“ Streaming STT + LLM Gateway Enhancement (SOAP-ready)

What this does
--------------
1) Streams mic audio to AssemblyAI Streaming STT (with formatted turns + keyterms)
2) On every utterance or formatted final turn, calls AssemblyAI LLM Gateway to
   apply *medical* edits (terminology, punctuation, proper nouns, etc.)
3) Logs encounter turns and generates a SOAP note at session end via the Gateway

Quick start
-----------
export ASSEMBLYAI_API_KEY=your_key
# Optional: pick a Gateway model (defaults to Claude 3.5 Haiku)
export LLM_GATEWAY_MODEL=claude-3-5-haiku-20241022

python medical_scribe_llm_gateway.py
"""

# === Config ===
ASSEMBLYAI_API_KEY = os.environ.get("ASSEMBLYAI_API_KEY", "your_api_key_here")

# Medical context and terminology (seed â€“ you can swap at runtime)
MEDICAL_KEYTERMS = [
    "hypertension",
    "diabetes mellitus",
    "coronary artery disease",
    "metformin 1000mg",
    "lisinopril 10mg",
    "atorvastatin 20mg",
    "chief complaint",
    "history of present illness",
    "review of systems",
    "physical examination",
    "assessment and plan",
    "auscultation",
    "palpation",
    "reflexes",
    "range of motion",
]

# WebSocket / STT parameters - CONSERVATIVE SETTINGS FOR MEDICAL
CONNECTION_PARAMS = {
    "sample_rate": 16000,
    "format_turns": True,  # Always true for readable clinical notes

    # MEDICAL SCRIBE CONFIGURATION - Conservative for clinical accuracy
    # Medical conversations have LONG pauses (provider thinking, examining patient, reviewing charts)
    "end_of_turn_confidence_threshold": 0.7,  # Higher confidence (vs 0.4 for voice agents)
    "min_end_of_turn_silence_when_confident": 800,  # Wait much longer (vs 160ms voice agents, 560ms meetings)
    "max_turn_silence": 3600,  # Much longer for clinical thinking pauses

    "keyterms_prompt": json.dumps(MEDICAL_KEYTERMS),  # JSON string
}

API_ENDPOINT_BASE_URL = "wss://streaming.assemblyai.com/v3/ws"
API_ENDPOINT = f"{API_ENDPOINT_BASE_URL}?{urlencode(CONNECTION_PARAMS)}"

# Audio config
FRAMES_PER_BUFFER = 800  # 50ms @ 16kHz
SAMPLE_RATE = CONNECTION_PARAMS["sample_rate"]
CHANNELS = 1
FORMAT = pyaudio.paInt16

# Globals
audio = None
stream = None
ws_app = None
audio_thread = None
stop_event = threading.Event()
encounter_buffer = []  # list of dicts with turn data
last_processed_turn = None

# === Model selection ===
AVAILABLE_MODELS = [
    {"id": "claude-3-haiku-20240307", "name": "Claude 3 Haiku", "description": "Fastest Claude, good for simple tasks"},
    {"id": "claude-3-5-haiku-20241022", "name": "Claude 3.5 Haiku", "description": "Fast with better reasoning"},
    {"id": "claude-sonnet-4-20250514", "name": "Claude Sonnet 4", "description": "Balanced speed & intelligence"},
    {"id": "claude-sonnet-4-5-20250929", "name": "Claude Sonnet 4.5", "description": "Best for coding & agents"},
    {"id": "claude-opus-4-20250514", "name": "Claude Opus 4", "description": "Most powerful, deep reasoning"},
]

def select_model():
    menu_entries = [f"{m['name']} - {m['description']}" for m in AVAILABLE_MODELS]
    terminal_menu = TerminalMenu(
        menu_entries,
        title="Select a model (Use â†‘â†“ arrows, Enter to select):",
        menu_cursor="â¯ ",
        menu_cursor_style=("fg_cyan", "bold"),
        menu_highlight_style=("bg_cyan", "fg_black"),
        cycle_cursor=True,
        clear_screen=False,
        show_search_hint=True,
    )
    idx = terminal_menu.show()
    if idx is None:
        print("Model selection cancelled. Exiting...")
        raise SystemExit(0)
    return AVAILABLE_MODELS[idx]["id"]

selected_model = None

# === Gateway helpers ===

def _gateway_chat(messages, max_tokens=800, temperature=0.2, retries=3, backoff=0.75):
    """Call AssemblyAI LLM Gateway with debug logging and retry."""
    url = "https://llm-gateway.assemblyai.com/v1/chat/completions"
    headers = {
        "Authorization": ASSEMBLYAI_API_KEY,
        "Content-Type": "application/json",
    }
    payload = {
        "model": selected_model,
        "messages": messages,
        "max_tokens": max_tokens,
        "temperature": temperature,
    }

    last = None
    for attempt in range(retries):
        try:
            print(f"[LLM] POST {url} (model={selected_model}, attempt {attempt+1}/{retries})")
            resp = requests.post(url, headers=headers, json=payload, timeout=60)
            print(f"[LLM] â† status {resp.status_code}, bytes {len(resp.content)}")
            last = resp
        except Exception as e:
            if attempt == retries - 1:
                raise RuntimeError(f"Gateway request error: {e}")
            time.sleep(backoff * (attempt + 1))
            continue

        if resp.status_code == 200:
            data = resp.json()
            if not data.get("choices") or not data["choices"][0].get("message"):
                raise RuntimeError(f"Gateway OK but empty body: {str(data)[:200]}")
            return data
        if resp.status_code in (429, 500, 502, 503, 504):
            print(f"[LLM RETRY] {resp.status_code}: {resp.text[:180]}")
            time.sleep(backoff * (attempt + 1))
            continue
        raise RuntimeError(f"Gateway error {resp.status_code}: {resp.text[:300]}")

    raise RuntimeError(
        f"Gateway failed after retries. Last={getattr(last,'status_code','n/a')} {getattr(last,'text','')[:180]}"
    )


def post_process_with_llm(text: str) -> str:
    """Medical editing & normalization using LLM Gateway."""
    system = {
        "role": "system",
        "content": (
            "You are a clinical transcription editor. Keep the speaker's words, "
            "fix medical terminology (drug names, dosages, anatomy), proper nouns, "
            "and punctuation for readability. Preserve meaning and avoid inventing "
            "details. Prefer U.S. clinical style. If a medication or condition is "
            "phonetically close, correct to the most likely clinical term."
        ),
    }

    user = {
        "role": "user",
        "content": (
            "Context keyterms (JSON array):\n" + json.dumps(MEDICAL_KEYTERMS) + "\n\n"
            "Edit this short transcript for medical accuracy and readability.\n\n"
            f"Transcript:\n{text}"
        ),
    }

    try:
        res = _gateway_chat([system, user], max_tokens=600)
        return res["choices"][0]["message"]["content"].strip()
    except Exception as e:
        print(f"[LLM EDIT ERROR] {e}. Falling back to original.")
        return text


def generate_clinical_note():
    """Create a SOAP note from the encounter buffer via Gateway."""
    if not encounter_buffer:
        print("No encounter data to summarize.")
        return

    print("\n=== GENERATING CLINICAL DOCUMENTATION (SOAP) ===")
    # Build a compact transcript string for the LLM
    lines = []
    for e in encounter_buffer:
        if e.get("type") == "utterance":
            lines.append(f"[{e['timestamp']}] {e.get('speaker', 'Speaker')}: {e['text']}")
        elif e.get("type") == "final":
            lines.append(f"[{e['timestamp']}] FINAL: {e['text']}")
    combined = "\n".join(lines)

    system = {
        "role": "system",
        "content": (
            "You are a clinician generating concise, structured notes. "
            "Produce a SOAP note (Subjective, Objective, Assessment, Plan). "
            "Use bullet points, keep it factual, infer reasonable clinical semantics "
            "from the transcript but do NOT invent data. Include medications with dosage "
            "and frequency if mentioned."
        ),
    }
    user = {
        "role": "user",
        "content": (
            "Create a SOAP note from this clinical encounter transcript.\n\n"
            f"Transcript:\n{combined}\n\n"
            "Format strictly as:\n"
            "Subjective:\n- ...\n\nObjective:\n- ...\n\nAssessment:\n- ...\n\nPlan:\n- ...\n"
        ),
    }

    try:
        res = _gateway_chat([system, user], max_tokens=1200)
        soap = res["choices"][0]["message"]["content"].strip()
        fname = f"clinical_note_soap_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
        with open(fname, "w", encoding="utf-8") as f:
            f.write(soap)
        print(f"SOAP note saved: {fname}")
    except Exception as e:
        print(f"[SOAP ERROR] {e}")


# === WebSocket callbacks ===

def on_open(ws):
    print("=" * 80)
    print(f"[{datetime.now().strftime('%H:%M:%S')}] Medical transcription started")
    print(f"Connected to: {API_ENDPOINT_BASE_URL}")
    print(f"Gateway model: {selected_model}")
    print("=" * 80)
    print("\nSpeak to begin. Press Ctrl+C to stop.\n")

    def stream_audio():
        global stream
        while not stop_event.is_set():
            try:
                audio_data = stream.read(FRAMES_PER_BUFFER, exception_on_overflow=False)
                ws.send(audio_data, websocket.ABNF.OPCODE_BINARY)
            except Exception as e:
                if not stop_event.is_set():
                    print(f"Error streaming audio: {e}")
                break

    global audio_thread
    audio_thread = threading.Thread(target=stream_audio, daemon=True)
    audio_thread.start()


def on_message(ws, message):
    global last_processed_turn
    try:
        data = json.loads(message)
        msg_type = data.get("type")

        if msg_type == "Begin":
            print(f"[SESSION] Started - ID: {data.get('id','N/A')}\n")

        elif msg_type == "Turn":
            end_of_turn = data.get("end_of_turn", False)
            turn_is_formatted = data.get("turn_is_formatted", False)
            transcript = data.get("transcript", "")
            utterance = data.get("utterance", "")
            turn_order = data.get("turn_order", 0)
            eot_conf = data.get("end_of_turn_confidence", 0.0)

            # live partials
            if not end_of_turn and transcript:
                print(f"\r[PARTIAL] {transcript[:120]}...", end="", flush=True)

            # If AssemblyAI has finalized a turn AND it's formatted, LLM-edit the transcript
            if end_of_turn and transcript:
                if not turn_is_formatted:
                    # Explicitly skip unformatted finals
                    print("[DEBUG] EOT received (unformatted) â€“ skipping LLM edit, waiting for formatted finalâ€¦")
                elif turn_is_formatted:
                    if last_processed_turn == turn_order:
                        return  # avoid duplicate processing
                    last_processed_turn = turn_order

                    ts = datetime.now().strftime('%H:%M:%S')
                    print("\n[DEBUG] EOT received (formatted). Calling LLMâ€¦")
                    edited = post_process_with_llm(transcript)

                    changed = "(edited)" if edited.strip() != transcript.strip() else "(no change)"
                    print(f"\n[{ts}] [FINAL {changed}]")
                    print(f"  â”œâ”€ Original STT : {transcript}")
                    print(f"  â””â”€ Edited by LLM: {edited}")
                    print(f"Turn: {turn_order} | Confidence: {eot_conf:.2%}")

                    encounter_buffer.append({
                        "timestamp": ts,
                        "text": edited,
                        "original_text": transcript,
                        "turn_order": turn_order,
                        "confidence": eot_conf,
                        "type": "final",
                    })

            # If we also get per-utterance chunks, just log them raw (no LLM) for timeline
            if utterance:
                ts = datetime.now().strftime('%H:%M:%S')

                low = utterance.lower()
                if any(t in low for t in ["medication", "prescribe", "dosage", "mg", "daily"]):
                    print("           ðŸ’Š MEDICATION MENTIONED")
                if any(t in low for t in ["pain", "symptom", "complaint", "problem"]):
                    print("           ðŸ¥ SYMPTOM REPORTED")
                if any(t in low for t in ["diagnose", "assessment", "impression"]):
                    print("           ðŸ“‹ DIAGNOSIS DISCUSSED")

                encounter_buffer.append({
                    "timestamp": ts,
                    "text": utterance,
                    "original_text": utterance,
                    "turn_order": turn_order,
                    "confidence": eot_conf,
                    "type": "utterance",
                })
                print()

        elif msg_type == "Termination":
            dur = data.get("audio_duration_seconds", 0)
            print(f"\n[SESSION] Terminated â€“ Duration: {dur}s")
            save_encounter_transcript()
            generate_clinical_note()

        elif msg_type == "Error":
            print(f"\n[ERROR] {data.get('error', 'Unknown error')}")

    except json.JSONDecodeError as e:
        print(f"Error decoding message: {e}")
    except Exception as e:
        print(f"Error handling message: {e}")


def on_error(ws, error):
    print(f"\n[WEBSOCKET ERROR] {error}")
    stop_event.set()


def on_close(ws, close_status_code, close_msg):
    print(f"\n[WEBSOCKET] Disconnected â€“ Status: {close_status_code}")
    global stream, audio
    stop_event.set()

    if stream:
        if stream.is_active():
            stream.stop_stream()
        stream.close()
        stream = None
    if audio:
        audio.terminate()
        audio = None
    if audio_thread and audio_thread.is_alive():
        audio_thread.join(timeout=1.0)


# === Persist artifacts ===

def save_encounter_transcript():
    if not encounter_buffer:
        print("No encounter data to save.")
        return

    fname = f"encounter_transcript_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
    with open(fname, "w", encoding="utf-8") as f:
        f.write("Clinical Encounter Transcript\n")
        f.write(f"Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write("=" * 80 + "\n\n")
        for e in encounter_buffer:
            if e.get("speaker"):
                f.write(f"[{e['timestamp']}] {e['speaker']}: {e['text']}\n")
            else:
                f.write(f"[{e['timestamp']}] {e['text']}\n")
            f.write(f"Confidence: {e['confidence']:.2%}\n\n")
    print(f"Encounter transcript saved: {fname}")


# === Main ===

def run():
    global audio, stream, ws_app, selected_model

    print("=" * 60)
    print("  ðŸŽ™ï¸  Medical Scribe - STT + LLM Gateway")
    print("=" * 60)
    selected_model = select_model()
    print(f"âœ“ Using model: {selected_model}")

    # Init mic
    audio = pyaudio.PyAudio()
    try:
        stream = audio.open(
            input=True,
            frames_per_buffer=FRAMES_PER_BUFFER,
            channels=CHANNELS,
            format=FORMAT,
            rate=SAMPLE_RATE,
        )
        print("Audio stream opened successfully.")
    except Exception as e:
        print(f"Error opening audio stream: {e}")
        if audio:
            audio.terminate()
        return

    # Connect WS
    ws_headers = [f"Authorization: {ASSEMBLYAI_API_KEY}"]
    ws_app = websocket.WebSocketApp(
        API_ENDPOINT,
        header=ws_headers,
        on_open=on_open,
        on_message=on_message,
        on_error=on_error,
        on_close=on_close,
    )

    ws_thread = threading.Thread(target=ws_app.run_forever, daemon=True)
    ws_thread.start()

    try:
        while ws_thread.is_alive():
            time.sleep(0.1)
    except KeyboardInterrupt:
        print("\n\nCtrl+C received. Stopping...")
        stop_event.set()
        # best-effort terminate
        if ws_app and ws_app.sock and ws_app.sock.connected:
            try:
                ws_app.send(json.dumps({"type": "Terminate"}))
                time.sleep(0.5)
            except Exception as e:
                print(f"Error sending termination: {e}")
        if ws_app:
            ws_app.close()
        ws_thread.join(timeout=2.0)
    finally:
        if stream and stream.is_active():
            stream.stop_stream()
        if stream:
            stream.close()
        if audio:
            audio.terminate()
        print("Cleanup complete. Exiting.")


if __name__ == "__main__":
    run()
```

## How Do I Handle HIPAA Compliance?

HIPAA compliance is mandatory for all medical transcription workflows. Here's how to ensure your medical scribe meets requirements:

### Required HIPAA Guardrails

**1. Business Associate Agreement (BAA)**

- AssemblyAI provides a BAA for healthcare customers
- Required before processing any PHI
- [Contact us](https://www.assemblyai.com/contact/support) to execute BAA

**2. PII Redaction (Required)**

```python
config = aai.TranscriptionConfig(
    # HIPAA-mandated PII redaction
    redact_pii=True,
    redact_pii_policies=[
        # All 18 HIPAA identifiers
        PIIRedactionPolicy.person_name,              # Patient & provider names
        PIIRedactionPolicy.date_of_birth,            # DOB
        PIIRedactionPolicy.date,                     # All dates (except year)
        PIIRedactionPolicy.phone_number,             # Phone numbers
        PIIRedactionPolicy.email_address,            # Email addresses
        PIIRedactionPolicy.medical_record_number,    # MRN, account numbers
        PIIRedactionPolicy.social_security_number,   # SSN
        PIIRedactionPolicy.account_number,           # Financial accounts
        PIIRedactionPolicy.certificate_number,       # License numbers
        PIIRedactionPolicy.vehicle_identifier,       # License plates, VINs
        PIIRedactionPolicy.device_identifier,        # Serial numbers
        PIIRedactionPolicy.web_url,                  # URLs
        PIIRedactionPolicy.ip_address,               # IP addresses
        PIIRedactionPolicy.biometric_identifier,     # Fingerprints, voiceprints
        PIIRedactionPolicy.face_identifier,          # Facial photos
        PIIRedactionPolicy.other_identifier,         # Any other unique identifiers
    ],
    redact_pii_sub=PIISubstitutionPolicy.hash,  # Use stable hash tokens
    redact_pii_audio=True,  # Create de-identified audio file
)
```

**3. Secure Audio Storage**

```python
# HIPAA-compliant storage requirements
# - Encryption at rest (AES-256)
# - Encryption in transit (TLS 1.2+)
# - Access controls and audit logging
# - Automatic deletion after retention period

# Example with AWS S3
audio_url = "https://your-hipaa-compliant-s3.amazonaws.com/encounters/patient123.mp3"
# Ensure bucket has:
# - Server-side encryption enabled
# - Access logging enabled
# - Bucket policy restricting access
# - Lifecycle policy for automatic deletion
```

**4. Access Controls**

```python
# Implement role-based access control
def can_access_encounter(user_role: str, patient_id: str) -> bool:
    """Verify user has permission to access patient encounter"""
    # Check EHR permissions
    # Verify provider-patient relationship
    # Audit access attempt
    return has_clinical_relationship(user_role, patient_id)
```

**5. Audit Logging**

```python
# Log all PHI access
def log_phi_access(user_id: str, patient_id: str, action: str):
    """HIPAA requires audit trail of all PHI access"""
    audit_log.write({
        "timestamp": datetime.now(),
        "user_id": user_id,
        "patient_id": patient_id,
        "action": action,  # "transcribe", "view", "edit", "delete"
        "ip_address": request.remote_addr,
    })
```

For complete HIPAA guidance, see our [Healthcare Compliance Guide](https://www.assemblyai.com/docs/security-compliance).

## What Workflows Can I Build for My AI Medical Scribe?

Use these flags to transform raw medical conversations into structured clinical documentation. Below is plain-English behavior, output shape, and clinical use cases for each option.

### Entity Detection (Medical)

`entity_detection: true`

**What it does:** Extracts medical entities (medications, conditions, procedures, anatomy).

**Output:** Array of `{ entity_type, text, start, end, confidence }`.

**Great for:** Medication reconciliation, problem list updates, procedure coding.

**Notes:** Recognizes brand/generic drug names, medical conditions, surgical procedures.

### Redact PII Text (HIPAA Compliance)

`redact_pii: true`

**What it does:** Scans transcript for Protected Health Information and **replaces** per HIPAA requirements.

**Output:** `text` with PHI replaced; original timing preserved.

**Great for:** De-identification, research datasets, training data.

**Notes:** Covers all 18 HIPAA identifiers when properly configured.

`redact_pii_policies: [person_name, date_of_birth, medical_record_number, phone_number, email_address]`

Restricts redaction scope to key HIPAA identifiers:

- **`person_name`** â€“ patient and provider names
- **`date_of_birth`** â€“ full or partial DOB
- **`medical_record_number`** â€“ MRN, account numbers
- **`phone_number`** â€“ contact numbers
- **`email_address`** â€“ electronic addresses

**Why this set:** Ensures HIPAA compliance while preserving clinical content for documentation.

`redact_pii_sub: hash`

**What it does:** Replaces each PHI span with a **stable hash token**.

**Example:**
`"Patient John Doe, DOB 1/15/1980, MRN 12345"` âŸ¶
`"Patient #2af4â€¦, DOB #7b91â€¦, MRN #e13câ€¦"`

**Benefits:**

- Maintains referential integrity across document
- Preserves sentence structure for NLP/LLM processing
- Prevents reconstruction of original PHI

### Redact PII Audio (HIPAA Compliance)

`redact_pii_audio: true`

**What it does:** Produces HIPAA-compliant audio with PHI portions silenced.

**Output:** `redacted_audio_url` in the transcript payload.

**Great for:** Quality assurance, training, research.

**Notes:** Original audio preserved separately; ensure proper access controls.

### Sentiment Analysis (Patient Experience)

`sentiment_analysis: true`

**What it does:** Analyzes emotional tone of patient responses.

**Output:** Array of `{ text, sentiment, confidence, start, end }`.

**Great for:** Patient satisfaction, pain assessment, mental health screening.

**Notes:** Helpful for identifying distressed or dissatisfied patients.

### End-to-End Clinical Documentation Effect

| Model                     | You get                    | Typical consumer           |
| ------------------------- | -------------------------- | -------------------------- |
| `entity_detection`        | Medical entities extracted | EHR integration, coding    |
| `sentiment_analysis`      | Patient emotion tracking   | Quality metrics, alerts    |
| `redact_pii` (+ policies) | HIPAA-compliant **text**   | Research, QA, training     |
| `redact_pii_sub=hash`     | Stable PHI placeholders    | Analytics & LLM processing |
| `redact_pii_audio`        | De-identified **audio**    | Compliance archives        |

### Clinical Documentation Example

**Original Encounter:**

> "Hi, I'm _Dr. Smith_. _John Doe_, born _1/15/1980_, is here for follow-up. He's taking _metformin 1000mg twice daily_ for his _diabetes_."

**With medical scribe settings:**

- **Text:** "Hi, I'm **#2af4â€¦**. **#7b91â€¦**, born **#e13câ€¦**, is here for follow-up. He's taking _metformin 1000mg twice daily_ for his _diabetes_."
- **Entities:** `[ { type: "medication", text: "metformin 1000mg" }, { type: "condition", text: "diabetes" } ]`
- **Clinical note:** Structured SOAP format via LLM Gateway
- **Redacted audio:** PHI portions silenced for compliance

### LLM Gateway for Clinical Notes

Our LLM Gateway enables transformation of raw transcripts into structured clinical documentation using the same API.

Here's a complete example of generating structured SOAP notes from medical encounter transcripts:

```python
import requests
import json
from typing import Dict, List, Optional

class MedicalSOAPGenerator:
    """Generate structured SOAP notes from medical transcripts using LLM Gateway"""

    def __init__(self, api_key: str):
        self.api_key = api_key
        self.base_url = "https://llm-gateway.assemblyai.com/v1/chat/completions"
        self.headers = {"authorization": api_key}

    def generate_soap_note(self,
                          transcript: str,
                          patient_context: Optional[Dict] = None,
                          visit_type: str = "general") -> Dict:
        """Generate SOAP note from medical transcript"""

        # Build context for the LLM
        context_prompt = self._build_context_prompt(transcript, patient_context, visit_type)

        messages = [
            {
                "role": "system",
                "content": """You are a clinical documentation specialist. Generate a structured SOAP note from the medical encounter transcript.

SOAP Format:
- Subjective: Patient's chief complaint, history of present illness, and symptoms
- Objective: Provider's observations, physical exam findings, vital signs, and test results
- Assessment: Provider's clinical impressions, diagnoses, and differential diagnoses
- Plan: Treatment recommendations, medications, follow-up instructions, and referrals

Guidelines:
- Use medical terminology appropriately
- Include specific details mentioned in the encounter
- Maintain clinical accuracy
- Use bullet points for clarity
- Include medications with dosages and frequencies
- Note any follow-up appointments or referrals"""
            },
            {
                "role": "user",
                "content": context_prompt
            }
        ]

        response = requests.post(
            self.base_url,
            headers=self.headers,
            json={
                "model": "claude-sonnet-4-5-20250929",  # Best for medical reasoning
                "messages": messages,
                "max_tokens": 2000,
                "temperature": 0.1  # Low temperature for consistent medical documentation
            }
        )

        if response.status_code == 200:
            result = response.json()
            soap_content = result["choices"][0]["message"]["content"]

            return {
                "soap_note": soap_content,
                "structured_data": self._extract_structured_data(soap_content),
                "visit_type": visit_type,
                "generation_timestamp": self._get_timestamp()
            }
        else:
            raise Exception(f"LLM Gateway error: {response.status_code} - {response.text}")

    def _build_context_prompt(self, transcript: str, patient_context: Optional[Dict], visit_type: str) -> str:
        """Build comprehensive context prompt for SOAP generation"""

        prompt_parts = [
            f"Generate a SOAP note for a {visit_type} medical encounter.",
            "",
            "MEDICAL ENCOUNTER TRANSCRIPT:",
            transcript,
            ""
        ]

        if patient_context:
            prompt_parts.extend([
                "PATIENT CONTEXT:",
                f"- Age: {patient_context.get('age', 'Not specified')}",
                f"- Known conditions: {', '.join(patient_context.get('conditions', []))}",
                f"- Current medications: {', '.join(patient_context.get('medications', []))}",
                f"- Allergies: {', '.join(patient_context.get('allergies', []))}",
                ""
            ])

        prompt_parts.extend([
            "Please generate a comprehensive SOAP note following the format:",
            "Subjective:",
            "Objective:",
            "Assessment:",
            "Plan:",
            "",
            "Include specific details, medications with dosages, and any follow-up instructions mentioned."
        ])

        return "\n".join(prompt_parts)

    def _extract_structured_data(self, soap_content: str) -> Dict:
        """Extract structured data from SOAP note"""

        sections = {
            "subjective": self._extract_section(soap_content, "Subjective"),
            "objective": self._extract_section(soap_content, "Objective"),
            "assessment": self._extract_section(soap_content, "Assessment"),
            "plan": self._extract_section(soap_content, "Plan")
        }

        return {
            "sections": sections,
            "medications": self._extract_medications(soap_content),
            "diagnoses": self._extract_diagnoses(soap_content),
            "follow_up": self._extract_follow_up(soap_content)
        }

    def _extract_section(self, content: str, section_name: str) -> str:
        """Extract specific SOAP section"""
        import re

        pattern = rf"{section_name}:\s*(.*?)(?=\n\w+:|$)"
        match = re.search(pattern, content, re.DOTALL | re.IGNORECASE)
        return match.group(1).strip() if match else ""

    def _extract_medications(self, content: str) -> List[str]:
        """Extract medication mentions from SOAP note"""
        import re

        # Look for medication patterns
        medication_patterns = [
            r"([A-Z][a-z]+(?:mycin|pril|sartan|pine|zole|statin|pam|zepam))\s+\d+\s*mg",
            r"([A-Z][a-z]+)\s+\d+\s*mg\s+(?:daily|twice daily|BID|TID|QID)",
            r"([A-Z][a-z]+)\s+\d+\s*mg\s+(?:once|twice|three times)\s+(?:daily|a day)"
        ]

        medications = []
        for pattern in medication_patterns:
            matches = re.findall(pattern, content, re.IGNORECASE)
            medications.extend(matches)

        return list(set(medications))  # Remove duplicates

    def _extract_diagnoses(self, content: str) -> List[str]:
        """Extract diagnosis mentions from Assessment section"""
        assessment = self._extract_section(content, "Assessment")

        # Common diagnosis patterns
        diagnosis_patterns = [
            r"([A-Z][a-z]+(?:\s+[A-Z][a-z]+)*)\s+(?:syndrome|disease|disorder|condition)",
            r"(?:diagnosis|impression):\s*([^,\n]+)",
            r"([A-Z][a-z]+(?:\s+[A-Z][a-z]+)*)\s+likely"
        ]

        diagnoses = []
        for pattern in diagnosis_patterns:
            matches = re.findall(pattern, assessment, re.IGNORECASE)
            diagnoses.extend(matches)

        return list(set(diagnoses))

    def _extract_follow_up(self, content: str) -> List[str]:
        """Extract follow-up instructions from Plan section"""
        plan = self._extract_section(content, "Plan")

        follow_up_patterns = [
            r"follow[-\s]up\s+in\s+([^,\n]+)",
            r"return\s+in\s+([^,\n]+)",
            r"recheck\s+in\s+([^,\n]+)",
            r"schedule\s+([^,\n]+)"
        ]

        follow_ups = []
        for pattern in follow_up_patterns:
            matches = re.findall(pattern, plan, re.IGNORECASE)
            follow_ups.extend(matches)

        return list(set(follow_ups))

    def _get_timestamp(self) -> str:
        """Get current timestamp"""
        from datetime import datetime
        return datetime.now().isoformat()

# Example usage
async def generate_clinical_documentation(audio_file: str, patient_id: str):
    """Complete workflow: transcribe + generate SOAP note"""

    config = aai.TranscriptionConfig(
        speech_model=aai.SpeechModel.slam_1,
        speaker_labels=True,
        speakers_expected=2,
        keyterms_prompt=get_patient_medical_history(patient_id),
        entity_detection=True,
        redact_pii=True,
        redact_pii_policies=[...],  # All HIPAA identifiers
    )

    transcript = await transcribe_async(audio_file, config)

    # Step 2: Load patient context from EHR
    patient_context = ehr.get_patient(patient_id)

    # Step 3: Generate SOAP note using LLM Gateway
    soap_generator = MedicalSOAPGenerator(api_key="your_api_key")

    soap_result = soap_generator.generate_soap_note(
        transcript=transcript.text,
        patient_context={
            "age": patient_context.get("age"),
            "conditions": [c.name for c in patient_context.get("conditions", [])],
            "medications": [f"{m.name} {m.dosage}" for m in patient_context.get("medications", [])],
            "allergies": [a.name for a in patient_context.get("allergies", [])]
        },
        visit_type="primary_care_followup"
    )

    # Step 4: Update EHR with structured data
    ehr.update_patient_record(patient_id, {
        "soap_note": soap_result["soap_note"],
        "medications_mentioned": soap_result["structured_data"]["medications"],
        "diagnoses": soap_result["structured_data"]["diagnoses"],
        "follow_up_instructions": soap_result["structured_data"]["follow_up"]
    })

    return {
        "transcript": transcript,
        "soap_note": soap_result["soap_note"],
        "structured_data": soap_result["structured_data"],
        "clinical_entities": transcript.entities
    }

# Example output
"""
Subjective:
- Patient presents with chest pain for 3 days
- Pain is substernal, 7/10 intensity, radiating to left arm
- Associated with shortness of breath and diaphoresis
- No relief with rest or nitroglycerin
- History of hypertension and diabetes mellitus type 2

Objective:
- Vital signs: BP 160/95, HR 95, RR 22, O2 sat 94% on room air
- Physical exam: Diaphoretic, mild distress
- Heart: Regular rate and rhythm, no murmurs
- Lungs: Clear bilaterally
- Extremities: No edema

Assessment:
- Acute coronary syndrome, rule out STEMI
- Hypertension, poorly controlled
- Diabetes mellitus type 2, stable

Plan:
- STAT EKG and troponin levels
- Aspirin 325mg daily
- Atorvastatin 80mg at bedtime
- Cardiology consultation
- Follow up in 1 week
- Return to ED if chest pain worsens
"""
```

#### Advanced SOAP Note Features

```python
class AdvancedSOAPGenerator(MedicalSOAPGenerator):
    """Enhanced SOAP generator with specialty-specific templates"""

    def generate_specialty_soap(self, transcript: str, specialty: str, patient_context: Dict) -> Dict:
        """Generate specialty-specific SOAP notes"""

        specialty_templates = {
            "cardiology": self._cardiology_template(),
            "endocrinology": self._endocrinology_template(),
            "oncology": self._oncology_template(),
            "psychiatry": self._psychiatry_template()
        }

        template = specialty_templates.get(specialty, self._general_template())

        messages = [
            {
                "role": "system",
                "content": f"""You are a {specialty} specialist. Generate a detailed SOAP note using this template:

                {template}

                Focus on {specialty}-specific terminology, assessments, and treatment plans."""
            },
            {
                "role": "user",
                "content": f"Generate a {specialty} SOAP note for this encounter:\n\n{transcript}"
            }
        ]

        response = requests.post(
            self.base_url,
            headers=self.headers,
            json={
                "model": "claude-sonnet-4-5-20250929",
                "messages": messages,
                "max_tokens": 2500,
                "temperature": 0.1
            }
        )

        return response.json()

    def _cardiology_template(self) -> str:
        return """
        Subjective:
        - Chief complaint and cardiac history
        - Chest pain characteristics (quality, location, radiation, timing)
        - Dyspnea, orthopnea, paroxysmal nocturnal dyspnea
        - Palpitations, syncope, presyncope
        - Risk factors (smoking, diabetes, hypertension, family history)

        Objective:
        - Vital signs including orthostatic vitals
        - Cardiovascular exam (heart sounds, murmurs, gallops)
        - Peripheral vascular exam (pulses, edema, JVD)
        - Relevant lab values (troponin, BNP, lipids)
        - Imaging results (EKG, echo, stress test, cath)

        Assessment:
        - Primary cardiac diagnosis
        - Secondary diagnoses
        - Risk stratification (Framingham, ASCVD)

        Plan:
        - Medications with cardiac indications
        - Procedures (cath, echo, stress test)
        - Lifestyle modifications
        - Follow-up and monitoring
        """

    def _endocrinology_template(self) -> str:
        return """
        Subjective:
        - Diabetes symptoms (polyuria, polydipsia, weight changes)
        - Thyroid symptoms (fatigue, weight changes, heat/cold intolerance)
        - Medication adherence and side effects
        - Blood glucose monitoring results

        Objective:
        - Vital signs including BMI
        - Thyroid exam
        - Diabetic foot exam
        - Lab values (HbA1c, glucose, thyroid function)

        Assessment:
        - Diabetes control and complications
        - Thyroid function status
        - Endocrine disorders

        Plan:
        - Medication adjustments
        - Lab monitoring schedule
        - Patient education
        - Specialist referrals
        """

# Usage example for specialty SOAP notes
async def generate_cardiology_soap(transcript: str, patient_id: str):
    """Generate cardiology-specific SOAP note"""

    generator = AdvancedSOAPGenerator(api_key="your_api_key")

    patient_context = ehr.get_patient(patient_id)

    soap_result = generator.generate_specialty_soap(
        transcript=transcript,
        specialty="cardiology",
        patient_context=patient_context
    )

    return soap_result
```

## How Do I Improve the Accuracy of My Medical Scribe?

### Medical Keyterms Strategy

**The most effective approach for medical keyterms:**

#### 1. Patient-Specific Context

```python
# Load from EHR before transcription
patient_keyterms = [
    # Current medications with dosages
    "metformin 1000mg twice daily",
    "lisinopril 20mg once daily",
    "atorvastatin 40mg at bedtime",

    # Known conditions
    "type 2 diabetes mellitus",
    "hypertension stage 2",
    "hyperlipidemia",
    "chronic kidney disease stage 3",

    # Recent procedures
    "colonoscopy March 2024",
    "echocardiogram",

    # Allergies
    "penicillin anaphylaxis",
    "sulfa drugs rash",
]
```

#### 2. Specialty-Specific Terms

```python
# Cardiology
cardiology_terms = [
    "ejection fraction",
    "coronary artery disease",
    "atrial fibrillation",
    "ST elevation",
    "myocardial infarction",
    "cardiac catheterization",
]

# Endocrinology
endocrinology_terms = [
    "hemoglobin A1c",
    "thyroid stimulating hormone",
    "diabetic ketoacidosis",
    "insulin resistance",
]
```

#### 3. Visit-Specific Context

```python
# Load based on appointment type
if appointment_type == "diabetes_followup":
    visit_keyterms = [
        "blood glucose monitoring",
        "hemoglobin A1c",
        "retinopathy screening",
        "foot examination",
        "diabetes self-management",
    ]
```

### Using Keyterms Prompt for Streaming with LLM Gateway Enhancement

```python
# Streaming with medical context and post-processing
medical_terms = [
    # Patient-specific history
    "coronary artery disease",
    "CABG in 2019",
    "ejection fraction 45%",

    # Current visit context
    "chest pain",
    "shortness of breath",
    "orthopnea",

    # Likely medications
    "carvedilol",
    "furosemide",
    "spironolactone"
]

transcriber = aai.RealtimeTranscriber(
    sample_rate=16000,
    format_turns=True,
    key_terms=medical_terms,
    on_data=lambda transcript: post_process_medical(transcript)
)

def post_process_medical(transcript):
    """Apply LLM correction for medical context"""
    # Send to LLM Gateway for medical terminology correction
    # This improves contextual accuracy significantly
    corrected = llm_gateway.correct_medical(transcript.text)
    return corrected
```

### Common Medical Terminology - Top 1000 Terms

Even if you don't know the context of a specific medical conversation, you can boost the accuracy of transcription by providing the top 1000 medical words in your field.

```python
# General medical keyterms for improved accuracy
common_medical_terms = [
    "hypertension","diabetes","sepsis","asthma","pneumonia","influenza","bronchitis","copd","stroke","migraine","epilepsy","cancer","angina","obesity","gerd","ulcer","colitis","crohn","hepatitis","cirrhosis","pancreatitis","appendicitis","cholecystitis","diverticulitis","anemia","leukemia","lymphoma","myeloma","arthritis","osteoarthritis","gout","lupus","psoriasis","eczema","dermatitis","cellulitis","abscess","depression","anxiety","bipolar","schizophrenia","adhd","autism","dementia","parkinson","hypothyroidism","hyperthyroidism","hyperlipidemia","dehydration","preeclampsia","endometriosis","pcos","bph","uti","pyelonephritis","prostatitis","meningitis","encephalitis","sinusitis","otitis","pharyngitis","tonsillitis","gastritis","enteritis","nephrolithiasis","urolithiasis","thrombosis","embolism","dvt","pe","concussion","sciatica","scoliosis","stenosis","herniation","tendonitis","bursitis","fracture","dislocation","laceration","contusion","hematoma","neuropathy","myopathy","cardiomyopathy","nephropathy","retinopathy","keratitis","uveitis","iritis","scleritis","blepharitis","conjunctivitis","keratoconus","cataract","glaucoma","maculopathy","retinoblastoma","sarcoidosis","amyloidosis","hemochromatosis","thalassemia","hemophilia","hyperglycemia","hypoglycemia","hypernatremia","hyponatremia","hyperkalemia","hypokalemia","hypercalcemia","hypocalcemia","hypermagnesemia","hypomagnesemia","acidosis","alkalosis","ketoacidosis","endocarditis","myocarditis","pericarditis","peritonitis","osteomyelitis","spondylitis","vasculitis","arteritis","phlebitis","panniculitis","tenosynovitis","myositis","rhabdomyolysis","xerostomia","dysgeusia","anosmia","ageusia","aphasia","ataxia","dystonia","chorea","tremor","bradykinesia","tachycardia","bradycardia","hypotension","syncope","hemoptysis","hematuria","melena","hematochezia","leukocytosis","leukopenia","neutropenia","thrombocytopenia","thrombocytosis","hyperbilirubinemia","jaundice","pruritus","urticaria","angioedema","anaphylaxis","dyspnea","orthopnea","paronychia","onychomycosis","candidiasis","histoplasmosis","blastomycosis","coccidioidomycosis","aspergillosis","toxoplasmosis","giardiasis","amebiasis","malaria","trichomoniasis","syphilis","gonorrhea","chlamydia","herpes","varicella","measles","rubella","mumps","pertussis","tetanus","diphtheria","botulism","anthrax","smallpox","tularemia","brucellosis","leptospirosis","yersiniosis","campylobacteriosis","listeriosis","norovirus","rotavirus","hepatitisb","hepatitisc","hepatitisa","hiv","aids","covid19","sars","mers","ebola","zika","dengue","chikungunya","yellowfever","rabies","lyme","babesiosis","ehrlichiosis","anaplasmosis","rockymountainspottedfever",
    "appendectomy","cholecystectomy","mastectomy","hysterectomy","oophorectomy","salpingectomy","prostatectomy","nephrectomy","splenectomy","thyroidectomy","parathyroidectomy","adenoidectomy","tonsillectomy","colectomy","hemicolectomy","gastrectomy","pancreatectomy","hepatectomy","laminectomy","discectomy","craniotomy","craniectomy","thoracotomy","lobectomy","pneumonectomy","tracheostomy","bronchoscopy","laryngoscopy","endoscopy","colonoscopy","sigmoidoscopy","cystoscopy","ureteroscopy","arthroscopy","laparoscopy","angiography","ventriculostomy","thoracentesis","paracentesis","pericardiocentesis","arthrocentesis","amniocentesis","cardioversion","defibrillation","intubation","extubation","tracheotomy","catheterization","cannulation","dialysis","plasmapheresis","phototherapy","radiotherapy","chemotherapy","brachytherapy","cryotherapy","cauterization","electrocardiography","echocardiography","electroencephalography","spirometry","plethysmography","manometry","oximetry","capnography","ventriculography","mammography","tomography","fluoroscopy","ultrasonography","scintigraphy","venography","myelography","cholangiography","hysterosalpingography","urography","pyelography","amniotomy","episiotomy","debridement","fasciotomy","arthroplasty","angioplasty","valvuloplasty","sclerotherapy","phlebectomy","embolectomy","thrombectomy","endarterectomy","stenting","bypass","ablation","curettage","aspiration","biopsy",
    "hemoglobin","hematocrit","leukocyte","erythrocyte","platelet","creatinine","bun","bilirubin","alkalinephosphatase","aspartatetransaminase","alaninetransaminase","lactatedehydrogenase","troponin","bnp","procalcitonin","ferritin","transferrin","uricacid","cholesterol","triglyceride","hdl","ldl","hba1c","glucose","insulin","cpeptide","tsh","t3","t4","cortisol","prolactin","testosterone","estradiol","progesterone","psa","crp","esr","dimer","lactate","amylase","lipase","natriuretic","urinalysis","ketones","proteinuria","microalbumin","bacteriuria","pyuria","nitrites","leukocyteesterase","culture","cytology","histology","serology","pcr","antigen","antibody","titer","crossmatch","coagulation","protime","inr","aptt","fibrinogen","ddu","osmolality","sodium","potassium","chloride","bicarbonate","calcium","magnesium","phosphate","albumin","globulin","totalprotein","aniongap","osmolarity","hematology","biochemistry","microbiology","virology","parasitology","toxicology",
    "mandible","maxilla","zygomatic","sphenoid","ethmoid","occipital","temporal","parietal","frontal","atlas","axis","clavicle","scapula","sternum","humerus","radius","ulna","carpals","scaphoid","lunate","triquetrum","pisiform","trapezium","trapezoid","capitate","hamate","metacarpal","phalanx","pelvis","ilium","ischium","pubis","acetabulum","femur","patella","tibia","fibula","tarsals","talus","calcaneus","navicular","cuboid","cuneiform","sacrum","coccyx","diaphragm","pleura","peritoneum","mesentery","omentum","myocardium","endocardium","pericardium","epidermis","dermis","hypodermis","alveolus","bronchiole","larynx","pharynx","esophagus","duodenum","jejunum","ileum","cecum","colon","sigmoid","rectum","anus","hepatocyte","nephron","glomerulus","tubule","ureter","bladder","urethra","cortex","medulla","cerebrum","cerebellum","thalamus","hypothalamus","hippocampus","amygdala","pituitary","pineal","thyroid","parathyroid","adrenal","pancreas","spleen","thymus","tonsil","lymphocyte","macrophage","neutrophil","eosinophil","basophil","monocyte","osteocyte","chondrocyte","myocyte","neuron","astrocyte","oligodendrocyte","microglia","retina","cornea","sclera","choroid","iris","lens","cochlea","vestibule","stapes","tarsus","metatarsal","falx","tentorium","dura","arachnoid","pia",
    "acetaminophen","ibuprofen","naproxen","ketorolac","diclofenac","celecoxib","meloxicam","morphine","hydromorphone","oxycodone","hydrocodone","fentanyl","buprenorphine","naloxone","tramadol","gabapentin","pregabalin","lidocaine","bupivacaine","ropivacaine","amoxicillin","ampicillin","penicillin","piperacillin","tazobactam","cefazolin","cephalexin","cefuroxime","cefdinir","ceftriaxone","cefepime","ceftaroline","meropenem","imipenem","ertapenem","aztreonam","vancomycin","daptomycin","linezolid","tedizolid","clindamycin","metronidazole","azithromycin","clarithromycin","erythromycin","doxycycline","minocycline","tigecycline","ciprofloxacin","levofloxacin","moxifloxacin","trimethoprim","sulfamethoxazole","nitrofurantoin","fosfomycin","rifampin","isoniazid","pyrazinamide","ethambutol","amphotericin","fluconazole","itraconazole","voriconazole","posaconazole","micafungin","caspofungin","anidulafungin","acyclovir","valacyclovir","famciclovir","oseltamivir","zanamivir","remdesivir","ivermectin","albendazole","mebendazole","praziquantel","hydroxychloroquine","chloroquine","atovaquone","proguanil","pyrimethamine","clotrimazole","nystatin","terbinafine",
    "lisinopril","enalapril","captopril","benazepril","ramipril","perindopril","losartan","valsartan","candesartan","irbesartan","olmesartan","telmisartan","azilsartan","amlodipine","nifedipine","felodipine","isradipine","nicardipine","diltiazem","verapamil","metoprolol","atenolol","propranolol","carvedilol","bisoprolol","nebivolol","labetalol","hydrochlorothiazide","chlorthalidone","indapamide","furosemide","torsemide","bumetanide","spironolactone","eplerenone","triamterene","amiloride","hydralazine","minoxidil","nitroglycerin","isosorbidedinitrate","isosorbidemononitrate","ranolazine","digoxin","amiodarone","sotalol","dofetilide","dronedarone","flecainide","propafenone","adenosine","warfarin","heparin","enoxaparin","dalteparin","fondaparinux","apixaban","rivaroxaban","edoxaban","dabigatran","clopidogrel","prasugrel","ticagrelor","abciximab","eptifibatide","tirofiban","atorvastatin","simvastatin","rosuvastatin","pravastatin","lovastatin","pitavastatin","fluvastatin","ezetimibe","fenofibrate","gemfibrozil","niacin","alirocumab","evolocumab","inclisiran",
    "metformin","glipizide","glyburide","glimepiride","pioglitazone","rosiglitazone","sitagliptin","saxagliptin","linagliptin","alogliptin","exenatide","liraglutide","dulaglutide","semaglutide","tirzepatide","pramlintide","acarbose","miglitol","canagliflozin","dapagliflozin","empagliflozin","ertugliflozin","insulin","glargine","detemir","degludec","lispro","aspart","glulisine","levothyroxine","liothyronine","methimazole","propylthiouracil","hydrocortisone","prednisone","prednisolone","methylprednisolone","dexamethasone","fludrocortisone","desmopressin","somatropin","octreotide","lanreotide","cabergoline","bromocriptine","calcitriol","alendronate","risedronate","ibandronate","zoledronic","denosumab","teriparatide","abaloparatide",
    "albuterol","levalbuterol","ipratropium","tiotropium","umeclidinium","aclidinium","budesonide","fluticasone","beclomethasone","mometasone","ciclesonide","salmeterol","formoterol","vilanterol","montelukast","zafirlukast","zileuton","roflumilast","omalizumab","mepolizumab","reslizumab","benralizumab","dupilumab","tezepelumab",
    "sertraline","fluoxetine","paroxetine","citalopram","escitalopram","vilazodone","vortioxetine","venlafaxine","desvenlafaxine","duloxetine","bupropion","mirtazapine","trazodone","amitriptyline","nortriptyline","imipramine","clomipramine","lithium","lamotrigine","valproate","carbamazepine","oxcarbazepine","topiramate","levetiracetam","phenytoin","phenobarbital","clonazepam","lorazepam","diazepam","alprazolam","temazepam","buspirone","zolpidem","eszopiclone","zaleplon","quetiapine","olanzapine","risperidone","ziprasidone","aripiprazole","clozapine","haloperidol","lurasidone","paliperidone","brexpiprazole","cariprazine","iloperidone",
    "omeprazole","esomeprazole","lansoprazole","pantoprazole","rabeprazole","sucralfate","famotidine","cimetidine","ranitidine","metoclopramide","ondansetron","prochlorperazine","promethazine","dicyclomine","hyoscyamine","loperamide","diphenoxylate","mesalamine","sulfasalazine","infliximab","adalimumab","vedolizumab","ustekinumab","tofacitinib","linaclotide","plecanatide","lubiprostone","polyethyleneglycol","senna","bisacodyl","lactulose","rifaximin","pancrelipase","ursodiol","cholestyramine","colesevelam","colestipol",
    "methotrexate","leflunomide","hydroxychloroquine","sulfasalazine","azathioprine","mycophenolate","cyclosporine","tacrolimus","sirolimus","everolimus","belatacept","rituximab","abatacept","tocilizumab","sarilumab","anakinra","canakinumab","secukinumab","ixekizumab","brodalumab","guselkumab","risankizumab","tildrakizumab","dupilumab","omalizumab","certolizumab","golimumab","etanercept","apremilast","thalidomide","lenalidomide","pomalidomide","acitretin","isotretinoin","tretinoin","clobetasol","betamethasone","triamcinolone","pimecrolimus","calcipotriene",
    "imatinib","dasatinib","nilotinib","bosutinib","ponatinib","erlotinib","gefitinib","afatinib","osimertinib","lapatinib","sorafenib","sunitinib","pazopanib","axitinib","cabozantinib","lenvatinib","vandetanib","regorafenib","nintedanib","bevacizumab","ramucirumab","cetuximab","panitumumab","trastuzumab","pertuzumab","ado","trastuzumabemtansine","obinutuzumab","ofatumumab","brentuximab","inotuzumab","blinatumomab","pembrolizumab","nivolumab","cemiplimab","atezolizumab","durvalumab","avelumab","ipilimumab","talimogene","olaparib","rucaparib","niraparib","talazoparib","palbociclib","ribociclib","abemaciclib","bortezomib","carfilzomib","ixazomib","venetoclax","idelalisib","copanlisib","duvelisib","acalabrutinib","ibrutinib","zanubrutinib","midostaurin","gilteritinib","enasidenib","ivosidenib","selpercatinib","pralsetinib","larotrectinib","entrectinib","dabrafenib","trametinib","binimetinib","cobimetinib","vemurafenib","encorafenib","tepotinib","capmatinib","savolitinib","crizotinib","ceritinib","alectinib","brigatinib","lorlatinib",
    "gravida","para","abortus","primigravida","multigravida","nulliparous","primiparous","multiparous","parturition","lactation","menarche","menopause","metrorrhagia","menorrhagia","oligomenorrhea","amenorrhea","dysmenorrhea","dyspareunia","placenta","chorion","amnion","decidua","endometrium","myometrium","cervix","oocyte","follicle","corpusluteum",
    "staphylococcus","streptococcus","enterococcus","pneumococcus","meningococcus","listeria","clostridium","pseudomonas"
]

config = aai.TranscriptionConfig(
    speech_model=aai.SpeechModel.slam_1,
    keyterms_prompt=common_medical_terms,
)
```

## How Can I Improve the Latency of My Medical Scribe?

### Async Chunking for Long Encounters

For lengthy patient visits, implement chunking to get progressive documentation. This is especially useful for:

- Hospital rounds (in-person microphone running ambient)
- Comprehensive physicals
- Specialty consultations

### When to Use Streaming Instead

For optimal clinical workflow integration, streaming is ideal when:

1. **Real-time documentation needed:**

   - Emergency department encounters
   - Telemedicine visits
   - Procedure documentation

2. **Immediate clinical decision support:**

   - Medication interaction checking
   - Diagnosis suggestion
   - Protocol reminders

3. **Live quality assurance:**
   - Compliance monitoring
   - Training supervision
   - Documentation coaching

Streaming provides:

- ~300ms latency for immediate documentation
- Real-time partial results for provider review
- No delay between encounter end and note availability
- Live clinical decision support integration

## How Can I Use Speaker Identification for Doctor and Patient Recognition?

Speaker Identification can automatically distinguish between doctors and patients in medical encounters, replacing generic "Speaker A" and "Speaker B" labels with meaningful role-based identifiers.

### Why Use Speaker Identification in Medical Scribes?

**Clinical Benefits:**

- **Clear attribution** - Know exactly who said what in clinical documentation
- **SOAP note structure** - Automatically separate subjective (patient) from objective (provider) statements
- **Compliance documentation** - Proper attribution for regulatory requirements
- **Quality assurance** - Review provider-patient communication patterns
- **Training analysis** - Analyze communication styles for medical education

### Medical Speaker Identification Setup

#### Method 1: Role-Based Identification (Recommended)

```python
import assemblyai as aai

# Configure for medical encounter
config = aai.TranscriptionConfig(
    speech_model=aai.SpeechModel.slam_1,
    speaker_labels=True,
    speakers_expected=2,  # Doctor and patient

    # Enable speaker identification with medical roles
    speech_understanding={
        "request": {
            "speaker_identification": {
                "speaker_type": "role",
                "known_values": ["Doctor", "Patient"]
            }
        }
    }
)

# Transcribe medical encounter
transcript = await transcribe_async(audio_file, config)

# Results show clear role attribution
for utterance in transcript.utterances:
    print(f"{utterance.speaker}: {utterance.text}")
    # Output: "Doctor: What brings you in today?"
    #         "Patient: I've been having chest pain for the past week."
```

#### Method 2: Name-Based Identification

For scenarios where you know the specific doctor's name:

```python
config = aai.TranscriptionConfig(
    speech_model=aai.SpeechModel.slam_1,
    speaker_labels=True,
    speakers_expected=2,

    speech_understanding={
        "request": {
            "speaker_identification": {
                "speaker_type": "name",
                "known_values": ["Dr. Sarah Johnson", "Patient"]
            }
        }
    }
)
```

## Additional Resources

- [Keyterms Prompting Documentation](https://www.assemblyai.com/docs/speech-to-text/pre-recorded-audio/improving-transcript-accuracy)
- [Speaker Diarization Guide](https://www.assemblyai.com/docs/speech-to-text/pre-recorded-audio/speaker-diarization)
- [Speaker Identification Guide](https://www.assemblyai.com/docs/speech-to-text/pre-recorded-audio/speaker-identification)
- [API Playground](https://www.assemblyai.com/playground/streaming)
