---
title: "Best Practices for building Medical Scribes"
description: "Complete guide for building medical scribes with AssemblyAI"
---

## Introduction

Building a robust medical scribe requires careful consideration of accuracy, latency, speaker identification, and real-time capabilities while maintaining HIPAA compliance and clinical documentation standards. This guide addresses common questions and provides practical solutions for both post-visit and live encounter transcription scenarios.

## Why AssemblyAI for Medical Scribes?

AssemblyAI stands out as the premier choice for medical scribes with several key advantages:

### Industry-Leading Accuracy with Pre-recorded Audio
- **Universal-3-Pro model** delivers exceptional accuracy for medical terminology and clinical documentation
- **2.9% speaker diarization error rate** for precise attribution between provider and patient
- Comprehensive LLM Gateway integration for intelligent post-processing into structured clinical notes

### Real-Time Streaming Advantages
As medical scribes evolve toward real-time documentation, AssemblyAI's Universal-Streaming model offers significant benefits:
- **Ultra-low latency (~300ms)** enables live transcription during patient encounters
- **Format turns** feature provides structured, speaker-aware output in real-time
- **Keyterms prompt** allows providing medical context and patient history to improve accuracy

### End-to-End Voice AI Platform
Unlike fragmented solutions, AssemblyAI provides a unified API for:
- Transcription with speaker diarization (provider vs. patient)
- Medical terminology recognition and contextual understanding
- HIPAA-compliant PII redaction on both text and audio
- Post-processing workflows with LLM Gateway - from SOAP notes to completely custom clinical documentation
- Real-time and batch processing in a single platform
- Compliance and Security built for medical workloads (BAA, HIPAA, DPA, etc.)

## What Languages and Features for a Medical Scribe?

### Pre-Recorded Doctor Patient Visits (Universal-3-Pro)
**Languages:**
For post-visit documentation, Universal-3-Pro supports English for the highest accuracy transcription. If you want to use other languages, Universal-3 is a suitable alternative.

**Core Features**:
- Speaker diarization (provider-patient separation)
- Automatic formatting, punctuation, and capitalization
- Keyterms Prompting for medical specialties and conditions
- Ability to prompt on related medical terms and improve the accuracy of others (for example, `ibuprofen` improving `naproxen`)

**Speech Understanding Models**:
- Entity detection for medications, conditions, and procedures
- PII redaction on text and audio for HIPAA compliance
- Sentiment analysis for patient experience insights

### Real-Time Streaming
**Languages**:
For live encounter transcription, Universal-Streaming supports:
- English model optimized for medical contexts
- Multilingual model for visits in other languages or with code switching (English, Spanish, German, French, Portuguese, Italian)
- Post-processing LLM Gateway tight integration for increasing medical accuracy

**Streaming-Specific Features**:
- Partial and final transcripts for responsive documentation
- Format turns for structured provider-patient dialogue
- Keyterms Prompt for patient history and current medications
- End-of-utterance detection for natural clinical conversation flow
- Post-processing LLM Gateway integration for increasing medical accuracy

### Coming Soon
- Medical model which packages up the best ways to contextually influence transcript output
- Multilingual Universal-3-Pro, especially important for multilingual medical conversations to improve accuracy

## How Can I Get Started Building a Post-Visit Medical Scribe?

Here's a complete example implementing async transcription with Universal-3-Pro:

```python
import assemblyai as aai
import asyncio
from typing import Dict, List
from assemblyai.types import (
    SpeakerOptions,
    PIIRedactionPolicy,
    PIISubstitutionPolicy,
)

# Configure API key
aai.settings.api_key = "your_api_key_here"

async def transcribe_encounter_async(audio_file_path: str, audio_url: str) -> Dict:
    """
    Asynchronously transcribe a medical encounter with Universal-3-Pro
    """
    # Configure comprehensive medical transcription
    config = aai.TranscriptionConfig(
        # Use Universal-3-Pro for medical accuracy
        model="universal-3-pro",
        
        # Diarize provider and patient
        speaker_labels=True,
        speakers_expected=2,  # Typically provider and patient
        
        # Punctuation and Formatting
        punctuate=True,
        format_text=True,
        
        # Boost accuracy of medical terminology
        keyterms_prompt=[
            # Patient-specific context
            "hypertension", "diabetes mellitus type 2", "metformin",
            
            # Specialty-specific terms
            "auscultation", "palpation", "differential diagnosis",
            "chief complaint", "review of systems", "physical examination",
            
            # Common medications
            "lisinopril", "atorvastatin", "levothyroxine",
            
            # Procedure terms
            "electrocardiogram", "complete blood count", "hemoglobin A1c"
        ],
        
        # Speech understanding for medical documentation
        entity_detection=True,  # Extract medications, conditions, procedures
        redact_pii=True,  # HIPAA compliance
        redact_pii_policies=[
            PIIRedactionPolicy.person_name,
            PIIRedactionPolicy.date_of_birth,
            PIIRedactionPolicy.medical_record_number,
            PIIRedactionPolicy.phone_number,
            PIIRedactionPolicy.email_address,
        ],
        redact_pii_sub=PIISubstitutionPolicy.hash,
        redact_pii_audio=True  # Create HIPAA-compliant audio
    )
    
    # Create async transcriber
    transcriber = aai.Transcriber()
    
    try:
        # Submit transcription job
        if audio_file_path:
            transcript = await asyncio.to_thread(
                transcriber.transcribe, 
                audio_file_path,
                config=config
            )
        elif audio_url:
            transcript = await asyncio.to_thread(
                transcriber.transcribe,
                audio_url,
                config=config
            )
        
        # Check status
        if transcript.status == aai.TranscriptStatus.error:
            raise Exception(f"Transcription failed: {transcript.error}")
        
        # Process speaker-labeled utterances
        print("\n=== PROVIDER-PATIENT DIALOGUE ===\n")
        
        for utterance in transcript.utterances:
            # Format timestamp
            start_time = utterance.start / 1000  # Convert to seconds
            end_time = utterance.end / 1000
            
            # Identify speaker role
            speaker_label = "Provider" if utterance.speaker == "A" else "Patient"
            
            # Print formatted utterance
            print(f"[{start_time:.1f}s - {end_time:.1f}s] {speaker_label}:")
            print(f"  {utterance.text}")
            print(f"  Confidence: {utterance.confidence:.2%}\n")
        
        # Extract clinical entities
        if transcript.entities:
            print("\n=== CLINICAL ENTITIES DETECTED ===\n")
            medications = [e for e in transcript.entities if e.entity_type == "medication"]
            conditions = [e for e in transcript.entities if e.entity_type == "medical_condition"]
            procedures = [e for e in transcript.entities if e.entity_type == "medical_procedure"]
            
            if medications:
                print("Medications:", ", ".join([m.text for m in medications]))
            if conditions:
                print("Conditions:", ", ".join([c.text for c in conditions]))
            if procedures:
                print("Procedures:", ", ".join([p.text for p in procedures]))
        
        return {
            "transcript": transcript,
            "utterances": transcript.utterances,
            "entities": transcript.entities,
            "redacted_audio_url": transcript.redacted_audio_url
        }
        
    except Exception as e:
        print(f"Error during transcription: {e}")
        raise

async def main():
    """
    Example usage for medical encounter
    """
    audio_file = ""  # "path/to/patient_encounter.mp3" Use this for a local file
    audio_url = "https://your-secure-storage.com/encounter.mp3"  # Ensure HIPAA-compliant storage
    
    try:
        result = await transcribe_encounter_async(audio_file, audio_url)
        
        # Additional processing
        print(f"\nEncounter duration: {result['transcript'].audio_duration} seconds")
        
        # Could send to LLM Gateway for SOAP note generation here
        
    except Exception as e:
        print(f"Failed to process encounter: {e}")

if __name__ == "__main__":
    asyncio.run(main())
```

## How Can I Get Started Building a Real-Time Medical Scribe?

Here's a complete example for real-time streaming transcription with LLM post-processing:

```python
import os
import json
import time
import threading
from datetime import datetime
from urllib.parse import urlencode

import pyaudio
import websocket
import requests
from dotenv import load_dotenv
from simple_term_menu import TerminalMenu

# Load environment variables from .env if present
try:
    load_dotenv()
except Exception:
    pass

"""
Medical Scribe â€“ Streaming STT + LLM Gateway Enhancement (SOAP-ready)

What this does
--------------
1) Streams mic audio to AssemblyAI Streaming STT (with formatted turns + keyterms)
2) On every utterance or formatted final turn, calls AssemblyAI LLM Gateway to
   apply *medical* edits (terminology, punctuation, proper nouns, etc.)
3) Logs encounter turns and generates a SOAP note at session end via the Gateway

Quick start
-----------
export ASSEMBLYAI_API_KEY=your_key
# Optional: pick a Gateway model (defaults to Claude 3.5 Haiku)
export LLM_GATEWAY_MODEL=claude-3-5-haiku-20241022

python medical_scribe_llm_gateway.py
"""

# === Config ===
ASSEMBLYAI_API_KEY = "c0cfac05943e4922a7b66039eb45514c"


# Medical context and terminology (seed â€“ you can swap at runtime)
MEDICAL_KEYTERMS = [
    "hypertension",
    "diabetes mellitus",
    "coronary artery disease",
    "metformin 1000mg",
    "lisinopril 10mg",
    "atorvastatin 20mg",
    "chief complaint",
    "history of present illness",
    "review of systems",
    "physical examination",
    "assessment and plan",
    "auscultation",
    "palpation",
    "reflexes",
    "range of motion",
]

# WebSocket / STT parameters
CONNECTION_PARAMS = {
    "sample_rate": 16000,
    "format_turns": True,  # request formatted final transcripts ONLY
    # tuned turn detection for clinical speech (balancedâ€“conservative)
    "end_of_turn_confidence_threshold": 0.6,
    "min_end_of_turn_silence_when_confident": 160,  # frames (â‰ˆms at 10ms hop)
    "max_turn_silence": 2400,  # ensure EOT even if confidence is low
    "keyterms_prompt": json.dumps(MEDICAL_KEYTERMS),  # JSON string
}
API_ENDPOINT_BASE_URL = "wss://streaming.assemblyai.com/v3/ws"
API_ENDPOINT = f"{API_ENDPOINT_BASE_URL}?{urlencode(CONNECTION_PARAMS)}"

# Audio config
FRAMES_PER_BUFFER = 800  # 50ms @ 16kHz
SAMPLE_RATE = CONNECTION_PARAMS["sample_rate"]
CHANNELS = 1
FORMAT = pyaudio.paInt16

# Globals
audio = None
stream = None
ws_app = None
audio_thread = None
stop_event = threading.Event()
encounter_buffer = []  # list of dicts with turn data
last_processed_turn = None

# === Model selection (matches your Gateway helper script) ===
AVAILABLE_MODELS = [
    {"id": "claude-3-haiku-20240307", "name": "Claude 3 Haiku", "description": "Fastest Claude, good for simple tasks", "context_length": 200000, "max_completion_tokens": 4096},
    {"id": "claude-3-5-haiku-20241022", "name": "Claude 3.5 Haiku", "description": "Fast with better reasoning", "context_length": 200000, "max_completion_tokens": 8192},
    {"id": "claude-sonnet-4-20250514", "name": "Claude Sonnet 4", "description": "Balanced speed & intelligence", "context_length": 200000, "max_completion_tokens": 64000},
    {"id": "claude-sonnet-4-5-20250929", "name": "Claude Sonnet 4.5", "description": "Best for coding & agents", "context_length": 200000, "max_completion_tokens": 64000},
    {"id": "claude-opus-4-20250514", "name": "Claude Opus 4", "description": "Most powerful, deep reasoning", "context_length": 200000, "max_completion_tokens": 64000},
    {"id": "gpt-oss-20b", "name": "GPT OSS 20B", "description": "Open source, 20B parameters", "context_length": 131072, "max_completion_tokens": 131072},
    {"id": "gpt-oss-120b", "name": "GPT OSS 120B", "description": "Open source, 120B parameters", "context_length": 131072, "max_completion_tokens": 131072},
    {"id": "gpt-5", "name": "GPT-5", "description": "Most advanced reasoning", "context_length": 400000, "max_completion_tokens": 128000},
    {"id": "gpt-5-nano", "name": "GPT-5 Nano", "description": "Fast GPT-5 variant", "context_length": 400000, "max_completion_tokens": 128000},
    {"id": "gpt-5-mini", "name": "GPT-5 Mini", "description": "Balanced GPT-5 variant", "context_length": 400000, "max_completion_tokens": 128000},
    {"id": "gpt-4.1", "name": "GPT-4.1", "description": "Speed focused, low latency", "context_length": 1047576, "max_completion_tokens": 32768},
    {"id": "chatgpt-4o-latest", "name": "ChatGPT-4o Latest", "description": "General purpose", "context_length": 128000, "max_completion_tokens": 16384},
    {"id": "gemini-2.5-flash-lite", "name": "Gemini 2.5 Flash Lite", "description": "Fastest, mobile-optimized", "context_length": 1048576, "max_completion_tokens": 64000},
    {"id": "gemini-2.5-flash", "name": "Gemini 2.5 Flash", "description": "Fast, high-throughput", "context_length": 1048576, "max_completion_tokens": 64000},
    {"id": "gemini-2.5-pro", "name": "Gemini 2.5 Pro", "description": "Most capable Gemini", "context_length": 1048576, "max_completion_tokens": 65536}
]

def select_model():
    menu_entries = [f"{m['name']} - {m['description']}" for m in AVAILABLE_MODELS]
    terminal_menu = TerminalMenu(
        menu_entries,
        title="Select a model (Use â†‘â†“ arrows, Enter to select):",
        menu_cursor="â¯ ",
        menu_cursor_style=("fg_cyan", "bold"),
        menu_highlight_style=("bg_cyan", "fg_black"),
        cycle_cursor=True,
        clear_screen=False,
        show_search_hint=True,
    )
    idx = terminal_menu.show()
    if idx is None:
        print("Model selection cancelled. Exiting...")
        raise SystemExit(0)
    return AVAILABLE_MODELS[idx]["id"]

selected_model = None

# === Gateway helpers ===

def _gateway_chat(messages, max_tokens=800, temperature=0.2, retries=3, backoff=0.75):
    """Call AssemblyAI LLM Gateway (single endpoint) with debug logging and retry."""
    url = "https://llm-gateway.assemblyai.com/v1/chat/completions"
    headers = {
        "Authorization": ASSEMBLYAI_API_KEY,
        "Content-Type": "application/json",
    }
    payload = {
        "model": selected_model,
        "messages": messages,
        "max_tokens": max_tokens,
        "temperature": temperature,
    }

    last = None
    for attempt in range(retries):
        try:
            print(f"[LLM] POST {url} (model={selected_model}, attempt {attempt+1}/{retries})")
            resp = requests.post(url, headers=headers, json=payload, timeout=60)
            print(f"[LLM] â† status {resp.status_code}, bytes {len(resp.content)}")
            last = resp
        except Exception as e:
            if attempt == retries - 1:
                raise RuntimeError(f"Gateway request error: {e}")
            time.sleep(backoff * (attempt + 1))
            continue

        if resp.status_code == 200:
            data = resp.json()
            if not data.get("choices") or not data["choices"][0].get("message"):
                raise RuntimeError(f"Gateway OK but empty body: {str(data)[:200]}")
            return data
        if resp.status_code in (429, 500, 502, 503, 504):
            print(f"[LLM RETRY] {resp.status_code}: {resp.text[:180]}")
            time.sleep(backoff * (attempt + 1))
            continue
        raise RuntimeError(f"Gateway error {resp.status_code}: {resp.text[:300]}")

    raise RuntimeError(
        f"Gateway failed after retries. Last={getattr(last,'status_code','n/a')} {getattr(last,'text','')[:180]}"
    )


def post_process_with_llm(text: str) -> str:
    """Medical editing & normalization using LLM Gateway."""
    system = {
        "role": "system",
        "content": (
            "You are a clinical transcription editor. Keep the speaker's words, "
            "fix medical terminology (drug names, dosages, anatomy), proper nouns, "
            "and punctuation for readability. Preserve meaning and avoid inventing "
            "details. Prefer U.S. clinical style. If a medication or condition is "
            "phonetically close, correct to the most likely clinical term."
        ),
    }

    user = {
        "role": "user",
        "content": (
            "Context keyterms (JSON array):\n" + json.dumps(MEDICAL_KEYTERMS) + "\n\n"
            "Edit this short transcript for medical accuracy and readability.\n\n"
            f"Transcript:\n{text}"
        ),
    }

    try:
        res = _gateway_chat([system, user], max_tokens=600)
        return res["choices"][0]["message"]["content"].strip()
    except Exception as e:
        print(f"[LLM EDIT ERROR] {e}. Falling back to original.")
        return text


def generate_clinical_note():
    """Create a SOAP note from the encounter buffer via Gateway."""
    if not encounter_buffer:
        print("No encounter data to summarize.")
        return

    print("\n=== GENERATING CLINICAL DOCUMENTATION (SOAP) ===")
    # Build a compact transcript string for the LLM
    lines = []
    for e in encounter_buffer:
        if e.get("type") == "utterance":
            lines.append(f"[{e['timestamp']}] {e['speaker']}: {e['text']}")
        elif e.get("type") == "final":
            lines.append(f"[{e['timestamp']}] FINAL: {e['text']}")
    combined = "\n".join(lines)

    system = {
        "role": "system",
        "content": (
            "You are a clinician generating concise, structured notes. "
            "Produce a SOAP note (Subjective, Objective, Assessment, Plan). "
            "Use bullet points, keep it factual, infer reasonable clinical semantics "
            "from the transcript but do NOT invent data. Include medications with dosage "
            "and frequency if mentioned."
        ),
    }
    user = {
        "role": "user",
        "content": (
            "Create a SOAP note from this clinical encounter transcript.\n\n"
            f"Transcript:\n{combined}\n\n"
            "Format strictly as:\n"
            "Subjective:\n- ...\n\nObjective:\n- ...\n\nAssessment:\n- ...\n\nPlan:\n- ...\n"
        ),
    }

    try:
        res = _gateway_chat([system, user], max_tokens=1200)
        soap = res["choices"][0]["message"]["content"].strip()
        fname = f"clinical_note_soap_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
        with open(fname, "w", encoding="utf-8") as f:
            f.write(soap)
        print(f"SOAP note saved: {fname}")
    except Exception as e:
        print(f"[SOAP ERROR] {e}")


# === WebSocket callbacks ===

def on_open(ws):
    print("=" * 80)
    print(f"[{datetime.now().strftime('%H:%M:%S')}] Medical transcription started")
    print(f"Connected to: {API_ENDPOINT_BASE_URL}")
    print(f"Gateway model: {selected_model}")
    print("=" * 80)
    print("\nSpeak to begin. Press Ctrl+C to stop.\n")

    def stream_audio():
        global stream
        while not stop_event.is_set():
            try:
                audio_data = stream.read(FRAMES_PER_BUFFER, exception_on_overflow=False)
                ws.send(audio_data, websocket.ABNF.OPCODE_BINARY)
            except Exception as e:
                if not stop_event.is_set():
                    print(f"Error streaming audio: {e}")
                break

    global audio_thread
    audio_thread = threading.Thread(target=stream_audio, daemon=True)
    audio_thread.start()


def on_message(ws, message):
    global last_processed_turn
    try:
        data = json.loads(message)
        msg_type = data.get("type")

        if msg_type == "Begin":
            print(f"[SESSION] Started - ID: {data.get('id','N/A')}\n")

        elif msg_type == "Turn":
            end_of_turn = data.get("end_of_turn", False)
            turn_is_formatted = data.get("turn_is_formatted", False)
            transcript = data.get("transcript", "")
            utterance = data.get("utterance", "")
            turn_order = data.get("turn_order", 0)
            eot_conf = data.get("end_of_turn_confidence", 0.0)

            # live partials
            if not end_of_turn and transcript:
                print(f"\r[PARTIAL] {transcript[:120]}...", end="", flush=True)

            # If AssemblyAI has finalized a turn AND it's formatted, LLM-edit the transcript
            if end_of_turn and transcript:
                if not turn_is_formatted:
                    # Explicitly skip unformatted finals
                    print("[DEBUG] EOT received (unformatted) â€“ skipping LLM edit, waiting for formatted finalâ€¦")
                elif turn_is_formatted:
                    if last_processed_turn == turn_order:
                        return  # avoid duplicate processing
                    last_processed_turn = turn_order

                    ts = datetime.now().strftime('%H:%M:%S')
                    print("[DEBUG] EOT received (formatted). Calling LLMâ€¦")
                    edited = post_process_with_llm(transcript)

                    changed = "(edited)" if edited.strip() != transcript.strip() else "(no change)"
                    print(f"\n[{ts}] [FINAL {changed}]")
                    print(f"  â”œâ”€ Original STT : {transcript}")
                    print(f"  â””â”€ Edited by LLM: {edited}")
                    print(f"Turn: {turn_order} | Confidence: {eot_conf:.2%}")

                    encounter_buffer.append({
                        "timestamp": ts,
                        "text": edited,
                        "original_text": transcript,
                        "turn_order": turn_order,
                        "confidence": eot_conf,
                        "type": "final",
                    })

            # If we also get per-utterance chunks, just log them raw (no LLM) for timeline
            if utterance:
                ts = datetime.now().strftime('%H:%M:%S')

                low = utterance.lower()
                if any(t in low for t in ["medication", "prescribe", "dosage", "mg", "daily"]):
                    print("           ðŸ’Š MEDICATION MENTIONED")
                if any(t in low for t in ["pain", "symptom", "complaint", "problem"]):
                    print("           ðŸ¥ SYMPTOM REPORTED")
                if any(t in low for t in ["diagnose", "assessment", "impression"]):
                    print("           ðŸ“‹ DIAGNOSIS DISCUSSED")

                encounter_buffer.append({
                    "timestamp": ts,
                    "text": utterance,
                    "original_text": utterance,
                    "turn_order": turn_order,
                    "confidence": eot_conf,
                    "type": "utterance",
                })
                print()

        elif msg_type == "Termination":
            dur = data.get("audio_duration_seconds", 0)
            print(f"\n[SESSION] Terminated â€“ Duration: {dur}s")
            save_encounter_transcript()
            generate_clinical_note()

        elif msg_type == "Error":
            print(f"\n[ERROR] {data.get('error', 'Unknown error')}")

    except json.JSONDecodeError as e:
        print(f"Error decoding message: {e}")
    except Exception as e:
        print(f"Error handling message: {e}")


def on_error(ws, error):
    print(f"\n[WEBSOCKET ERROR] {error}")
    stop_event.set()


def on_close(ws, close_status_code, close_msg):
    print(f"\n[WEBSOCKET] Disconnected â€“ Status: {close_status_code}")
    global stream, audio
    stop_event.set()

    if stream:
        if stream.is_active():
            stream.stop_stream()
        stream.close()
        stream = None
    if audio:
        audio.terminate()
        audio = None
    if audio_thread and audio_thread.is_alive():
        audio_thread.join(timeout=1.0)


# === Persist artifacts ===

def save_encounter_transcript():
    if not encounter_buffer:
        print("No encounter data to save.")
        return

    fname = f"encounter_transcript_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt"
    with open(fname, "w", encoding="utf-8") as f:
        f.write("Clinical Encounter Transcript\n")
        f.write(f"Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write("=" * 80 + "\n\n")
        for e in encounter_buffer:
            if e.get("speaker"):
                f.write(f"[{e['timestamp']}] {e['speaker']}: {e['text']}\n")
            else:
                f.write(f"[{e['timestamp']}] {e['text']}\n")
            f.write(f"Confidence: {e['confidence']:.2%}\n\n")
    print(f"Encounter transcript saved: {fname}")


# === Main ===

def run():
    global audio, stream, ws_app, selected_model

    print("" + "="*60)
    print("  ðŸŽ™ï¸  Streaming Dictation - STT + AAI Chat Gateway")
    print("="*60 + "")
    selected_model = select_model()
    print(f"âœ“ Using model: {selected_model}")

    # Init mic
    audio = pyaudio.PyAudio()
    try:
        stream = audio.open(
            input=True,
            frames_per_buffer=FRAMES_PER_BUFFER,
            channels=CHANNELS,
            format=FORMAT,
            rate=SAMPLE_RATE,
        )
        print("Audio stream opened successfully.")
    except Exception as e:
        print(f"Error opening audio stream: {e}")
        if audio:
            audio.terminate()
        return

    # Connect WS
    ws_headers = [f"Authorization: {ASSEMBLYAI_API_KEY}"]
    ws_app = websocket.WebSocketApp(
        API_ENDPOINT,
        header=ws_headers,
        on_open=on_open,
        on_message=on_message,
        on_error=on_error,
        on_close=on_close,
    )

    ws_thread = threading.Thread(target=ws_app.run_forever, daemon=True)
    ws_thread.start()

    try:
        while ws_thread.is_alive():
            time.sleep(0.1)
    except KeyboardInterrupt:
        print("\n\nCtrl+C received. Stopping...")
        stop_event.set()
        # best-effort terminate
        if ws_app and ws_app.sock and ws_app.sock.connected:
            try:
                ws_app.send(json.dumps({"type": "Terminate"}))
                time.sleep(0.5)
            except Exception as e:
                print(f"Error sending termination: {e}")
        if ws_app:
            ws_app.close()
        ws_thread.join(timeout=2.0)
    finally:
        if stream and stream.is_active():
            stream.stop_stream()
        if stream:
            stream.close()
        if audio:
            audio.terminate()
        print("Cleanup complete. Exiting.")


if __name__ == "__main__":
    run()
```

## What Workflows Can I Build for My AI Medical Scribe?

Use these flags to transform raw medical conversations into structured clinical documentation. Below is plain-English behavior, output shape, and clinical use cases for each option.

### Entity Detection (Medical)
`entity_detection: true`
**What it does:** Extracts medical entities (medications, conditions, procedures, anatomy).  
**Output:** Array of `{ entity_type, text, start, end, confidence }`.  
**Great for:** Medication reconciliation, problem list updates, procedure coding.  
**Notes:** Recognizes brand/generic drug names, medical conditions, surgical procedures.

### Redact PII Text (HIPAA Compliance)
`redact_pii: true`
**What it does:** Scans transcript for Protected Health Information and **replaces** per HIPAA requirements.  
**Output:** `text` with PHI replaced; original timing preserved.  
**Great for:** De-identification, research datasets, training data.  
**Notes:** Covers all 18 HIPAA identifiers when properly configured.

`redact_pii_policies: [person_name, date_of_birth, medical_record_number, phone_number, email_address]`
Restricts redaction scope to key HIPAA identifiers:
- **`person_name`** â€“ patient and provider names  
- **`date_of_birth`** â€“ full or partial DOB  
- **`medical_record_number`** â€“ MRN, account numbers  
- **`phone_number`** â€“ contact numbers  
- **`email_address`** â€“ electronic addresses  

**Why this set:** Ensures HIPAA compliance while preserving clinical content for documentation.

`redact_pii_sub: hash`
**What it does:** Replaces each PHI span with a **stable hash token**.  
**Example:**  
`"Patient John Doe, DOB 1/15/1980, MRN 12345"` âŸ¶  
`"Patient #2af4â€¦, DOB #7b91â€¦, MRN #e13câ€¦"`  

**Benefits:**  
- Maintains referential integrity across document  
- Preserves sentence structure for NLP/LLM processing  
- Prevents reconstruction of original PHI  

### Redact PII Audio (HIPAA Compliance)
`redact_pii_audio: true`
**What it does:** Produces HIPAA-compliant audio with PHI portions silenced.  
**Output:** `redacted_audio_url` in the transcript payload.  
**Great for:** Quality assurance, training, research.  
**Notes:** Original audio preserved separately; ensure proper access controls.

### Sentiment Analysis (Patient Experience)
`sentiment_analysis: true`
**What it does:** Analyzes emotional tone of patient responses.  
**Output:** Array of `{ text, sentiment, confidence, start, end }`.  
**Great for:** Patient satisfaction, pain assessment, mental health screening.  
**Notes:** Helpful for identifying distressed or dissatisfied patients.

### End-to-End Clinical Documentation Effect

| Model | You get | Typical consumer |
| --- | --- | --- |
| `entity_detection` | Medical entities extracted | EHR integration, coding |
| `sentiment_analysis` | Patient emotion tracking | Quality metrics, alerts |
| `redact_pii` (+ policies) | HIPAA-compliant **text** | Research, QA, training |
| `redact_pii_sub=hash` | Stable PHI placeholders | Analytics & LLM processing |
| `redact_pii_audio` | De-identified **audio** | Compliance archives |

### Clinical Documentation Example

**Original Encounter:**  
> "Hi, I'm *Dr. Smith*. *John Doe*, born *1/15/1980*, is here for follow-up. He's taking *metformin 1000mg twice daily* for his *diabetes*."

**With medical scribe settings:**  
- **Text:** "Hi, I'm **#2af4â€¦**. **#7b91â€¦**, born **#e13câ€¦**, is here for follow-up. He's taking *metformin 1000mg twice daily* for his *diabetes*."  
- **Entities:** `[ { type: "medication", text: "metformin 1000mg" }, { type: "condition", text: "diabetes" } ]`  
- **Clinical note:** Structured SOAP format via LLM Gateway  
- **Redacted audio:** PHI portions silenced for compliance  

### LLM Gateway for Clinical Notes

Our LLM Gateway enables transformation of raw transcripts into structured clinical documentation:

*[Placeholder: LLM Gateway integration for SOAP notes, H&P reports, and discharge summaries will be added once the public API is relaunched]*

## How Do I Improve the Accuracy of My Medical Scribe?

### Using Keyterms Prompt for Pre-recorded Transcription with known context

Given the context for medical is highly specialized, we recommend using Universal-3-Pro for this use case. It will properly pick up on the context of related medical terms to improve transcript accuracy.

```python
# Define medical context
patient_medications = [
    "metformin 1000mg twice daily",
    "lisinopril 10mg daily",
    "atorvastatin 20mg at bedtime"
]

patient_conditions = [
    "type 2 diabetes mellitus",
    "essential hypertension",
    "hyperlipidemia",
    "obesity"
]

specialty_terms = [
    # Cardiology
    "ejection fraction",
    "ST elevation",
    "atrial fibrillation",
    
    # Endocrinology
    "hemoglobin A1c",
    "insulin resistance",
    "diabetic neuropathy"
]

# Configure Universal-3-Pro with medical context
config = aai.TranscriptionConfig(
    model="universal-3-pro",
    keyterms_prompt=patient_medications + patient_conditions + specialty_terms,
)
```

### Using Keyterms Prompt for Pre-recorded transcription with unknown context

Even if you don't know the context of a specific medical conversation, you can boost the accuracy of transcription by providing the top 1000 medical words in your field.

Here's a general medical example - using these keyterms will improve your transcription accuracy automatically with Universal-3-Pro.

```python
# Define medical context
common_medical_terms = [
    "hypertension","diabetes","sepsis","asthma","pneumonia","influenza","bronchitis","copd","stroke","migraine","epilepsy","cancer","angina","obesity","gerd","ulcer","colitis","crohn","hepatitis","cirrhosis","pancreatitis","appendicitis","cholecystitis","diverticulitis","anemia","leukemia","lymphoma","myeloma","arthritis","osteoarthritis","gout","lupus","psoriasis","eczema","dermatitis","cellulitis","abscess","depression","anxiety","bipolar","schizophrenia","adhd","autism","dementia","parkinson","hypothyroidism","hyperthyroidism","hyperlipidemia","dehydration","preeclampsia","endometriosis","pcos","bph","uti","pyelonephritis","prostatitis","meningitis","encephalitis","sinusitis","otitis","pharyngitis","tonsillitis","gastritis","enteritis","nephrolithiasis","urolithiasis","thrombosis","embolism","dvt","pe","concussion","sciatica","scoliosis","stenosis","herniation","tendonitis","bursitis","fracture","dislocation","laceration","contusion","hematoma","neuropathy","myopathy","cardiomyopathy","nephropathy","retinopathy","keratitis","uveitis","iritis","scleritis","blepharitis","conjunctivitis","keratoconus","cataract","glaucoma","maculopathy","retinoblastoma","sarcoidosis","amyloidosis","hemochromatosis","thalassemia","hemophilia","hyperglycemia","hypoglycemia","hypernatremia","hyponatremia","hyperkalemia","hypokalemia","hypercalcemia","hypocalcemia","hypermagnesemia","hypomagnesemia","acidosis","alkalosis","ketoacidosis","endocarditis","myocarditis","pericarditis","peritonitis","osteomyelitis","spondylitis","vasculitis","arteritis","phlebitis","panniculitis","tenosynovitis","myositis","rhabdomyolysis","xerostomia","dysgeusia","anosmia","ageusia","aphasia","ataxia","dystonia","chorea","tremor","bradykinesia","tachycardia","bradycardia","hypotension","syncope","hemoptysis","hematuria","melena","hematochezia","leukocytosis","leukopenia","neutropenia","thrombocytopenia","thrombocytosis","hyperbilirubinemia","jaundice","pruritus","urticaria","angioedema","anaphylaxis","dyspnea","orthopnea","paronychia","onychomycosis","candidiasis","histoplasmosis","blastomycosis","coccidioidomycosis","aspergillosis","toxoplasmosis","giardiasis","amebiasis","malaria","trichomoniasis","syphilis","gonorrhea","chlamydia","herpes","varicella","measles","rubella","mumps","pertussis","tetanus","diphtheria","botulism","anthrax","smallpox","tularemia","brucellosis","leptospirosis","yersiniosis","campylobacteriosis","listeriosis","norovirus","rotavirus","hepatitisb","hepatitisc","hepatitisa","hiv","aids","covid19","sars","mers","ebola","zika","dengue","chikungunya","yellowfever","rabies","lyme","babesiosis","ehrlichiosis","anaplasmosis","rockymountainspottedfever",
    "appendectomy","cholecystectomy","mastectomy","hysterectomy","oophorectomy","salpingectomy","prostatectomy","nephrectomy","splenectomy","thyroidectomy","parathyroidectomy","adenoidectomy","tonsillectomy","colectomy","hemicolectomy","gastrectomy","pancreatectomy","hepatectomy","laminectomy","discectomy","craniotomy","craniectomy","thoracotomy","lobectomy","pneumonectomy","tracheostomy","bronchoscopy","laryngoscopy","endoscopy","colonoscopy","sigmoidoscopy","cystoscopy","ureteroscopy","arthroscopy","laparoscopy","angiography","ventriculostomy","thoracentesis","paracentesis","pericardiocentesis","arthrocentesis","amniocentesis","cardioversion","defibrillation","intubation","extubation","tracheotomy","catheterization","cannulation","dialysis","plasmapheresis","phototherapy","radiotherapy","chemotherapy","brachytherapy","cryotherapy","cauterization","electrocardiography","echocardiography","electroencephalography","spirometry","plethysmography","manometry","oximetry","capnography","ventriculography","mammography","tomography","fluoroscopy","ultrasonography","scintigraphy","venography","myelography","cholangiography","hysterosalpingography","urography","pyelography","amniotomy","episiotomy","debridement","fasciotomy","arthroplasty","angioplasty","valvuloplasty","sclerotherapy","phlebectomy","embolectomy","thrombectomy","endarterectomy","stenting","bypass","ablation","curettage","aspiration","biopsy",
    "hemoglobin","hematocrit","leukocyte","erythrocyte","platelet","creatinine","bun","bilirubin","alkalinephosphatase","aspartatetransaminase","alaninetransaminase","lactatedehydrogenase","troponin","bnp","procalcitonin","ferritin","transferrin","uricacid","cholesterol","triglyceride","hdl","ldl","hba1c","glucose","insulin","cpeptide","tsh","t3","t4","cortisol","prolactin","testosterone","estradiol","progesterone","psa","crp","esr","dimer","lactate","amylase","lipase","natriuretic","urinalysis","ketones","proteinuria","microalbumin","bacteriuria","pyuria","nitrites","leukocyteesterase","culture","cytology","histology","serology","pcr","antigen","antibody","titer","crossmatch","coagulation","protime","inr","aptt","fibrinogen","ddu","osmolality","sodium","potassium","chloride","bicarbonate","calcium","magnesium","phosphate","albumin","globulin","totalprotein","aniongap","osmolarity","hematology","biochemistry","microbiology","virology","parasitology","toxicology",
    "mandible","maxilla","zygomatic","sphenoid","ethmoid","occipital","temporal","parietal","frontal","atlas","axis","clavicle","scapula","sternum","humerus","radius","ulna","carpals","scaphoid","lunate","triquetrum","pisiform","trapezium","trapezoid","capitate","hamate","metacarpal","phalanx","pelvis","ilium","ischium","pubis","acetabulum","femur","patella","tibia","fibula","tarsals","talus","calcaneus","navicular","cuboid","cuneiform","sacrum","coccyx","diaphragm","pleura","peritoneum","mesentery","omentum","myocardium","endocardium","pericardium","epidermis","dermis","hypodermis","alveolus","bronchiole","larynx","pharynx","esophagus","duodenum","jejunum","ileum","cecum","colon","sigmoid","rectum","anus","hepatocyte","nephron","glomerulus","tubule","ureter","bladder","urethra","cortex","medulla","cerebrum","cerebellum","thalamus","hypothalamus","hippocampus","amygdala","pituitary","pineal","thyroid","parathyroid","adrenal","pancreas","spleen","thymus","tonsil","lymphocyte","macrophage","neutrophil","eosinophil","basophil","monocyte","osteocyte","chondrocyte","myocyte","neuron","astrocyte","oligodendrocyte","microglia","retina","cornea","sclera","choroid","iris","lens","cochlea","vestibule","stapes","tarsus","metatarsal","falx","tentorium","dura","arachnoid","pia",
    "acetaminophen","ibuprofen","naproxen","ketorolac","diclofenac","celecoxib","meloxicam","morphine","hydromorphone","oxycodone","hydrocodone","fentanyl","buprenorphine","naloxone","tramadol","gabapentin","pregabalin","lidocaine","bupivacaine","ropivacaine","amoxicillin","ampicillin","penicillin","piperacillin","tazobactam","cefazolin","cephalexin","cefuroxime","cefdinir","ceftriaxone","cefepime","ceftaroline","meropenem","imipenem","ertapenem","aztreonam","vancomycin","daptomycin","linezolid","tedizolid","clindamycin","metronidazole","azithromycin","clarithromycin","erythromycin","doxycycline","minocycline","tigecycline","ciprofloxacin","levofloxacin","moxifloxacin","trimethoprim","sulfamethoxazole","nitrofurantoin","fosfomycin","rifampin","isoniazid","pyrazinamide","ethambutol","amphotericin","fluconazole","itraconazole","voriconazole","posaconazole","micafungin","caspofungin","anidulafungin","acyclovir","valacyclovir","famciclovir","oseltamivir","zanamivir","remdesivir","ivermectin","albendazole","mebendazole","praziquantel","hydroxychloroquine","chloroquine","atovaquone","proguanil","pyrimethamine","clotrimazole","nystatin","terbinafine",
    "lisinopril","enalapril","captopril","benazepril","ramipril","perindopril","losartan","valsartan","candesartan","irbesartan","olmesartan","telmisartan","azilsartan","amlodipine","nifedipine","felodipine","isradipine","nicardipine","diltiazem","verapamil","metoprolol","atenolol","propranolol","carvedilol","bisoprolol","nebivolol","labetalol","hydrochlorothiazide","chlorthalidone","indapamide","furosemide","torsemide","bumetanide","spironolactone","eplerenone","triamterene","amiloride","hydralazine","minoxidil","nitroglycerin","isosorbidedinitrate","isosorbidemononitrate","ranolazine","digoxin","amiodarone","sotalol","dofetilide","dronedarone","flecainide","propafenone","adenosine","warfarin","heparin","enoxaparin","dalteparin","fondaparinux","apixaban","rivaroxaban","edoxaban","dabigatran","clopidogrel","prasugrel","ticagrelor","abciximab","eptifibatide","tirofiban","atorvastatin","simvastatin","rosuvastatin","pravastatin","lovastatin","pitavastatin","fluvastatin","ezetimibe","fenofibrate","gemfibrozil","niacin","alirocumab","evolocumab","inclisiran",
    "metformin","glipizide","glyburide","glimepiride","pioglitazone","rosiglitazone","sitagliptin","saxagliptin","linagliptin","alogliptin","exenatide","liraglutide","dulaglutide","semaglutide","tirzepatide","pramlintide","acarbose","miglitol","canagliflozin","dapagliflozin","empagliflozin","ertugliflozin","insulin","glargine","detemir","degludec","lispro","aspart","glulisine","levothyroxine","liothyronine","methimazole","propylthiouracil","hydrocortisone","prednisone","prednisolone","methylprednisolone","dexamethasone","fludrocortisone","desmopressin","somatropin","octreotide","lanreotide","cabergoline","bromocriptine","calcitriol","alendronate","risedronate","ibandronate","zoledronic","denosumab","teriparatide","abaloparatide",
    "albuterol","levalbuterol","ipratropium","tiotropium","umeclidinium","aclidinium","budesonide","fluticasone","beclomethasone","mometasone","ciclesonide","salmeterol","formoterol","vilanterol","montelukast","zafirlukast","zileuton","roflumilast","omalizumab","mepolizumab","reslizumab","benralizumab","dupilumab","tezepelumab",
    "sertraline","fluoxetine","paroxetine","citalopram","escitalopram","vilazodone","vortioxetine","venlafaxine","desvenlafaxine","duloxetine","bupropion","mirtazapine","trazodone","amitriptyline","nortriptyline","imipramine","clomipramine","lithium","lamotrigine","valproate","carbamazepine","oxcarbazepine","topiramate","levetiracetam","phenytoin","phenobarbital","clonazepam","lorazepam","diazepam","alprazolam","temazepam","buspirone","zolpidem","eszopiclone","zaleplon","quetiapine","olanzapine","risperidone","ziprasidone","aripiprazole","clozapine","haloperidol","lurasidone","paliperidone","brexpiprazole","cariprazine","iloperidone",
    "omeprazole","esomeprazole","lansoprazole","pantoprazole","rabeprazole","sucralfate","famotidine","cimetidine","ranitidine","metoclopramide","ondansetron","prochlorperazine","promethazine","dicyclomine","hyoscyamine","loperamide","diphenoxylate","mesalamine","sulfasalazine","infliximab","adalimumab","vedolizumab","ustekinumab","tofacitinib","linaclotide","plecanatide","lubiprostone","polyethyleneglycol","senna","bisacodyl","lactulose","rifaximin","pancrelipase","ursodiol","cholestyramine","colesevelam","colestipol",
    "methotrexate","leflunomide","hydroxychloroquine","sulfasalazine","azathioprine","mycophenolate","cyclosporine","tacrolimus","sirolimus","everolimus","belatacept","rituximab","abatacept","tocilizumab","sarilumab","anakinra","canakinumab","secukinumab","ixekizumab","brodalumab","guselkumab","risankizumab","tildrakizumab","dupilumab","omalizumab","certolizumab","golimumab","etanercept","apremilast","thalidomide","lenalidomide","pomalidomide","acitretin","isotretinoin","tretinoin","clobetasol","betamethasone","triamcinolone","pimecrolimus","calcipotriene",
    "imatinib","dasatinib","nilotinib","bosutinib","ponatinib","erlotinib","gefitinib","afatinib","osimertinib","lapatinib","sorafenib","sunitinib","pazopanib","axitinib","cabozantinib","lenvatinib","vandetanib","regorafenib","nintedanib","bevacizumab","ramucirumab","cetuximab","panitumumab","trastuzumab","pertuzumab","ado","trastuzumabemtansine","obinutuzumab","ofatumumab","brentuximab","inotuzumab","blinatumomab","pembrolizumab","nivolumab","cemiplimab","atezolizumab","durvalumab","avelumab","ipilimumab","talimogene","olaparib","rucaparib","niraparib","talazoparib","palbociclib","ribociclib","abemaciclib","bortezomib","carfilzomib","ixazomib","venetoclax","idelalisib","copanlisib","duvelisib","acalabrutinib","ibrutinib","zanubrutinib","midostaurin","gilteritinib","enasidenib","ivosidenib","selpercatinib","pralsetinib","larotrectinib","entrectinib","dabrafenib","trametinib","binimetinib","cobimetinib","vemurafenib","encorafenib","tepotinib","capmatinib","savolitinib","crizotinib","ceritinib","alectinib","brigatinib","lorlatinib",
    "gravida","para","abortus","primigravida","multigravida","nulliparous","primiparous","multiparous","parturition","lactation","menarche","menopause","metrorrhagia","menorrhagia","oligomenorrhea","amenorrhea","dysmenorrhea","dyspareunia","placenta","chorion","amnion","decidua","endometrium","myometrium","cervix","oocyte","follicle","corpusluteum",
    "staphylococcus","streptococcus","enterococcus","pneumococcus","meningococcus","listeria","clostridium","pseudomonas"
]

# Configure Universal-3-Pro with medical context
config = aai.TranscriptionConfig(
    model="universal-3-pro",
    keyterms_prompt=common_medical_terms,
)
```

### Using Keyterms Prompt for Streaming with LLM Gateway Enhancement

```python
# Streaming with medical context and post-processing
medical_terms = [
    # Patient-specific history
    "coronary artery disease",
    "CABG in 2019",
    "ejection fraction 45%",
    
    # Current visit context
    "chest pain",
    "shortness of breath",
    "orthopnea",
    
    # Likely medications
    "carvedilol",
    "furosemide",
    "spironolactone"
]

transcriber = aai.RealtimeTranscriber(
    sample_rate=16000,
    format_turns=True,
    key_terms=medical_terms,
    on_data=lambda transcript: post_process_medical(transcript)
)

def post_process_medical(transcript):
    """Apply LLM correction for medical context"""
    # Send to LLM Gateway for medical terminology correction
    # This improves contextual accuracy significantly
    corrected = llm_gateway.correct_medical(transcript.text)
    return corrected
```

## How Can I Improve the Latency of My Medical Scribe?

### Async Chunking for Long Encounters

For lengthy patient visits, implement chunking to get progressive documentation. This is especially useful for:
- Hospital rounds (in-person microphone running ambient)
- Comprehensive physicals  
- Specialty consultations

### When to Use Streaming Instead

For optimal clinical workflow integration, streaming is ideal when:

1. **Real-time documentation needed:**
   - Emergency department encounters
   - Telemedicine visits
   - Procedure documentation

2. **Immediate clinical decision support:**
   - Medication interaction checking
   - Diagnosis suggestion
   - Protocol reminders

3. **Live quality assurance:**
   - Compliance monitoring
   - Training supervision
   - Documentation coaching

Streaming provides:
- ~300ms latency for immediate documentation
- Real-time partial results for provider review
- No delay between encounter end and note availability
- Live clinical decision support integration

## Additional Resources

- [Universal-3-Pro Documentation](https://www.assemblyai.com/docs/speech-to-text/pre-recorded-audio) *(Coming Soon)*
- [Universal-Streaming Documentation](https://www.assemblyai.com/docs/speech-to-text/universal-streaming)
- [HIPAA Compliance Guide](https://www.assemblyai.com/docs/security-compliance)
- [Medical Terminology Best Practices](https://www.assemblyai.com/blog/medical-transcription)
- [API Playground](https://www.assemblyai.com/playground/streaming)
- [Healthcare Support](https://www.assemblyai.com/contact/support)