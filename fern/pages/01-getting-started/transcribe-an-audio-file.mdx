---
title: 'Transcribe an audio file'
subtitle: 'Learn how to transcribe and analyze an audio file.'
hide-nav-links: true
description: 'Learn how to transcribe and analyze an audio file.'
---


  





<Info title="Universal-2 is live">
Dive into our research paper to see how we're redefining speech AI accuracy. Read more [here](https://www.assemblyai.com/research/universal-2).

</Info>

## Overview

By the end of this tutorial, you'll be able to:

- Transcribe an audio file.
- Enable [Speaker Diarization](../02-speech-to-text/speaker-diarization.mdx) to detect speakers in an audio file.

Here's the full sample code for what you'll build in this tutorial:

<Tabs groupId="language">
  <Tab value="python" title="Python" default>

```python


aai.settings.api_key = "<YOUR_API_KEY>"

transcriber = aai.Transcriber()

# You can use a local filepath:
# audio_file = "./example.mp3"

# Or use a publicly-accessible URL:
audio_file = (
    "https://assembly.ai/sports_injuries.mp3"
)

config = aai.TranscriptionConfig(speaker_labels=True)

transcript = transcriber.transcribe(audio_file, config)

if transcript.status == aai.TranscriptStatus.error:
    print(f"Transcription failed: {transcript.error}")
    exit(1)

print(transcript.text)

for utterance in transcript.utterances:
	print(f"Speaker {utterance.speaker}: {utterance.text}")
```

  </Tab>
  <Tab value="typescript" title="TypeScript">

```ts


const client = new AssemblyAI({
  apiKey: '<YOUR_API_KEY>'
})

// You can use a local filepath:
// const audioFile = "./example.mp3"

// Or use a publicly-accessible URL:
const audioFile = 'https://assembly.ai/sports_injuries.mp3'

const params = {
  audio: audioFile,
  speaker_labels: true
}

const run = async () => {
  const transcript = await client.transcripts.transcribe(params)

  if (transcript.status === 'error') {
    console.error(`Transcription failed: ${transcript.error}`)
    process.exit(1)
  }

  console.log(transcript.text)

  for (let utterance of transcript.utterances!) {
    console.log(`Speaker ${utterance.speaker}: ${utterance.text}`)
  }
}

run()
```

  </Tab>
  <Tab value="go" title="Go">

```go
package main


	"context"
	"fmt"
	"os"

	aai "github.com/AssemblyAI/assemblyai-go-sdk"
)

func main() {
	ctx := context.Background()

	client := aai.NewClient("<YOUR_API_KEY>")

	params := &aai.TranscriptOptionalParams{
		SpeakerLabels: aai.Bool(true),
	}

	// You can use a local file:
	/*
	f, err := os.Open("./example.mp3")
	[error handling here]
	transcript, err := client.Transcripts.TranscribeFromReader(ctx, f, params)
	*/

	// Or use a publicly-accessible URL:
	audioURL := "https://assembly.ai/sports_injuries.mp3"

	transcript, err := client.Transcripts.TranscribeFromURL(ctx, audioURL, params)
	if err != nil {
		fmt.Println("Something bad happened:", err)
		os.Exit(1)
	}

	fmt.Println(*transcript.Text)

	for _, utterance := range transcript.Utterances {
		fmt.Printf("Speaker %v: %v\n", *utterance.Speaker, *utterance.Text)
	}
}
```

</Tab>
<Tab value="java" title="Java">

```java



public final class App {
    public static void main(String[] args) {
        AssemblyAI client = AssemblyAI.builder()
                .apiKey("<YOUR_API_KEY>")
                .build();

        var params = TranscriptOptionalParams.builder()
                .speakerLabels(true)
                .build();

        // You can use a local file:
        /*
        Transcript transcript = aai.transcripts().transcribe(
                new File("./example.mp3"), params);
        */

        // Or use a publicly-accessible URL:
        String audioUrl = "https://assembly.ai/sports_injuries.mp3";
        Transcript transcript = client.transcripts().transcribe(audioUrl, params);

        if (transcript.getStatus().equals(TranscriptStatus.ERROR)) {
          System.err.println(transcript.getError().get());
          System.exit(1);
        }

        System.out.println(transcript.getText().get());

        transcript.getUtterances().get().forEach(utterance ->
                System.out.println("Speaker " + utterance.getSpeaker() + ": " + utterance.getText())
        );
    }
}
```

</Tab>
<Tab value="csharp" title="C#">

```csharp
using AssemblyAI;
using AssemblyAI.Transcripts;

var client = new AssemblyAIClient("<YOUR_API_KEY>");

// You can use a local file:
/*
var transcript = await client.Transcripts.TranscribeAsync(
    new FileInfo("./example.mp3"),
    new TranscriptOptionalParams
    {
        SpeakerLabels = true
    }
);
*/

// Or use a publicly-accessible URL:
const string audioUrl = "https://assembly.ai/sports_injuries.mp3";

var transcript = await client.Transcripts.TranscribeAsync(new TranscriptParams
{
    AudioUrl = audioUrl,
    SpeakerLabels = true
});

if (transcript.Status == TranscriptStatus.Error)
{
    Console.WriteLine(transcript.Error);
    Environment.Exit(1);
}

// Alternatively, you can use the EnsureStatusCompleted() method
// to throw an exception if the transcription status is not "completed".
// transcript.EnsureStatusCompleted();

Console.WriteLine(transcript.Text);

foreach (var utterance in transcript.Utterances!)
{
    Console.WriteLine($"Speaker {utterance.Speaker}: {utterance.Text}");
}
```

</Tab>
<Tab value="ruby" title="Ruby">

```ruby
require 'assemblyai'

client = AssemblyAI::Client.new(api_key: '<YOUR_API_KEY>')

# You can upload and transcribe a local file:
# uploaded_file = client.files.upload(file: '/path/to/your/file')
# transcript = client.transcripts.transcribe(audio_url: uploaded_file.upload_url, speaker_labels: true)

# Or use a publicly-accessible URL:
audio_url = 'https://assembly.ai/sports_injuries.mp3'

transcript = client.transcripts.transcribe(
  audio_url: audio_url,
  speaker_labels: true
)

abort transcript.error if transcript.status == AssemblyAI::Transcripts::TranscriptStatus::ERROR

puts transcript.text

transcript.utterances.each do |utterance|
  printf('Speaker %<speaker>s: %<text>s', speaker: utterance.speaker, text: utterance.text)
end
```

</Tab>
</Tabs>

  


## Before you begin

To complete this tutorial, you need:

- [Python](https://www.python.org/), [TypeScript](https://www.typescriptlang.org/), [Go](https://go.dev), Java, [.NET](https://dotnet.microsoft.com/en-us/download), or [Ruby](https://www.ruby-lang.org/en/documentation/installation/) installed.
- A <a href="https://www.assemblyai.com/dashboard/signup" target="_blank">free AssemblyAI account</a>.





## Step 1: Install the SDK


<Tabs>
  <Tab title="Python">

Install the package via pip:

  </Tab>
  <Tab title="TypeScript">

Install the package via NPM:

  </Tab>
  <Tab title="Go">

Install the package via `go get`:

  </Tab>
  <Tab title="Java">

Include the latest version of [AssemblyAI's Java SDK](https://central.sonatype.com/artifact/com.assemblyai/assemblyai-java) in your project dependencies:

  </Tab>
  <Tab title="C#">

Add the [AssemblyAI NuGet package](https://www.nuget.org/packages/AssemblyAI) to your project:

  </Tab>
  <Tab title="Ruby">

Install the latest gem for the [AssemblyAI Ruby SDK](https://rubygems.org/gems/assemblyai):

  </Tab>
</Tabs>

<Tabs groupId="language">

<Tab value="python" title="Python" default>

```bash
pip install assemblyai
```

</Tab>

<Tab value="typescript" title="TypeScript">

```bash
npm install assemblyai
```

</Tab>
<Tab value="go" title="Go">

```bash
go get github.com/AssemblyAI/assemblyai-go-sdk
```

</Tab>
<Tab value="java" title="Java">
<Tabs groupId="java-language">
<Tab value="xml" title="Maven">

```xml
<dependency>
    <groupId>com.assemblyai</groupId>
    <artifactId>assemblyai-java</artifactId>
    <version>ASSEMBLYAI_SDK_VERSION</version>
</dependency>
```

</Tab>
<Tab value="groovy" title="Gradle">

```groovy
dependencies {
    implementation 'com.assemblyai:assemblyai-java:ASSEMBLYAI_SDK_VERSION'
}
```

</Tab>
</Tabs>
</Tab>
<Tab value="csharp" title="C#">
<Tabs groupId="dotnet-dependency">
<Tab value="dotnet-cli" title=".NET CLI">

```bash
dotnet add package AssemblyAI
```

</Tab>
<Tab value="package-manager" title="Package Manager">

```PowerShell
Install-Package AssemblyAI
```

</Tab>
<Tab value="package-reference" title="PackageReference">

```xml
<PackageReference Include="AssemblyAI" Version="ASSEMBLYAI_SDK_VERSION" />
```

</Tab>
</Tabs>
</Tab>
<Tab value="ruby" title="Ruby">

```bash
gem install assemblyai
```

</Tab>

</Tabs>





## Step 2: Configure the SDK

In this step, you 'll create an SDK client and configure it to use your API key.

<Steps>
<Step>

Browse to <a href="https://www.assemblyai.com/app/account" target="_blank">Account</a>, and then click the text under **Your API key** to copy it.

</Step>
<Step>

<Tabs groupId="language">

<Tab value="python" title="Python" default>

Create a new `Transcriber` and configure it to use your API key. Replace `YOUR_API_KEY` with your copied API key.

```python


aai.settings.api_key = "<YOUR_API_KEY>"

transcriber = aai.Transcriber()
```

</Tab>

<Tab value="typescript" title="TypeScript">

Create a new client using your API key. Replace `YOUR_API_KEY` with your copied API key.

```ts


const client = new AssemblyAI({
  apiKey: '<YOUR_API_KEY>'
})
```

</Tab>
<Tab value="go" title="Go">

Create a new client using your API key. Replace `YOUR_API_KEY` with your copied API key.

```go
package main


	aai "github.com/AssemblyAI/assemblyai-go-sdk"
)

func main() {
	client := aai.NewClient("<YOUR_API_KEY>")
}
```

</Tab>
<Tab value="java" title="Java">

Create a new client using your API key. Replace `YOUR_API_KEY` with your copied API key.

```java



AssemblyAI client = AssemblyAI.builder()
                .apiKey("<YOUR_API_KEY>")
                .build();
```

</Tab>
<Tab value="csharp" title="C#">

Create a new client using your API key. Replace `YOUR_API_KEY` with your copied API key.

```csharp
using AssemblyAI;
using AssemblyAI.Transcripts;

var client = new AssemblyAIClient("<YOUR_API_KEY>");
```

</Tab>
<Tab value="ruby" title="Ruby">

Create a new client using your API key. Replace `YOUR_API_KEY` with your copied API key.

```ruby
require 'assemblyai'

client = AssemblyAI::Client.new(api_key: '<YOUR_API_KEY>')
```

</Tab>
</Tabs>

</Step>
</Steps>




## Step 3: Submit audio for transcription

In this step, you'll submit the audio file for transcription and wait until it's completes. The time it takes to process an audio file depends on its duration and the enabled models. Most transcriptions complete within 45 seconds.

<Steps>
<Step>

Specify a URL to the audio you want to transcribe. The URL needs to be accessible from AssemblyAI's servers. For a list of supported formats, see [FAQ](/Concepts/faq).

<Tabs groupId="language">

<Tab value="python" title="Python" default>

```python
audio_file = "https://assembly.ai/sports_injuries.mp3"
```

</Tab>
<Tab value="typescript" title="TypeScript">

```ts
const audioFile = 'https://assembly.ai/sports_injuries.mp3'
```

</Tab>
<Tab value="go" title="Go">

```go
audioURL := "https://assembly.ai/sports_injuries.mp3"
```

</Tab>
<Tab value="java" title="Java">

```java
String audioUrl = "https://assembly.ai/sports_injuries.mp3";
```

</Tab>
<Tab value="csharp" title="C#">

```csharp
const string audioUrl = "https://assembly.ai/sports_injuries.mp3";
```

</Tab>
<Tab value="ruby" title="Ruby">

```ruby
audio_url = 'https://assembly.ai/sports_injuries.mp3'
```

</Tab>

</Tabs>

<Tabs>
<Tab title="Python">

<Note title="Local audio files">

If you want to use a local file, you can also specify a local path, for example:

```python
audio_file = "./example.mp3"
```

</Note>

</Tab>
<Tab title="TypeScript">

<Note title="Local audio files">

If you want to use a local file, you can also specify a local path, for example:

```ts
const audioFile = './example.mp3'
```

</Note>

</Tab>
<Tab title="Go">

<Note title="Local audio files">

If you want to use a local file, you can transcribe it like this:

```go
f, err := os.Open("./example.mp3")
// [error handling here]
transcript, err := client.Transcripts.TranscribeFromReader(ctx, f, nil)
```

</Note>

</Tab>
<Tab title="Java">

<Note title="Local audio files">

If you want to use a local file, you can transcribe it like this:

```java
Transcript transcript = aai.transcripts().transcribe(
                    new File("./example.mp3"));
```

</Note>

</Tab>

<Tab title="C#">

<Note title="Local audio files">

If you want to use a local file, you can transcribe it like this:

```csharp
var transcript = await client.Transcripts.TranscribeAsync(
    new FileInfo("./example.mp3")
);
```

</Note>

</Tab>
<Tab title="Ruby">

<Note title="Local audio files">

If you want to use a local file, you can transcribe it like this:

```ruby
uploaded_file = client.files.upload(file: '/path/to/your/file.mp3')
transcript = client.transcripts.transcribe(
  audio_url: uploaded_file.upload_url
)
```

</Note>

</Tab>
</Tabs>

<Note title="YouTube">

YouTube URLs are not supported. If you want to transcribe a YouTube video, you need to download the audio first.

</Note>

</Step>
<Step>

This may take a minute while we're processing the audio.

<Tabs groupId="language">

<Tab value="python" title="Python" default>

To generate the transcript, pass the audio URL to `client.Transcripts.Transcribe()`.

```python
transcript = transcriber.transcribe(audio_file)
```

</Tab>
<Tab value="typescript" title="TypeScript">

To generate the transcript, pass the audio URL to `client.transcripts.transcribe()`.

```ts
const transcript = await client.transcripts.transcribe({ audio: audioFile })
```

</Tab>
<Tab value="go" title="Go">

To generate the transcript, pass the audio URL to `client.Transcripts.TranscribeFromURL()`.

```go
transcript, err := client.Transcripts.TranscribeFromURL(ctx, audioURL, nil)
```

</Tab>
<Tab value="java" title="Java">

To generate the transcript, pass the audio URL to `transcribe()`.

```java
Transcript transcript = client.transcripts().transcribe(audioUrl);
```

</Tab>
<Tab value="csharp" title="C#">

To generate the transcript, pass the audio URL to `transcribe()`.

```csharp
var transcript = await client.Transcripts.TranscribeAsync(new TranscriptParams
{
    AudioUrl = audioUrl
});
```

</Tab>
<Tab value="ruby" title="Ruby">

To generate the transcript, pass the audio URL to `transcribe()`.

```ruby
transcript = client.transcripts.transcribe(audio_url: audio_url)
```

</Tab>

</Tabs>

<Tip title="Select the speech model">
You can select the class of models to use in order to make cost-performance tradeoffs best suited for your application. See [Select the speech model](../02-speech-to-text/speech-recognition.mdx#select-the-speech-model-with-best--nano).
</Tip>

</Step>
<Step>


<Tabs groupId="language">
<Tab value="python" title="Python" default>

If the transcription failed, the `status` of the transcription will be set to
`error`. To see why it failed you can print the value of `error`.

```python
if transcript.error:
   print(transcript.error)
   exit(1)
```

</Tab>
<Tab value="typescript" title="TypeScript">

If the transcription failed, the `status` of the transcription will be set to
`error`. To see why it failed you can print the value of `error`.

```ts
if (transcript.status === 'error') {
  console.error(transcript.error)
  process.exit(1)
}
```

</Tab>
<Tab value="go" title="Go">

If the transcription failed, you can print `err` to see why.

```go
if err != nil {
	fmt.Println("Something bad happened:", err)
	os.Exit(1)
}
```

</Tab>
<Tab value="java" title="Java">

If the transcription failed, the `status` of the transcription will be set to
`error`. To see why it failed you can print the value of `error`.

```java
if (transcript.getStatus().equals(TranscriptStatus.ERROR)) {
    System.err.println(transcript.getError().get());
    System.exit(1);
}
```

</Tab>
<Tab value="csharp" title="C#">

If the transcription failed, the `status` of the transcription will be set to
`error`. To see why it failed you can print the value of `error`.

```csharp
if (transcript.Status == TranscriptStatus.Error)
{
    Console.WriteLine(transcript.Error);
    Environment.Exit(1);
}

// Alternatively, you can use the EnsureStatusCompleted() method
// to throw an exception if the transcription status is not "completed".
// transcript.EnsureStatusCompleted();
```

</Tab>
<Tab value="ruby" title="Ruby">

If the transcription failed, the `status` of the transcription will be set to
`error`. To see why it failed you can print the value of `error`.

```ruby
abort transcript.error if transcript.status == AssemblyAI::Transcripts::TranscriptStatus::ERROR
```

</Tab>
</Tabs>
</Step>
<Step>

Print the complete transcript.

<Tabs groupId="language">

<Tab value="python" title="Python" default>

```python
print(transcript.text)
```

</Tab>
<Tab value="typescript" title="TypeScript">

```ts
console.log(transcript.text)
```

</Tab>
<Tab value="go" title="Go">

```go
fmt.Println(*transcript.Text)
```

</Tab>
<Tab value="java" title="Java">

```java
System.out.println(transcript.getText().get());
```

</Tab>
<Tab value="csharp" title="C#">

```csharp
Console.WriteLine(transcript.Text);
```

</Tab>
<Tab value="ruby" title="Ruby">

```ruby
puts transcript.text
```

</Tab>

</Tabs>

</Step>
<Step>

Run the application and wait for it to finish.

</Step>
</Steps>

You've successfully transcribed your first audio file. You can see all submitted transcription jobs in the <a href="https://www.assemblyai.com/app/processing-queue" target="_blank">Processing queue</a>.




## Step 4: Enable additional AI models

You can extract even more insights from the audio by enabling any of our [AI models](/audio-intelligence) using _transcription options_. In this step, you'll enable the [Speaker diarization](../02-speech-to-text/speaker-diarization.mdx) model to detect who said what.

<Steps>
<Step>

<Tabs>
  <Tab title="Python">

Create a `TranscriptionConfig` with `speaker_labels` set to `True`, and then pass it as the second argument to `transcribe()`.

  </Tab>
  <Tab title="TypeScript">

Set the `speaker_labels` property to `true` in the `params` object.

  </Tab>
  <Tab title="Go">

Create a `TranscriptOptionalParams` with `SpeakerLabels` set to `true`, and pass it to `TranscribeFromURL()`.

  </Tab>
  <Tab title="Java">

Build `TranscriptOptionalParams` with `speakerLabels` set to `true`, and pass the params to `transcribe()`.

  </Tab>
  <Tab title="C#">

Set the `SpeakerLabels` parameter to `true`.

  </Tab>
  <Tab title="Ruby">

Set the `speaker_labels` parameter to `true` on `transcribe()`.

  </Tab>
</Tabs>

<Tabs groupId="language">

<Tab value="python" title="Python" default>

```python
config = aai.TranscriptionConfig(speaker_labels=True)

transcript = transcriber.transcribe(audio_file, config)
```

</Tab>
<Tab value="typescript" title="TypeScript">

```ts
const params = {
  audio: audioFile,
  speaker_labels: true
}

const transcript = await client.transcripts.transcribe(params)
```

</Tab>
<Tab value="go" title="Go">

```go
params := &assemblyai.TranscriptOptionalParams{
	SpeakerLabels: aai.Bool(true),
}

transcript, err := client.Transcripts.TranscribeFromURL(ctx, audioURL, params)
```

</Tab>
<Tab value="java" title="Java">

```java
var params = TranscriptOptionalParams.builder()
                .speakerLabels(true)
                .build();

Transcript transcript = client.transcripts().transcribe(audioUrl, params);
```

</Tab>
<Tab value="csharp" title="C#">

```csharp
var transcript = await client.Transcripts.TranscribeAsync(new TranscriptParams
{
    AudioUrl = audioUrl,
    SpeakerLabels = true
});
```

</Tab>
<Tab value="ruby" title="Ruby">

```ruby
transcript = client.transcripts.transcribe(
  audio_url: audio_url,
  speaker_labels: true
)
```

</Tab>

</Tabs>

</Step>
<Step>

In addition to the full transcript, you now have access to utterances from each speaker.

<Tabs groupId="language">

<Tab value="python" title="Python" default>

```python
for utterance in transcript.utterances:
	print(f"Speaker {utterance.speaker}: {utterance.text}")
```

</Tab>
<Tab value="typescript" title="TypeScript">

```typescript
for (let utterance of transcript.utterances!) {
  console.log(`Speaker ${utterance.speaker}: ${utterance.text}`)
}
```

</Tab>
<Tab value="go" title="Go">

```go
for _, utterance := range transcript.Utterances {
	fmt.Printf("Speaker %v: %v\n", *utterance.Speaker, *utterance.Text)
}
```

</Tab>
<Tab value="java" title="Java">

```java
transcript.getUtterances().get().forEach(utterance ->
        System.out.println("Speaker " + utterance.getSpeaker() + ": " + utterance.getText())
);
```

</Tab>
<Tab value="csharp" title="C#">

```csharp
foreach (var utterance in transcript.Utterances!)
{
    Console.WriteLine($"Speaker {utterance.Speaker}: {utterance.Text}");
}
```

</Tab>
<Tab value="ruby" title="Ruby">

```ruby
transcript.utterances.each do |utterance|
  printf('Speaker %<speaker>s: %<text>s', speaker: utterance.speaker, text: utterance.text)
end
```

</Tab>

</Tabs>

</Step>
</Steps>

Many of the properties in the transcript object only become available after you enable the corresponding model. For more information, see the models under [Speech-to-Text](/speech-to-text) and [Audio Intelligence](/audio-intelligence).




## Next steps

In this tutorial, you've learned how to generate a transcript for an audio file and how to extract speaker information by enabling the [Speaker diarization](../02-speech-to-text/speaker-diarization.mdx) model.

Want to learn more?

- For more ways to analyze your audio data, explore our [Audio Intelligence models](/audio-intelligence).
- If you want to transcribe audio in real-time, see [Transcribe streaming audio from a microphone](/getting-started/transcribe-streaming-audio-from-a-microphone).
- To search, summarize, and ask questions on your transcripts with LLMs, see [LeMUR](/lemur).




## Need some help?

If you get stuck, or have any other questions, we'd love to help you out. Ask our support team in our [Discord server](https://discord.gg/aSMMpMadFh).



