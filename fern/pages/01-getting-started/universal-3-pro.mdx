---
title: "Introducing Universal-3-Pro"
subtitle: "Learn how to transcribe pre-recorded audio using Universal-3-Pro."
hide-nav-links: true
description: "Learn how to transcribe pre-recorded audio using Universal-3-Pro."
---

## Overview

Universal-3-Pro is our best transcription model designed to capture the "hard stuff" that traditional ASR models struggle with, namely:

- **Natural language prompting** - control the style and context of transcription
- **Key terms prompting** - boost accuracy of known rare words in transcription
- **Built-in code switching** - native switching between languages and context
- **Max verbatim mode** - control elements like disfluencies, stutters, false starts, colloquialisms, and more
- **Audio tags for non-speech** - add markers for non-speech events in the audio file

Using the above altogether, you can get an entirely customized transcription output that rivals near-human-level transcription.

Without any prompting or changes, the model out of the box outperforms all ASR models on the market on accuracy, especially as it pertains to entities and rare words.

## Quick Start

This example shows how you can transcribe a pre-recorded audio file with our Universal-3-Pro model and print the transcript text to your terminal.

<Tabs groupId="language">
<Tab language="python" title="Python" default>

```python
import requests
import time

base_url = "https://api.assemblyai.com"
headers = {"authorization": "<YOUR_API_KEY>"}

data = {
    "audio_url": "https://assembly.ai/sports_injuries.mp3",
    "language_detection": True,
    "speech_models": ["universal-3-pro", "universal"]
}

response = requests.post(base_url + "/v2/transcript", headers=headers, json=data)

if response.status_code != 200:
    print(f"Error: {response.status_code}, Response: {response.text}")
    response.raise_for_status()

transcript_response = response.json()
transcript_id = transcript_response["id"]
polling_endpoint = f"{base_url}/v2/transcript/{transcript_id}"

while True:
    transcript = requests.get(polling_endpoint, headers=headers).json()
    if transcript["status"] == "completed":
        print(transcript["text"])
        break
    elif transcript["status"] == "error":
        raise RuntimeError(f"Transcription failed: {transcript['error']}")
    else:
        time.sleep(3)
```

</Tab>
<Tab language="javascript" title="JavaScript">

```javascript
import axios from 'axios'

const baseUrl = 'https://api.assemblyai.com'
const headers = {
  authorization: '<YOUR_API_KEY>'
}

const data = {
  audio_url: 'https://assembly.ai/sports_injuries.mp3',
  language_detection: true,
  speech_models: ['universal-3-pro', 'universal']
}

const url = `${baseUrl}/v2/transcript`
const response = await axios.post(url, data, { headers: headers })

const transcriptId = response.data.id
const pollingEndpoint = `${baseUrl}/v2/transcript/${transcriptId}`

while (true) {
  const pollingResponse = await axios.get(pollingEndpoint, {
    headers: headers
  })
  const transcriptionResult = pollingResponse.data

  if (transcriptionResult.status === 'completed') {
    console.log(transcriptionResult.text)
    break
  } else if (transcriptionResult.status === 'error') {
    throw new Error(`Transcription failed: ${transcriptionResult.error}`)
  } else {
    await new Promise((resolve) => setTimeout(resolve, 3000))
  }
}
```

</Tab>
</Tabs>

<Note title="Language Support">

Universal-3-Pro currently offers support for English, Spanish, Portuguese, French, German, and Italian.

For best results, we suggest using our [Automatic Language Detection](/docs/speech-to-text/pre-recorded-audio/automatic-language-detection) feature along with including our Universal model as a `speech_model` option in your request, which is the approach shown in this code example.

Using this approach will result in the broadest language support for all 99 [languages supported by our API](/docs/speech-to-text/pre-recorded-audio/supported-languages).

</Note>

<Note title="Local audio files">

The above code examples show how to transcribe a file that is available via URL. If you would like to work with local files, see our [API Reference](https://www.assemblyai.com/docs/api-reference/files/upload) for more information on transcribing local files.

</Note>

## Learn more about what you can do with natural-language prompting

*This section will include more information on things like verbatim transcripts, audio tags, and link to the prompting resources that Ryan is working on in a separate doc update.*
