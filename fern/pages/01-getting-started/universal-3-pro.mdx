---
title: "Introducing Universal 3 Pro"
subtitle: "Learn how to transcribe pre-recorded audio using Universal 3 Pro."
hide-nav-links: true
description: "Learn how to transcribe pre-recorded audio using Universal 3 Pro."
---

## Overview

Universal 3 Pro represents a fundamental shift in speech recognition technology. By combining LLM architecture with our best-in-class ASR encoders, we've created the world's first Speech Language Model optimized explicitly for speech-to-text tasks.

This innovative approach moves beyond traditional speech recognition to deliver LLM-powered transcription with unprecedented accuracy and capabilities.

Universal 3 Pro is available in two model options:

- **Universal 3 Pro**: Supports English only and delivers the highest accuracy for English audio.
- **Universal 3 Pro Multilingual**: Supports English, Spanish, German, French, Portuguese, and Italian. Note that while it supports English, it is not as performant as Universal 3 Pro on English-only audio. Multilingual Universal 3 Pro is particularly useful for code-switching scenarios.

## Quick Start

Universal 3 Pro is available via the https://api.assemblyai.com/v2/transcript endpoint using your API key. To use Universal 3 Pro, include the `speech_models` parameter with a value of `["universal-3-pro"]` as shown in the code examples below.

For Multilingual Universal 3 Pro, use `speech_models=["universal-3-pro-ml"]`.

<Tabs groupId="language">
<Tab language="python-sdk" title="Python SDK" default>

```python
import assemblyai as aai

aai.settings.api_key = "<YOUR_API_KEY>"

# You can use a local filepath:
# audio_file = "./local_file.mp3"

# Or use a publicly-accessible URL:
audio_file = "https://assembly.ai/sports_injuries.mp3"

# Configure to use Universal 3 Pro
config = aai.TranscriptionConfig(speech_models=["universal-3-pro"])
transcript = aai.Transcriber(config=config).transcribe(audio_file)

if transcript.status == "error":
    raise RuntimeError(f"Transcription failed: {transcript.error}")

print(transcript.text)
```

</Tab>
<Tab language="python" title="Python">

```python
import requests
import time

base_url = "https://api.assemblyai.com"
headers = {"authorization": "<YOUR_API_KEY>"}

data = {
    "audio_url": "https://assembly.ai/sports_injuries.mp3",
    "speech_models": ["universal-3-pro"]
}

response = requests.post(base_url + "/v2/transcript", headers=headers, json=data)

if response.status_code != 200:
    print(f"Error: {response.status_code}, Response: {response.text}")
    response.raise_for_status()

transcript_response = response.json()
transcript_id = transcript_response["id"]
polling_endpoint = f"{base_url}/v2/transcript/{transcript_id}"

while True:
    transcript = requests.get(polling_endpoint, headers=headers).json()
    if transcript["status"] == "completed":
        print(transcript["text"])
        break
    elif transcript["status"] == "error":
        raise RuntimeError(f"Transcription failed: {transcript['error']}")
    else:
        time.sleep(3)
```

</Tab>
<Tab language="javascript-sdk" title="JavaScript SDK">

```javascript
import { AssemblyAI } from 'assemblyai';

const client = new AssemblyAI({
  apiKey: '<YOUR_API_KEY>'
});

const audioUrl = 'https://assembly.ai/sports_injuries.mp3';

const config = {
  audio: audioUrl,
  speech_models: ['universal-3-pro']
};

const transcript = await client.transcripts.transcribe(config);

if (transcript.status === 'error') {
  throw new Error(`Transcription failed: ${transcript.error}`);
}

console.log(transcript.text);
```

</Tab>
<Tab language="javascript" title="JavaScript">

```javascript
import axios from 'axios'

const baseUrl = 'https://api.assemblyai.com'
const headers = {
  authorization: '<YOUR_API_KEY>'
}

const data = {
  audio_url: 'https://assembly.ai/sports_injuries.mp3',
  speech_models: ['universal-3-pro']
}

const url = `${baseUrl}/v2/transcript`
const response = await axios.post(url, data, { headers: headers })

const transcriptId = response.data.id
const pollingEndpoint = `${baseUrl}/v2/transcript/${transcriptId}`

while (true) {
  const pollingResponse = await axios.get(pollingEndpoint, {
    headers: headers
  })
  const transcriptionResult = pollingResponse.data

  if (transcriptionResult.status === 'completed') {
    console.log(transcriptionResult.text)
    break
  } else if (transcriptionResult.status === 'error') {
    throw new Error(`Transcription failed: ${transcriptionResult.error}`)
  } else {
    await new Promise((resolve) => setTimeout(resolve, 3000))
  }
}
```

</Tab>
</Tabs>

<Note title="Local audio files">

The above code examples show how to transcribe a file that is available via URL. If you would like to work with local files, see our [API Reference](https://www.assemblyai.com/docs/api-reference/files/upload) for more information on transcribing local files.

</Note>

## Fine-tuning Universal 3 Pro

What truly sets Universal 3 Pro apart is its ability to be customized for specific industries and use cases with minimal effort. Rather than spending months developing custom models or implementing complex post-processing rules, Universal 3 Pro offers two distinct customization approaches that give you unprecedented control over your transcription results.

One approach is to prompt the model with key terminology in the form of a list of words and phrases. The other approach is to prompt the model with contextual information about the audio in your file. Continue reading for more information on these two approaches.

### Contextual prompting of words and phrases

Improve transcription accuracy by leveraging Universal 3 Pro's contextual understanding capabilities by prompting the model with certain words or phrases that are likely to appear frequently in your audio file.

Rather than simply increasing the likelihood of detecting specific words, Universal 3 Pro's multi-modal architecture actually understands the semantic meaning and context of the terminology you provide, enhancing transcription quality not just of the exact terms you specify, but also related terminology, variations, and contextually similar phrases.

Provide up to 1000 domain-specific words or phrases (maximum 6 words per phrase) that may appear in your audio using the optional `keyterms_prompt` parameter:

<Tabs groupId="language">
<Tab language="python" title="Python" default>

```python
import requests
import time

base_url = "https://api.assemblyai.com"
headers = {"authorization": "<YOUR_API_KEY>"}

data = {
    "audio_url": "https://assembly.ai/sports_injuries.mp3",
    "speech_models": ["universal-3-pro"],
    "keyterms_prompt": ['differential diagnosis', 'hypertension', 'Wellbutrin XL 150mg']
}

response = requests.post(base_url + "/v2/transcript", headers=headers, json=data)

if response.status_code != 200:
    print(f"Error: {response.status_code}, Response: {response.text}")
    response.raise_for_status()

transcript_response = response.json()
transcript_id = transcript_response["id"]
polling_endpoint = f"{base_url}/v2/transcript/{transcript_id}"

while True:
    transcript = requests.get(polling_endpoint, headers=headers).json()
    if transcript["status"] == "completed":
        print(transcript["text"])
        break
    elif transcript["status"] == "error":
        raise RuntimeError(f"Transcription failed: {transcript['error']}")
    else:
        time.sleep(3)
```

</Tab>
<Tab language="javascript" title="JavaScript">

```javascript
import axios from 'axios'

const baseUrl = 'https://api.assemblyai.com'
const headers = {
  authorization: '<YOUR_API_KEY>'
}

const data = {
  audio_url: 'https://assembly.ai/sports_injuries.mp3',
  speech_models: ['universal-3-pro'],
  keyterms_prompt: ['differential diagnosis', 'hypertension', 'Wellbutrin XL 150mg']
}

const url = `${baseUrl}/v2/transcript`
const response = await axios.post(url, data, { headers: headers })

const transcriptId = response.data.id
const pollingEndpoint = `${baseUrl}/v2/transcript/${transcriptId}`

while (true) {
  const pollingResponse = await axios.get(pollingEndpoint, {
    headers: headers
  })
  const transcriptionResult = pollingResponse.data

  if (transcriptionResult.status === 'completed') {
    console.log(transcriptionResult.text)
    break
  } else if (transcriptionResult.status === 'error') {
    throw new Error(`Transcription failed: ${transcriptionResult.error}`)
  } else {
    await new Promise((resolve) => setTimeout(resolve, 3000))
  }
}
```

</Tab>
</Tabs>

<Note title="Keyword count limits">

While we support up to 1000 keywords and phrases, actual capacity may be lower due to internal tokenization and implementation constraints.

Key points to remember:

- Each word in a multi-word phrase counts towards the 1000 keyword limit
- Capitalization affects capacity (uppercase tokens consume more than lowercase)
- Longer words consume more capacity than shorter words

For optimal results, use shorter phrases when possible and be mindful of your total token count when approaching the keyword limit.

</Note>

Here is an example of what a `keyterms_prompt` list might look like for a transcription of a professional therapy session for a patient named Jane Doe, who is being treated for anxiety and depression:

```txt wordWrap
["Jane Doe", "cognitive behavioral therapy", "major depressive disorder", "generalized anxiety disorder", "ADHD", "trauma-informed care", "Lexapro 10mg", "psychosocial assessment", "therapeutic alliance", "emotional dysregulation", "GAD-7", "PHQ-9", "Citalopram 20mg", "Lorazepam 2mg"]
```

### Contextual prompting with natural language

Another way to improve transcription accuracy is to leverage Universal 3 Pro's contextual understanding capabilities by prompting the model with a description of your audio in plain English. This allows the model to understand the broader context of your audio file and make more intelligent transcription decisions. You can provide up to 1,500 words of contextual information, giving the model rich background knowledge about the content, participants, domain, and purpose of the audio.

A common use case for these contextual prompts is to leverage known context about the call and provide it with the transcription. This might look like:

- **Legal Deposition**: "This is a deposition in the case of Smith v. Acme Corporation, a product liability lawsuit involving an alleged defect in the XJ-5000 power tool that resulted in severe lacerations to the plaintiff's right hand. The deposition will involve questioning of Dr. Elizabeth Chen, an orthopedic surgeon who treated the plaintiff's injuries."
- **Veterinary Consultation**: "This is a veterinary consultation about a dog with hip dysplasia."
- **Medical Consultation**: "This is a medical consultation between Dr. Jones, a pulmonologist, and Dan Rayman who is being evaluated for recurring pneumonia."

To prompt the model with contextual language, include the `prompt` parameter in your request as shown in the code example below.

<Tabs groupId="language">
<Tab language="python" title="Python" default>

```python
import requests
import time

base_url = "https://api.assemblyai.com"
headers = {"authorization": "<YOUR_API_KEY>"}

data = {
    "audio_url": "https://assembly.ai/sports_injuries.mp3",
    "speech_models": ["universal-3-pro"],
    "prompt": "This is a shareholder meeting for the ACME Corporation to discuss Q3 financial results and expectations for Q4 and beyond."
}

response = requests.post(base_url + "/v2/transcript", headers=headers, json=data)

if response.status_code != 200:
    print(f"Error: {response.status_code}, Response: {response.text}")
    response.raise_for_status()

transcript_response = response.json()
transcript_id = transcript_response["id"]
polling_endpoint = f"{base_url}/v2/transcript/{transcript_id}"

while True:
    transcript = requests.get(polling_endpoint, headers=headers).json()
    if transcript["status"] == "completed":
        print(transcript["text"])
        break
    elif transcript["status"] == "error":
        raise RuntimeError(f"Transcription failed: {transcript['error']}")
    else:
        time.sleep(3)
```

</Tab>
<Tab language="javascript" title="JavaScript">

```javascript
import axios from 'axios'

const baseUrl = 'https://api.assemblyai.com'
const headers = {
  authorization: '<YOUR_API_KEY>'
}

const data = {
  audio_url: 'https://assembly.ai/sports_injuries.mp3',
  speech_models: ['universal-3-pro'],
  prompt: 'This is a shareholder meeting for the ACME Corporation to discuss Q3 financial results and expectations for Q4 and beyond.'
}

const url = `${baseUrl}/v2/transcript`
const response = await axios.post(url, data, { headers: headers })

const transcriptId = response.data.id
const pollingEndpoint = `${baseUrl}/v2/transcript/${transcriptId}`

while (true) {
  const pollingResponse = await axios.get(pollingEndpoint, {
    headers: headers
  })
  const transcriptionResult = pollingResponse.data

  if (transcriptionResult.status === 'completed') {
    console.log(transcriptionResult.text)
    break
  } else if (transcriptionResult.status === 'error') {
    throw new Error(`Transcription failed: ${transcriptionResult.error}`)
  } else {
    await new Promise((resolve) => setTimeout(resolve, 3000))
  }
}
```

</Tab>
</Tabs>

## Should I use keyterms_prompt or prompt?

Prompting with the `keyterms_prompt` parameter is a good option when you have a specific terminology or vocabulary that you would like to fine-tune the model with. `keyterms_prompt` works best with targeted use cases where specific words and phrases can be identified.

Prompting with the `prompt` parameter is a good option when you know the context of the audio, perhaps derived from some metadata, but exact terminology may be too broad or numerous to capture in a list. `prompt` works best when you would rather pass a high level description than specific words or phrases.

<Note>

The `keyterms_prompt` and `prompt` parameters cannot both be used in the same request.

</Note>
