---
title: "Transcribe a pre-recorded audio file"
subtitle: "Learn how to transcribe and analyze an audio file."
hide-nav-links: true
description: "Learn how to transcribe and analyze an audio file."
---

## Overview

By the end of this tutorial, you'll be able to:

- Transcribe a pre-recorded audio file.
- [Select the speech model](/docs/speech-to-text/pre-recorded-audio/select-the-speech-model) for your request (optional).

When transcribing an audio file, there are three main things you will want to specify:

1. Select the speech models you would like to use (required).
2. Select the region you would like to use (optional).
3. Select any other models you would like to use like Speaker Diarization or PII Redaction (optional).

Here's the full sample code for what you'll build in this tutorial:

<Tabs groupId="language">
<Tab language="python-sdk" title="Python SDK" default>

```python
import assemblyai as aai

aai.settings.api_key = "<YOUR_API_KEY>"

transcriber = aai.Transcriber()

# You can use a local filepath:
# audio_file = "./example.mp3"

# Or use a publicly-accessible URL:
audio_file = "https://assembly.ai/sports_injuries.mp3"

# Optionally specify a speech model (defaults to "universal"):
# config = aai.TranscriptionConfig(speech_models=["slam-1"])
# transcript = transcriber.transcribe(audio_file, config=config)

transcript = transcriber.transcribe(audio_file)

if transcript.status == aai.TranscriptStatus.error:
    print(f"Transcription failed: {transcript.error}")
    exit(1)

print(f" \nFull Transcript: \n\n{transcript.text}")
```

</Tab>
<Tab language="python" title="Python">

```python
import requests
import time

base_url = "https://api.assemblyai.com"
headers = {"authorization": "<YOUR_API_KEY>"}

# Use a publicly-accessible URL:
audio_file = "https://assembly.ai/sports_injuries.mp3"

''' Or upload a local file:
with open("./example.mp3", "rb") as f:
    response = requests.post(base_url + "/v2/upload", headers=headers, data=f)

    if response.status_code != 200:
        print(f"Error: {response.status_code}, Response: {response.text}")
        response.raise_for_status()

    upload_json = response.json()
    upload_url = upload_json["upload_url"]
'''

data = {
    "audio_url": audio_file,  # For local files use: "audio_url": upload_url
    # Optionally specify a speech model (defaults to "universal"):
    # "speech_models": ["slam-1"]
}

response = requests.post(base_url + "/v2/transcript", headers=headers, json=data)

if response.status_code != 200:
    print(f"Error: {response.status_code}, Response: {response.text}")
    response.raise_for_status()

transcript_json = response.json()
transcript_id = transcript_json["id"]
polling_endpoint = f"{base_url}/v2/transcript/{transcript_id}"

while True:
    transcript = requests.get(polling_endpoint, headers=headers).json()
    if transcript["status"] == "completed":
        print(f" \nFull Transcript: \n\n{transcript['text']}")
        break
    elif transcript["status"] == "error":
        raise RuntimeError(f"Transcription failed: {transcript['error']}")
    else:
        time.sleep(3)
```

</Tab>
<Tab language="javascript-sdk" title="JavaScript SDK">

```javascript
import { AssemblyAI } from "assemblyai";

const client = new AssemblyAI({
  apiKey: "<YOUR_API_KEY>",
});

// You can use a local filepath:
// const audioFile = "./example.mp3"

// Or use a publicly-accessible URL:
const audioFile = "https://assembly.ai/sports_injuries.mp3";

const params = {
  audio: audioFile,
  // Optionally specify a speech model (defaults to "universal"):
  // speech_models: ["slam-1"],
};

const run = async () => {
  const transcript = await client.transcripts.transcribe(params);

  if (transcript.status === "error") {
    console.error(`Transcription failed: ${transcript.error}`);
    process.exit(1);
  }

  console.log(`\nFull Transcript:\n\n${transcript.text}\n`);
};

run();
```

</Tab>
<Tab language="javascript" title="JavaScript">

```javascript
import axios from "axios";
import fs from "fs-extra";

const baseUrl = "https://api.assemblyai.com";

const headers = {
  authorization: "<YOUR_API_KEY>",
};

async function transcribe() {
  try {
    // Use a publicly accessible URL:
    const audioFile = "https://assembly.ai/sports_injuries.mp3";

    // Or upload a local file
    /*     
    let uploadUrl

         try {
          const audio = './audio/audio.mp3'
          const audioData = await fs.readFile(audio)
          const uploadResponse = await axios.post(`${baseUrl}/v2/upload`, audioData, { headers })
          uploadUrl = uploadResponse.data.upload_url

         } catch(error) {
          console.error("Error from '/upload' request:", error.response?.data || error.response || error);
         } 
         */

    const data = {
      audio_url: audioFile, // For local files use: audio_url: uploadUrl
      // Optionally specify a speech model (defaults to "universal"):
      // speech_models: ["slam-1"],
    };

    const url = `${baseUrl}/v2/transcript`;
    let transcriptId;

    try {
      const transcriptResponse = await axios.post(url, data, { headers });
      transcriptId = transcriptResponse.data.id;
    } catch (error) {
      console.error(
        "Error from POST '/transcript' request:",
        error.response.data.error || error
      );
    }

    const pollingEndpoint = `${baseUrl}/v2/transcript/${transcriptId}`;

    while (true) {
      const pollingResponse = await axios.get(pollingEndpoint, { headers });
      const transcriptionResult = pollingResponse.data;

      if (transcriptionResult.status === "completed") {
        console.log(`\nFull Transcript:\n\n${transcriptionResult.text}\n`);
        break;
      } else if (transcriptionResult.status === "error") {
        throw new Error(`Transcription failed: ${transcriptionResult.error}`);
      } else {
        await new Promise((resolve) => setTimeout(resolve, 3000));
      }
    }
  } catch (error) {
    console.error(error.message);
  }
}

transcribe();
```

</Tab>
</Tabs>

## Before you begin

To complete this tutorial, you need:

- If opting to use the Python or Python SDK code, you will need [Python](https://www.python.org/) installed.
- If opting to use the JavaScript or JavaScript SDK code, you will need [Node.js](https://nodejs.org/) installed.
- <a href="https://www.assemblyai.com/dashboard/signup" target="_blank">
    A free AssemblyAI account.
  </a>

## Step 1: Install the necessary libraries

<Tabs>
<Tab language="python-sdk" title="Python SDK">

<Steps>
<Step>

Install our Python SDK via pip:

```bash
pip install assemblyai
```

</Step>
<Step>

Create a new file and import the `assemblyai` package.

```python
import assemblyai as aai
```

</Step>
</Steps>

</Tab>
<Tab language="python" title="Python">

<Steps>
<Step>

Install the requests library used for making an HTTP request.

```bash
pip install requests
```

</Step>
<Step>

Create a new file and import the requests and time library.

```python
import requests
import time
```

</Step>
</Steps>
</Tab>
<Tab language="javascript-sdk" title="JavaScript SDK">
<Steps>
<Step>

Install the `assemblyai` package via NPM:

```bash
npm install assemblyai
```

</Step>
<Step>

Create a new file and import the `assemblyai` package.

```javascript
import { AssemblyAI } from "assemblyai";
```

</Step>
</Steps>

</Tab>
<Tab language="javascript" title="JavaScript">

<Steps>
<Step>

Install the `axios` and `fs-extra` packages via NPM:

```bash
npm install axios fs-extra
```

</Step>
<Step>

Create a new file and import the `axios` and `fs-extra` packages.

```javascript
import axios from "axios";
import fs from "fs-extra";
```

</Step>
</Steps>
</Tab>
</Tabs>

## Step 2: Configure your request

<Tabs>
<Tab language="python-sdk" title="Python SDK">
In this step, you'll create an SDK client and configure it to use your API key.

<Steps>
<Step>

Browse to <a href="https://www.assemblyai.com/app/api-keys" target="_blank">API Keys</a> in your dashboard, and then copy your API key.

</Step>

<Step>

Create a new `Transcriber` and configure it to use your API key. Replace `YOUR_API_KEY` with your copied API key.

```python
aai.settings.api_key = "<YOUR_API_KEY>"

transcriber = aai.Transcriber()
```

</Step>
<Step>

Specify a URL to the audio you want to transcribe. The URL needs to be accessible from AssemblyAI's servers. For a list of supported formats, see [FAQ](/docs/faq/what-audio-and-video-file-types-are-supported-by-your-api).

```python
audio_file = "https://assembly.ai/sports_injuries.mp3"
```

<Note title="Creating self hosted audio URLs">

You can use a service like Amazon S3, Google Cloud Storage, or any platform that supports direct file access to generate a shareable audio file URL. Check out this cookbook on how to [transcribe from an S3 bucket.](/docs/guides/transcribe_from_s3)

</Note>

<Note title="Local audio files">

If you want to use a local file, you can also specify a local path, for example:

```python
audio_file = "./example.mp3"
```

</Note>

<Note title="YouTube">

YouTube URLs are not supported. If you want to transcribe a YouTube video, you need to download the audio first.

</Note>

</Step>
</Steps>

</Tab>
<Tab language="python" title="Python">

In this step you'll set the base URL and configure your API key.

<Steps>
<Step>

Browse to <a href="https://www.assemblyai.com/app/api-keys" target="_blank">API Keys</a> in your dashboard, and then copy your API key.

</Step>
<Step>

Set the base URL and set your headers. Replace `YOUR_API_KEY` with your copied API key.

```python
base_url = "https://api.assemblyai.com"

headers = { "authorization": "<YOUR_API_KEY>"}
```

</Step>
<Step>

Specify a URL to the audio you want to transcribe. The URL needs to be accessible from AssemblyAI's servers. For a list of supported formats, see [FAQ](/docs/faq/what-audio-and-video-file-types-are-supported-by-your-api).

```python
audio_file = "https://assembly.ai/sports_injuries.mp3"
```

<Note title="Creating self hosted audio URLs">

You can use a service like Amazon S3, Google Cloud Storage, or any platform that supports direct file access to generate a shareable audio file URL. Check out this cookbook on how to [transcribe from an S3 bucket.](/docs/guides/transcribe_from_s3)

</Note>

<Note title="Local audio files">

If you want to use a local file, you can send the file to our upload endpoint. You'll want to add some error handling in case the upload fails. If the request is successful, the upload endpoint will respond with an `upload_url` :

```python
with open("./example.mp3", "rb") as f:
    response = requests.post(base_url + "/v2/upload", headers=headers, data=f)
if response.status_code != 200:
    print(f"Error: {response.status_code}, Response: {response.text}")
    response.raise_for_status()
upload_json =  response.json()
upload_url = upload_json["upload_url"]
```

We delete uploaded files from our servers either after the transcription has completed, or 24 hours after you uploaded the file. After the file has been deleted, the corresponding `upload_url` is no longer valid.

</Note>

<Note title="YouTube">

YouTube URLs are not supported. If you want to transcribe a YouTube video, you need to download the audio first.

</Note>

</Step>
<Step>

Pass the audio URL to the data object.

```python
data = {"audio_url": audio_file}
# Or pass the upload_url if you used the upload endpoint
# data = {"audio_url": upload_url}
```

</Step>
</Steps>

</Tab>
<Tab language="javascript-sdk" title="JavaScript SDK">

In this step, you'll create an SDK client and configure it to use your API key.

<Steps>
<Step>

Browse to <a href="https://www.assemblyai.com/app/api-keys" target="_blank">API Keys</a> in your dashboard, and then copy your API key.

</Step>

<Step>

Create a new client using your API key. Replace `YOUR_API_KEY` with your copied API key.

```javascript
import { AssemblyAI } from "assemblyai";

const client = new AssemblyAI({
  apiKey: "<YOUR_API_KEY>",
});
```

</Step>
<Step>

Specify a URL to the audio you want to transcribe. The URL needs to be accessible from AssemblyAI's servers. For a list of supported formats, see [FAQ](/docs/faq/what-audio-and-video-file-types-are-supported-by-your-api).

```javascript
const audioFile = "https://assembly.ai/sports_injuries.mp3";
```

<Note title="Creating self hosted audio URLs">
  You can use a service like Amazon S3, Google Cloud Storage, or any platform
  that supports direct file access to generate a shareable audio file URL. Check
  out this cookbook on how to [transcribe from an S3
  bucket.](/docs/guides/transcribe_from_s3)
</Note>

<Note title="Local audio files">

If you want to use a local file, you can also specify a local path, for example:

```javascript
const audioFile = "./example.mp3";
```

</Note>

<Note title="YouTube">

YouTube URLs are not supported. If you want to transcribe a YouTube video, you need to download the audio first.

</Note>

</Step>
</Steps>

</Tab>
<Tab language="javascript" title="JavaScript">
In this step you'll set the base URL and configure your API key.
<Steps>
<Step>

Browse to <a href="https://www.assemblyai.com/app/api-keys" target="_blank">API Keys</a> in your dashboard, and then copy your API key.

</Step>

<Step>

Set the base URL and set your headers. Replace `YOUR_API_KEY` with your copied API key.

```javascript
const baseUrl = "https://api.assemblyai.com";

const headers = {
  authorization: "<YOUR_API_KEY>",
};
```

</Step>
<Step>

Create a `transcribe` function and specify a URL to the audio you want to transcribe. Add a `data` object and pass the `audioFile` to the `audio_url` parameter. The URL needs to be accessible from AssemblyAI's servers. For a list of supported formats, see [FAQ](https://support.assemblyai.com/).

```javascript
async function transcribe() {
  const audioFile = "https://assembly.ai/sports_injuries.mp3";
  const data = { audio_url: audioFile };
}
```

<Note title="Creating self hosted audio URLs">

You can use a service like Amazon S3, Google Cloud Storage, or any platform that supports direct file access to generate a shareable audio file URL. Check out this cookbook on how to [transcribe from an S3 bucket.](/docs/guides/transcribe_from_s3)

</Note>

<Note title="Local audio files">

If you want to use a local file, you can send the file to our upload endpoint. You'll want to add some error handling in case the upload fails. If the request is successful, the upload endpoint will respond with an upload URL :

```javascript
async function transcribe() {
  let uploadUrl;

  try {
    const audio = "./example.mp3";
    const audioData = await fs.readFile(audio);
    const uploadResponse = await axios.post(`${baseUrl}/v2/upload`, audioData, {
      headers,
    });
    uploadUrl = uploadResponse.data.upload_url;
  } catch (error) {
    console.error(
      "Error from '/upload' request:",
      error.response?.data || error.response || error
    );
  }

  const data = { audio_url: uploadUrl };
}
```

We delete uploaded files from our servers either after the transcription has completed, or 24 hours after you uploaded the file. After the file has been deleted, the corresponding `upload_url` is no longer valid.

</Note>

<Note title="YouTube">

YouTube URLs are not supported. If you want to transcribe a YouTube video, you need to download the audio first.

</Note>
</Step>
</Steps>

</Tab>
</Tabs>

## Step 3: Select the speech model (optional)

AssemblyAI offers multiple speech models optimized for different use cases. You can use the `speech_models` parameter to specify which model to use for your transcription.

The available models are:

- **Universal** (default): Best for out-of-the-box transcription with multi-language support and excellent accuracy.
- **Slam-1** (beta): Highest accuracy for English content with fine-tuning support and customization via prompting.

For more details on model capabilities and pricing, see [Models](/docs/getting-started/models).

<Note>
  If you do not specify a speech model, the Universal model will be used by
  default.
</Note>

<Tabs>
<Tab language="python-sdk" title="Python SDK">

To specify a speech model, create a `TranscriptionConfig` with the `speech_models` parameter:

```python
config = aai.TranscriptionConfig(speech_models=["slam-1"])
```

You can also specify multiple models in priority order. The system will use the first compatible model:

```python
config = aai.TranscriptionConfig(speech_models=["slam-1", "universal"])
```

</Tab>
<Tab language="python" title="Python">

To specify a speech model, add the `speech_models` parameter to the data object:

```python
data = {
    "audio_url": audio_file,
    "speech_models": ["slam-1"]
}
```

You can also specify multiple models in priority order. The system will use the first compatible model:

```python
data = {
    "audio_url": audio_file,
    "speech_models": ["slam-1", "universal"]
}
```

</Tab>
<Tab language="javascript-sdk" title="JavaScript SDK">

To specify a speech model, set the `speech_models` property in the params object:

```javascript
const params = {
  audio: audioFile,
  speech_models: ["slam-1"],
};
```

You can also specify multiple models in priority order. The system will use the first compatible model:

```javascript
const params = {
  audio: audioFile,
  speech_models: ["slam-1", "universal"],
};
```

</Tab>
<Tab language="javascript" title="JavaScript">

To specify a speech model, add the `speech_models` property to the data object:

```javascript
const data = {
  audio_url: audioFile,
  speech_models: ["slam-1"],
};
```

You can also specify multiple models in priority order. The system will use the first compatible model:

```javascript
const data = {
  audio_url: audioFile,
  speech_models: ["slam-1", "universal"],
};
```

</Tab>
</Tabs>

For more information on selecting speech models, see [Select the speech model](/docs/speech-to-text/pre-recorded-audio/select-the-speech-model).

## Step 4: Submit for transcription

<Tabs>
<Tab language="python-sdk" title="Python SDK">
<Steps>
<Step>

To generate the transcript, pass the `audio_file` or file to `transcriber.transcribe()`. This may take a minute while we're processing the audio.

```python
transcript = transcriber.transcribe(audio_file)
```

If you configured a `TranscriptionConfig` in Step 3, pass it to the `transcribe()` method:

```python
transcript = transcriber.transcribe(audio_file, config=config)
```

</Step>
<Step>

If the transcription failed, the `status` of the transcription will be set to
`error`. To see why it failed you can print the value of `error`.

```python
if transcript.error:
  print(transcript.error)
  exit(1)
```

</Step>
<Step>

Print the complete transcript.

```python
print(transcript.text)
```

</Step>
<Step>

Run the application and wait for it to finish.

</Step>
</Steps>

</Tab>
<Tab language="python" title="Python">

<Steps>
<Step>

Make a `POST` request to the AssemblyAI API endpoint with the payload and headers and check for potential errors.

```python
response = requests.post(base_url + "/v2/transcript", headers=headers, json=data)

if response.status_code != 200:
    print(f"Error: {response.status_code}, Response: {response.text}")
    response.raise_for_status()
```

</Step>
<Step>

After making the request, you’ll receive an `id` for the transcription. Use it to poll the API every few seconds to check the `status` of the transcript job. Once the `status` is `completed`, you can retrieve the transcript from the API response. If the `status` is `error`, print the error value to get more information on why your request failed.

```python
transcript_json = response.json()
transcript_id = transcript_json["id"]
polling_endpoint = f"{base_url}/v2/transcript/{transcript_id}"

while True:
    transcript = requests.get(polling_endpoint, headers=headers).json()
    if transcript["status"] == "completed":
        print(transcript["text"])
        break
    elif transcript["status"] == "error":
        raise RuntimeError(f"Transcription failed: {transcript['error']}")
    else:
        time.sleep(3)
```

</Step>
<Step>

Run the application and wait for it to finish.

</Step>
</Steps>

</Tab>
<Tab language="javascript-sdk" title="JavaScript SDK">
<Steps>
<Step>

To generate the transcript, pass the audio URL to `client.transcripts.transcribe()`. This may take a minute while we're processing the audio.

```javascript
const transcript = await client.transcripts.transcribe(params);
```

</Step>
<Step>

If the transcription failed, the `status` of the transcription will be set to
`error`. To see why it failed you can print the value of `error`.

```javascript
if (transcript.status === "error") {
  console.error(transcript.error);
  process.exit(1);
}
```

</Step>
<Step>

Print the complete transcript.

```javascript
console.log(transcript.text);
```

</Step>
<Step>

Run the application and wait for it to finish.

</Step>
</Steps>

</Tab>
<Tab language="javascript" title="JavaScript">
<Steps>
<Step>

Under the `data` object, make a `POST` request to the AssemblyAI API endpoint with the payload and headers and check for potential errors. After making the request, you’ll receive an `id` for the transcription. Store it to use in the next step.

```javascript
try {
  const url = `${baseUrl}/v2/transcript`;
  let transcriptId;
  try {
    const transcriptResponse = await axios.post(url, data, { headers });
    transcriptId = transcriptResponse.data.id;
  } catch (error) {
    console.error(
      "Error from POST '/transcript' request:",
      error.response.data.error || error
    );
  }

  //Polling code for next step will be here
} catch (error) {
  console.error(error.message);
}
```

</Step>
<Step>

After the `POST` request, use the `id` to poll the API every few seconds to check the `status` of the transcript job. Once the `status` is `completed`, you can retrieve the transcript from the API response. If the `status` is `error`, print the error value to get more information on why your request failed.

```javascript
const pollingEndpoint = `${baseUrl}/v2/transcript/${transcriptId}`;

while (true) {
  const pollingResponse = await axios.get(pollingEndpoint, { headers });

  const transcriptionResult = pollingResponse.data;

  if (transcriptionResult.status === "completed") {
    console.log(transcriptionResult.text);
    break;
  } else if (transcriptionResult.status === "error") {
    throw new Error(`Transcription failed: ${transcriptionResult.error}`);
  } else {
    await new Promise((resolve) => setTimeout(resolve, 3000));
  }
}
```

</Step>
<Step>

Call the `transcribe` function, run the application and wait for it to finish.

```javascript
transcribe();
```

</Step>
</Steps>

</Tab>
</Tabs>

## Next steps

Want to learn more?

- For more ways to analyze your audio data, explore our [Speech Understanding features](https://www.assemblyai.com/products/speech-understanding).
- To search, summarize, and ask questions on your transcripts with LLMs, see [LLM Gateway](/docs/llm-gateway/overview).
- For detailed endpoint documentation, see the [API Reference](/docs/api-reference/overview).

## Need some help?

If you get stuck, or have any other questions, we'd love to help you out. Contact our support team at support@assemblyai.com or create a [support ticket](https://www.assemblyai.com/contact/support).
