---
title: "How to get started using Slam-1"
subtitle: "Learn how to transcribe using Slam-1."
hide-nav-links: true
description: "Learn how to transcribe prerecorded audio using Slam-1."
---

## Overview

Slam-1 is our new Speech Language Model that combines LLM architecture with ASR encoders for superior speech-to-text transcription. This model delivers unprecedented accuracy through its understanding of context and semantic meaning.

## Quick Start

Slam-1 is available in beta through our standard API endpoint. To use it:
1. Make requests to https://api.assemblyai.com/v2/transcript with your API key
2. Add the speech_model parameter with value "slam-1"

<Tabs groupId="language">
  <Tab language="python" title="Python" default>
    ```python
    import requests
    import time

    base_url = "https://api.assemblyai.com"
    headers = {"authorization": "<YOUR_API_KEY>"}

    data = {
        "audio_url": "https://assembly.ai/sports_injuries.mp3",
        "speech_model": "slam-1"
    }

    response = requests.post(base_url + "/v2/transcript", headers=headers, json=data)

    if response.status_code != 200:
        print(f"Error: {response.status_code}, Response: {response.text}")
        response.raise_for_status()

    transcript_response = response.json()
    transcript_id = transcript_response["id"]
    polling_endpoint = f"{base_url}/v2/transcript/{transcript_id}"

    while True:
        transcript = requests.get(polling_endpoint, headers=headers).json()
        if transcript["status"] == "completed":
            print(transcript["text"])
            break
        elif transcript["status"] == "error":
            raise RuntimeError(f"Transcription failed: {transcript['error']}")
        else:
            time.sleep(3)
    ```

  </Tab>
  <Tab language="typescript" title="Typescript">
    ```ts
      import axios from 'axios'

      const baseUrl = 'https://api.assemblyai.com'

      const headers = {
        authorization: '<YOUR_API_KEY>'
      }

      const data = {
        audio_url: 'https://assembly.ai/sports_injuries.mp3',
        speech_model: 'slam-1'
      }

      const url = `${baseUrl}/v2/transcript`
      const response = await axios.post(url, data, { headers: headers })

      const transcriptId = response.data.id
      const pollingEndpoint = `${baseUrl}/v2/transcript/${transcriptId}`

      while (true) {
        const pollingResponse = await axios.get(pollingEndpoint, {
          headers: headers
        })
        const transcriptionResult = pollingResponse.data

        if (transcriptionResult.status === 'completed') {
          console.log(transcriptionResult.text)
          break
        } else if (transcriptionResult.status === 'error') {
          throw new Error(`Transcription failed: ${transcriptionResult.error}`)
        } else {
          await new Promise((resolve) => setTimeout(resolve, 3000))
        }
      }
    ```

  </Tab>
</Tabs>

<Note title="Local audio files">
  The above code example shows how to transcribe a file that is available via
  URL. If you would like to work with local files see our [API
  Reference](https://www.assemblyai.com/docs/api-reference/files/upload) for
  more information on transcribing local files.
</Note>

## Fine-tuning Slam-1

What truly sets Slam-1 apart is its ability to be customized for specific industries and use cases with minimal effort. Rather than spending months developing custom models or implementing complex post-processing rules, Slam-1 offers two customization approaches to improve accuracy:

### Keyword Prompting (`keyterms_prompt`)

Improve transcription accuracy by leveraging Slam-1's contextual understanding capabilities by prompting the model with certain words or phrases that are likely to appear frequently in your audio file. Rather than simply increasing the likelihood of detecting specific words, Slam-1's multi-modal architecture actually understands the semantic meaning and context of the terminology you provide, enhancing transcription quality not just of the exact terms you specify, but also related terminology, variations, and contextually similar phrases. Provide up to 1000 domain-specific words or phrases (maximum 6 words per phrase) that may appear in your audio using the option `keyterms_prompt` parameter:

<Tabs groupId="language">
  <Tab language="python" title="Python" default>
    ```python
    import requests
    import time

    base_url = "https://api.assemblyai.com"
    headers = {"authorization": "<YOUR_API_KEY>"}

    data = {
        "audio_url": "https://assembly.ai/sports_injuries.mp3",
        "speech_model": "slam-1",
        "keyterms_prompt": ['differential diagnosis', 'hypertension', 'Wellbutrin XL 150mg']
    }

    response = requests.post(base_url + "/v2/transcript", headers=headers, json=data)

    if response.status_code != 200:
        print(f"Error: {response.status_code}, Response: {response.text}")
        response.raise_for_status()

    transcript_response = response.json()
    transcript_id = transcript_response["id"]
    polling_endpoint = f"{base_url}/v2/transcript/{transcript_id}"

    while True:
        transcript = requests.get(polling_endpoint, headers=headers).json()
        if transcript["status"] == "completed":
            print(transcript["text"])
            break
        elif transcript["status"] == "error":
            raise RuntimeError(f"Transcription failed: {transcript['error']}")
        else:
            time.sleep(3)
    ```

  </Tab>
  <Tab language="typescript" title="Typescript">
    ```ts
      import axios from 'axios'

      const baseUrl = 'https://api.assemblyai.com'

      const headers = {
        authorization: '<YOUR_API_KEY>'
      }

      const data = {
        audio_url: 'https://assembly.ai/sports_injuries.mp3',
        speech_model: 'slam-1',
        keyterms_prompt: ['differential diagnosis', 'hypertension', 'Wellbutrin XL 150mg']
      }

      const url = `${baseUrl}/v2/transcript`
      const response = await axios.post(url, data, { headers: headers })

      const transcriptId = response.data.id
      const pollingEndpoint = `${baseUrl}/v2/transcript/${transcriptId}`

      while (true) {
        const pollingResponse = await axios.get(pollingEndpoint, {
          headers: headers
        })
        const transcriptionResult = pollingResponse.data

        if (transcriptionResult.status === 'completed') {
          console.log(transcriptionResult.text)
          break
        } else if (transcriptionResult.status === 'error') {
          throw new Error(`Transcription failed: ${transcriptionResult.error}`)
        } else {
          await new Promise((resolve) => setTimeout(resolve, 3000))
        }
      }
    ```

  </Tab>
</Tabs>

<Note title="Keyword count limits">
While we support up to 1000 Word Boost keywords, actual capacity may be lower due to internal tokenization and implementation constraints.
Key points to remember:
- Each word in a multi-word phrase counts towards the 1000 keyword limit
- Capitalization affects capacity (uppercase tokens consume more than lowercase)
- Longer words consume more capacity than shorter words

For optimal results, use shorter phrases when possible and be mindful of your total token count when approaching the keyword limit.
</Note>

Keyword prompting is best for specific terminology in specialized fields like medicine, legal, or technical domains.

Here is an example of what a `keyterms_prompt` list might look like for a transcription of a professional therapy session for a patient named Jane Doe, who is being treated for anxiety and depression:
```txt wordwrap
["Jane Doe", "cognitive behavioral therapy", "major depressive disorder", "generalized anxiety disorder", "ADHD", "trauma-informed care", "Lexapro 10mg", "psychosocial assessment", "therapeutic alliance", "emotional dysregulation", "GAD-7", "PHQ-9", "Citalopram 20mg", "Lorazepam 2mg"]
```

### Context prompting (`prompt`)

Improve transcription accuracy by leveraging Slam-1's contextual understanding capabilities by prompting the model with a description of your audio in plain English. This allows the model to understand the broader context of your audio file and make more intelligent transcription decisions. Provide up to 1,500 words of context about your audio:

<Tabs groupId="language">
  <Tab language="python" title="Python" default>
    ```python
    import requests
    import time

    base_url = "https://api.assemblyai.com"
    headers = {"authorization": "<YOUR_API_KEY>"}

    data = {
              "audio_url": "https://assembly.ai/sports_injuries.mp3",
              "speech_model": "slam-1",
              "prompt": "This is a shareholder meeting for the ACME Corporation to discuss Q3 financial results and expectations for Q4 and beyond."
          }

    response = requests.post(base_url + "/v2/transcript", headers=headers, json=data)

    if response.status_code != 200:
        print(f"Error: {response.status_code}, Response: {response.text}")
        response.raise_for_status()

    transcript_response = response.json()
    transcript_id = transcript_response["id"]
    polling_endpoint = f"{base_url}/v2/transcript/{transcript_id}"

    while True:
        transcript = requests.get(polling_endpoint, headers=headers).json()
        if transcript["status"] == "completed":
            print(transcript["text"])
            break
        elif transcript["status"] == "error":
            raise RuntimeError(f"Transcription failed: {transcript['error']}")
        else:
            time.sleep(3)
    ```

  </Tab>
  <Tab language="typescript" title="Typescript">
    ```ts
      import axios from 'axios'

      const baseUrl = 'https://api.assemblyai.com'

      const headers = {
        authorization: '<YOUR_API_KEY>'
      }

      const data = {
        audio_url: 'https://assembly.ai/sports_injuries.mp3',
        speech_model: 'slam-1',
        prompt: 'This is a shareholder meeting for the ACME Corporation to discuss Q3 financial results and expectations for Q4 and beyond.'
      }

      const url = `${baseUrl}/v2/transcript`
      const response = await axios.post(url, data, { headers: headers })

      const transcriptId = response.data.id
      const pollingEndpoint = `${baseUrl}/v2/transcript/${transcriptId}`

      while (true) {
        const pollingResponse = await axios.get(pollingEndpoint, {
          headers: headers
        })
        const transcriptionResult = pollingResponse.data

        if (transcriptionResult.status === 'completed') {
          console.log(transcriptionResult.text)
          break
        } else if (transcriptionResult.status === 'error') {
          throw new Error(`Transcription failed: ${transcriptionResult.error}`)
        } else {
          await new Promise((resolve) => setTimeout(resolve, 3000))
        }
      }
    ```

  </Tab>
</Tabs>

<Warning>
Contextual prompting via the `prompt` features is currently experimental and is in an early form of release so your milage may vary when using this parameter.

Please email our Support team at support@assemblyai.com if you would like help iterating on the description you are using in the `prompt` field.
</Warning>

Context prompting is best when you know the general context of the audio but specific terminology is too broad to capture in a list.

Here is an example of contextual prompting for a legal deposition in the case of Smith versus the ACME corporation: 
```txt wordwrap
A common use case for these contextual prompts is to leverage known context about the call and provide it with the transcription. This might look like: "This is a deposition in the case of Smith v. Acme Corporation, a product liability lawsuit involving an alleged defect in the XJ-5000 power tool that resulted in severe lacerations to the plaintiff's right hand. The deposition will involve questioning of Dr. Elizabeth Chen, an orthopedic surgeon who treated the plaintiff's injuries."
```

### Choosing the right method

Use the `keyterms_prompt` parameter when you have specific terminology lists. Keyterms prompting works best with targeted use cases where specific words and phrases can be identified.

Use the `prompt`parameter when you have general context about the audio content. Contextual prompting works best when you would rather pass a high level description than specific words or phrases.

<Note>
The `keyterms_prompt` and `prompt` parameters cannot both be used in the same request.
</Note>

## Feedback

We welcome your feedback on Slam-1 during this beta period. Share thoughts by emailing our Support team at support@assemblyai.com.
