---
title: "Transcribe streaming audio from a microphone in Python"
subtitle: "Learn how to transcribe streaming audio in Python."
hide-nav-links: true
description: "Learn how to transcribe streaming audio in Python."
---

## Overview

By the end of this tutorial, you'll be able to transcribe audio from your microphone in Python.

<Note title="Supported languages">
  Streaming Speech-to-Text is only available for English.
</Note>

## Before you begin

To complete this tutorial, you need:

- [Python](https://www.python.org/) installed.
- An <a href="https://www.assemblyai.com/dashboard/signup" target="_blank">AssemblyAI account</a> with a credit card set up.

Here's the full sample code of what you'll build in this tutorial:

<Tabs groupId="language">
  <Tab language="python-sdk" title="Python SDK" default>
```python
import assemblyai as aai

aai.settings.api_key = "<YOUR_API_KEY>"

def on_open(session_opened: aai.RealtimeSessionOpened):
print("Session ID:", session_opened.session_id)

def on_data(transcript: aai.RealtimeTranscript):
if not transcript.text:
return

    if isinstance(transcript, aai.RealtimeFinalTranscript):
        print(transcript.text, end="\r\n")
    else:
        print(transcript.text, end="\r")

def on_error(error: aai.RealtimeError):
print("An error occurred:", error)

def on_close():
print("Closing Session")

transcriber = aai.RealtimeTranscriber(
sample_rate=16_000,
on_data=on_data,
on_error=on_error,
on_open=on_open,
on_close=on_close,
)

transcriber.connect()

microphone_stream = aai.extras.MicrophoneStream(sample_rate=16_000)
transcriber.stream(microphone_stream)

transcriber.close()

````

</Tab>

<Tab language ="python" title="Python">

```python
import pyaudio
import websocket
import json
from threading import Thread

YOUR_API_KEY = "<YOUR_API_KEY>"

def on_open(ws):
    def stream_audio():
        while True:
            try:
                audio_data = stream.read(FRAMES_PER_BUFFER, exception_on_overflow=False)
                ws.send(audio_data, websocket.ABNF.OPCODE_BINARY)
            except Exception as e:
                print(f'\nError streaming audio: {e}')
                break

    audio_thread = Thread(target=stream_audio, daemon=True)
    audio_thread.start()

def on_message(ws, message):
    try:
        msg = json.loads(message)
        msg_type = msg.get('message_type')

        if msg_type == 'SessionBegins':
            session_id = msg.get('session_id')
            print("Session ID:", session_id)
            return

        text = msg.get('text', '')
        if not text:
            return

        if msg_type == 'PartialTranscript':
            print(text, end='\r')
        elif msg_type == 'FinalTranscript':
            print(text, end='\r\n')
        elif msg_type == 'error':
            print(f'\nError: {msg.get("error", "Unknown error")}')
    except Exception as e:
        print(f'\nError handling message: {e}')

def on_error(ws, error):
    print(f'\nError: {error}')

def on_close(ws, status, msg):
    stream.stop_stream()
    stream.close()
    audio.terminate()
    print('\nDisconnected')

FRAMES_PER_BUFFER = 3200  # 200ms of audio (0.2s * 16000Hz)
SAMPLE_RATE = 16000       # 16kHz sample rate
CHANNELS = 1              # Mono audio
FORMAT = pyaudio.paInt16  # 16-bit audio

audio = pyaudio.PyAudio()
stream = audio.open(
    input=True,
    frames_per_buffer=FRAMES_PER_BUFFER,
    channels=CHANNELS,
    format=FORMAT,
    rate=SAMPLE_RATE
)

ws = websocket.WebSocketApp(
    f'wss://api.assemblyai.com/v2/realtime/ws?sample_rate={SAMPLE_RATE}',
    header={'Authorization': YOUR_API_KEY},
    on_message=on_message,
    on_open=on_open,
    on_error=on_error,
    on_close=on_close
)

try:
    ws.run_forever()
except Exception as e:
    print(f'\nError: {e}')
````

</Tab>
</Tabs>

## Step 1: Install dependencies

<Steps>
<Step>

<Tabs groupId="language">
<Tab language="python-sdk" title="Python SDK">

First, install PortAudio, a cross-platform library for streaming audio. The Python SDK uses PortAudio to stream audio from your microphone.

```bash
# (Mac)
brew install portaudio

# (Windows)
# PortAudio is already installed on most versions of Windows.

# (Linux)
apt install portaudio19-dev
```

Then install the AssemblyAI Python SDK with extras enabled for microphone support:

```bash
pip install "assemblyai[extras]"
```

</Tab>
<Tab language="python" title="Python">

Install the required Python packages:

```bash
pip install pyaudio websocket-client
```

</Tab>
</Tabs>

</Step>
</Steps>

## Step 2: Configure the API key

In this step, you'll configure your API key to authenticate with AssemblyAI.

<Steps>
<Step>

Browse to <a href="https://www.assemblyai.com/app/api-keys" target="_blank">API Keys</a> in your dashboard, and then copy your API key.

</Step>
<Step>

<Tabs groupId="language">
<Tab language="python-sdk" title="Python SDK">

Configure the SDK to use your API key. Replace `YOUR_API_KEY` with your copied API key.

```python
import assemblyai as aai

aai.settings.api_key = "<YOUR_API_KEY>"
```

</Tab>
<Tab language="python" title="Python">

Store your API key in a variable. Replace `YOUR_API_KEY` with your copied API key.

```python
YOUR_API_KEY = "<YOUR_API_KEY>"
```

</Tab>
</Tabs>

</Step>
</Steps>

## Step 3: Set up audio configuration

<Steps>
<Step>

<Tabs groupId="language">
<Tab language="python-sdk" title="Python SDK">

The Python SDK handles audio configuration automatically. You'll specify the sample rate when creating the transcriber.

</Tab>
<Tab language="python" title="Python">

Configure the audio settings for your microphone stream:

```python maxLines=10
import pyaudio

FRAMES_PER_BUFFER = 3200  # 200ms of audio (0.2s * 16000Hz)
SAMPLE_RATE = 16000       # 16kHz sample rate
CHANNELS = 1              # Mono audio
FORMAT = pyaudio.paInt16  # 16-bit audio

audio = pyaudio.PyAudio()
stream = audio.open(
    input=True,
    frames_per_buffer=FRAMES_PER_BUFFER,
    channels=CHANNELS,
    format=FORMAT,
    rate=SAMPLE_RATE
)
```

</Tab>
</Tabs>

<Note title="Audio data format">

If you want to stream data from elsewhere, make sure that your audio data is in the following format:

- Single channel
- 16-bit signed integer PCM or mu-law encoding
- A sample rate that matches the value of the supplied sample_rate parameter
- 100 to 2000 milliseconds of audio per message

By default, transcriptions expect PCM16-encoded audio. If you want to use mu-law encoding, see [Specifying the encoding](/docs/speech-to-text/streaming#specify-the-encoding).

</Note>

</Step>
</Steps>

## Step 4: Create event handlers

In this step, youâ€™ll set up callback functions that handle the different events.

<Steps>
<Step>

Create functions to handle the events from the real-time service.

<Tabs groupId="language">

<Tab language="python-sdk" title="Python SDK">
```python
def on_open(session_opened: aai.RealtimeSessionOpened):
    print("Session ID:", session_opened.session_id)

def on_error(error: aai.RealtimeError):
print("An error occurred:", error)

def on_close():
print("Closing Session")

````

</Tab>
<Tab language="python" title="Python">

```python maxLines=10
from threading import Thread

def on_open(ws):
    def stream_audio():
        while True:
            try:
                audio_data = stream.read(FRAMES_PER_BUFFER, exception_on_overflow=False)
                ws.send(audio_data, websocket.ABNF.OPCODE_BINARY)
            except Exception as e:
                print(f'\nError streaming audio: {e}')
                break

    audio_thread = Thread(target=stream_audio, daemon=True)
    audio_thread.start()

def on_error(ws, error):
    print(f'\nError: {error}')

def on_close(ws, status, msg):
    stream.stop_stream()
    stream.close()
    audio.terminate()
    print('\nDisconnected')
````

</Tab>
</Tabs>

</Step>

<Step>

Create another function to handle transcripts. The real-time transcriber returns two types of transcripts: _Final transcripts_ and _Partial transcripts_.

- _Partial transcripts_ are returned as the audio is being streamed to AssemblyAI.
- _Final transcripts_ are returned after a moment of silence.

<Tabs groupId="language">
<Tab language="python-sdk" title="Python SDK">
```python
def on_data(transcript: aai.RealtimeTranscript):
    if not transcript.text:
        return

    if isinstance(transcript, aai.RealtimeFinalTranscript):
        # Add new line after final transcript.
        print(transcript.text, end="\r\n")
    else:
        print(transcript.text, end="\r")

````
</Tab>
<Tab language="python" title="Python">

```python maxLines=10
import json

def on_message(ws, message):
    try:
        msg = json.loads(message)
        msg_type = msg.get('message_type')
        if msg_type == 'SessionBegins':
            session_id = msg.get('session_id')
            print("Session ID:", session_id)
            return
        text = msg.get('text', '')
        if not text:
            return
        if msg_type == 'PartialTranscript':
            print(text, end='\r')
        elif msg_type == 'FinalTranscript':
            # Add new line after final transcript.
            print(text, end='\r\n')
        elif msg_type == 'error':
            print(f'\nError: {msg.get("error", "Unknown error")}')
    except Exception as e:
        print(f'\nError handling message: {e}')
````

</Tab>
</Tabs>

<Tip title="End of utterance controls">
  You can [configure the silence
  threshold](/docs/speech-to-text/streaming#configure-the-threshold-for-automatic-utterance-detection)
  for automatic utterance detection and programmatically [force the end of an
  utterance](/docs/speech-to-text/streaming#manually-end-current-utterance) to
  immediately get a _Final transcript_.
</Tip>

</Step>

</Steps>

## Step 5: Connect and start transcription

<Steps>
<Step>

Streaming Speech-to-Text uses [WebSockets](https://developer.mozilla.org/en-US/docs/Web/API/WebSockets_API) to stream audio to AssemblyAI. This requires first establishing a connection to the API.

<Tabs groupId="language">
<Tab language="python-sdk" title="Python SDK">

First, create a transcriber and connect to the Realtime service:

```python
transcriber = aai.RealtimeTranscriber(
    sample_rate=16_000,
    on_data=on_data,
    on_error=on_error,
    on_open=on_open,
    on_close=on_close,
)

transcriber.connect()
```

Then, create a microphone stream and start transcribing audio:

```python
microphone_stream = aai.extras.MicrophoneStream(sample_rate=16_000)
transcriber.stream(microphone_stream)  # Press Ctrl+C to stop
```

</Tab>
<Tab language="python" title="Python">

Create a WebSocket connection to the Realtime service:

```python
import websocket

ws = websocket.WebSocketApp(
    f'wss://api.assemblyai.com/v2/realtime/ws?sample_rate={SAMPLE_RATE}',
    header={'Authorization': YOUR_API_KEY},
    on_message=on_message,
    on_open=on_open,
    on_error=on_error,
    on_close=on_close
)
```

Then, start the WebSocket connection to start transcribing audio:

```python
try:
    ws.run_forever() # Press Ctrl+C to stop
except Exception as e:
    print(f'\nError: {e}')
```

</Tab>
</Tabs>

<Note title="Sample rate">

The `sample_rate` is the number of audio samples per second, measured in hertz (Hz). Higher sample rates result in higher quality audio, which may lead to better transcripts, but also more data being sent over the network.

We recommend the following sample rates:

- Minimum quality: `8_000` (8 kHz)
- Medium quality: `16_000` (16 kHz)
- Maximum quality: `48_000` (48 kHz)

</Note>

</Step>
</Steps>

## Step 6: Close the connection

<Steps>
<Step>

<Tabs groupId="language">
<Tab language="python-sdk" title="Python SDK">

Close the transcriber when you're done:

```python
transcriber.close()
```

</Tab>
<Tab language="python" title="Python">

Close the WebSocket connection when you're done:

```python
ws.close()
```

</Tab>
</Tabs>

The connection will also close automatically when you press Ctrl+C. In both cases, the `on_close` handler will clean up the audio resources.

</Step>
</Steps>

## Next steps

To learn more about Streaming Speech-to-Text, see the following resources:

- [Streaming Speech-to-Text](/docs/speech-to-text/streaming)
- [WebSocket API reference](https://assemblyai.com/docs/api-reference/streaming)

## Need some help?

If you get stuck, or have any other questions, we'd love to help you out. Contact our support team at support@assemblyai.com or create a [support ticket](https://www.assemblyai.com/contact/support).
