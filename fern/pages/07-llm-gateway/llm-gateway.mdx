---
title: "LLM Gateway Overview"
description: "AssemblyAI's LLM Gateway is a unified API providing access to 15+ models from Claude, GPT, and Gemini through a single interface."
hidden: true
---

## Overview

**AssemblyAI's LLM Gateway** is a unified interface that allows you to connect with multiple LLM providers including Claude, GPT, and Gemini. You can use the LLM Gateway to build sophisticated AI applications through a single API.

The LLM Gateway provides access to 15+ models across major AI providers with support for:

- **Basic Chat Completions** - Simple request/response interactions
- **Multi-turn Conversations** - Maintain context across multiple exchanges
- **Tool/Function Calling** - Enable models to execute custom functions
- **Agentic Workflows** - Multi-step reasoning with automatic tool chaining
- **Unified Interface** - One API for Claude, GPT, Gemini, and more

## Available models

### Anthropic Claude

| Model                 | Parameter                    | Latency per 10,000 tokens | [LMArena Score](https://lmarena.ai/leaderboard) | Description                                            |
| --------------------- | ---------------------------- | ------------------------- | ------------- | ------------------------------------------------------ |
| **Claude 4.5 Sonnet** | `claude-sonnet-4-5-20250929` | 10.1s                     | 1438          | Claude's best model for complex agents and coding      |
| **Claude 4 Sonnet**   | `claude-sonnet-4-20250514`   | 7.1s                      | 1389          | High-performance model                                 |
| **Claude 4 Opus**     | `claude-opus-4-20250514`     | 15.4s                     | 1411          | Claude's previous flagship model                       |
| **Claude 4.5 Haiku**  | `claude-haiku-4-5-20251001`  | 4.6s                      | 1397          | Claude's fastest and most intelligent Haiku model      |
| **Claude 3.5 Haiku**  | `claude-3-5-haiku-20241022`  | 5.4s                      | 1320          | Fast and efficient model with strong performance       |
| **Claude 3.0 Haiku**  | `claude-3-haiku-20240307`    | 4.8s                      | 1260          | Fast and compact model for near-instant responsiveness |

### OpenAI GPT

| Model            | Parameter           | Latency per 10,000 tokens | [LMArena Score](https://lmarena.ai/leaderboard) | Description                                                      |
| ---------------- | ------------------- | ------------------------- | ------------- | ---------------------------------------------------------------- |
| **GPT-5**        | `gpt-5`             | 18.9s                     | 1425          | OpenAI's best model for coding and agentic tasks across domains  |
| **GPT-5 nano**   | `gpt-5-nano`        | 11.2s                     | 1337          | OpenAI's fastest, most cost-efficient version of GPT-5           |
| **GPT-5 mini**   | `gpt-5-mini`        | 21.9s                     | 1395          | A faster, cost-efficient version of GPT-5 for well-defined tasks |
| **GPT-4.1**      | `gpt-4.1`           | 12.6s                     | 1411          | OpenAI's smartest non-reasoning model                            |
| **ChatGPT-4o**   | `chatgpt-4o-latest` | 8.0s                      | 1440          | GPT-4o model used in ChatGPT                                     |
| **gpt-oss-120b** | `gpt-oss-120b`      | 10.5s                     | 1348          | OpenAI's most powerful open-weight model                         |
| **gpt-oss-20b**  | `gpt-oss-20b`       | 4.2s                      | 1317          | Medium-sized open-weight model for low latency                   |

### Google Gemini

| Model                     | Parameter               | Latency per 10,000 tokens | [LMArena Score](https://lmarena.ai/leaderboard) | Description                                                                           |
| ------------------------- | ----------------------- | ------------------------- | ------------- | ------------------------------------------------------------------------------------- |
| **Gemini 2.5 Pro**        | `gemini-2.5-pro`        | 13.9s                     | 1451          | Gemini's state-of-the-art thinking model, capable of reasoning over complex problems  |
| **Gemini 2.5 Flash**      | `gemini-2.5-flash`      | 8.3s                      | 1404          | Gemini's best model in terms of price-performance, offering well-rounded capabilities |
| **Gemini 2.5 Flash-Lite** | `gemini-2.5-flash-lite` | 1.6s                      | 1374          | Gemini's fastest flash model optimized for cost-efficiency and high throughput        |

Unsure which model to choose?

- Consider Claude models for nuanced reasoning and complex instructions
- Consider GPT models for code generation and structured outputs
- Consider Gemini models for cost-effective high-volume applications

<Note>
  Head to [our Playground](https://www.assemblyai.com/dashboard/playground) to
  test out LLM Gateway without having to write any code!
</Note>

## Select a model

You can specify which model to use in your request by setting the `model` parameter. Here are examples showing how to use Claude 4.5 Sonnet:

<Tabs>
<Tab title="Python">

```python {11}
import requests

headers = {
  "authorization": "<YOUR_API_KEY>"
}

response = requests.post(
    "https://llm-gateway.assemblyai.com/v1/chat/completions",
    headers = headers,
    json = {
        "model": "claude-sonnet-4-5-20250929",
        "messages": [
            {"role": "user", "content": "What is the capital of France?"}
        ],
        "max_tokens": 1000
    }
)

result = response.json()
print(result["choices"][0]["message"]["content"])
```

</Tab>
<Tab title="JavaScript">

```javascript {10}
const response = await fetch(
  "https://llm-gateway.assemblyai.com/v1/chat/completions",
  {
    method: "POST",
    headers: {
      authorization: "<YOUR_API_KEY>",
      "content-type": "application/json",
    },
    body: JSON.stringify({
      model: "claude-sonnet-4-5-20250929",
      messages: [{ role: "user", content: "What is the capital of France?" }],
      max_tokens: 1000,
    }),
  }
);

const result = await response.json();
console.log(result.choices[0].message.content);
```

</Tab>
</Tabs>

Simply change the `model` parameter to use any of the available models listed in the [Available models](#available-models) section above.

## Next steps

- [Basic Chat Completions](/docs/llm-gateway/chat-completions) - Learn how to send simple messages and receive responses
- [Multi-turn Conversations](/docs/llm-gateway/conversations) - Maintain context across multiple exchanges
- [Tool Calling](/docs/llm-gateway/tool-calling) - Enable models to execute custom functions
- [Agentic Workflows](/docs/llm-gateway/agentic-workflows) - Build multi-step reasoning applications

<Note>
  The LLM Gateway API is separate from the Speech-to-Text and Audio Intelligence
  APIs. It provides a unified interface to work with large language models
  across multiple providers.
</Note>
