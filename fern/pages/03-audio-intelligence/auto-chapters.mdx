---
title: 'Auto Chapters'
description: 'Automatically summarize your audio into chapters'
---


  


The Auto Chapters model summarizes audio data over time into chapters. Chapters makes it easy for users to navigate and find specific information.

Each chapter contains the following:

- Summary
- One-line gist
- Headline
- Start and end timestamps

<Warning title="Auto Chapters and Summarization">
You can only enable one of the Auto Chapters and [Summarization](/docs/audio-intelligence/summarization) models in the same transcription.
</Warning>





## Quickstart

<Tabs groupId="language">
  <Tab language="python-sdk" title="Python SDK" default>
  
  Enable Auto Chapters by setting `auto_chapters` to `True` in the transcription config. `punctuate` must be enabled to use Auto Chapters (`punctuate` is enabled by default).

```python {8}
import assemblyai as aai

aai.settings.api_key = "<YOUR_API_KEY>"

# audio_file = "./local_file.mp3"
audio_file = "https://assembly.ai/wildfires.mp3"

config = aai.TranscriptionConfig(auto_chapters=True)

transcript = aai.Transcriber().transcribe(audio_file, config)
print(f"Transcript ID:", transcript.id)

for chapter in transcript.chapters:
  print(f"{chapter.start}-{chapter.end}: {chapter.headline}")
```

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1xnr8yS3SeiiI-4gwuhP-uuAHrcK76LR9#scrollTo=tU7QCoAs1lze)

  </Tab>
  <Tab language="python" title="Python" default>
  
   Enable Auto Chapters by setting `auto_chapters` to `True` in the JSON payload.

```python {20}
import requests
import json
import time

base_url = "https://api.assemblyai.com"

headers = {
    "authorization": "<YOUR_API_KEY>"
}

with open("./local_file.mp3", "rb") as f:
    response = requests.post(base_url + "/v2/upload",
                            headers=headers,
                            data=f)

upload_url = response.json()["upload_url"]

data = {
    "audio_url": upload_url, # You can also use a URL to an audio or video file on the web
    "auto_chapters": True
}

url = base_url + "/v2/transcript"
response = requests.post(url, json=data, headers=headers)

transcript_id = response.json()['id']
polling_endpoint = f"https://api.assemblyai.com/v2/transcript/{transcript_id}"

print(f"Transcript ID:", transcript_id)

while True:
    transcription_result = requests.get(polling_endpoint, headers=headers).json()

    if transcription_result['status'] == 'completed':

        for chapter in transcription_result['chapters']:
            print(f"{chapter['start']} - {chapter['end']}: {chapter['headline']}")
        break
    elif transcription_result['status'] == 'error':
        raise RuntimeError(f"Transcription failed: {transcription_result['error']}")
    else:
        time.sleep(3)
```

  </Tab>
  <Tab language="typescript-sdk" title="TypeScript SDK">
  
  Enable Auto Chapters by setting `auto_chapters` to `true` in the transcription config. `punctuate` must be enabled to use Auto Chapters (`punctuate` is enabled by default).


```ts {13}
import { AssemblyAI } from 'assemblyai'

const client = new AssemblyAI({
  apiKey: '<YOUR_API_KEY>'
})

// const audioFile = './local_file.mp3'
const audioFile =
  'https://assembly.ai/wildfires.mp3'

const params = {
  audio: audioFile,
  auto_chapters: true
}

const run = async () => {
  const transcript = await client.transcripts.transcribe(params)
  console.log('Transcript ID: ', transcript.id)

  for (const chapter of transcript.chapters!) {
    console.log(`${chapter.start}-${chapter.end}: ${chapter.headline}`)
  }
}

run()
```

  </Tab>
  <Tab language="typescript" title="TypeScript">
  
  Enable Auto Chapters by setting `auto_chapters` to `true` in the JSON payload.

```ts {19}
import axios from 'axios'
import fs from 'fs-extra'

const baseUrl = 'https://api.assemblyai.com'

const headers = {
  authorization: '<YOUR_API_KEY>'
}

const path = './my-audio.mp3'
const audioData = await fs.readFile(path)
const uploadResponse = await axios.post(`${baseUrl}/v2/upload`, audioData, {
  headers
})
const uploadUrl = uploadResponse.data.upload_url

const data = {
  audio_url: uploadUrl, // You can also use a URL to an audio or video file on the web
  auto_chapters: true
}

const url = `${baseUrl}/v2/transcript`
const response = await axios.post(url, data, { headers: headers })

const transcriptId = response.data.id
console.log("Transcript ID: ", transcriptId)

const pollingEndpoint = `${baseUrl}/v2/transcript/${transcriptId}`

while (true) {
  const pollingResponse = await axios.get(pollingEndpoint, {
    headers: headers
  })
  const transcriptionResult = pollingResponse.data

  if (transcriptionResult.status === 'completed') {
    for (const chapter of transcriptionResult.chapters){
      console.log(`${chapter.start} - ${chapter.end}: ${chapter.headline}`)
    }
    break
  } else if (transcriptionResult.status === 'error') {
    throw new Error(`Transcription failed: ${transcriptionResult.error}`)
  } else {
    await new Promise((resolve) => setTimeout(resolve, 3000))
  }
}
```

  </Tab>
  <Tab language="csharp" title="C#">
  
  Enable Auto Chapters by setting `auto_chapters` to `true` in the JSON payload.

<Info>
Most of these libraries are included by default, but on .NET Framework and Mono you need to reference the System.Net.Http library and install the [System.Net.Http.Json NuGet package](https://www.nuget.org/packages/System.Net.Http.Json).
</Info>

```csharp {46}
using System;
using System.IO;
using System.Net.Http;
using System.Net.Http.Headers;
using System.Net.Http.Json;
using System.Text;
using System.Text.Json;
using System.Threading.Tasks;
using System.Text.Json.Serialization;

class Program
{
    static async Task Main(string[] args)
    {
        using (var httpClient = new HttpClient())
        {
            httpClient.DefaultRequestHeaders.Authorization =
                new AuthenticationHeaderValue("<YOUR_API_KEY>");

            var uploadUrl = await UploadFileAsync("/my_audio.mp3", httpClient);
            var transcript = await CreateTranscriptAsync(uploadUrl, httpClient);
            transcript = await WaitForTranscriptToProcess(transcript, httpClient);
            
            Console.WriteLine(transcript.Text);
        }
    }

    static async Task<string> UploadFileAsync(string filePath, HttpClient httpClient)
    {
        using (var fileStream = File.OpenRead(filePath))
        using (var fileContent = new StreamContent(fileStream))
        {
            fileContent.Headers.ContentType = new MediaTypeHeaderValue("application/octet-stream");

            using (var response = await httpClient.PostAsync("https://api.assemblyai.com/v2/upload", fileContent))
            {
                response.EnsureSuccessStatusCode();
                var jsonDoc = await response.Content.ReadFromJsonAsync<JsonDocument>();
                return jsonDoc.RootElement.GetProperty("upload_url").GetString();
            }
        }
    }

    static async Task<Transcript> CreateTranscriptAsync(string audioUrl, HttpClient httpClient)
    {
        var data = new { audio_url = audioUrl, auto_chapters = true };
        var content = new StringContent(JsonSerializer.Serialize(data), Encoding.UTF8, "application/json");

        using (var response = await httpClient.PostAsync("https://api.assemblyai.com/v2/transcript", content))
        {
            response.EnsureSuccessStatusCode();
            return await response.Content.ReadFromJsonAsync<Transcript>();
        }
    }

    static async Task<Transcript> WaitForTranscriptToProcess(Transcript transcript, HttpClient httpClient)
    {
        var pollingEndpoint = $"https://api.assemblyai.com/v2/transcript/{transcript.Id}";

        while (true)
        {
            var pollingResponse = await httpClient.GetAsync(pollingEndpoint);
            transcript = await pollingResponse.Content.ReadFromJsonAsync<Transcript>();
            switch (transcript.Status)
            {
                case "processing":
                case "queued":
                    await Task.Delay(TimeSpan.FromSeconds(3));
                    break;
                case "completed":
                    return transcript;
                case "error":
                    throw new Exception($"Transcription failed: {transcript.Error}");
                default:
                    throw new Exception("This code shouldn't be reachable.");
            }
        }
    }

    public class Transcript
    {
        public string Id { get; set; }
        public string Status { get; set; }
        public string Text { get; set; }

        [JsonPropertyName("language_code")]
        public string LanguageCode { get; set; }

        public string Error { get; set; }
    }
}
```
  </Tab>
  <Tab language="ruby" title="Ruby">
  
  Enable Auto Chapters by setting `auto_chapters` to `true` in the JSON payload.

```ruby {23}
require 'net/http'
require 'json'

base_url = 'https://api.assemblyai.com'

headers = {
  'authorization' => '<YOUR_API_KEY>',
  'content-type' => 'application/json'
}

path = "/my_audio.mp3"
uri = URI("#{base_url}/v2/upload")
request = Net::HTTP::Post.new(uri, headers)
request.body = File.read(path)

http = Net::HTTP.new(uri.host, uri.port)
http.use_ssl = true
upload_response = http.request(request)
upload_url = JSON.parse(upload_response.body)["upload_url"]

data = {
    "audio_url" => upload_url, # You can also use a URL to an audio or video file on the web
    "auto_chapters" => true
}

uri = URI.parse("#{base_url}/v2/transcript")
http = Net::HTTP.new(uri.host, uri.port)
http.use_ssl = true

request = Net::HTTP::Post.new(uri.request_uri, headers)
request.body = data.to_json

response = http.request(request)
response_body = JSON.parse(response.body)

unless response.is_a?(Net::HTTPSuccess)
  raise "API request failed with status #{response.code}: #{response.body}"
end

transcript_id = response_body['id']
puts "Transcript ID: #{transcript_id}"

polling_endpoint = URI.parse("#{base_url}/v2/transcript/#{transcript_id}")

while true
  polling_http = Net::HTTP.new(polling_endpoint.host, polling_endpoint.port)
  polling_http.use_ssl = true
  polling_request = Net::HTTP::Get.new(polling_endpoint.request_uri, headers)
  polling_response = polling_http.request(polling_request)
  
  transcription_result = JSON.parse(polling_response.body)
  
  if transcription_result['status'] == 'completed'
    transcription_result['chapters'].each do |chapter|
      puts "#{chapter['start']} - #{chapter['end']}: #{chapter['headline']}"
    end
  break
  elsif transcription_result['status'] == 'error'
    raise "Transcription failed: #{transcription_result['error']}"
  else
    sleep(3)
  end
end
```

  </Tab>
 <Tab language="php" title="PHP">
  
  Enable Auto Chapters by setting `auto_chapters` to `true` in the JSON payload.

```php {30}
<?php
$ch = curl_init();
curl_setopt($ch, CURLOPT_RETURNTRANSFER, true);

$base_url = "https://api.assemblyai.com";

$headers = array(
    "authorization: <YOUR_API_KEY>",
    "content-type: application/json"
);

$path = "./my-audio.mp3";

$ch = curl_init();

curl_setopt($ch, CURLOPT_URL, $base_url . "/v2/upload");
curl_setopt($ch, CURLOPT_POST, 1);
curl_setopt($ch, CURLOPT_POSTFIELDS, file_get_contents($path));
curl_setopt($ch, CURLOPT_HTTPHEADER, $headers);
curl_setopt($ch, CURLOPT_RETURNTRANSFER, 1);

$response = curl_exec($ch);
$response_data = json_decode($response, true);
$upload_url = $response_data["upload_url"];

curl_close($ch);

$data = array(
    "audio_url" => $upload_url, // You can also use a URL to an audio or video file on the web
    "auto_chapters" => true,
);

$url = $base_url . "/v2/transcript";
$curl = curl_init($url);

curl_setopt($curl, CURLOPT_POST, true);
curl_setopt($curl, CURLOPT_POSTFIELDS, json_encode($data));
curl_setopt($curl, CURLOPT_HTTPHEADER, $headers);
curl_setopt($curl, CURLOPT_RETURNTRANSFER, true);

$response = curl_exec($curl);

$response = json_decode($response, true);

curl_close($curl);

$transcript_id = $response['id'];
echo "Transcript ID: $transcript_id\n";

$polling_endpoint = "https://api.assemblyai.com/v2/transcript/" . $transcript_id;

while (true) {
    $polling_response = curl_init($polling_endpoint);

    curl_setopt($polling_response, CURLOPT_HTTPHEADER, $headers);
    curl_setopt($polling_response, CURLOPT_RETURNTRANSFER, true);

    $transcription_result = json_decode(curl_exec($polling_response), true);

    if ($transcription_result['status'] === "completed") {
        foreach ($transcription_result['chapters'] as $chapter) {
            echo "{$chapter['start']} - {$chapter['end']}: {$chapter['headline']}\n";
        }
        break;
    }  else if ($transcription_result['status'] === "error") {
        throw new Exception("Transcription failed: " . $transcription_result['error']);
    } else {
        sleep(3);
    }
}
```

  </Tab>
</Tabs>

### Example output

```plain
250-28840: Smoke from hundreds of wildfires in Canada is triggering air quality alerts across US
29610-280340: High particulate matter in wildfire smoke can lead to serious health problems
```

<Tip title="Auto Chapters Using LeMUR">
Check out this cookbook [Creating Chapter Summaries](https://github.com/AssemblyAI/cookbook/blob/master/lemur/input-text-chapters.ipynb) for an example of how to leverage LeMUR's custom text input parameter for chapter summaries.
</Tip>



## API reference

### Request

```bash {6}
curl https://api.assemblyai.com/v2/transcript \
--header "Authorization: <YOUR_API_KEY>" \
--header "Content-Type: application/json" \
--data '{
  "audio_url": "YOUR_AUDIO_URL",
  "auto_chapters": true
}'
```

| Key             | Type    | Description           |
| --------------- | ------- | --------------------- |
| `auto_chapters` | boolean | Enable Auto Chapters. |

### Response
<Markdown src="auto-chapters-response.mdx" />

| Key | Type | Description |
| --- | --- | --- |
| `chapters` | array | An array of temporally sequential chapters for the audio file. |
| `chapters[i].gist` | string | An short summary in a few words of the content spoken in the i-th chapter. |
| `chapters[i].headline` | string | A single sentence summary of the content spoken during the i-th chapter. |
| `chapters[i].summary` | string | A one paragraph summary of the content spoken during the i-th chapter. |
| `chapters[i].start` | number | The starting time, in milliseconds, for the i-th chapter. |
| `chapters[i].end` | number | The ending time, in milliseconds, for the i-th chapter. |

The response also includes the request parameters used to generate the transcript.





## Frequently asked questions

<Accordion
  title="Can I specify the number of chapters to be generated by the Auto Chapters model?"
  theme="dark"
  iconColor="white"
>

No, the number of chapters generated by the Auto Chapters model isn't configurable by the user. The model automatically segments the audio file into logical chapters as the topic of conversation changes.

</Accordion>

## Troubleshooting

<Accordion
  title="Why am I not getting any chapter predictions for my audio file?"
  theme="dark"
  iconColor="white"
>

One possible reason is that the audio file doesn't contain enough variety in topic or tone for the model to identify separate chapters. Another reason could be due to background noise or low-quality audio interfering with the model's analysis.

</Accordion>




