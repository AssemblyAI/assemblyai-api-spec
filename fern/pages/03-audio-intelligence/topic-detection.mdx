---
title: "Topic Detection"
description: "Label topics that are mentioned in your audio file"
---

import { LanguageTable } from "../../assets/components/LanguagesTable";

<AccordionGroup>

<Accordion title="Supported languages">
  <LanguageTable
    languages={[
      { name: "Global English", code: "en" },
      { name: "Australian English", code: "en_au" },
      { name: "British English", code: "en_uk" },
      { name: "US English", code: "en_us" },
      { name: "Spanish", code: "es" },
      { name: "French", code: "fr" },
      { name: "German", code: "de" },
      { name: "Italian", code: "it" },
      { name: "Portuguese", code: "pt" },
    ]}
    columns={2}
  />
  <br />
</Accordion>

<Accordion title="Supported models">
  <LanguageTable
    languages={[
      { name: "Universal-3-Pro", code: "universal-3-pro" },
      { name: "Universal-2", code: "universal-2" },
    ]}
    columns={2}
  />
  <br />
</Accordion>

<Accordion title="Supported regions">
  US & EU <br />
</Accordion>

</AccordionGroup>

The Topic Detection model lets you identify different topics in the transcript. The model uses the [IAB Content Taxonomy](https://airtable.com/shr7KNXOtvfhTTS4i/tblqVLDb7YSsCMXo4?backgroundColor=purple&viewControls=on), a standardized language for content description which consists of 698 comprehensive topics.

## Quickstart

<Tabs groupId="language">
  <Tab language="python-sdk" title="Python SDK" default>
  
  Enable Topic Detection by setting `iab_categories` to `True` in the transcription parameters.

```python {8}
import assemblyai as aai

aai.settings.api_key = "<YOUR_API_KEY>"

# audio_file = "./local_file.mp3"
audio_file = "https://assembly.ai/wildfires.mp3"

config = aai.TranscriptionConfig(
    speech_models=["universal-3-pro", "universal-2"],
    language_detection=True,
    iab_categories=True
)

transcript = aai.Transcriber().transcribe(audio_file, config)
print(f"Transcript ID:", transcript.id)

# Get the parts of the transcript that were tagged with topics
for result in transcript.iab_categories.results:
    print(result.text)
    print(f"Timestamp: {result.timestamp.start} - {result.timestamp.end}")
    for label in result.labels:
        print(f"{label.label} ({label.relevance})")

# Get a summary of all topics in the transcript
for topic, relevance in transcript.iab_categories.summary.items():
    print(f"Audio is {relevance * 100}% relevant to {topic}")
```

  </Tab>
  <Tab language="python" title="Python" default>
  
  Enable Topic Detection by setting `iab_categories` to `true` in the JSON payload.

```python {19}
import requests
import time

base_url = "https://api.assemblyai.com"

headers = {
    "authorization": "<YOUR_API_KEY>"
}

with open("./local_file.mp3", "rb") as f:
    response = requests.post(base_url + "/v2/upload",
                            headers=headers,
                            data=f)

upload_url = response.json()["upload_url"]

data = {
    "audio_url": upload_url, # You can also use a URL to an audio or video file on the web
    "speech_models": ["universal-3-pro", "universal-2"],
    "language_detection": True,
    "iab_categories": True
}

url = base_url + "/v2/transcript"
response = requests.post(url, json=data, headers=headers)

transcript_id = response.json()['id']
polling_endpoint = base_url + "/v2/transcript/" + transcript_id

print(f"Transcript ID:", transcript_id)

while True:
    transcription_result = requests.get(polling_endpoint, headers=headers).json()

    if transcription_result['status'] == 'completed':
      # Get the parts of the transcript that were tagged with topics
      for result in transcription_result['iab_categories_result']['results']:
        print(result['text'])
        print(f"Timestamp: {result['timestamp']['start']} - {result['timestamp']['end']}")

        for label in result['labels']:
          print(f"{label['label']} ({label['relevance']})")

      # Get a summary of all topics in the transcript
      for topic, relevance in transcription_result['iab_categories_result']['summary'].items():
        print(f"Audio is {relevance * 100}% relevant to {topic}")
      break
    elif transcription_result['status'] == 'error':
        raise RuntimeError(f"Transcription failed: {transcription_result['error']}")
    else:
        time.sleep(3)
```

  </Tab>
  <Tab language="javascript-sdk" title="JavaScript SDK">
  
  Enable Topic Detection by setting `iab_categories` to `true` in the transcription config.

```javascript {12}
import { AssemblyAI } from "assemblyai";

const client = new AssemblyAI({
  apiKey: "<YOUR_API_KEY>",
});

// const audioFile = './local_file.mp3'
const audioFile = "https://assembly.ai/wildfires.mp3";

const params = {
  audio: audioFile,
  speech_models: ["universal-3-pro", "universal-2"],
  language_detection: true,
  iab_categories: true,
};

const run = async () => {
  const transcript = await client.transcripts.transcribe(params);
  console.log("Transcript ID: ", transcript.id);

  // Get the parts of the transcript that were tagged with topics
  for (const result of transcript.iab_categories_result.results) {
    console.log(result.text);
    console.log(
      `Timestamp: ${result.timestamp?.start} - ${result.timestamp?.end}`
    );
    for (const label of result.labels) {
      console.log(`${label.label} (${label.relevance})`);
    }
  }

  // Get a summary of all topics in the transcript
  for (const [topic, relevance] of Object.entries(
    transcript.iab_categories_result.summary
  )) {
    console.log(`Audio is ${relevance * 100} relevant to ${topic}`);
  }
};

run();
```

  </Tab>
  <Tab language="javascript" title="JavaScript">
  
  Enable Topic Detection by setting `iab_categories` to `true` in the JSON payload.

```javascript {19}
import axios from "axios";
import fs from "fs-extra";

const baseUrl = "https://api.assemblyai.com";

const headers = {
  authorization: "<YOUR_API_KEY>",
};

const path = "./my-audio.mp3";
const audioData = await fs.readFile(path);
const uploadResponse = await axios.post(`${baseUrl}/v2/upload`, audioData, {
  headers,
});
const uploadUrl = uploadResponse.data.upload_url;

const data = {
  audio_url: uploadUrl, // You can also use a URL to an audio or video file on the web
  speech_models: ["universal-3-pro", "universal-2"],
  language_detection: true,
  iab_categories: true,
};

const url = `${baseUrl}/v2/transcript`;
const response = await axios.post(url, data, { headers: headers });

const transcriptId = response.data.id;
console.log("Transcript ID: ", transcriptId);

const pollingEndpoint = `${baseUrl}/v2/transcript/${transcriptId}`;

while (true) {
  const pollingResponse = await axios.get(pollingEndpoint, {
    headers: headers,
  });
  const transcriptionResult = pollingResponse.data;

  if (transcriptionResult.status === "completed") {
    // Get the parts of the transcript that were tagged with topics
    for (const result of transcriptionResult.iab_categories_result.results) {
      console.log(result.text);
      console.log(
        `Timestamp: ${result.timestamp.start} - ${result.timestamp.end}`
      );

      for (const label of result.labels) {
        console.log(`${label.label} (${label.relevance})`);
      }
    }
    // Get a summary of all topics in the transcript
    for (const [topic, relevance] of Object.entries(
      transcriptionResult.iab_categories_result.summary
    )) {
      console.log(`Audio is ${relevance * 100} relevant to ${topic}`);
    }
  } else if (transcriptionResult.status === "error") {
    throw new Error(`Transcription failed: ${transcriptionResult.error}`);
  } else {
    await new Promise((resolve) => setTimeout(resolve, 3000));
  }
}
```

  </Tab>
  <Tab language="csharp" title="C#">
  
  Enable Topic Detection by setting `iab_categories` to `true` in the JSON payload.

<Info>
  Most of these libraries are included by default, but on .NET Framework and
  Mono you need to reference the System.Net.Http library and install the
  [System.Net.Http.Json NuGet
  package](https://www.nuget.org/packages/System.Net.Http.Json).
</Info>

```csharp {53}
using System;
using System.IO;
using System.Net.Http;
using System.Net.Http.Headers;
using System.Net.Http.Json;
using System.Text;
using System.Text.Json;
using System.Threading.Tasks;
using System.Text.Json.Serialization;
using System.Collections.Generic;

class Program
{
    static async Task Main(string[] args)
    {
        string baseUrl = "https://api.assemblyai.com";

        using (var httpClient = new HttpClient())
        {
            httpClient.DefaultRequestHeaders.Authorization =
                new AuthenticationHeaderValue("<YOUR_API_KEY>");

            string uploadUrl = await UploadFileAsync("./local_file.mp3", httpClient, baseUrl);

            var transcript = await CreateTranscriptWithIabCategoriesAsync(uploadUrl, httpClient, baseUrl);

            Console.WriteLine($"Transcript ID: {transcript.Id}");
            transcript = await WaitForTranscriptToProcessAndAnalyzeCategories(transcript, httpClient, baseUrl);
        }
    }

    static async Task<string> UploadFileAsync(string filePath, HttpClient httpClient, string baseUrl)
    {
        using (var fileStream = File.OpenRead(filePath))
        using (var fileContent = new StreamContent(fileStream))
        {
            fileContent.Headers.ContentType = new MediaTypeHeaderValue("application/octet-stream");

            using (var response = await httpClient.PostAsync($"{baseUrl}/v2/upload", fileContent))
            {
                response.EnsureSuccessStatusCode();
                var jsonDoc = await response.Content.ReadFromJsonAsync<JsonDocument>();
                return jsonDoc.RootElement.GetProperty("upload_url").GetString();
            }
        }
    }

    static async Task<Transcript> CreateTranscriptWithIabCategoriesAsync(string audioUrl, HttpClient httpClient, string baseUrl)
    {
        var data = new
        {
            audio_url = audioUrl,
            speech_models = new[] { "universal-3-pro", "universal-2" },
            language_detection = true,
            iab_categories = true
        };

        var content = new StringContent(JsonSerializer.Serialize(data), Encoding.UTF8, "application/json");

        using (var response = await httpClient.PostAsync($"{baseUrl}/v2/transcript", content))
        {
            response.EnsureSuccessStatusCode();
            return await response.Content.ReadFromJsonAsync<Transcript>();
        }
    }

    static async Task<Transcript> WaitForTranscriptToProcessAndAnalyzeCategories(Transcript transcript, HttpClient httpClient, string baseUrl)
    {
        string pollingEndpoint = $"{baseUrl}/v2/transcript/{transcript.Id}";

        while (true)
        {
            var pollingResponse = await httpClient.GetAsync(pollingEndpoint);
            transcript = await pollingResponse.Content.ReadFromJsonAsync<Transcript>();

            switch (transcript.Status)
            {
                case "completed":
                    // Process IAB categories results
                    if (transcript.IabCategoriesResult != null)
                    {
                        // Get the parts of the transcript that were tagged with topics
                        if (transcript.IabCategoriesResult.Results != null)
                        {
                            foreach (var result in transcript.IabCategoriesResult.Results)
                            {
                                Console.WriteLine(result.Text);
                                Console.WriteLine($"Timestamp: {result.Timestamp.Start} - {result.Timestamp.End}");

                                foreach (var label in result.Labels)
                                {
                                    Console.WriteLine($"{label.Label} ({label.Relevance})");
                                }
                                Console.WriteLine();
                            }
                        }

                        // Get a summary of all topics in the transcript
                        if (transcript.IabCategoriesResult.Summary != null)
                        {
                            foreach (var topicEntry in transcript.IabCategoriesResult.Summary)
                            {
                                Console.WriteLine($"Audio is {topicEntry.Value * 100}% relevant to {topicEntry.Key}");
                            }
                        }
                    }

                    return transcript;

                case "error":
                    throw new Exception($"Transcription failed: {transcript.Error}");

                default:
                    await Task.Delay(TimeSpan.FromSeconds(3));
                    break;
            }
        }
    }

    public class Transcript
    {
        [JsonPropertyName("id")]
        public string Id { get; set; }

        [JsonPropertyName("status")]
        public string Status { get; set; }

        [JsonPropertyName("text")]
        public string Text { get; set; }

        [JsonPropertyName("iab_categories_result")]
        public IabCategoriesResult IabCategoriesResult { get; set; }

        [JsonPropertyName("error")]
        public string Error { get; set; }
    }

    public class IabCategoriesResult
    {
        [JsonPropertyName("results")]
        public List<CategoryResult> Results { get; set; }

        [JsonPropertyName("summary")]
        public Dictionary<string, double> Summary { get; set; }
    }

    public class CategoryResult
    {
        [JsonPropertyName("text")]
        public string Text { get; set; }

        [JsonPropertyName("timestamp")]
        public TimeRange Timestamp { get; set; }

        [JsonPropertyName("labels")]
        public List<CategoryLabel> Labels { get; set; }
    }

    public class TimeRange
    {
        [JsonPropertyName("start")]
        public int Start { get; set; }

        [JsonPropertyName("end")]
        public int End { get; set; }
    }

    public class CategoryLabel
    {
        [JsonPropertyName("label")]
        public string Label { get; set; }

        [JsonPropertyName("relevance")]
        public double Relevance { get; set; }
    }
}
```

  </Tab>
  <Tab language="ruby" title="Ruby">
  
  Enable Topic Detection by setting `iab_categories` to `true` in the JSON payload.

```ruby {23}
require 'net/http'
require 'json'

base_url = 'https://api.assemblyai.com'

headers = {
  'authorization' => '<YOUR_API_KEY>',
  'content-type' => 'application/json'
}

path = "/my_audio.mp3"
uri = URI("#{base_url}/v2/upload")
request = Net::HTTP::Post.new(uri, headers)
request.body = File.read(path)

http = Net::HTTP.new(uri.host, uri.port)
http.use_ssl = true
upload_response = http.request(request)
upload_url = JSON.parse(upload_response.body)["upload_url"]

data = {
    "audio_url" => upload_url, # You can also use a URL to an audio or video file on the web
    "speech_models" => ["universal-3-pro", "universal-2"],
    "language_detection" => true,
    "iab_categories" => true
}

uri = URI.parse("#{base_url}/v2/transcript")
http = Net::HTTP.new(uri.host, uri.port)
http.use_ssl = true

request = Net::HTTP::Post.new(uri.request_uri, headers)
request.body = data.to_json

response = http.request(request)
response_body = JSON.parse(response.body)

unless response.is_a?(Net::HTTPSuccess)
  raise "API request failed with status #{response.code}: #{response.body}"
end

transcript_id = response_body['id']
puts "Transcript ID: #{transcript_id}"

polling_endpoint = URI.parse("#{base_url}/v2/transcript/#{transcript_id}")

while true
  polling_http = Net::HTTP.new(polling_endpoint.host, polling_endpoint.port)
  polling_http.use_ssl = true
  polling_request = Net::HTTP::Get.new(polling_endpoint.request_uri, headers)
  polling_response = polling_http.request(polling_request)

  transcription_result = JSON.parse(polling_response.body)

  if transcription_result['status'] == 'completed'
    # Get the parts of the transcript that were tagged with topics
    transcription_result['iab_categories_result']['results'].each do |result|
      puts result['text']
      puts "Timestamp: #{result['timestamp']['start']} - #{result['timestamp']['end']}"

      result['labels'].each do |label|
        puts "#{label['label']} - (#{label['relevance']})"
      end
    end
    # Get a summary of all topics in the transcript
    transcription_result['iab_categories_result']['summary'].each do |topic, relevance|
      puts "Audio is #{relevance * 100}% relevant to #{topic}"
    end
  break
  elsif transcription_result['status'] == 'error'
    raise "Transcription failed: #{transcription_result['error']}"
  else
    sleep(3)
  end
end
```

  </Tab>
  <Tab language="php" title="PHP">
  
  Enable Topic Detection by setting `iab_categories` to `true` in the JSON payload.

```php {30}
<?php
$ch = curl_init();
curl_setopt($ch, CURLOPT_RETURNTRANSFER, true);

$base_url = "https://api.assemblyai.com";

$headers = array(
    "authorization: <YOUR_API_KEY>",
    "content-type: application/json"
);

$path = "./my-audio.mp3";

$ch = curl_init();

curl_setopt($ch, CURLOPT_URL, $base_url . "/v2/upload");
curl_setopt($ch, CURLOPT_POST, 1);
curl_setopt($ch, CURLOPT_POSTFIELDS, file_get_contents($path));
curl_setopt($ch, CURLOPT_HTTPHEADER, $headers);
curl_setopt($ch, CURLOPT_RETURNTRANSFER, 1);

$response = curl_exec($ch);
$response_data = json_decode($response, true);
$upload_url = $response_data["upload_url"];

curl_close($ch);

$data = array(
    "audio_url" => $upload_url, // You can also use a URL to an audio or video file on the web
    "speech_models" => array("universal-3-pro", "universal-2"),
    "language_detection" => true,
    "iab_categories" => true,
);

$url = $base_url . "/v2/transcript";
$curl = curl_init($url);

curl_setopt($curl, CURLOPT_POST, true);
curl_setopt($curl, CURLOPT_POSTFIELDS, json_encode($data));
curl_setopt($curl, CURLOPT_HTTPHEADER, $headers);
curl_setopt($curl, CURLOPT_RETURNTRANSFER, true);

$response = curl_exec($curl);

$response = json_decode($response, true);

curl_close($curl);

$transcript_id = $response['id'];
echo "Transcript ID: $transcript_id\n";

$polling_endpoint = $base_url . "/v2/transcript/" . $transcript_id;

while (true) {
    $polling_response = curl_init($polling_endpoint);

    curl_setopt($polling_response, CURLOPT_HTTPHEADER, $headers);
    curl_setopt($polling_response, CURLOPT_RETURNTRANSFER, true);

    $transcription_result = json_decode(curl_exec($polling_response), true);

    if ($transcription_result['status'] === "completed") {
        $content_safety_labels = $transcription_result['iab_categories_result'];

        // Get the parts of the transcript that were tagged with topics
        foreach ($content_safety_labels['results'] as $result) {
            echo $result['text'] . "\n";
            echo "Timestamp: {$result['timestamp']['start']} - {$result['timestamp']['end']}\n";

            foreach ($result['labels'] as $label) {
                echo "{$label['label']} - {$label['relevance']}\n";
            }
        }
        // Get a summary of all topics in the transcript
        foreach ($content_safety_labels['summary'] as $topic => $relevance) {
          echo "Audio is " . ($relevance * 100) . "% relevant to $topic\n";
        }
        break;
    }  else if ($transcription_result['status'] === "error") {
        throw new Exception("Transcription failed: " . $transcription_result['error']);
    } else {
        sleep(3);
    }
}
```

  </Tab>
</Tabs>

### Example output

```plain
Smoke from hundreds of wildfires in Canada is triggering air quality alerts throughout the US. Skylines...
Timestamp: 250 - 28920
Home&Garden>IndoorEnvironmentalQuality (0.9881)
NewsAndPolitics>Weather (0.5561)
MedicalHealth>DiseasesAndConditions>LungAndRespiratoryHealth (0.0042)
...
Audio is 100.0% relevant to NewsAndPolitics>Weather
Audio is 93.78% relevant to Home&Garden>IndoorEnvironmentalQuality
...
```

<Tip title="Topic Detection Using LLM Gateway">
  Check out this cookbook [Custom Topic Tags](/docs/guides/custom-topic-tags)
  for an example of how to use LLM Gateway to create custom topic tags.
</Tip>

## API reference

### Request

```bash {6}
curl https://api.assemblyai.com/v2/transcript \
--header "Authorization: <YOUR_API_KEY>" \
--header "Content-Type: application/json" \
--data '{
  "audio_url": "YOUR_AUDIO_URL",
  "iab_categories": true
}'
```

| Key              | Type    | Description             |
| ---------------- | ------- | ----------------------- |
| `iab_categories` | boolean | Enable Topic Detection. |

### Response

<Markdown src="topic-detection-response.mdx" />

| Key                                                    | Type   | Description                                                                                                                                |
| ------------------------------------------------------ | ------ | ------------------------------------------------------------------------------------------------------------------------------------------ |
| `iab_categories_result`                                | object | The result of the Topic Detection model.                                                                                                   |
| `iab_categories_result.status`                         | string | Is either `success`, or `unavailable` in the rare case that the Content Moderation model failed.                                           |
| `iab_categories_result.results`                        | array  | An array of the Topic Detection results.                                                                                                   |
| `iab_categories_result.results[i].text`                | string | The text in the transcript in which the i-th instance of a detected topic occurs.                                                          |
| `iab_categories_result.results[i].labels[j].relevance` | number | How relevant the j-th detected topic is in the i-th instance of a detected topic.                                                          |
| `iab_categories_result.results[i].labels[j].label`     | string | The IAB taxonomical label for the j-th label of the i-th instance of a detected topic, where `>` denotes supertopic/subtopic relationship. |
| `iab_categories_result.results[i].timestamp.start`     | number | The starting time in the audio file at which the i-th detected topic instance is discussed.                                                |
| `iab_categories_result.results[i].timestamp.end`       | number | The ending time in the audio file at which the i-th detected topic instance is discussed.                                                  |
| `iab_categories_result.summary`                        | object | Summary where each property is a detected topic.                                                                                           |
| `iab_categories_result.summary.topic`                  | number | The overall relevance of <i>topic</i> to the entire audio file.                                                                            |

The response also includes the request parameters used to generate the transcript.

## Frequently asked questions

{" "}

<Accordion
  title="How does the Topic Detection model handle misspelled or unrecognized words?"
  theme="dark"
  iconColor="white"
>
  <p>
    The Topic Detection model uses natural language processing and machine
    learning to identify related words and phrases even if they are misspelled
    or unrecognized. However, the accuracy of the detection may depend on the
    severity of the misspelling or the obscurity of the word.
  </p>
</Accordion>

<Accordion
  title="Can I use the Topic Detection model to identify entities that aren't part of the IAB Taxonomy?"
  theme="dark"
  iconColor="white"
>
  <p>
    No, the Topic Detection model can only identify entities that are part of
    the IAB Taxonomy. The model is optimized for contextual targeting use cases,
    so using the predefined IAB categories ensures the most accurate results.
  </p>
</Accordion>

<Accordion
  title="Why am I not getting any topic predictions for my audio file?"
  theme="dark"
  iconColor="white"
>
  <p>
    There could be several reasons why you aren't getting any topic predictions
    for your audio file. One possible reason is that the audio file doesn't
    contain enough relevant content for the model to analyze. Additionally, the
    accuracy of the predictions may be affected by factors such as background
    noise, low-quality audio, or a low confidence threshold for topic detection.
    It's recommended to review and adjust the model's configuration parameters
    and to provide high-quality, relevant audio files for analysis.
  </p>
</Accordion>

<Accordion
  title="Why am I getting inaccurate or irrelevant topic predictions for my audio file?"
  theme="dark"
  iconColor="white"
>
  <p>
    There could be several reasons why you're getting inaccurate or irrelevant
    topic predictions for your audio file. One possible reason is that the audio
    file contains background noise or other non-relevant content that's
    interfering with the model's analysis. Additionally, the accuracy of the
    predictions may be affected by factors such as low-quality audio, a low
    confidence threshold for topic detection, or insufficient training data.
    It's recommended to review and adjust the model's configuration parameters,
    to provide high-quality, relevant audio files for analysis, and to consider
    adding additional training data to the model.
  </p>
</Accordion>

<Accordion
  title="Is AssemblyAI associated with IAB?"
  theme="dark"
  iconColor="white"
>
  <p>
    As of 2023, AssemblyAI is a partner with the Interactive Advertising Bureau
    (IAB), a certification and community for advertising across the internet.
    AssemblyAI built Topic Detection using the IAB Taxonomy, which is a
    blueprint of the approximately 700 topics used to categorize ads.
  </p>
</Accordion>
