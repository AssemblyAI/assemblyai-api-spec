---
title: 'Summarization'
description: 'Generate a single summary of your entire audio file'
---


  


Distill important information by summarizing your audio files.

The Summarization model generates a summary of the resulting transcript. You can control the style and format of the summary using [Summary models](#summary-models) and [Summary types](#summary-types).

<Warning title="Summarization and Auto Chapters">
You can only enable one of the Summarization and [Auto Chapters](/docs/audio-intelligence/auto-chapters) models in the same transcription.
</Warning>





## Quickstart


<Tabs groupId="language">
  <Tab language="python-sdk" title="Python SDK" default>
  
  Enable Summarization by setting `summarization` to `True` in the transcription config. Use `summary_model` and `summary_type` to change the summary format.

If you specify one of `summary_model` or `summary_type`, then you must specify the other.

The following example returns an informative summary in a bulleted list.

```python {9-11}
import assemblyai as aai

aai.settings.api_key = "<YOUR_API_KEY>"

# audio_file = "./local_file.mp3"
audio_file = "https://assembly.ai/wildfires.mp3"

config = aai.TranscriptionConfig(
  summarization=True,
  summary_model=aai.SummarizationModel.informative,
  summary_type=aai.SummarizationType.bullets
)

transcript = aai.Transcriber().transcribe(audio_file, config)

print(f"Transcript ID: ", transcript.id)
print(transcript.summary)
```

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1xnr8yS3SeiiI-4gwuhP-uuAHrcK76LR9#scrollTo=TfnrKdbV1dVD)

  </Tab>
  <Tab language="python" title="Python" default>
  
  Enable Summarization by setting `summarization` to `True` in the JSON payload. Use `summary_model` and `summary_type` to change the summary format.

If you specify one of `summary_model` or `summary_type`, then you must specify the other.

The following example returns an informative summary in a bulleted list.

```python {20-22}
import requests
import json
import time

base_url = "https://api.assemblyai.com"

headers = {
    "authorization": "<YOUR_API_KEY>"
}

with open("./my-audio.mp3", "rb") as f:
  response = requests.post(base_url + "/v2/upload",
                          headers=headers,
                          data=f)

upload_url = response.json()["upload_url"]

data = {
    "audio_url": upload_url, # You can also use a URL to an audio or video file on the web
    "summarization": True,
    "summary_model": "informative",
    "summary_type": "bullets"
}

url = base_url + "/v2/transcript"
response = requests.post(url, json=data, headers=headers)

transcript_id = response.json()['id']
polling_endpoint = f"https://api.assemblyai.com/v2/transcript/{transcript_id}"

while True:
  transcription_result = requests.get(polling_endpoint, headers=headers).json()

  if transcription_result['status'] == 'completed':
    print(f"Transcript ID:", transcript.id)
    print(transcription_result['summary'])
    break

  elif transcription_result['status'] == 'error':
    raise RuntimeError(f"Transcription failed: {transcription_result['error']}")

  else:
    time.sleep(3)

```

  </Tab>
  <Tab language="typescript-sdk" title="TypeScript SDK">
  
  Enable Summarization by setting `summarization` to `true` in the transcription config. Use `summary_model` and `summary_type` to change the summary format.

If you specify one of `summary_model` or `summary_type`, then you must specify the other.

The following example returns an informative summary in a bulleted list.

```ts {13-15}
import { AssemblyAI } from 'assemblyai'

const client = new AssemblyAI({
  apiKey: '<YOUR_API_KEY>'
})

// const audioFile = './local_file.mp3'
const audioFile =
  'https://assembly.ai/wildfires.mp3'

const params = {
  audio: audioFile,
  summarization: true,
  summary_model: 'informative',
  summary_type: 'bullets'
}

const run = async () => {
  const transcript = await client.transcripts.transcribe(params)

  console.log("Transcript ID: ", transcript.id)
  console.log(transcript.summary)
}

run()
```

  </Tab>
  <Tab language="typescript" title="TypeScript">
  
  Enable Summarization by setting `summarization` to `true` in the JSON payload. Use `summary_model` and `summary_type` to change the summary format.

If you specify one of `summary_model` or `summary_type`, then you must specify the other.

The following example returns an informative summary in a bulleted list.

```ts {19-21}
import axios from 'axios'
import fs from 'fs-extra'

const baseUrl = 'https://api.assemblyai.com'

const headers = {
  authorization: '<YOUR_API_KEY>'
}

const path = './my-audio.mp3'
const audioData = await fs.readFile(path)
const uploadResponse = await axios.post(`${baseUrl}/v2/upload`, audioData, {
  headers
})
const uploadUrl = uploadResponse.data.upload_url

const data = {
  audio_url: uploadUrl, // You can also use a URL to an audio or video file on the web
  summarization: true,
  summary_model: 'informative',
  summary_type: 'bullets'
}

const url = `${baseUrl}/v2/transcript`
const response = await axios.post(url, data, { headers: headers })

const transcriptId = response.data.id
const pollingEndpoint = `${baseUrl}/v2/transcript/${transcriptId}`

while (true) {
  const pollingResponse = await axios.get(pollingEndpoint, {
    headers: headers
  })
  const transcriptionResult = pollingResponse.data

  if (transcriptionResult.status === 'completed') {
    console.log("Transcript ID: ", transcriptionResult.id)
    console.log(transcriptionResult.summary)
    break
  } else if (transcriptionResult.status === 'error') {
    throw new Error(`Transcription failed: ${transcriptionResult.error}`)
  } else {
    await new Promise((resolve) => setTimeout(resolve, 3000))
  }
}

```

  </Tab>
  <Tab language="csharp" title="C#">
  
  Enable `summarization` in the transcription parameters. Use `summary_model` and `summary_type` to change the summary format.

If you specify one of `summary_model` and `summary_type`, then you must specify the other.

The following example returns an informative summary in a bulleted list.

<Info>
Most of these libraries are included by default, but on .NET Framework and Mono you need to reference the System.Net.Http library and install the [System.Net.Http.Json NuGet package](https://www.nuget.org/packages/System.Net.Http.Json).
</Info>

```csharp {34}
using System;
using System.IO;
using System.Net.Http;
using System.Net.Http.Headers;
using System.Net.Http.Json;
using System.Text;
using System.Text.Json;
using System.Threading.Tasks;

using (var httpClient = new HttpClient())
{
    httpClient.DefaultRequestHeaders.Authorization =
        new AuthenticationHeaderValue("<YOUR_API_KEY>");
}

private static async Task<string> UploadFileAsync(string filePath, HttpClient httpClient)
{
    using (var fileStream = File.OpenRead(filePath))
    using (var fileContent = new StreamContent(fileStream))
    {
        fileContent.Headers.ContentType = new MediaTypeHeaderValue("application/octet-stream");

        using (var response = await httpClient.PostAsync("https://api.assemblyai.com/v2/upload", fileContent))
        {
            response.EnsureSuccessStatusCode();
            var jsonDoc = await response.Content.ReadFromJsonAsync<JsonDocument>();
            return jsonDoc.RootElement.GetProperty("upload_url").GetString();
        }
    }
}

private static async Task<Transcript> CreateTranscriptAsync(string audioUrl, HttpClient httpClient)
{
    var data = new { audio_url = audioUrl, summarization = true, summary_model = "informative", summary_type = "bullets" };
    var content = new StringContent(JsonSerializer.Serialize(data), Encoding.UTF8, "application/json");

    using (var response = await httpClient.PostAsync("https://api.assemblyai.com/v2/transcript", content))
    {
        response.EnsureSuccessStatusCode();
        return await response.Content.ReadFromJsonAsync<Transcript>();
    }
}

public class Transcript
{
    public string Id { get; set; }
    public string Status { get; set; }
    public string Text { get; set; }

    [JsonPropertyName("language_code")]
    public string LanguageCode { get; set; }

    public string Error { get; set; }
}

private static async Task<Transcript> WaitForTranscriptToProcess(Transcript transcript, HttpClient httpClient)
{
    var pollingEndpoint = $"https://api.assemblyai.com/v2/transcript/{transcript.Id}";

    while (true)
    {
        var pollingResponse = await httpClient.GetAsync(pollingEndpoint);
        transcript = await pollingResponse.Content.ReadFromJsonAsync<Transcript>();
        switch (transcript.Status)
        {
            case "processing":
            case "queued":
                await Task.Delay(TimeSpan.FromSeconds(3));
                break;
            case "completed":
                return transcript;
            case "error":
                throw new Exception($"Transcription failed: {transcript.Error}");
            default:
                throw new Exception("This code shouldn't be reachable.");
        }
    }
}

using (var httpClient = new HttpClient())
{
    httpClient.DefaultRequestHeaders.Authorization =
        new AuthenticationHeaderValue("<YOUR_API_KEY>");

    var uploadUrl = await UploadFileAsync("/my_audio.mp3", httpClient);
    var transcript = await CreateTranscriptAsync(uploadUrl, httpClient);
    transcript = await WaitForTranscriptToProcess(transcript, httpClient);

    Console.WriteLine(transcript.Summary);
}
```
  </Tab>
  <Tab language="ruby" title="Ruby">
  
  Enable Summarization by setting `summarization` to `true` in the JSON payload. Use `summary_model` and `summary_type` to change the summary format.

If you specify one of `summary_model` or `summary_type`, then you must specify the other.

The following example returns an informative summary in a bulleted list.

```ruby {23-25}
require 'net/http'
require 'json'

base_url = 'https://api.assemblyai.com'

headers = {
  'authorization' => '<YOUR_API_KEY>',
  'content-type' => 'application/json'
}

path = "/my_audio.mp3"
uri = URI("#{base_url}/v2/upload")
request = Net::HTTP::Post.new(uri, headers)
request.body = File.read(path)

http = Net::HTTP.new(uri.host, uri.port)
http.use_ssl = true
upload_response = http.request(request)
upload_url = JSON.parse(upload_response.body)["upload_url"]

data = {
    "audio_url" => upload_url, # You can also use a URL to an audio or video file on the web
    "summarization" => true,
    "summary_model" => "informative",
    "summary_type" => "bullets"
}

uri = URI.parse("#{base_url}/v2/transcript")
http = Net::HTTP.new(uri.host, uri.port)
http.use_ssl = true

request = Net::HTTP::Post.new(uri.request_uri, headers)
request.body = data.to_json

response = http.request(request)
response_body = JSON.parse(response.body)

unless response.is_a?(Net::HTTPSuccess)
  raise "API request failed with status #{response.code}: #{response.body}"
end

transcript_id = response_body['id']
puts "Transcript ID: #{transcript_id}"

polling_endpoint = URI.parse("#{base_url}/v2/transcript/#{transcript_id}")

while true
  polling_http = Net::HTTP.new(polling_endpoint.host, polling_endpoint.port)
  polling_http.use_ssl = true
  polling_request = Net::HTTP::Get.new(polling_endpoint.request_uri, headers)
  polling_response = polling_http.request(polling_request)
  
  transcription_result = JSON.parse(polling_response.body)

  if transcription_result['status'] == 'completed'
    puts "Transcription text: #{transcription_result['summary']}"
    break
  elsif transcription_result['status'] == 'error'
    raise "Transcription failed: #{transcription_result['error']}"
  else
    puts 'Waiting for transcription to complete...'
    sleep(3)
  end
end
```

  </Tab>
  <Tab language="php" title="PHP">
  
  Enable Summarization by setting `summarization` to `true` in the JSON payload. Use `summary_model` and `summary_type` to change the summary format.

If you specify one of `summary_model` or `summary_type`, then you must specify the other.

The following example returns an informative summary in a bulleted list.

```php {30-32}
<?php
$ch = curl_init();
curl_setopt($ch, CURLOPT_RETURNTRANSFER, true);

$base_url = "https://api.assemblyai.com";

$headers = array(
    "authorization: d8a377b7d8fd4a4ca74c6bd875bdf015",
    "content-type: application/json"
);

$path = "audio files/audio05853.wav";

$ch = curl_init();

curl_setopt($ch, CURLOPT_URL, $base_url . "/v2/upload");
curl_setopt($ch, CURLOPT_POST, 1);
curl_setopt($ch, CURLOPT_POSTFIELDS, file_get_contents($path));
curl_setopt($ch, CURLOPT_HTTPHEADER, $headers);
curl_setopt($ch, CURLOPT_RETURNTRANSFER, 1);

$response = curl_exec($ch);
$response_data = json_decode($response, true);
$upload_url = $response_data["upload_url"];

curl_close($ch);

$data = array(
    "audio_url" => $upload_url, // You can also use a URL to an audio or video file on the web
    "summarization" => true,
    "summary_model" => "informative",
    "summary_type" => "bullets"
);

$url = $base_url . "/v2/transcript";
$curl = curl_init($url);

curl_setopt($curl, CURLOPT_POST, true);
curl_setopt($curl, CURLOPT_POSTFIELDS, json_encode($data));
curl_setopt($curl, CURLOPT_HTTPHEADER, $headers);
curl_setopt($curl, CURLOPT_RETURNTRANSFER, true);

$response = curl_exec($curl);

$response = json_decode($response, true);

curl_close($curl);

$transcript_id = $response['id'];
echo "Transcript ID: $transcript_id\n";

$polling_endpoint = "https://api.assemblyai.com/v2/transcript/" . $transcript_id;

while (true) {
    $polling_response = curl_init($polling_endpoint);

    curl_setopt($polling_response, CURLOPT_HTTPHEADER, $headers);
    curl_setopt($polling_response, CURLOPT_RETURNTRANSFER, true);

    $transcription_result = json_decode(curl_exec($polling_response), true);

    if ($transcription_result['status'] === "completed") {
        echo $transcription_result['summary'];
        break;
    } else if ($transcription_result['status'] === "error") {
        throw new Exception("Transcription failed: " . $transcription_result['error']);
    } else {
        sleep(3);
    }
}
```

  </Tab>
</Tabs>

### Example output

```plain
- Smoke from hundreds of wildfires in Canada is triggering air quality alerts throughout the US. Skylines from Maine to Maryland to Minnesota are gray and smoggy. In some places, the air quality warnings include the warning to stay inside.
- Air pollution levels in Baltimore are considered unhealthy. Exposure to high levels can lead to a host of health problems. With climate change, we are seeing more wildfires. Will we be seeing more of these kinds of wide ranging air quality consequences?
```

<Tip title="Custom Summaries Using LeMUR">
If you want more control of the output format, see how to generate a [Custom summary using LeMUR](/docs/lemur/summarize-audio).
</Tip>





## API reference

### Request

```bash {6-8}
curl https://api.assemblyai.com/v2/transcript \
--header "Authorization: <YOUR_API_KEY>" \
--header "Content-Type: application/json" \
--data '{
  "audio_url": "YOUR_AUDIO_URL",
  "summarization": true,
  "summary_model": "informative",
  "summary_type": "bullets"
}'
```

| Key             | Type    | Description                                                    |
| --------------- | ------- | -------------------------------------------------------------- |
| `summarization` | boolean | Enable Summarization.                                          |
| `summary_type`  | string  | [Summary type](#summary-types) to use for the transcription.   |
| `summary_model` | string  | [Summary model](#summary-models) to use for the transcription. |

### Response

<Markdown src="summarization-response.mdx" />

| Key       | Type   | Description                  |
| --------- | ------ | ---------------------------- |
| `summary` | string | A summary of the audio file. |

The response also includes the request parameters used to generate the transcript.





### Summary types

The summary type determines both the length and the format of the summary, for example as a bulleted list or a paragraph.

| Value | Description | Example |
| --------- | ------ | ---------------------------- |
| `bullets` (default) | A bulleted summary with the most important points. |  - The human brain has nearly tripled in mass in two million years. <br /> - One of the main reasons that our brain got so big is because it got a new part, called the frontal lobe. |
| `bullets_verbose` | A longer bullet point list summarizing the entire transcription text. | Dan Gilbert is a psychologist and a happiness expert. His talk is recorded live at Ted conference. He explains why the human brain has nearly tripled in size in 2 million years. He also explains the difference between winning the lottery and becoming a paraplegic.\n- In 1994, Pete Best said he's happier than he would have been with the Beatles. In the free choice paradigm, monet prints are ranked from the one they like the most to the one that they don't. People prefer the third one over the fourth one because it's a little better.\n- People synthesize happiness when they change their affective. Hedonic aesthetic to make up your mind and change your mind is the friend of natural happiness. But it's the enemy of synthetic happiness. The psychological immune system works best when we are stuck. This is the difference between dating and marriage. People don't know this about themselves and it can work to their disadvantage.\n- In a photography course at Harvard, 66% of students choose not to take the course where they have the opportunity to change their mind. Adam Smith said that some things are better than others. Dan Gilbert recorded at Ted, 2004 in Monterey, California, 2004. |
| `gist` | A few words summarizing the entire transcription text. | A big brain |
| `headline` | A single sentence summarizing the entire transcription text. | The human brain has nearly tripled in mass in two million years. |  
| `paragraph` | A single paragraph summarizing the entire transcription text. | The human brain has nearly tripled in mass in two million years. It went from the one-and-a-quarter-pound brain of our ancestor, habilis, to the almost three-pound meatloaf everybody here has between their ears. |

### Summary models

The summary model determines the style and tone of the summary.

| Value | When to use | Supported summary type | Required parameters |
| --------- | ------ | ---------------------------- | ---------------------------- |
| `informative` (default) | Best for files with a single speaker, such as presentations or lectures. | `bullets`, `bullets_verbose`, `headline`, or `paragraph` | `punctuate` and `format_text` set to `true` |
| `conversational` | Best for any 2-person conversation, such as customer/agent or interview/interviewee calls. | `bullets`, `bullets_verbose`, `headline`, or `paragraph` | `punctuate`, `format_text`, and `speaker_labels` or `multichannel` set to `true` |
| `catchy` | Best for creating video, podcast, or media titles. | `headline`, or `gist` | `punctuate` and `format_text` set to `true` |


## Frequently asked questions

<Accordion title="How long does it take to generate a summarization output?" theme="dark" iconColor="white" >
  
The inference speed of the Summary model depends on the desired output length. However, a single batch can be processed in less than 1 second.

  </Accordion>

<Accordion title="Can I extract individual words and their corresponding speaker labels with Summarization?" theme="dark" iconColor="white" >
  
No. Summarization only generates a single abstractive summary of the entire audio file, and doesn't provide word-level information or speaker labels. If you need word-level information, consider using [Word-level timestamps](/docs/speech-to-text/pre-recorded-audio#word-level-timestamps) and [Speaker Diarization](/docs/speech-to-text/speaker-diarization) instead.

  </Accordion>




