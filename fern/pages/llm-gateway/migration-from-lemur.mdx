---
title: "Migration Guide: From LeMUR to LLM Gateway"
subtitle: "Learn how to migrate your existing LeMUR prompts to the new LLM Gateway"
description: "Step-by-step guide to migrate from the deprecated LeMUR API to AssemblyAI's LLM Gateway with practical examples."
---

<Warning>
  **LeMUR will be deprecated on March 31st, 2026.** Please migrate to the [LLM
  Gateway](/docs/llm-gateway) before that date for continued access to language
  model capabilities with more models and better performance.
</Warning>

## Overview

This guide helps you migrate from LeMUR to AssemblyAI's LLM Gateway. While LeMUR was designed specifically for processing transcripts, LLM Gateway provides a more flexible, unified interface for working with multiple language models.

## Key differences

| Feature     | LeMUR                         | LLM Gateway                      |
| ----------- | ----------------------------- | -------------------------------- |
| **Purpose** | Transcript-specific LLM tasks | General-purpose LLM interface    |
| **Models**  | Limited model selection       | 15+ models (Claude, GPT, Gemini) |

## Migration steps

### Step 1: Replace transcript processing

**Before (LeMUR):** LeMUR automatically retrieved transcript text using transcript IDs.

**After (LLM Gateway):** You need to include the transcript text directly in your request.

<Tabs>
<Tab title="Before: LeMUR" language="python">

<Code src="../../snippets/llm-gateway/migration-from-lemur/python-1.py" />
</Tab>
<Tab title="After: LLM Gateway" language="python">

<Code src="../../snippets/llm-gateway/migration-from-lemur/python-2.py" />
</Tab>
</Tabs>

### Step 2: Update model names

LLM Gateway uses different model identifiers:

| LeMUR Model                               | LLM Gateway Model            |
| ----------------------------------------- | ---------------------------- |
| `aai.LemurModel.claude_sonnet_4_20250514` | `"claude-sonnet-4-20250514"` |
| `"anthropic/claude-sonnet-4-20250514"`    | `"claude-sonnet-4-20250514"` |

### Step 3: Modify response handling

**Before:** LeMUR returned a simple response object.
**After:** LLM Gateway returns OpenAI-compatible response format.

<Tabs>
<Tab title="Before: LeMUR" language="python">

```python
result = transcript.lemur.task(prompt)
print(result.response)  # Direct access to response text
```

</Tab>
<Tab title="After: LLM Gateway" language="python">

```python
result = response.json()
print(result["choices"][0]["message"]["content"])  # Extract from choices array
```

</Tab>
</Tabs>

## Complete migration example

Here's a complete example showing how to migrate a LeMUR sentiment analysis task:

<Tabs groupId="language">
<Tab language="python-sdk" title="Python SDK (Before: LeMUR)" default>

<Code src="../../snippets/llm-gateway/migration-from-lemur/python-sdk-1.py" />
</Tab>
<Tab language="python-sdk" title="Python SDK (After: LLM Gateway)">

<Code src="../../snippets/llm-gateway/migration-from-lemur/python-sdk-2.py" />
</Tab>
<Tab language="python" title="Python (Before: LeMUR)">

<Code src="../../snippets/llm-gateway/migration-from-lemur/python-3.py" />
</Tab>
<Tab language="python" title="Python (After: LLM Gateway)">

<Code src="../../snippets/llm-gateway/migration-from-lemur/python-4.py" />
</Tab>
<Tab language="javascript-sdk" title="JavaScript SDK (Before: LeMUR)">

<Code src="../../snippets/llm-gateway/migration-from-lemur/javascript-sdk-1.js" />
</Tab>
<Tab language="javascript-sdk" title="JavaScript SDK (After: LLM Gateway)">

<Code src="../../snippets/llm-gateway/migration-from-lemur/javascript-sdk-2.js" />
</Tab>
</Tabs>

## Migration benefits

Moving to LLM Gateway provides several advantages:

### More model choices

- **15+ models** including Claude 4.5 Sonnet, GPT-5, and Gemini 2.5 Pro
- **Better performance** with newer, more capable models

### Flexible input handling

- **Multi-turn conversations** for complex interactions
- **Custom system prompts** for better context control

### Enhanced capabilities

- **Tool calling** for function execution
- **Agentic workflows** for multi-step reasoning
- **OpenAI-compatible API** for easier integration

## Next steps

After migrating to LLM Gateway, explore additional capabilities:

- **[Multi-turn Conversations](/docs/llm-gateway/conversations)** - Build conversational experiences
- **[Tool Calling](/docs/llm-gateway/tool-calling)** - Enable function execution
- **[Agentic Workflows](/docs/llm-gateway/agentic-workflows)** - Create multi-step reasoning

## Need help?

If you encounter issues during migration:

1. **Check model availability** - Ensure your chosen model is [supported](/docs/llm-gateway#available-models)
2. **Verify API endpoints** - LLM Gateway uses different URLs than LeMUR
3. **Update response parsing** - Response format follows OpenAI standards
4. **Review token limits** - Different models have different context windows

<Note>
  The LLM Gateway provides more flexibility and capabilities than LeMUR, but
  requires slightly more setup to include transcript content in requests.
</Note>
