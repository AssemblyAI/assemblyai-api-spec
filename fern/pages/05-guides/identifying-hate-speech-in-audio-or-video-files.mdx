---
title: 'Identifying hate speech in audio or video files'
hide-nav-links: true
description: 'Detect sensitive content in your audio files'
---





Our [Content Moderation](/docs/audio-intelligence/content-moderation) model can help you ensure that your content is safe and appropriate for all audiences.

The model pinpoints sensitive discussions in spoken data and provides information on the severity to which they occurred.

In this guide, we'll learn how to use the Content Moderation model, and look at an example response to understand its structure.





## Get started

Before we begin, make sure you have an AssemblyAI account and an API key. You can [sign up](https://assemblyai.com/dashboard/signup) for a free account and get your API key from your dashboard.

The complete source code for this guide can be viewed [here](https://github.com/AssemblyAI-Community/docs-snippets/tree/main/hate-speech).

Here is an audio example for this guide:

```bash
https://assembly.ai/wildfires.mp3
```





## Step-by-step instructions

<Steps>
<Step>
<Tabs>
  <Tab title="Python SDK">

Install the SDK.

  </Tab>
  <Tab>

Create a new file and 
request.

  </Tab>
</Tabs>

<Tabs groupId="language">

<Tab value="python-sdk" title="Python SDK" default>

```python
pip install -U assemblyai
```

  </Tab>

  <Tab value="python" title="Python (requests)">

```python



```

  </Tab>

  <Tab value="typescript" title="TypeScript">

```typescript


```

  </Tab>

  <Tab value="php" title="PHP">

```php
$ch = curl_init();
curl_setopt($ch, CURLOPT_RETURNTRANSFER, true);
```

  </Tab>

  <Tab value="ruby" title="Ruby">

```ruby
require 'net/http'
require 'json'
require 'rest-client'
require 'httparty'
```

  </Tab>

<Tab value="csharp" title="C#">

```csharp
using System.Net.Http;
using System.Threading;
```

</Tab>

</Tabs>

</Step>
<Step>

<Tabs>
  <Tab>

Set up the API endpoint and headers. The headers should include your API
key.

  </Tab>
</Tabs>

<Tabs groupId="language">

<Tab value="python-sdk" title="Python SDK" default>

```python
import assemblyai as aai

aai.settings.api_key = "<YOUR_API_KEY>"
```

  </Tab>

  <Tab value="python" title="Python (requests)">

```python
base_url = "https://api.assemblyai.com/v2"

headers = {
    "authorization": "<YOUR_API_KEY>"
}
```

  </Tab>

  <Tab value="typescript" title="TypeScript">

```typescript
const baseUrl = 'https://api.assemblyai.com/v2'

const headers = {
  authorization: '<YOUR_API_KEY>'
}
```

  </Tab>

  <Tab value="php" title="PHP">

```php
$base_url = "https://api.assemblyai.com/v2";

$headers = array(
  "authorization: <YOUR_API_KEY>",
  "content-type: application/json"
);
```

  </Tab>

  <Tab value="ruby" title="Ruby">

```ruby
base_url = "https://api.assemblyai.com/v2"

headers = {
    "authorization" => "<YOUR_API_KEY>",
    "content-type" => "application/json"
}
```

  </Tab>

  <Tab value="csharp" title="C#">

```csharp
string apiKey = "<YOUR_API_KEY>";
```

  </Tab>

</Tabs>

</Step>
<Step>
<Tabs>
  <Tab title="Python SDK">

Create a `TranscriptionConfig` with `content_safety` set to `True`.

  </Tab>
  <Tab>

Upload your local file to the AssemblyAI API.

  </Tab>
</Tabs>

<Tabs groupId="language">

<Tab value="python-sdk" title="Python SDK" default>

```python
# highlight-next-line
config = aai.TranscriptionConfig(content_safety=True)
```

  </Tab>

  <Tab value="python" title="Python (requests)">

```python wordHighlight="./my-audio.mp3"
with open("./my-audio.mp3", "rb") as f:
  response = requests.post(base_url + "/upload",
                          headers=headers,
                          data=f)

upload_url = response.json()["upload_url"]
```

  </Tab>

  <Tab value="typescript" title="TypeScript">

```typescript wordHighlight="./my-audio.mp3"
const path = './my-audio.mp3'
const audioData = await fs.readFile(path)
const urlResponse = await axios.post(`${baseUrl}/upload`, audioData, {
  headers
})
const uploadUrl = urlResponse.data.upload_url
```

  </Tab>

  <Tab value="php" title="PHP">

```php wordHighlight="/my_audio.mp3"
$path = "/my_audio.mp3";

$ch = curl_init();

curl_setopt($ch, CURLOPT_URL, $base_url . "/upload");
curl_setopt($ch, CURLOPT_POST, 1);
curl_setopt($ch, CURLOPT_POSTFIELDS, file_get_contents($path));
curl_setopt($ch, CURLOPT_HTTPHEADER, $headers);
curl_setopt($ch, CURLOPT_RETURNTRANSFER, 1);

$response = curl_exec($ch);
$response_data = json_decode($response, true);
$upload_url = $response_data["upload_url"];

curl_close($ch);
```

  </Tab>

  <Tab value="ruby" title="Ruby">

```ruby wordHighlight="/my_audio.mp3"
path = "/my_audio.mp3"
response = RestClient.post("#{base_url}/upload", File.read(path), headers)
upload_url = JSON.parse(response.body)["upload_url"]
```

  </Tab>

  <Tab value="csharp" title="C#">

```csharp
public async Task<string> UploadFileAsync(string apiKey, string path)
{
    using var client = new HttpClient();
    client.DefaultRequestHeaders.Authorization = new System.Net.Http.Headers.AuthenticationHeaderValue(apiKey);

    using var fileContent = new ByteArrayContent(File.ReadAllBytes(path));
    fileContent.Headers.ContentType = new System.Net.Http.Headers.MediaTypeHeaderValue("application/octet-stream");

    HttpResponseMessage response;
    try
    {
        response = await client.PostAsync("https://api.assemblyai.com/v2/upload", fileContent);
    }
    catch (Exception e)
    {
        Console.Error.WriteLine($"Error: {e.Message}");
        return null;
    }

    if (response.IsSuccessStatusCode)
    {
        string responseBody = await response.Content.ReadAsStringAsync();
        var json = JObject.Parse(responseBody);
        return json["upload_url"].ToString();
    }
    else
    {
        Console.Error.WriteLine($"Error: {response.StatusCode} - {response.ReasonPhrase}");
        return null;
    }
}
```

  </Tab>

</Tabs>

</Step>
<Step>

<Tabs>
  <Tab title="Python SDK">

Create a `Transcriber` object and pass in the configuration.

  </Tab>
  <Tab>

Use the `upload_url` returned by the AssemblyAI API to create a JSON payload
containing the `audio_url` parameter and the `content_safety` parameter set to
`True`.

  </Tab>
</Tabs>

<Tabs groupId="language">

<Tab value="python-sdk" title="Python SDK" default>

```python
transcriber = aai.Transcriber(config=config)
```

  </Tab>

  <Tab value="python" title="Python (requests)">

```python
data = {
    "audio_url": upload_url,
    "content_safety": True
}
```

  </Tab>

  <Tab value="typescript" title="TypeScript">

```typescript
const data = {
  audio_url: uploadUrl,
  content_safety: true
}
```

  </Tab>

  <Tab value="php" title="PHP">

```php
$data = array(
    "audio_url" => upload_url,
    "content_safety" => true
);
```

  </Tab>

  <Tab value="ruby" title="Ruby">

```ruby
data = {
    "audio_url" => upload_url,
    "content_safety" => true
}
```

  </Tab>

  <Tab value="csharp" title="C#">

```csharp
var data = new Dictionary<string, dynamic>(){
    { "audio_url", upload_url },
    { "content_safety", true }
};
```

  </Tab>

</Tabs>

</Step>
<Step>
<Tabs>
  <Tab title="Python SDK">

Use the `Transcriber` object's transcribe method and pass in the audio file's
path as a parameter. The `transcribe` method saves the results of the transcription to the `Transcriber` object's `transcript` attribute.

  </Tab>
  <Tab>

Make a `POST` request to the AssemblyAI API endpoint with the payload and
headers.

  </Tab>
</Tabs>

<Tabs groupId="language">

<Tab value="python-sdk" title="Python SDK" default>

```python
FILE_URL = "https://assembly.ai/wildfires.mp3"

transcript = transcriber.transcribe(FILE_URL)
```

  </Tab>

  <Tab value="python" title="Python (requests)">

```python
url = base_url + "/transcript"
response = requests.post(url, json=data, headers=headers)
```

  </Tab>

  <Tab value="typescript" title="TypeScript">

```typescript
const url = `${baseUrl}/transcript`
const response = await axios.post(url, data, { headers: headers })
```

  </Tab>

  <Tab value="php" title="PHP">

```php
$url = $base_url . "/transcript";
$curl = curl_init($url);

curl_setopt($curl, CURLOPT_POST, true);
curl_setopt($curl, CURLOPT_POSTFIELDS, json_encode($data));
curl_setopt($curl, CURLOPT_HTTPHEADER, $headers);
curl_setopt($curl, CURLOPT_RETURNTRANSFER, true);

$response = curl_exec($curl);

curl_close($curl);
```

  </Tab>

  <Tab value="ruby" title="Ruby">

```ruby
uri = URI.parse("#{base_url}/transcript")
http = Net::HTTP.new(uri.host, uri.port)
http.use_ssl = true

request = Net::HTTP::Post.new(uri.request_uri, headers)
request.body = data.to_json

response = http.request(request)
```

  </Tab>

  <Tab value="csharp" title="C#">

```csharp
using (var client = new HttpClient())
{
    client.DefaultRequestHeaders.Add("authorization", apiKey);
    var content = new StringContent(JsonConvert.SerializeObject(data), Encoding.UTF8, "application/json");
    HttpResponseMessage response = await client.PostAsync("https://api.assemblyai.com/v2/transcript", content);
    var responseContent = await response.Content.ReadAsStringAsync();
    var responseJson = JsonConvert.DeserializeObject<dynamic>(responseContent);
}
```

  </Tab>

</Tabs>

</Step>
<Step>
<Tabs>
  <Tab title="Python SDK">

You can access the content moderation results through the `Transcriber` object's `content_safety` attribute.

  </Tab>
  <Tab>

After making the request, you'll receive an ID for the transcription. Use it
to poll the API every few seconds to check the status of the transcript job.
Once the status is `completed`, you can retrieve the transcript from the API
response, using the `content_safety_labels` key to view the results.

  </Tab>
</Tabs>

<Tabs groupId="language">

  <Tab value="python-sdk" title="Python SDK" default>

```python
# Get the parts of the transcript which were flagged as sensitive
for result in transcript.content_safety.results:
  print(result.text)  # sensitive text snippet
  print(result.timestamp.start)
  print(result.timestamp.end)

  for label in result.labels:
    print(label.label)  # content safety category
    print(label.confidence) # model's confidence that the text is in this category
    print(label.severity) # severity of the text in relation to the category

# Get the confidence of the most common labels in relation to the entire audio file
for label, confidence in transcript.content_safety.summary.items():
  print(f"{confidence * 100}% confident that the audio contains {label}")

# Get the overall severity of the most common labels in relation to the entire audio file
for label, severity_confidence in transcript.content_safety.severity_score_summary.items():
  print(f"{severity_confidence.low * 100}% confident that the audio contains low-severity {label}")
  print(f"{severity_confidence.medium * 100}% confident that the audio contains mid-severity {label}")
  print(f"{severity_confidence.high * 100}% confident that the audio contains high-severity {label}")
```

  </Tab>

  <Tab value="python" title="Python (requests)">

```python
transcript_id = response.json()['id']
polling_endpoint = f"https://api.assemblyai.com/v2/transcript/{transcript_id}"

while True:
   transcription_result = requests.get(polling_endpoint, headers=headers).json()

   if transcription_result['status'] == 'completed':
       # Uncomment the next line to print everything
       # print(transcription_result['content_safety_labels'])

       content_safety_labels = transcription_result['content_safety_labels']['results']
       for results in content_safety_labels:
           labels = results['labels']
           for label in labels:
             # The severity score measures how severe the flagged content is on a scale of 0-1, with 1 being the most severe.
             if label['label'] == 'hate_speech' and label['severity'] >= 0.5:
                 print("Hate speech detected with severity score:", label['severity'])
                 # Do something with this information, such as flagging the transcription for review
       break

   elif transcription_result['status'] == 'error':
       raise RuntimeError(f"Transcription failed: {transcription_result['error']}")

   else:
       time.sleep(3)
```

  </Tab>

  <Tab value="typescript" title="TypeScript">

```typescript
const transcriptId = response.data.id
const pollingEndpoint = `${baseUrl}/transcript/${transcriptId}`

while (true) {
  const pollingResponse = await axios.get(pollingEndpoint, {
    headers: headers
  })
  const transcriptionResult = pollingResponse.data

  if (transcriptionResult.status === 'completed') {
    // Uncomment the next line to print everything
    // console.log(transcriptionResult.content_safety_labels)

    const contentSafetyLabels =
      transcriptionResult.content_safety_labels.results
    contentSafetyLabels.forEach((label) => {
      const labels = label.labels
      labels.forEach((label) => {
        // The severity score measures how severe the flagged content is on a scale of 0-1, with 1 being the most severe.
        if (label.label === 'hate_speech' && label.severity >= 0.5) {
          console.log(
            `Hate speech detected with severity score: ${label.severity}`
          )
          // Do something with this information, such as flagging the transcription for review
        }
      })
    })
    break
  } else if (transcriptionResult.status === 'error') {
    throw new Error(`Transcription failed: ${transcriptionResult.error}`)
  } else {
    await new Promise((resolve) => setTimeout(resolve, 3000))
  }
}
```

  </Tab>

  <Tab value="php" title="PHP">

```php
$transcript_id = $response['id'];
$polling_endpoint = "https://api.assemblyai.com/v2/transcript/" . $transcript_id;

while (true) {
    $polling_response = curl_init($polling_endpoint);

    curl_setopt($polling_response, CURLOPT_HTTPHEADER, $headers);
    curl_setopt($polling_response, CURLOPT_RETURNTRANSFER, true);

    $transcription_result = json_decode(curl_exec($polling_response), true);

    if ($transcription_result['status'] === "completed") {
        $content_safety_labels = $transcription_result['content_safety_labels'];

        // Uncomment the next line to print everything
        // echo $content_safety_labels

        foreach ($content_safety_labels as $label) {
            // The severity score measures how severe the flagged content is on a scale of 0-1, with 1 being the most severe.
            if ($label['name'] === 'hate_speech' && $label['severity'] >= 0.5) {
                echo "Hate speech detected with severity score: " . $label['severity'] . "\n";
                // Do something with this information, such as flagging the transcription for review
            }
        }
        break;
    } else if ($transcription_result['status'] === "error") {
        throw new Exception("Transcription failed: " . $transcription_result['error']);
    } else {
        sleep(3);
    }
}
```

  </Tab>

  <Tab value="ruby" title="Ruby">

```ruby
transcript_id = response.parsed_response["id"]
polling_endpoint = "https://api.assemblyai.com/v2/transcript/#{transcript_id}"

while true
    polling_response = HTTParty.get(polling_endpoint, headers: headers)
    transcription_result = polling_response.parsed_response

    if transcription_result["status"] == "completed"
        content_safety_labels = transcription_result['content_safety_labels']

        # Uncomment the next line to print everything
        # puts content_safety_labels

        content_safety_labels.each do |label|
            # The severity score measures how severe the flagged content is on a scale of 0-1, with 1 being the most severe.
            if label['name'] == 'hate_speech' && label['severity'] >= 0.5
                puts "Hate speech detected with severity score: #{label['severity']}"
                # Do something with this information, such as flagging the transcription for review
            end
        end
        break
    elsif transcription_result["status"] == "error"
        raise "Transcription failed: #{transcription_result["error"]}"
    else
        sleep(3)
    end
end
```

  </Tab>

  <Tab value="csharp" title="C#">

```csharp
using (var client = new HttpClient())
{
    ...

    var responseJson = JsonConvert.DeserializeObject<dynamic>(responseContent);

    string transcriptId = responseJson.id;
    string pollingEndpoint = $"https://api.assemblyai.com/v2/transcript/{transcriptId}";

    while (true)
    {
        var pollingResponse = await client.GetAsync(pollingEndpoint);
        var pollingResponseContent = await pollingResponse.Content.ReadAsStringAsync();
        var pollingResponseJson = JsonConvert.DeserializeObject<dynamic>(pollingResponseContent);

        if (pollingResponseJson.status == "completed")
        {
            JArray contentSafetyLabels = (JArray)pollingResponseJson["content_safety_labels"];

            // Uncomment the next line to print everything
            // Console.WriteLine(contentSafetyLabels.ToString())

            foreach (JObject label in contentSafetyLabels) {
                // The severity score measures how severe the flagged content is on a scale of 0-1, with 1 being the most severe.
                if (label["name"].ToString() == "hate_speech" && (double)label["severity"] >= 0.5) {
                    Console.WriteLine($"Hate speech detected with severity score: {label["severity"]}");
                    // Do something with this information, such as flagging the transcription for review
                }
            }

            return pollingResponseJson;
        }
        else if (pollingResponseJson.status == "error")
        {
            throw new Exception($"Transcription failed: {pollingResponseJson.error}");
        }
        else
        {
            Thread.Sleep(3000);
        }
    }
}
```

  </Tab>

</Tabs>

</Step>
</Steps>





## Understanding the response

In the JSON response, there'll be an additional key called `content_safety_labels` that contains information about any sensitive content detected. The full text is contained in the `text` key, and each problematic utterance has its own `labels` and `timestamp`. The entire audio is assigned a `summary` and a `severity_score_summary` for each category of unsafe content. Each label is returned with a confidence score and a severity score.

<CodeBlock>
  <JsonViewer
    displayDataTypes={false}
    quotesOnKeys={false}
    displayObjectSize={false}
    src={{
      content_safety_labels: {
        status: 'success',
        results: [
          {
            text: 'You know, the problem with...',
            labels: [
              {
                label: 'sensitive_social_issues',
                confidence: 0.9962000250816345,
                severity: null
              },
              {
                label: 'hate_speech',
                confidence: 0.9268788695335388,
                severity: 0.5201690793037415
              }
            ],
            timestamp: {
              start: 650,
              end: 4970
            }
          }
        ],
        summary: {
          sensitive_social_issues: 0.9999820200945412,
          hate_speech: 0.9999516283032464
        },
        severity_score_summary: {
          hate_speech: {
            low: 0,
            medium: 1,
            high: 0
          }
        }
      }
    }}
  />
</CodeBlock>

For more information, see [Content Moderation model documentation](/docs/audio-intelligence/content-moderation#understanding-the-response) and [API reference](https://assemblyai.com/docs/api-reference/transcripts).





## Conclusion

The AssemblyAI API supports many different [content safety labels](/docs/audio-intelligence/content-moderation#all-labels-supported-by-the-model). Identifying hate speech is only a single, important use case for automated content moderation, and you can learn about others on the [AssemblyAI blog](https://www.assemblyai.com/blog/content-moderation-what-it-is-how-it-works-best-apis-2/).



