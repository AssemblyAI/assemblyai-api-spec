---
title: 'Identifying speakers in audio recordings'
hide-nav-links: true
description: 'Add speaker labels to your transcript'
---






When applying the [Speaker Diarization model](/docs/speech-to-text/speaker-diarization), the transcription not only contains the text but also includes speaker labels, enhancing the overall structure and organization of the output.

In this step-by-step guide, you'll learn how to apply the model. In short, you have to send the `speaker_labels` parameter in your request, and then find the results inside a field called `utterances`.





## Get started

Before we begin, make sure you have an AssemblyAI account and an API key. You can [sign up](https://assemblyai.com/dashboard/signup) for a free account and get your API key from your dashboard.

The complete source code for this guide can be viewed [here](https://github.com/AssemblyAI-Community/docs-snippets/tree/main/speakers).

Here is an audio example for this guide:

```bash
https://assembly.ai/wildfires.mp3
```





## Step-by-step instructions

<Steps>
<Step>
<Tabs>
  <Tab title="Python SDK">

Install the SDK.

  </Tab>
  <Tab fallback>

Create a new file and 
request.

  </Tab>
</Tabs>

<Tabs groupId="language">

<Tab value="python-sdk" title="Python SDK" default>

```python
pip install -U assemblyai
```

  </Tab>

  <Tab value="python" title="Python (requests)">

```python



```

  </Tab>

  <Tab value="typescript" title="TypeScript">

```typescript


```

  </Tab>

  <Tab value="php" title="PHP">

```php
$ch = curl_init();
curl_setopt($ch, CURLOPT_RETURNTRANSFER, true);
```

  </Tab>

  <Tab value="ruby" title="Ruby">

```ruby
require 'net/http'
require 'json'
require 'rest-client'
require 'httparty'
```

  </Tab>

<Tab value="csharp" title="C#">

```csharp
using System.Net.Http;
using System.Threading;
```

</Tab>

</Tabs>

</Step>
<Step>
<Tabs>
  <Tab title="Python SDK">

Import the `assemblyai` package and set the API key.

  </Tab>
  <Tab fallback>

Set up the API endpoint and headers. The headers should include your API
key.

  </Tab>
</Tabs>

<Tabs groupId="language">

<Tab value="python-sdk" title="Python SDK" default>

```python
import assemblyai as aai

aai.settings.api_key = "<YOUR_API_KEY>"
```

  </Tab>

  <Tab value="python" title="Python (requests)">

```python
base_url = "https://api.assemblyai.com/v2"

headers = {
    "authorization": "<YOUR_API_KEY>"
}
```

  </Tab>

  <Tab value="typescript" title="TypeScript">

```typescript
const baseUrl = 'https://api.assemblyai.com/v2'

const headers = {
  authorization: '<YOUR_API_KEY>'
}
```

  </Tab>

  <Tab value="php" title="PHP">

```php
$base_url = "https://api.assemblyai.com/v2";

$headers = array(
  "authorization: <YOUR_API_KEY>",
  "content-type: application/json"
);
```

  </Tab>

  <Tab value="ruby" title="Ruby">

```ruby
base_url = "https://api.assemblyai.com/v2"

headers = {
    "authorization" => "<YOUR_API_KEY>",
    "content-type" => "application/json"
}
```

  </Tab>

  <Tab value="csharp" title="C#">

```csharp
string apiKey = "<YOUR_API_KEY>";
```

  </Tab>

</Tabs>

</Step>
<Step>
<Tabs>
  <Tab title="Python SDK">

Create a `TranscriptionConfig` with `speaker_labels` set to `True`.

  </Tab>
  <Tab fallback>

Upload your local file to the AssemblyAI API.

  </Tab>
</Tabs>

<Tabs groupId="language">

<Tab value="python-sdk" title="Python SDK" default>

```python
# highlight-next-line
config = aai.TranscriptionConfig(speaker_labels=True)
```

  </Tab>

  <Tab value="python" title="Python (requests)">

```python wordHighlight="./my-audio.mp3"
with open("./my-audio.mp3", "rb") as f:
  response = requests.post(base_url + "/upload",
                          headers=headers,
                          data=f)

upload_url = response.json()["upload_url"]
```

  </Tab>

  <Tab value="typescript" title="TypeScript">

```typescript wordHighlight="./my-audio.mp3"
const path = './my-audio.mp3'
const audioData = await fs.readFile(path)
const uploadResponse = await axios.post(`${baseUrl}/upload`, audioData, {
  headers
})
const uploadUrl = uploadResponse.data.upload_url
```

  </Tab>

  <Tab value="php" title="PHP">

```php wordHighlight="/my_audio.mp3"
$path = "/my_audio.mp3";

$ch = curl_init();

curl_setopt($ch, CURLOPT_URL, $base_url . "/upload");
curl_setopt($ch, CURLOPT_POST, 1);
curl_setopt($ch, CURLOPT_POSTFIELDS, file_get_contents($path));
curl_setopt($ch, CURLOPT_HTTPHEADER, $headers);
curl_setopt($ch, CURLOPT_RETURNTRANSFER, 1);

$response = curl_exec($ch);
$response_data = json_decode($response, true);
$upload_url = $response_data["upload_url"];

curl_close($ch);
```

  </Tab>

  <Tab value="ruby" title="Ruby">

```ruby wordHighlight="/my_audio.mp3"
path = "/my_audio.mp3"
response = RestClient.post("#{base_url}/upload", File.read(path), headers)
upload_url = JSON.parse(response.body)["upload_url"]
```

  </Tab>

  <Tab value="csharp" title="C#">

```csharp
public async Task<string> UploadFileAsync(string apiKey, string path)
{
    using var client = new HttpClient();
    client.DefaultRequestHeaders.Authorization = new System.Net.Http.Headers.AuthenticationHeaderValue(apiKey);

    using var fileContent = new ByteArrayContent(File.ReadAllBytes(path));
    fileContent.Headers.ContentType = new System.Net.Http.Headers.MediaTypeHeaderValue("application/octet-stream");

    HttpResponseMessage response;
    try
    {
        response = await client.PostAsync("https://api.assemblyai.com/v2/upload", fileContent);
    }
    catch (Exception e)
    {
        Console.Error.WriteLine($"Error: {e.Message}");
        return null;
    }

    if (response.IsSuccessStatusCode)
    {
        string responseBody = await response.Content.ReadAsStringAsync();
        var json = JObject.Parse(responseBody);
        return json["upload_url"].ToString();
    }
    else
    {
        Console.Error.WriteLine($"Error: {response.StatusCode} - {response.ReasonPhrase}");
        return null;
    }
}
```

  </Tab>

</Tabs>

</Step>
<Step>

<Tabs>
  <Tab title="Python SDK">

Create a `Transcriber` object and pass in the configuration.

  </Tab>

  <Tab fallback>

Use the `upload_url` returned by the AssemblyAI API to create a JSON payload
containing the `audio_url` parameter and the `speaker_labels` paramter set to
`True`.

  </Tab>
</Tabs>

<Tabs groupId="language">

<Tab value="python-sdk" title="Python SDK" default>

```python wordHighlight="./my-audio.mp3"
transcriber = aai.Transcriber(config=config)
```

  </Tab>

  <Tab value="python" title="Python (requests)">

```python
data = {
    "audio_url": upload_url,
    "speaker_labels": True
}
```

  </Tab>

  <Tab value="typescript" title="TypeScript">

```typescript
const data = {
  audio_url: uploadUrl,
  speaker_labels: true
}
```

  </Tab>

  <Tab value="php" title="PHP">

```php
$data = array(
    "audio_url" => upload_url
    "speaker_labels" => True
);
```

  </Tab>

  <Tab value="ruby" title="Ruby">

```ruby
data = {
    "audio_url" => upload_url
    "speaker_labels" => true
}
```

  </Tab>

  <Tab value="csharp" title="C#">

```csharp
var data = new Dictionary<string, dynamic>(){
    { "audio_url", upload_url },
    { "speaker_labels", true }
};
```

  </Tab>

</Tabs>

</Step>
<Step>
<Tabs>
  <Tab title="Python SDK">

Use the `Transcriber` object's transcribe method and pass in the audio file's
path as a parameter. The `transcribe` method saves the results of the transcription to the `Transcriber` object's `transcript` attribute.

  </Tab>
  <Tab fallback>

Make a `POST` request to the AssemblyAI API endpoint with the payload and
headers.

  </Tab>
</Tabs>

<Tabs groupId="language">

<Tab value="python-sdk" title="Python SDK" default>

```python
FILE_URL = "https://assembly.ai/wildfires.mp3"

transcript = transcriber.transcribe(FILE_URL)
```

  </Tab>

  <Tab value="python" title="Python (requests)">

```python
url = base_url + "/transcript"
response = requests.post(url, json=data, headers=headers)
```

  </Tab>

  <Tab value="typescript" title="TypeScript">

```typescript
const url = `${baseUrl}/transcript`
const response = await axios.post(url, data, { headers: headers })
```

  </Tab>

  <Tab value="php" title="PHP">

```php
$url = $base_url . "/transcript";
$curl = curl_init($url);

curl_setopt($curl, CURLOPT_POST, true);
curl_setopt($curl, CURLOPT_POSTFIELDS, json_encode($data));
curl_setopt($curl, CURLOPT_HTTPHEADER, $headers);
curl_setopt($curl, CURLOPT_RETURNTRANSFER, true);

$response = curl_exec($curl);

curl_close($curl);
```

  </Tab>

  <Tab value="ruby" title="Ruby">

```ruby
uri = URI.parse("#{base_url}/transcript")
http = Net::HTTP.new(uri.host, uri.port)
http.use_ssl = true

request = Net::HTTP::Post.new(uri.request_uri, headers)
request.body = data.to_json

response = http.request(request)
```

  </Tab>

  <Tab value="csharp" title="C#">

```csharp
using (var client = new HttpClient())
{
    client.DefaultRequestHeaders.Add("authorization", apiKey);
    var content = new StringContent(JsonConvert.SerializeObject(data), Encoding.UTF8, "application/json");
    HttpResponseMessage response = await client.PostAsync("https://api.assemblyai.com/v2/transcript", content);
    var responseContent = await response.Content.ReadAsStringAsync();
    var responseJson = JsonConvert.DeserializeObject<dynamic>(responseContent);
}
```

  </Tab>

</Tabs>

</Step>
<Step>
<Tabs>
  <Tab title="Python SDK">

You can access the speaker label results through the transcription object's `utterances` attribute.

  </Tab>
  <Tab fallback>

After making the request, you'll receive an ID for the transcription. Use it
to poll the API every few seconds to check the status of the transcript job.
Once the status is `completed`, you can retrieve the transcript from the API
response, using the `utterances` key to access the results.

  </Tab>
</Tabs>
<Tabs groupId="language">

<Tab value="python-sdk" title="Python SDK" default>

```python
# extract all utterances from the response
utterances = transcript.utterances

# For each utterance, print its speaker and what was said
for utterance in utterances:
  speaker = utterance.speaker
  text = utterance.text
  print(f"Speaker {speaker}: {text}")
```

  </Tab>

  <Tab value="python" title="Python (requests)">

```python
transcript_id = response.json()['id']
polling_endpoint = f"https://api.assemblyai.com/v2/transcript/{transcript_id}"

while True:
  transcription_result = requests.get(polling_endpoint, headers=headers).json()

  if transcription_result['status'] == 'completed':
    # when the transcript is complete, extract all utterances from the response
    transcript_text = transcription_result['text']
    utterances = transcription_result['utterances']

    # For each utterance, print its speaker and what was said
    for utterance in utterances:
        speaker = utterance['speaker']
        text = utterance['text']
        print(f"Speaker {speaker}: {text}")

    break

  elif transcription_result['status'] == 'error':
    raise RuntimeError(f"Transcription failed: {transcription_result['error']}")

  else:
    time.sleep(3)
```

  </Tab>

  <Tab value="typescript" title="TypeScript">

```typescript
const transcriptId = response.data.id
const pollingEndpoint = `${baseUrl}/transcript/${transcriptId}`

while (true) {
  const pollingResponse = await axios.get(pollingEndpoint, {
    headers: headers
  })
  const transcriptionResult = pollingResponse.data

  if (transcriptionResult.status === 'completed') {
    const utterances = transcriptionResult.utterances

    // Iterate through each utterance and print the speaker and the text they spoke
    for (const utterance of utterances) {
      const speaker = utterance.speaker
      const text = utterance.text
      console.log(`Speaker ${speaker}: ${text}`)
    }

    break
  } else if (transcriptionResult.status === 'error') {
    throw new Error(`Transcription failed: ${transcriptionResult.error}`)
  } else {
    await new Promise((resolve) => setTimeout(resolve, 3000))
  }
}
```

  </Tab>

  <Tab value="php" title="PHP">

```php
$transcript_id = $response['id'];
$polling_endpoint = "https://api.assemblyai.com/v2/transcript/" . $transcript_id;

while (true) {
    $polling_response = curl_init($polling_endpoint);

    curl_setopt($polling_response, CURLOPT_HTTPHEADER, $headers);
    curl_setopt($polling_response, CURLOPT_RETURNTRANSFER, true);

    $transcription_result = json_decode(curl_exec($polling_response), true);

    if ($transcription_result['status'] === "completed") {
        $utterances = $transcription_result['utterances'];

        // Iterate through each utterance and print the speaker and the text they spoke
        foreach ($utterances as $utterance) {
            $speaker = $utterance['speaker'];
            $text = $utterance['text'];
            echo "Speaker $speaker: $text\n";
        }

        break;
    } else if ($transcription_result['status'] === "error") {
        throw new Exception("Transcription failed: " . $transcription_result['error']);
    } else {
        sleep(3);
    }
}
```

  </Tab>

  <Tab value="ruby" title="Ruby">

```ruby
transcript_id = response.parsed_response["id"]
polling_endpoint = "https://api.assemblyai.com/v2/transcript/#{transcript_id}"

while true
    polling_response = HTTParty.get(polling_endpoint, headers: headers)
    transcription_result = polling_response.parsed_response

    if transcription_result["status"] == "completed"
        utterances = transcription_result["utterances"]

        # Iterate through each utterance and print the speaker and the text they spoke
        utterances.each do |utterance|
            speaker = utterance["speaker"]
            text = utterance["text"]
            puts "Speaker #{speaker}: #{text}"
        end

        break
    elsif transcription_result["status"] == "error"
        raise "Transcription failed: #{transcription_result["error"]}"
    else
        sleep(3)
    end
end
```

  </Tab>

  <Tab value="csharp" title="C#">

```csharp
using (var client = new HttpClient())
{
    ...

    var responseJson = JsonConvert.DeserializeObject<dynamic>(responseContent);

    string transcriptId = responseJson.id;
    string pollingEndpoint = $"https://api.assemblyai.com/v2/transcript/{transcriptId}";

    while (true)
    {
        var pollingResponse = await client.GetAsync(pollingEndpoint);
        var pollingResponseContent = await pollingResponse.Content.ReadAsStringAsync();
        var pollingResponseJson = JsonConvert.DeserializeObject<dynamic>(pollingResponseContent);

        if (pollingResponseJson.status == "completed")
        {
            JArray utterances = (JArray)pollingResponseJson["utterances"];

            // Iterate through each utterance and print the speaker and the text they spoke
            foreach (JObject utterance in utterances) {
                string speaker = utterance["speaker"].ToString();
                string text = utterance["text"].ToString();
                Console.WriteLine($"Speaker {speaker}: {text}");
            }

            return pollingResponseJson;
        }
        else if (pollingResponseJson.status == "error")
        {
            throw new Exception($"Transcription failed: {pollingResponseJson.error}");
        }
        else
        {
            Thread.Sleep(3000);
        }
    }
}
```

  </Tab>

</Tabs>

</Step>
</Steps>




## Understanding the response

The speaker label information is included in the `utterances` key of the response. Each utterance object in the list includes a `speaker` field, which contains a string identifier for the speaker (e.g., "A", "B", etc.). The utterances list also contains a `text` field for each utterance containing the spoken text, and `confidence` scores both for utterances and their individual words.

<CodeBlock>
  <JsonViewer
    displayDataTypes={false}
    quotesOnKeys={false}
    displayObjectSize={false}
    collapsed={3}
    src={{
      utterances: [
        {
          confidence: 0.7246133333333334,
          end: 3738,
          speaker: 'A',
          start: 570,
          text: 'Um hey, Erica.',
          words: [
            {
              text: 'Um',
              start: 570,
              end: 1120,
              confidence: 0.42915,
              speaker: 'A'
            },
            {
              text: 'hey,',
              start: 2690,
              end: 3054,
              confidence: 0.98465,
              speaker: 'A'
            },
            {
              text: 'Erica.',
              start: 3092,
              end: 3738,
              confidence: 0.76004,
              speaker: 'A'
            }
          ]
        },
        {
          confidence: 0.6015349999999999,
          end: 4430,
          speaker: 'B',
          start: 3834,
          text: 'One in.',
          words: [
            {
              text: 'One',
              start: 3834,
              end: 4094,
              confidence: 0.25,
              speaker: 'B'
            },
            {
              text: 'in.',
              start: 4132,
              end: 4430,
              confidence: 0.95307,
              speaker: 'B'
            }
          ]
        }
      ]
    }}
  />
</CodeBlock>

For more information, see the [Speaker Diarization model documentation](/docs/speech-to-text/speaker-diarization#specifying-the-number-of-speakers) or see the [API reference](https://assemblyai.com/docs/api-reference/transcripts).





## Specifying the number of speakers

You can provide the optional parameter `speakers_expected`, that can be used to specify the expected number of speakers in an audio file.

<Button
  variant="text"
  color="yellow"
  theme="dark"
  endIcon="chevron"
  link={{
    href: '/speech-to-text/speaker-diarization#specifying-the-number-of-speakers'
  }}
>
  API/Model Reference
</Button>





## Conclusion

Automatically identifying different speakers from an audio recording, also called **speaker diarization**, is a multi-step process. It can unlock additional value from many genres of recording, including conference call transcripts, broadcast media, podcasts, and more. You can learn more about use cases for speaker diarization and the underlying research from the [AssemblyAI blog](https://www.assemblyai.com/blog/speaker-diarization-speaker-labels-for-mono-channel-files).




