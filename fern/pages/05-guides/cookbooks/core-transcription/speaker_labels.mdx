---
title: 'Identifying Speakers in Audio Recordings'
---




# Identifying Speakers in Audio Recordings

When applying the [Speaker Diarization model](https://www.assemblyai.com/docs/models/speaker-diarization), the transcription not only contains the text but also includes speaker labels, enhancing the overall structure and organization of the output.

In this step-by-step guide, you'll learn how to apply the model. In short, you have to send the `speaker_labels` parameter in your request, and then find the results inside a field called `utterances`.

### Get Started

Before we begin, make sure you have an AssemblyAI account and an API key. You can [sign up](https://assemblyai.com/dashboard/signup) for a free account and get your API key from your dashboard.

Here is an audio example for this guide:


### Step-by-Step Instructions

Install the SDK.


```python
pip install -U assemblyai
```

Import the `assemblyai` package and set the API.


```python
import assemblyai as aai
aai.settings.api_key = "YOUR_API_KEY"
```

Create a `TranscriptionConfig` with `speaker_labels` set to `True`.


```python
config = aai.TranscriptionConfig(speaker_labels=True)
```

Create a `Transcriber` object and pass in the configuration.


```python
transcriber = aai.Transcriber(config=config)
```

Use the `Transcriber` object's transcribe method and pass in the audio file's path as a parameter. The `transcribe` method saves the results of the transcription to the `Transcriber` object's `transcript` attribute.


```python
FILE_URL = "https://github.com/AssemblyAI-Examples/audio-examples/raw/main/20230607_me_canadian_wildfires.mp3"

transcript = transcriber.transcribe(FILE_URL)
```

You can access the speaker label results through the transcription object's `utterances` attribute.


```python
# Extract all utterances from the response
utterances = transcript.utterances

# For each utterance, print its speaker and what was said
for utterance in utterances:
   speaker = utterance.speaker
   text = utterance.text
   print(f"Speaker {speaker}: {text}")
```

### Understanding the Response

The speaker label information is included in the `utterances` key of the response. Each utterance object in the list includes a `speaker` field, which contains a string identifier for the speaker (e.g., "A", "B", etc.). The utterances list also contains a `text` field for each utterance containing the spoken text, and `confidence` scores both for utterances and their individual words.

```
{
    utterances:[
        0:{
            confidence:0.7246133333333334,
            end:3738,
            speaker:"A",
            start:570,
            text:"Um hey, Erica.",
            words:[
                0:{
                    text:"Um",
                    start:570,
                    end:1120,
                    confidence:0.42915,
                    speaker:"A"
                },
                1:{
                    text:"hey,",
                    start:2690,
                    end:3054,
                    confidence:0.98465,
                    speaker:"A"
                },
                2:{
                    text:"Erica.",
                    start:3092,
                    end:3738,
                    confidence:0.76004,
                    speaker:"A"
                }
            ]
        },
        1:{
            confidence:0.6015349999999999,
            end:4430,
            speaker:"B",
            start:3834,
            text:"One in.",
            words:[
                0:{
                    text:"One",
                    start:3834,
                    end:4094,
                    confidence:0.25,
                    speaker:"B"
                },
                1:{
                    text:"in.",
                    start:4132,
                    end:4430,
                    confidence:0.95307,
                    speaker:"B"
                }
            ]
        }
    ]
}
```

For more information, see the [Speaker Diarization model documentation](https://www.assemblyai.com/docs/models/speaker-diarization#specifying-the-number-of-speakers) or refer to the [API reference](https://www.assemblyai.com/docs/api-reference/transcript).

### Specifying the Number of Speakers

You can provide the optional parameter `speaker_expected`, that can be used to specify the expected number of speakers in an audio file.

[API/Model Reference](https://www.assemblyai.com/docs/models/speaker-diarization#specifying-the-number-of-speakers)

### Conclusion

Automatically identifying different speakers from an audio recording, also called **speaker diarization**, is a multi-step process. It can unlock additional value from many genres of recording, including conference call transcripts, broadcast media, podcasts, and more. You can learn more about use cases for speaker diarization and the underlying research from the [AssemblyAI blog](https://www.assemblyai.com/blog/speaker-diarization-speaker-labels-for-mono-channel-files).

