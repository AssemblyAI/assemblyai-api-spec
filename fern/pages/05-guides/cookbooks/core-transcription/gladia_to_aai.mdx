---
title: "Migration guide: Gladia to AssemblyAI"
---

This guide walks through the process of migrating from Gladia to AssemblyAI for transcribing pre-recorded audio.

### Get started

Before we begin, make sure you have an AssemblyAI account and an API key. You can [sign up](https://assemblyai.com/dashboard/signup) for a free account and get your API key from your [dashboard](https://www.assemblyai.com/dashboard/api-keys).
If you'd prefer to use one of our official SDKs, check our [documentation for the full list of available SDKs](https://www.assemblyai.com/docs/guides/do-more-with-sdk).

<Note>
The [Gladia documentation](https://docs.gladia.io/chapters/pre-recorded-stt/getting-started) uses cURL commands to demonstrate API usage. In this guide, we will use Python code snippets to illustrate the same functionality across both APIs.
If you prefer to use cURL, you can find the equivalent commands in the [AssemblyAI API Reference](https://www.assemblyai.com/docs/api-reference/overview).
</Note>

## Side-by-side code comparison

Below is a side-by-side comparison of a basic snippet to transcribe pre-recorded audio with Gladia and AssemblyAI:

<Tabs groupId="language">
<Tab language="gladia" title="Gladia">

```python
import requests
import time

base_url = "https://api.gladia.io"

headers = {
    "x-gladia-key": "<YOUR_API_KEY>"
}

with open("./my-audio.mp3", "rb") as f:
    files = {"audio": ("my-audio.mp3", f, "audio/mp3")}
    response = requests.post(base_url + "/v2/upload",
                            headers=headers,
                            files=files)
    
upload_url = response.json()["audio_url"]

data = {
    "audio_url": upload_url # You can also use a URL to an audio or video file on the web.
}

url = base_url + "/v2/pre-recorded"
response = requests.post(url, json=data, headers=headers)

transcript_id = response.json()['id'] # You can also use response.json()['result_url'] to get the polling_endpoint directly.
polling_endpoint = url + "/" + transcript_id

while True:
    transcript = requests.get(polling_endpoint, headers=headers).json()

    if transcript['status'] == 'done':
        print(f"Full Transcript:", transcript['result']['transcription']['full_transcript'])
        break

    elif transcript['status'] == 'error':
        raise RuntimeError(f"Transcription failed: {transcript['error_code']}")

    else:
        time.sleep(3)
```

</Tab>
<Tab language="aai" title="AssemblyAI">

```python
import requests
import time

base_url = "https://api.assemblyai.com"

headers = {
    "authorization": "<YOUR_API_KEY>"
}

with open("./my-audio.mp3", "rb") as f:
  response = requests.post(base_url + "/v2/upload",
                          headers=headers,
                          data=f)

upload_url = response.json()["upload_url"]

data = {
    "audio_url": upload_url # You can also use a URL to an audio or video file on the web
}

url = base_url + "/v2/transcript"
response = requests.post(url, json=data, headers=headers)

transcript_id = response.json()['id']
polling_endpoint = url + "/" + transcript_id

while True:
    transcript = requests.get(polling_endpoint, headers=headers).json()

    if transcript['status'] == 'completed':
        print(f"Full Transcript:", transcript['text'])
        break

    elif transcript['status'] == 'error':
        raise RuntimeError(f"Transcription failed: {transcript['error']}")

    else:
        time.sleep(3)
```

</Tab>
</Tabs>

## Installation and authentication

<Tabs groupId="language">
<Tab language="gladia" title="Gladia">

```python
import requests
import time

base_url = "https://api.gladia.io"

headers = {
    "x-gladia-key": "<YOUR_API_KEY>"
}
```

</Tab>
<Tab language="aai" title="AssemblyAI">

```python
import requests
import time

base_url = "https://api.assemblyai.com"

headers = {
    "authorization": "<YOUR_API_KEY>"
}
```

</Tab>
</Tabs>

When migrating from Gladia to AssemblyAI, you'll first need to handle authentication:

Get your API key from your [AssemblyAI dashboard](https://www.assemblyai.com/dashboard/api-keys).

Things to know:

- Store your API key securely in an environment variable.
- We support the ability to create [multiple API keys and projects](https://www.assemblyai.com/docs/deployment/account-management) to help you track and manage seperate environments.

<Note>
  Gladia uses the `x-gladia-key` HTTP header for authentication, while AssemblyAI uses the `authorization` header.
</Note>

## Audio file sources

You can provide either a locally stored audio file or a publicly accessible URL. 

<Tabs groupId="language">
<Tab language="gladia" title="Gladia">

```python
# Local Files
with open("./my-audio.mp3", "rb") as f:
    files = {"audio": ("my-audio.mp3", f, "audio/mp3")}
    response = requests.post(base_url + "/v2/upload",
                            headers=headers,
                            files=files)
    
upload_url = response.json()["audio_url"]

data = {
    "audio_url": upload_url
}

#Public URLs
audio_file = "https://assembly.ai/sports_injuries.mp3"

data = {
    "audio_url": audio_file
}
```

</Tab>
<Tab language="aai" title="AssemblyAI">

```python
# Local Files
with open("./my-audio.mp3", "rb") as f:
  response = requests.post(base_url + "/v2/upload",
                          headers=headers,
                          data=f)

upload_url = response.json()["upload_url"]

data = {
    "audio_url": upload_url
}

# Public URLs
audio_file = "https://assembly.ai/sports_injuries.mp3"

data = {
    "audio_url": audio_file
}
```

</Tab>
</Tabs>

## Basic transcription and polling the transcription status
<Tabs groupId="language">
<Tab language="gladia" title="Gladia">
<Steps>
<Step>
Make a `POST` request to the [/v2/pre-recorded](https://docs.gladia.io/api-reference/v2/pre-recorded/init) endpoint.

```python
url = base_url + "/v2/pre-recorded"
response = requests.post(url, json=data, headers=headers)
```

</Step>
<Step>
Every few seconds, make a `GET` request to the [/v2/pre-recorded/:transcript_id](https://docs.gladia.io/api-reference/v2/pre-recorded/get) endpoint until the transcription status is `'done'`.

```python
transcript_id = response.json()['id'] # You can also use response.json()['result_url'] to get the polling_endpoint directly.
polling_endpoint = url + "/" + transcript_id

while True:
    transcript = requests.get(polling_endpoint, headers=headers).json()

    if transcript['status'] == 'done':
        print(f"Full Transcript:", transcript['result']['transcription']['full_transcript'])
        break

    elif transcript['status'] == 'error':
        raise RuntimeError(f"Transcription failed: {transcript['error_code']}")

    else:
        time.sleep(3)
```
</Step>
</Steps>

</Tab>
<Tab language="aai" title="AssemblyAI">
<Steps>
<Step>
Make a `POST` request to the [/v2/transcript](https://www.assemblyai.com/docs/api-reference/transcripts/submit) endpoint.

```python
url = base_url + "/v2/transcript"
response = requests.post(url, json=data, headers=headers)
```
</Step>
<Step>
Every few seconds, make a `GET` request to the [/v2/transcript/:transcript_id](https://www.assemblyai.com/docs/api-reference/transcripts/get) endpoint until the transcription status is `'completed'`.

```python
transcript_id = response.json()['id']
polling_endpoint = url + "/" + transcript_id

while True:
    transcript = requests.get(polling_endpoint, headers=headers).json()

    if transcript['status'] == 'completed':
        print(f"Full Transcript:", transcript['text'])
        break

    elif transcript['status'] == 'error':
        raise RuntimeError(f"Transcription failed: {transcript['error']}")

    else:
        time.sleep(3)
```
</Step>
</Steps>

</Tab>
</Tabs>

<Note title="Transcription status">
Note that our APIs possible values for transcription status are `queued`, `processing`, `completed`, and `error`. Check out the [AssemblyAI API Reference](https://www.assemblyai.com/docs/api-reference/transcripts/get#response.body.status) for the full list of possible transcription status values.
If you'd rather not poll the API, you can use our [SDKs](https://www.assemblyai.com/docs/guides/do-more-with-sdk) which handle polling internally. Alternatively, you can also use [webhooks](https://www.assemblyai.com/docs/deployment/webhooks) to get notified when your transcript is complete.

</Note>

Here are helpful things to know when migrating your audio input handling:
- Both AssemblyAI and Gladia allow you the option of uploading a local file or specifying a publicly accessible URL.
- There's no need to specify the audio format to AssemblyAI - it's auto-detected. AssemblyAI accepts almost every audio/video file type: [here is a full list of all our supported file types](https://support.assemblyai.com/articles/2616970375-what-audio-and-video-file-types-are-supported-by-your-api)
- For self-hosted or pre-signed URLs (i.e. S3), [see our example in this cookbook](https://www.assemblyai.com/docs/guides/transcribe_from_s3).

## Adding features

<Tabs groupId="language">
<Tab language="gladia" title="Gladia">

```python
data = {
    "audio_url": upload_url,
    "diarization": True,                # Speaker diarization
    "chapterization": True,             # Auto chapter detection
    "named_entity_recognition": True    # Named entity detection 
}

# Access speaker labels
for utterance in transcript['result']['transcription']['utterances']:
    print(f"Speaker {utterance['speaker']}: {utterance['text']}")

# Access auto chapters
for chapter in transcript['result']['chapterization']['results']:
    print(f"{chapter['start']} - {chapter['end']}: {chapter['headline']}")

# Access named entities
for entity in transcript['result']['named_entity_recognition']['results']:
    print(entity['text'])
    print(entity['entity_type'])
    print(f"Timestamp: {entity['start']} - {entity['end']}\n")
```

</Tab>
<Tab language="aai" title="AssemblyAI">

```python
data = {
    "audio_url": upload_url,
    "speaker_labels": True,     # Speaker diarization
    "auto_chapters": True,      # Auto chapter detection
    "entity_detection": True    # Named entity detection
}

# Access speaker labels
for utterance in transcript['utterances']:
    print(f"Speaker {utterance['speaker']}: {utterance['text']}")

# Access auto chapters
for chapter in transcript['chapters']:
    print(f"{chapter['start']} - {chapter['end']}: {chapter['headline']}")

# Access named entities   
for entity in transcript['entities']:
    print(entity['text'])
    print(entity['entity_type'])
    print(f"Timestamp: {entity['start']} - {entity['end']}\n")
```

</Tab>
</Tabs>

Key differences:
- Make sure to note any differences in parameters or response structure. If using [Speaker Diarization](https://www.assemblyai.com/docs/speech-to-text/pre-recorded-audio/speaker-diarization), for example:
  - Parameters: AssemblyAI uses `speaker_labels`, while Gladia uses `diarization`.
  - Response: AssemblyAI uses `transcript.utterances`, while Gladia uses `transcript.result.transcription.utterances`.
- Make sure to review each API reference for the full list of parameters and response objects. 
  - [AssemblyAI API Reference](https://www.assemblyai.com/docs/api-reference/transcripts/submit)
  - [Gladia API Reference](https://docs.gladia.io/api-reference/v2/pre-recorded/init)