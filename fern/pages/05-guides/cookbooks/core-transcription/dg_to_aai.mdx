---
title: "Migration guide: Deepgram to AssemblyAI"
---

This guide walks through the process of migrating from Deepgram to AssemblyAI.

### Get Started

Before we begin, make sure you have an AssemblyAI account and an API key. You can [sign up](https://assemblyai.com/dashboard/signup) for a free account and get your API key from your dashboard.

## Side-By-Side Code Comparison

Below is a side-by-side comparison of a basic snippet to transcribe a **local file** by Deepgram and AssemblyAI:

<Tabs groupId="language">
<Tab language="dg" title="Deepgram">
```python
from deepgram import (
      DeepgramClient,
     PrerecordedOptions,
     FileSource,
)

API_KEY = "YOUR_DG_API_KEY"

AUDIO_FILE = "./example.wav"

def main():
try:
deepgram = DeepgramClient(API_KEY)

      with open(AUDIO_FILE, "rb") as file:
         buffer_data = file.read()

       payload: FileSource = {
              "buffer": buffer_data,
        }

       options = PrerecordedOptions(
           model="nova-2",
           smart_format=True,
           diarize=True

)

       response = deepgram.listen.prerecorded.v("1").transcribe_file(payload, options)

       print(response.to_json(indent=4))

except Exception as e:
print(f"Exception: {e}")

if name == "main":
main()

````
</Tab>

<Tab language="aai" title="AssemblyAI">
```python
import assemblyai as aai

aai.settings.api_key = "YOUR-API-KEY"
transcriber = aai.Transcriber()

audio_file = "./example.wav"

config = aai.TranscriptionConfig(speaker_labels=True)
transcript = transcriber.transcribe(audio_file, config)

if transcript.status == aai.TranscriptStatus.error:
    print(f"Transcription failed: {transcript.error}")
    exit(1)

print(transcript.text)
for utterance in transcript.utterances:
    print(f"Speaker {utterance.speaker}: {utterance.text}")
````

</Tab>
</Tabs>

Below is a side-by-side comparison of a basic snippet to transcribe a **publicly-accessible URL** by Deepgram and AssemblyAI:

<Tabs groupId="language">
<Tab language="dg" title="Deepgram">
```python
from deepgram import (
    DeepgramClient,
    PrerecordedOptions
)

API_KEY = "YOUR_DG_API_KEY"

AUDIO_URL = {
"url": "https://dpgr.am/spacewalk.wav"
}

def main():
try:
deepgram = DeepgramClient(API_KEY)

        options = PrerecordedOptions(
            model="nova-2",
            smart_format=True,
            diarize=True
        )

        response = deepgram.listen.prerecorded.v("1").transcribe_url(AUDIO_URL, options)

        print(response.to_json(indent=4))

    except Exception as e:
        print(f"Exception: {e}")

if name == "main":
main()

````
</Tab>

<Tab language="aai" title="AssemblyAI">
```python
import assemblyai as aai

aai.settings.api_key = "YOUR-API-KEY"
transcriber = aai.Transcriber()

audio_file = (
    "https://assembly.ai/sports_injuries.mp3"
)

config = aai.TranscriptionConfig(speaker_labels=True)
transcript = transcriber.transcribe(audio_file, config)

if transcript.status == aai.TranscriptStatus.error:
    print(f"Transcription failed: {transcript.error}")
    exit(1)

print(transcript.text)
for utterance in transcript.utterances:
    print(f"Speaker {utterance.speaker}: {utterance.text}")
````

</Tab>
</Tabs>

Here are helpful things to know about our `transcribe` method:

- The SDK handles polling under the hood
- Transcript is directly accessible via `transcript.text`
- English is the default language and Best is the default speech model if none is specified
- We have a [cookbook for error handling common errors](https://github.com/AssemblyAI/cookbook/blob/master/core-transcription/common_errors_and_solutions.md) when using our API.

## Installation

<Tabs groupId="language">
<Tab language="dg" title="Deepgram">
```python
from deepgram import (
    DeepgramClient,
    PrerecordedOptions,
    FileSource,
)

API_KEY = "YOUR_DG_API_KEY"
deepgram = DeepgramClient(API_KEY)

````
</Tab>

<Tab language="aai" title="AssemblyAI">
```python
import assemblyai as aai

aai.settings.api_key = "YOUR-API-KEY"
transcriber = aai.Transcriber()
````

</Tab>
</Tabs>

When migrating from Deepgram to AssemblyAI, you'll first need to handle authentication and SDK setup:

Get your API key from your [AssemblyAI dashboard](https://www.assemblyai.com/app/api-keys) \
To follow this guide, install AssemblyAI's Python SDK by typing this code into your terminal: `pip install assemblyai` \
Check our [documentation for the full list of available SDKs](https://www.assemblyai.com/docs/#quickstart)

Things to know:

- Store your API key securely in an environment variable
- API key authentication works the same across all AssemblyAI SDKs

## Audio File Sources

<Tabs groupId="language">
<Tab language="dg" title="Deepgram">
```python
# Local Files
AUDIO_FILE = "example.wav"
with open(AUDIO_FILE, "rb") as file:
  buffer_data = file.read()

payload: FileSource = {
"buffer": buffer_data,
}

options = PrerecordedOptions(
smart_format=True,
summarize="v2",
)

file_response = deepgram.listen.rest.v("1").transcribe_file(payload, options)

json = file_response.to_json()

#Public URLs
AUDIO_URL = {
"url": "https://static.deepgram.com/examples/Bueller-Life-moves-pretty-fast.wav"
}

options = PrerecordedOptions(
smart_format=True,
summarize="v2"
)

url_response = deepgram.listen.rest.v("1").transcribe_url(AUDIO_URL, options)

json = url_response.to_json()

````
</Tab>

<Tab language="aai" title="AssemblyAI">
```python
transcriber = aai.Transcriber()

# Local Files
transcript = transcriber.transcribe("./audio.mp3")

# Public URLs
transcript = transcriber.transcribe("https://example.com/audio.mp3")

# S3 files (using pre-signed URLs)
s3_client = boto3.client('s3')
presigned_url = s3_client.generate_presigned_url(
    'get_object',
    Params={'Bucket': 'my-bucket', 'Key': 'audio.mp3'},
    ExpiresIn=3600
)

transcript = transcriber.transcribe(presigned_url)
````

</Tab>
</Tabs>

Here are helpful things to know when migrating your audio input handling:

- There's no need to specify the audio format to AssemblyAI - it's auto-detected. AssemblyAI accepts almost every audio/video file type: [here is a full list of all our supported file types](https://support.assemblyai.com/articles/2616970375-what-audio-and-video-file-types-are-supported-by-your-api)
- Our SDK handles file upload and transcription automatically in one step
- For S3 files, you'll need to generate pre-signed URLs ([see example in cookbook](https://github.com/AssemblyAI/cookbook/blob/master/core-transcription/transcribe_from_s3.ipynb))

## Adding Features

<Tabs groupId="language">
<Tab language="dg" title="Deepgram">
```python
options = PrerecordedOptions(
   model="nova-2",
   smart_format=True,
   diarize=True,
   detect_entities=True
)

response = deepgram.listen.prerecorded.v("1").transcribe_url(AUDIO_URL, options)

````
</Tab>

<Tab language="aai" title="AssemblyAI">
```python
config = aai.TranscriptionConfig(
    speaker_labels=True, # Speaker diarization
    auto_chapters=True, # Auto chapter detection
    entity_detection=True, # Named entity detection
)

transcript = transcriber.transcribe(audio_url, config)

# Access speaker labels
for utterance in transcript.utterances:
    print(f"Speaker {utterance.speaker}: {utterance.text}")
````

</Tab>
</Tabs>

Key differences:

- Use `aai.TranscriptionConfig` to specify any extra features that you wish to use
- The results for Speaker Diarization are stored in `transcript.utterances`. To see the full transcript response object, refer to our [API Reference](https://www.assemblyai.com/docs/api-reference).
- Check our [documentation](https://www.assemblyai.com/docs/audio-intelligence) for our full list of available features and their parameters
