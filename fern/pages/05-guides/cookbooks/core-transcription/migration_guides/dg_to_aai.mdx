---
title: 'Migration guide: Deepgram to AssemblyAI'
---




# Migration guide: Deepgram to AssemblyAI

This guide walks through the process of migrating from Deepgram to AssemblyAI.

### Get Started

Before we begin, make sure you have an AssemblyAI account and an API key. You can [sign up](https://assemblyai.com/dashboard/signup) for a free account and get your API key from your dashboard.


## Installation

| <h3>Deepgram</h3> | <h3>AssemblyAI</h3> |
|----------------|------------|
|<pre><code>from deepgram import (<br>    DeepgramClient,<br>    PrerecordedOptions,<br>    FileSource,<br>)<br><br>API_KEY = "YOUR_DG_API_KEY"<br>deepgram = DeepgramClient(API_KEY)</code></pre>|<pre><code>import assemblyai as aai<br><br>aai.settings.api_key = "YOUR-API-KEY"<br>transcriber = aai.Transcriber()</code></pre>|


When migrating from Deepgram to AssemblyAI, you'll first need to handle authentication and SDK setup:

Get your API key from your [AssemblyAI dashboard](https://www.assemblyai.com/dashboard/login) \
To follow this guide, install AssemblyAI's Python SDK by typing this code into your terminal: `pip install assemblyai` \
Check our [documentation for the full list of available SDKs](https://www.assemblyai.com/docs/#quickstart)

Things to know:
- Store your API key securely in an environment variable
- API key authentication works the same across all AssemblyAI SDKs


## Side-By-Side Code Comparison

Below is a side-by-side comparison of a basic snippet to transcribe a **local file** by Deepgram and AssemblyAI:


| <h3>Deepgram</h3> | <h3>AssemblyAI</h3> |
|----------------|------------|
| <pre><code>from deepgram import (<br>      DeepgramClient,<br>     PrerecordedOptions,<br>     FileSource,<br>)<br><br>API_KEY = &quot;YOUR_DG_API_KEY&quot;<br><br>AUDIO_FILE = &quot;./example.wav&quot;<br><br>def main():<br>   try:<br>        deepgram = DeepgramClient(API_KEY)<br><br>      with open(AUDIO_FILE, &quot;rb&quot;) as file:<br>         buffer_data = file.read()<br><br>       payload: FileSource = {<br>              &quot;buffer&quot;: buffer_data,<br>        }<br><br>       options = PrerecordedOptions(<br>           model=&quot;nova-2&quot;,<br>           smart_format=True,<br>           diarize=True<br>)<br><br>       response = deepgram.listen.prerecorded.v(&quot;1&quot;).transcribe_file(payload, options)<br><br>       print(response.to_json(indent=4))<br><br>   except Exception as e:<br>      print(f&quot;Exception: {e}&quot;)<br><br>if __name__ == &quot;__main__&quot;:<br>   main()</code></pre> | <pre><code>import assemblyai as aai<br><br>aai.settings.api_key = "YOUR-API-KEY"<br>transcriber = aai.Transcriber()<br><br>audio_file = "./example.wav"<br><br>config = aai.TranscriptionConfig(speaker_labels=True)<br>transcript = transcriber.transcribe(audio_file, config)<br><br>if transcript.status == aai.TranscriptStatus.error:<br>    print(f"Transcription failed: {transcript.error}")<br>    exit(1)<br><br>print(transcript.text)<br>for utterance in transcript.utterances:<br>    print(f"Speaker {utterance.speaker}: {utterance.text}")</code></pre> |


Below is a side-by-side comparison of a basic snippet to transcribe a **publicly-accessible URL** by Deepgram and AssemblyAI:


| <h3>Deepgram</h3> | <h3>AssemblyAI</h3> |
|----------------|------------|
| <pre><code>from deepgram import (<br>    DeepgramClient,<br>    PrerecordedOptions<br>)<br><br>API_KEY = "YOUR_DG_API_KEY"<br><br>AUDIO_URL = {<br>    "url": "https://dpgr.am/spacewalk.wav"<br>}<br><br><br>def main():<br>    try:<br>        deepgram = DeepgramClient(API_KEY)<br><br>        options = PrerecordedOptions(<br>            model="nova-2",<br>            smart_format=True,<br>            diarize=True<br>        )<br><br>        response = deepgram.listen.prerecorded.v("1").transcribe_url(AUDIO_URL, options)<br><br>        print(response.to_json(indent=4))<br><br>    except Exception as e:<br>        print(f"Exception: {e}")<br><br>if __name__ == "__main__":<br>    main()</code></pre> | <pre><code>import assemblyai as aai<br><br>aai.settings.api_key = "YOUR-API-KEY"<br>transcriber = aai.Transcriber()<br><br>audio_file = (<br>    "https://assembly.ai/sports_injuries.mp3"<br>)<br><br>config = aai.TranscriptionConfig(speaker_labels=True)<br>transcript = transcriber.transcribe(audio_file, config)<br><br>if transcript.status == aai.TranscriptStatus.error:<br>    print(f"Transcription failed: {transcript.error}")<br>    exit(1)<br><br>print(transcript.text)<br>for utterance in transcript.utterances:<br>    print(f"Speaker {utterance.speaker}: {utterance.text}")</code></pre> |


Here are helpful things to know about our `transcribe` method:
- The SDK handles polling under the hood
- Transcript is directly accessible via `transcript.text`
- English is the default language and Best is the default speech model if none is specified
- We have a [cookbook for error handling common errors](https://github.com/AssemblyAI/cookbook/blob/master/core-transcription/common_errors_and_solutions.md) when using our API.


## Audio File Sources

| <h3>Deepgram</h3> | <h3>AssemblyAI</h3> |
|----------------|------------|
|<pre><code># Local Files<br>AUDIO_FILE = "example.wav"<br>with open(AUDIO_FILE, "rb") as file:<br>  buffer_data = file.read()<br><br>payload: FileSource = {<br>	"buffer": buffer_data,<br>}<br><br>options = PrerecordedOptions(<br>  smart_format=True,<br>  summarize="v2",<br>)<br><br>file_response = deepgram.listen.rest.v("1").transcribe_file(payload, options)<br><br>json = file_response.to_json()<br><br><br>#Public URLs<br>AUDIO_URL = {<br>    "url": "https://static.deepgram.com/examples/Bueller-Life-moves-pretty-fast.wav"<br>}<br><br>options = PrerecordedOptions(<br>    smart_format=True,<br>    summarize="v2"<br>)<br><br>url_response = deepgram.listen.rest.v("1").transcribe_url(AUDIO_URL, options)<br><br>json = url_response.to_json()</code></pre> | <pre><code>transcriber = aai.Transcriber()<br><br># Local Files<br>transcript = transcriber.transcribe("./audio.mp3")<br><br># Public URLs<br>transcript = transcriber.transcribe("https://example.com/audio.mp3")<br><br># S3 files (using pre-signed URLs)<br>s3_client = boto3.client('s3')<br>presigned_url = s3_client.generate_presigned_url(<br>    'get_object',<br>    Params={'Bucket': 'my-bucket', 'Key': 'audio.mp3'},<br>    ExpiresIn=3600<br>)<br><br>transcript = transcriber.transcribe(presigned_url)</code></pre> |


Here are helpful things to know when migrating your audio input handling:
- There's no need to specify the audio format to AssemblyAI - it's auto-detected. AssemblyAI accepts almost every audio/video file type: [here is a full list of all our supported file types](https://support.assemblyai.com/articles/2616970375-what-audio-and-video-file-types-are-supported-by-your-api)
- Our SDK handles file upload and transcription automatically in one step
- For S3 files, you'll need to generate pre-signed URLs ([see example in cookbook](https://github.com/AssemblyAI/cookbook/blob/master/core-transcription/transcribe_from_s3.ipynb))


## Adding Features


| <h3>Deepgram</h3> | <h3>AssemblyAI</h3> |
|----------------|------------|
|<pre><code>options = PrerecordedOptions(<br>   model="nova-2",<br>   smart_format=True,<br>   diarize=True,<br>   detect_entities=True<br>)<br><br>response = deepgram.listen.prerecorded.v("1").transcribe_url(AUDIO_URL, options)</code></pre> | <pre><code>config = aai.TranscriptionConfig(<br>    speaker_labels=True, # Speaker diarization<br>    auto_chapters=True, # Auto chapter detection<br>    entity_detection=True, # Named entity detection<br>)<br><br>transcript = transcriber.transcribe(audio_url, config)<br><br># Access speaker labels<br>for utterance in transcript.utterances:<br>    print(f"Speaker {utterance.speaker}: {utterance.text}")</code></pre> |



Key differences:
- Use `aai.TranscriptionConfig` to specify any extra features that you wish to use
- The results for Speaker Diarization are stored in `transcript.utterances`. To see the full transcript response object, refer to our [API Reference](https://www.assemblyai.com/docs/api-reference).
- Check our [documentation](https://www.assemblyai.com/docs/audio-intelligence) for our full list of available features and their parameters

