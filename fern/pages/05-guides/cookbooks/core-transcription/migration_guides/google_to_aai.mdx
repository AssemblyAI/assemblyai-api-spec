---
title: 'Migration guide: Google Speech-to-Text to AssemblyAI'
---




# Migration guide: Google Speech-to-Text to AssemblyAI

This guide walks through the process of migrating from Google Speech-to-Text (STT) to AssemblyAI.

### Get Started

Before we begin, make sure you have an AssemblyAI account and an API key. You can [sign up](https://assemblyai.com/dashboard/signup) for a free account and get your API key from your dashboard.


## Side-by-side code comparison

Below is a side-by-side comparison of a basic snippet to transcribe a file by Google Speech-to-Text and AssemblyAI.


| <h3>Google Speech-to-Text</h3>                                                                                     | <h3>AssemblyAI</h3>                                                                                        |
|--------------------------------------------------------------------------------------------------------------------|------------------------------------------------------------------------------------------------------------|
| <pre><code>from google.cloud import speech<br><br>client = speech.SpeechClient()<br><br>audio = speech.RecognitionAudio(<br>    uri="gs://cloud-samples-tests/speech/Google_Gnome.wav"<br>)<br><br>config = speech.RecognitionConfig(<br>    encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,<br>    sample_rate_hertz=16000,<br>    language_code="en-US",<br>    model="video",  # Chosen model<br>)<br><br>operation = client.long_running_recognize(config=config, audio=audio)<br><br>print("Waiting for operation to complete...")<br>response = operation.result(timeout=90)<br><br>for i, result in enumerate(response.results):<br>    alternative = result.alternatives[0]<br>    print("-" * 20)<br>    print(f"First alternative of result {i}")<br>    print(f"Transcript: {alternative.transcript}")</code></pre> | <pre><code>import assemblyai as aai<br><br>aai.settings.api_key = "YOUR-API-KEY"<br>transcriber = aai.Transcriber()<br><br># You can use a local filepath:<br># audio_file = "./example.mp3"<br># Or use a publicly-accessible URL:<br>audio_file = (<br>    "https://assembly.ai/sports_injuries.mp3"<br>)<br><br>transcript = transcriber.transcribe(audio_file)<br><br>if transcript.status == aai.TranscriptStatus.error:<br>    print(f"Transcription failed: {transcript.error}")<br>    exit(1)<br><br>print(transcript.text)</code></pre> |


## Installation

| <h3>Google Speech-to-Text</h3> | <h3>AssemblyAI</h3> |
|----------------|------------|
|<pre><code>from google.cloud import speech<br><br>client = speech.SpeechClient()<br></code></pre>|<pre><code>import assemblyai as aai<br><br>aai.settings.api_key = "YOUR-API-KEY"<br>transcriber = aai.Transcriber()</code></pre>|


When migrating from Google Speech-to-Text to AssemblyAI, you'll first need to handle authentication and SDK setup:

Get your API key from your [AssemblyAI dashboard](https://www.assemblyai.com/dashboard/login). \
Check our [documentation for the full list of available SDKs](https://www.assemblyai.com/docs/#quickstart).

Things to know:
- Store your API key securely in an environment variable
- API key authentication works the same across all AssemblyAI SDKs


## Audio File Sources

| <h3>Google Speech-to-Text</h3> | <h3>AssemblyAI</h3> |
|----------------|------------|
|<pre><code><br>audio = speech.RecognitionAudio(uri="gs://cloud-samples-tests/speech/Google_Gnome.wav")<br><br>config = speech.RecognitionConfig(<br> encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,<br> sample_rate_hertz=16000,<br> language_code="en-US",<br> model="video",  # Chosen model<br>)<br><br>operation = client.long_running_recognize(config=config, audio=audio)</code></pre> | <pre><code>transcriber = aai.Transcriber()<br><br># Local files<br>transcript = transcriber.transcribe("./audio.mp3")<br><br># Public URLs<br>transcript = transcriber.transcribe("https://example.com/audio.mp3")<br><br># S3 files (using pre-signed URLs)<br>s3_client = boto3.client('s3')<br>presigned_url = s3_client.generate_presigned_url(<br>    'get_object',<br>    Params={'Bucket': 'my-bucket', 'Key': 'audio.mp3'},<br>    ExpiresIn=3600<br>)<br>transcript = transcriber.transcribe(presigned_url)</code></pre> |


Here are helpful things to know when migrating your audio input handling:
- There's no need to specify the audio encoding format when using AssemblyAI - we have a transcoding pipeline under the hood which works on all [supported file types](https://support.assemblyai.com/articles/2616970375-what-audio-and-video-file-types-are-supported-by-your-api) so that you can get the most accurate transcription.
- You can submit a local file, URL, stream, buffer, blob, etc., directly to our transcriber. Check out some common ways you can host audio files [here](https://github.com/AssemblyAI/cookbook/blob/master/core-transcription/README.md#hosting-audio-files).
- You can transcribe audio files that are up to 10 hours long and you can transcribe multiple files in parallel. The default amount of jobs you can transcribe at once is 200 while on the PAYG plan.


## Basic Transcription

| <h3>Google Speech-to-Text</h3> | <h3>AssemblyAI</h3> |
|----------------|------------|
|<pre><code>print("Waiting for operation to complete...")<br>response = operation.result(timeout=90)<br>for i, result in enumerate(response.results):<br> alternative = result.alternatives[0]<br> print("-" * 20)<br> print(f"First alternative of result {i}")<br> print(f"Transcript: {alternative.transcript}")</code></pre> | <pre><code>transcriber = aai.Transcriber()<br>transcript = transcriber.transcribe(audio_file)<br><br>if transcript.status == aai.TranscriptStatus.error:<br>    print(f"Transcription failed: {transcript.error}")<br>else:<br>    print(transcript.text)</code></pre> |



Here are helpful things to know about our `transcribe` method:
- The SDK handles polling under the hood.
- The full transcript is directly accessible via `transcript.text`.
- English is the default language if none is specified.
- We have a [cookbook for error handling common errors](https://github.com/AssemblyAI/cookbook/blob/master/core-transcription/common_errors_and_solutions.md) when using our API.


## Adding Features


| <h3>Google Speech-to-Text</h3> | <h3>AssemblyAI</h3> |
|----------------|------------|
|<pre><code>config = speech.RecognitionConfig(<br> encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,<br> sample_rate_hertz=8000,<br> language_code="en-US", <br> enable_speaker_diarization=True,  # Speaker diarization<br> diarization_speaker_count=2,  # Specify amount of speakers<br> profanity_filter=True   # Remove profanity from transcript<br>)</code></pre> | <pre><code>config = aai.TranscriptionConfig(<br>    speaker_labels=True,  # Speaker diarization<br>    filter_profanity=True,  # Remove profanity from transcript<br>    speakers_expected:2  # Specify amount of speakers in audio<br>)<br><br>transcript = transcriber.transcribe(audio_file, config)<br><br># Access speaker labels<br>for utterance in transcript.utterances:<br>    print(f"Speaker {utterance.speaker}: {utterance.text}")</code></pre> |



Key differences:
- Use `aai.TranscriptionConfig` to specify any extra features that you wish to use.
- The results for Speaker Diarization are stored in `transcript.utterances`. To see the full transcript response object, refer to our [API Reference](https://www.assemblyai.com/docs/api-reference).
- Check our [documentation](https://www.assemblyai.com/docs/audio-intelligence) for our full list of available features and their parameters.

