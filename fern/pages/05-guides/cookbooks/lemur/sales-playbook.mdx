---
title: "Implement a Sales Playbook Using LLM Gateway"
---

This guide will show you how to use AssemblyAI's LLM Gateway to implement a sales playbook with a call from a sales representative to a client.

This guide aims to show different ways of using structured prompts with a hypothetical sales use case to produce personalized, precise responses. Using LLM Gateway, a user can immediately evaluate large numbers of sales calls and ensure that prospecting steps are followed, including quotes in the response, which can inform future sales by identifying trends and quantitative performance tracking.

In this example, we will demonstrate how to use structured prompts with context, answer formats, and answer options to create effective sales call evaluations with [LLM Gateway](/docs/llm-gateway/overview). You can use the concepts in this guide to create custom specifications to evaluate your sales representatives.

## Quickstart

```python
import requests
import time

base_url = "https://api.assemblyai.com"
headers = {"authorization": "<YOUR_API_KEY>"}

# Step 1: Transcribe the sales call
with open("./sales-call.mp3", "rb") as f:
    response = requests.post(base_url + "/v2/upload", headers=headers, data=f)

upload_url = response.json()["upload_url"]
data = {"audio_url": upload_url}

response = requests.post(base_url + "/v2/transcript", json=data, headers=headers)
transcript_id = response.json()['id']
polling_endpoint = base_url + "/v2/transcript/" + transcript_id

while True:
    transcription_result = requests.get(polling_endpoint, headers=headers).json()
    if transcription_result['status'] == 'completed':
        break
    elif transcription_result['status'] == 'error':
        raise RuntimeError(f"Transcription failed: {transcription_result['error']}")
    else:
        time.sleep(3)

# Step 2: Evaluate with LLM Gateway
context = "There are sales interactions between a salesperson who is selling an internet plan to customers who are warm leads."
answer_format = """
Answer with JSON in the following format:
{
    "Answer": "<answer_options>",
    "Reason": "<justification for the answer in one sentence including quotes>"
}
"""

questions = [
    {
        "question": "Did the salesperson start the conversation with a professional greeting?",
        "answer_options": ["Poor", "Satisfactory", "Excellent"]
    },
    {
        "question": "How well did the salesperson answer questions during the call?",
        "answer_options": ["Poor", "Good", "Excellent"]
    },
    {
        "question": "Did the salesperson discuss next steps clearly?",
        "answer_options": ["Yes", "No"]
    }
]

for q in questions:
    prompt = f"""
{q['question']}

Context: {context}

Answer Options: {', '.join(q['answer_options'])}

{answer_format}
"""

    llm_gateway_data = {
        "model": "claude-sonnet-4-5-20250929",
        "messages": [
            {"role": "user", "content": f"{prompt}\n\nTranscript: {transcription_result['text']}"}
        ],
        "max_tokens": 500
    }

    response = requests.post(
        "https://llm-gateway.assemblyai.com/v1/chat/completions",
        headers=headers,
        json=llm_gateway_data
    )

    result = response.json()["choices"][0]["message"]["content"]
    print(f"Question: {q['question']}")
    print(f"Answer: {result}")
    print()
```

## Get Started

Before we begin, make sure you have an AssemblyAI account and an API key. You can [sign up for an AssemblyAI account](https://www.assemblyai.com/app) and get your API key from your dashboard.

## Step-by-Step Instructions

In this guide, we will ask three questions evaluating the prospecting performance of the sales representative. Each question has slightly different parameters based on the use case but largely has a fixed `context` that we will apply to each question.

Install the required packages and set up the API client:

```python
import requests
import time

base_url = "https://api.assemblyai.com"
headers = {"authorization": "<YOUR_API_KEY>"}
```

Transcribe the sales call audio file:

```python
with open("./sales-call.mp3", "rb") as f:
    response = requests.post(base_url + "/v2/upload", headers=headers, data=f)

upload_url = response.json()["upload_url"]
data = {"audio_url": upload_url}  # You can also use a URL to an audio or video file on the web

response = requests.post(base_url + "/v2/transcript", json=data, headers=headers)
transcript_id = response.json()['id']
polling_endpoint = base_url + "/v2/transcript/" + transcript_id

while True:
    transcription_result = requests.get(polling_endpoint, headers=headers).json()

    if transcription_result['status'] == 'completed':
        print(f"Transcription completed: {transcript_id}")
        break
    elif transcription_result['status'] == 'error':
        raise RuntimeError(f"Transcription failed: {transcription_result['error']}")
    else:
        time.sleep(3)
```

Define your evaluation context and answer format for structured responses:

```python
context = "There are sales interactions between a salesperson who is selling an internet plan to customers who are warm leads."
answer_format = """
Answer with JSON in the following format:
{
    "Answer": "<answer_options>",
    "Reason": "<justification for the answer in one sentence including quotes>"
}
"""
```

Next, define your evaluation questions for your sales playbook processes. Note: You can edit the questions and answer options to provide custom evaluations for each aspect of the sales call.

```python
questions = [
    {
        "question": "Did the salesperson start the conversation with a professional greeting?",
        "answer_options": ["Poor", "Satisfactory", "Excellent"]
    },
    {
        "question": "How well did the salesperson answer questions during the call?",
        "answer_options": ["Poor", "Good", "Excellent"]
    },
    {
        "question": "Did the salesperson discuss next steps clearly?",
        "answer_options": ["Yes", "No"]
    }
]
```

Evaluate each question using LLM Gateway and print the results:

```python
for q in questions:
    prompt = f"""
{q['question']}

Context: {context}

Answer Options: {', '.join(q['answer_options'])}

{answer_format}
"""

    llm_gateway_data = {
        "model": "claude-sonnet-4-5-20250929",
        "messages": [
            {"role": "user", "content": f"{prompt}\n\nTranscript: {transcription_result['text']}"}
        ],
        "max_tokens": 500
    }

    response = requests.post(
        "https://llm-gateway.assemblyai.com/v1/chat/completions",
        headers=headers,
        json=llm_gateway_data
    )

    result = response.json()["choices"][0]["message"]["content"]
    print(f"Question: {q['question']}")
    print(f"Answer: {result}")
    print()
```
