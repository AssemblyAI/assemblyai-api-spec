---
title: "Generate Action Items with LLM Gateway"
---

This tutorial will demonstrate how to use AssemblyAI's [LLM Gateway](/docs/llm-gateway) framework to create action items from a transcript.

## Quickstart

```python
import requests
import time

API_KEY = "YOUR_API_KEY"
audio_url = "https://storage.googleapis.com/aai-web-samples/meeting.mp4"

# Step 1: Upload or provide audio URL and start transcription
transcript_request = requests.post(
    "https://api.assemblyai.com/v2/transcript",
    headers={"authorization": API_KEY, "content-type": "application/json"},
    json={"audio_url": audio_url},
)

transcript_id = transcript_request.json()["id"]

# Step 2: Poll until transcription completes
while True:
    polling_response = requests.get(
        f"https://api.assemblyai.com/v2/transcript/{transcript_id}",
        headers={"authorization": API_KEY},
    )
    status = polling_response.json()["status"]

    if status == "completed":
        transcript_text = polling_response.json()["text"]
        break
    elif status == "error":
        raise RuntimeError(f"Transcription failed: {polling_response.json()['error']}")
    else:
        print(f"Transcription status: {status}")
        time.sleep(3)

# Step 3: Build the prompt
prompt = """
Here are guidelines to follow:
- You are an expert at understanding transcripts of conversations, calls and meetings.
- You are an expert at coming up with ideal action items based on the contents of the transcripts.
- Action items are things that the transcript implies should get done.
- Your action item ideas do not make stuff up that isn't relevant to the transcript.
- You do not needlessly make up action items - you stick to important tasks.
- You are useful, true and concise, and write in perfect English.
- Your action items can be tied back to direct quotes in the transcript.
- You do not cite the quotes the action items relate to.
- The action items are written succinctly.
- Please give useful action items based on the transcript.
"""

answer_format = "Bullet Points"
if answer_format:
    prompt += f"\nYour response should have the following format: {answer_format}"

# Step 4: Send transcript text to LLM Gateway
headers = {"authorization": API_KEY}

response = requests.post(
    "https://llm-gateway.assemblyai.com/v1/chat/completions",
    headers=headers,
    json={
        "model": "claude-sonnet-4-5-20250929",
        "messages": [
            {
                "role": "user",
                "content": f"{prompt}\n\nTranscript:\n{transcript_text}",
            }
        ],
        "max_tokens": 1000,
    },
)

# Step 5: Print the LLM-generated action items
response_json = response.json()
print(response_json["choices"][0]["message"]["content"])
```

## Getting Started

Before we begin, make sure you have an AssemblyAI account and an API key. You can [sign up for an AssemblyAI account](https://www.assemblyai.com/app) and get your API key from your dashboard.

Find more details on the current LLM Gateway pricing in the AssemblyAI [pricing page](https://www.assemblyai.com/pricing).

## Step-by-Step Instructions

In this guide, we will prompt LLM Gateway to generate action items from our transcript.

First, we'll import the necessary libraries and set our AssemblyAI API key.

```python
import requests
import time

API_KEY = "YOUR_API_KEY"
```

Use AssemblyAI to transcribe a file and save the transcript.

```python
# Step 1: Upload or provide audio URL and start transcription
audio_url = "https://storage.googleapis.com/aai-web-samples/meeting.mp4"

transcript_request = requests.post(
    "https://api.assemblyai.com/v2/transcript",
    headers={"authorization": API_KEY, "content-type": "application/json"},
    json={"audio_url": audio_url},
)

transcript_id = transcript_request.json()["id"]

# Step 2: Poll until transcription completes
while True:
    polling_response = requests.get(
        f"https://api.assemblyai.com/v2/transcript/{transcript_id}",
        headers={"authorization": API_KEY},
    )
    status = polling_response.json()["status"]

    if status == "completed":
        transcript_text = polling_response.json()["text"]
        break
    elif status == "error":
        raise RuntimeError(f"Transcription failed: {polling_response.json()['error']}")
    else:
        print(f"Transcription status: {status}")
        time.sleep(3)
```

Provide detailed instructions to prompt LLM Gateway to create action items from the transcript.

```python
prompt = f"""
        Here are guidelines to follow:
        - You are an expert at understanding transcripts of conversations, calls and meetings.
        - You are an expert at coming up with ideal action items based on the contents of the transcripts.
        - Action items are things that the transcript implies should get done.
        - Your action item ideas do not make stuff up that isn't relevant to the transcript.
        - You do not needlessly make up action items - you stick to important tasks.
        - You are useful, true and concise, and write in perfect English.
        - Your action items can be tied back to direct quotes in the transcript.
        - You do not cite the quotes the action items relate to.
        - The action items are written succinctly.
        - Please give useful action items based on the transcript.
        - Your response should be formatted in bullet points.
        """
```

Generate the custom action items using LLM Gateway.

```python
answer_format = "Bullet Points"
if answer_format:
    prompt += f"\nYour response should have the following format: {answer_format}"
```

Prompt LLM Gateway using the transcript results and return the response.

```python
# Step 4: Send transcript text to LLM Gateway
headers = {"authorization": API_KEY}

response = requests.post(
    "https://llm-gateway.assemblyai.com/v1/chat/completions",
    headers=headers,
    json={
        "model": "claude-sonnet-4-5-20250929",
        "messages": [
            {
                "role": "user",
                "content": f"{prompt}\n\nTranscript:\n{transcript_text}",
            }
        ],
        "max_tokens": 1000,
    },
)

# Step 5: Print the LLM-generated action items
response_json = response.json()
print(response_json["choices"][0]["message"]["content"])


```
