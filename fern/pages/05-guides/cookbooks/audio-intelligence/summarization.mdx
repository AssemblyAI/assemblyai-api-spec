---
title: 'Summarizing Virtual Meetings'
---




# Summarizing Virtual Meetings

In this Colab, we'll show you how to use the [Summarization model](https://www.assemblyai.com/docs/models/summarization) to automatically generate summaries of your virtual meetings, so you can quickly review important information and take action based on the insights gathered from the conversations.

### Get Started
Before we begin, make sure you have an AssemblyAI account and an API key. You can [sign up](https://assemblyai.com/dashboard/signup) for a free account and get your API key from your dashboard.

### Step-by-Step Instructions

Install the SDK.


```python
pip install -U assemblyai
```

Import the `assemblyai` package and set the API key.


```python
import assemblyai as aai
aai.settings.api_key = "YOUR_API_KEY"
```

Create a `TranscriptionConfig` with `summarization=True`. By default, the `summary_model` is `informative` and the `summary_type` is `bullets`.

You can find all possible [summary models and types here](https://www.assemblyai.com/docs/models/summarization#types-and-models). Note that if the `summary_model` is specified, `summary_type` is also a required parameter, and vice versa.

Then created a `Transcriber` object and apply the config.


```python
config = aai.TranscriptionConfig(
    summarization=True,
    summary_model=aai.SummarizationModel.informative, # Optional
    summary_type=aai.SummarizationType.bullets # Optional
)

transcriber = aai.Transcriber(config=config)
```

Use the `Transcriber` object's `transcribe` method to pass in the audio file's path as a parameter.


```python
transcript = transcriber.transcribe("./my-audio.mp3")
```

Alternatively, you can pass in the URL of a publicly accessible audio file on the internet.


```python
transcript = transcriber.transcribe("https://example.org/audio.mp3")
```

You can access the summarization results through the `Transcriber` object's `summary` attribute.


```python
print(transcript.summary)
```

### Understanding the Response

Your transcript summary is located in the `summary` key of the API response. In addition to standard transcript metadata, you'll also find other parameters containing the `summary_type`, which indicates the type of summary that was generated, and `summary_model`, which indicates the specific AI summarization model that was used to generate the summary. More information on these parameters and their possible value can be found below.

```
{
    summary_type:"bullets",
    summary_model:"informative",
    summary:"There is a proposal to break up this meeting into four departmen ...",
    speakers_expected:NULL
}
```

Refer to the [API reference](https://www.assemblyai.com/docs/api-reference/transcript#the-transcript-object) for a breakdown of every element in your transcript output.

### Best Practices

Identify the most important information you want to incldue in the summary and choose the Summarization model and type that best suits your use case.

When using the `conversational` model, make sure that the two speakers have distinct voices and that there's minimal background noise. For shorter recordings, the `gist` or `headline` options may provide the most effective summary, whereas for longer recordings, the `bullets_verbose` or `paragraph` options may be more appropriate.

Consider the context in which the summary will be used, and whether additional context or explanation is necessary to understand the summary.

Experiment with different summarization options to find the one that works best for your specific use case.

### Advanced Usage
| Summary Model Options | Summary Type Options |
| --------------------- | -------------------- |
| `informative` (default): Best for files with a single speaker such as presentations or lectures. | `bullets` (default): A bulleted summary with the most important points. |
| `conversational`: Best for any two-person conversation such as customer/agent or interviewer/interviewee calls. | `bullets_verbose`: A longer bullet point list summarizing the entire transcription text. |
| `catchy`: Best for creating video, podcast, or media titles. | `gist`: A few words summarizing the entire transcription text. |
| | `headline`: A single sentence summarizing the entire transcription text. |
| | `paragraph`: A single paragraph summarizing the entire transcription text. |

Learn more [here](https://www.assemblyai.com/docs/models/summarization).

### Conclusion

AssemblyAI maintains a number of different [summarization models](https://www.assemblyai.com/blog/new-ai-models-to-summarize-audio-and-video-for-any-use-case/) for different use cases, so you can choose between a more informative summary or a catchier tagline for your audio. You can refer to the [AssemblyAI blog](https://www.assemblyai.com/blog/automatically-summarize-audio-and-video-files-at-scale-with-ai/) to see more examples of our summarization features in action.

If you're experiencing issues with generating a summary, make sure that you've included the `summarization` parameter in your request and set it to `true`. In addition, note that the [Auto Chapters](https://www.assemblyai.com/docs/models/auto-chapters) model and the Summarization model can't be active in the same request. If you try to enable both Auto Chapters and Summarization in a single request, you'll receive the following error message: `"Only one of the following models can be enabled at a time: auto_chapters, summarization."`



