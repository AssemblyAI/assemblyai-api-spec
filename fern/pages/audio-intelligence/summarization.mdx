---
title: "Summarization"
description: "Generate a single summary of your entire audio file"
---

import { LanguageTable } from "../../assets/components/LanguagesTable";

<AccordionGroup>

<Accordion title="Supported languages">
  <LanguageTable
    languages={[
      { name: "Global English", code: "en" },
      { name: "Australian English", code: "en_au" },
      { name: "British English", code: "en_uk" },
      { name: "US English", code: "en_us" },
    ]}
    columns={2}
  />
  <br />
</Accordion>

<Accordion title="Supported models">
  <LanguageTable
    languages={[
      { name: "Universal-3-Pro", code: "universal-3-pro" },
      { name: "Universal-2", code: "universal-2" },
    ]}
    columns={2}
  />
  <br />
</Accordion>

<Accordion title="Supported regions">
  US & EU <br />
</Accordion>

</AccordionGroup>

Distill important information by summarizing your audio files.

The Summarization model generates a summary of the resulting transcript. You can control the style and format of the summary using [Summary models](#summary-models) and [Summary types](#summary-types).

<Warning title="Summarization and Auto Chapters">
  You can only enable one of the Summarization and [Auto
  Chapters](/docs/audio-intelligence/auto-chapters) models in the same
  transcription.
</Warning>

## Quickstart

<Tabs groupId="language">
  <Tab language="python-sdk" title="Python SDK" default>
  
  Enable Summarization by setting `summarization` to `True` in the transcription config. Use `summary_model` and `summary_type` to change the summary format.

If you specify one of `summary_model` or `summary_type`, then you must specify the other.

The following example returns an informative summary in a bulleted list.

```python {9-11}
import assemblyai as aai

aai.settings.api_key = "<YOUR_API_KEY>"

# audio_file = "./local_file.mp3"
audio_file = "https://assembly.ai/wildfires.mp3"

config = aai.TranscriptionConfig(
  speech_models=["universal-3-pro", "universal-2"],
  language_detection=True,
  summarization=True,
  summary_model=aai.SummarizationModel.informative,
  summary_type=aai.SummarizationType.bullets
)

transcript = aai.Transcriber().transcribe(audio_file, config)

print(f"Transcript ID: ", transcript.id)
print(transcript.summary)
```

  </Tab>
  <Tab language="python" title="Python" default>
  
  Enable Summarization by setting `summarization` to `True` in the JSON payload. Use `summary_model` and `summary_type` to change the summary format.

If you specify one of `summary_model` or `summary_type`, then you must specify the other.

The following example returns an informative summary in a bulleted list.

```python {19-21}
import requests
import time

base_url = "https://api.assemblyai.com"

headers = {
    "authorization": "<YOUR_API_KEY>"
}

with open("./my-audio.mp3", "rb") as f:
  response = requests.post(base_url + "/v2/upload",
                          headers=headers,
                          data=f)

upload_url = response.json()["upload_url"]

data = {
    "audio_url": upload_url, # You can also use a URL to an audio or video file on the web
    "speech_models": ["universal-3-pro", "universal-2"],
    "language_detection": True,
    "summarization": True,
    "summary_model": "informative",
    "summary_type": "bullets"
}

url = base_url + "/v2/transcript"
response = requests.post(url, json=data, headers=headers)

transcript_id = response.json()['id']
polling_endpoint = base_url + "/v2/transcript/" + transcript_id

while True:
  transcription_result = requests.get(polling_endpoint, headers=headers).json()

  if transcription_result['status'] == 'completed':
    print(f"Transcript ID: ", transcript_id)
    print(transcription_result['summary'])
    break

  elif transcription_result['status'] == 'error':
    raise RuntimeError(f"Transcription failed: {transcription_result['error']}")

  else:
    time.sleep(3)

```

  </Tab>
  <Tab language="javascript-sdk" title="JavaScript SDK">
  
  Enable Summarization by setting `summarization` to `true` in the transcription config. Use `summary_model` and `summary_type` to change the summary format.

If you specify one of `summary_model` or `summary_type`, then you must specify the other.

The following example returns an informative summary in a bulleted list.

```javascript {12-14}
import { AssemblyAI } from "assemblyai";

const client = new AssemblyAI({
  apiKey: "<YOUR_API_KEY>",
});

// const audioFile = './local_file.mp3'
const audioFile = "https://assembly.ai/wildfires.mp3";

const params = {
  audio: audioFile,
  speech_models: ["universal-3-pro", "universal-2"],
  language_detection: true,
  summarization: true,
  summary_model: "informative",
  summary_type: "bullets",
};

const run = async () => {
  const transcript = await client.transcripts.transcribe(params);

  console.log("Transcript ID: ", transcript.id);
  console.log(transcript.summary);
};

run();
```

  </Tab>
  <Tab language="javascript" title="JavaScript">
  
  Enable Summarization by setting `summarization` to `true` in the JSON payload. Use `summary_model` and `summary_type` to change the summary format.

If you specify one of `summary_model` or `summary_type`, then you must specify the other.

The following example returns an informative summary in a bulleted list.

```javascript {19-21}
import axios from "axios";
import fs from "fs-extra";

const baseUrl = "https://api.assemblyai.com";

const headers = {
  authorization: "<YOUR_API_KEY>",
};

const path = "./my-audio.mp3";
const audioData = await fs.readFile(path);
const uploadResponse = await axios.post(`${baseUrl}/v2/upload`, audioData, {
  headers,
});
const uploadUrl = uploadResponse.data.upload_url;

const data = {
  audio_url: uploadUrl, // You can also use a URL to an audio or video file on the web
  speech_models: ["universal-3-pro", "universal-2"],
  language_detection: true,
  summarization: true,
  summary_model: "informative",
  summary_type: "bullets",
};

const url = `${baseUrl}/v2/transcript`;
const response = await axios.post(url, data, { headers: headers });

const transcriptId = response.data.id;
const pollingEndpoint = `${baseUrl}/v2/transcript/${transcriptId}`;

while (true) {
  const pollingResponse = await axios.get(pollingEndpoint, {
    headers: headers,
  });
  const transcriptionResult = pollingResponse.data;

  if (transcriptionResult.status === "completed") {
    console.log("Transcript ID: ", transcriptionResult.id);
    console.log(transcriptionResult.summary);
    break;
  } else if (transcriptionResult.status === "error") {
    throw new Error(`Transcription failed: ${transcriptionResult.error}`);
  } else {
    await new Promise((resolve) => setTimeout(resolve, 3000));
  }
}
```

  </Tab>
  <Tab language="csharp" title="C#">
  
  Enable Summarization by setting `summarization` to `true` in the JSON payload. Use `summary_model` and `summary_type` to change the summary format.

If you specify one of `summary_model` and `summary_type`, then you must specify the other.

The following example returns an informative summary in a bulleted list.

<Info>
  Most of these libraries are included by default, but on .NET Framework and
  Mono you need to reference the System.Net.Http library and install the
  [System.Net.Http.Json NuGet
  package](https://www.nuget.org/packages/System.Net.Http.Json).
</Info>

```csharp {52-54}
using System;
using System.IO;
using System.Net.Http;
using System.Net.Http.Headers;
using System.Net.Http.Json;
using System.Text;
using System.Text.Json;
using System.Threading.Tasks;
using System.Text.Json.Serialization;

class Program
{
    static async Task Main(string[] args)
    {
        using (var httpClient = new HttpClient())
        {
            httpClient.DefaultRequestHeaders.Authorization =
                new AuthenticationHeaderValue("<YOUR_API_KEY>");

            var uploadUrl = await UploadFileAsync("./my-audio.mp3", httpClient);

            var transcript = await CreateTranscriptAsync(uploadUrl, httpClient);

            transcript = await WaitForTranscriptToProcess(transcript, httpClient);

            // Print the transcript ID and summary
            Console.WriteLine($"Transcript ID: {transcript.Id}");
            Console.WriteLine(transcript.Summary);
        }
    }

    static async Task<string> UploadFileAsync(string filePath, HttpClient httpClient)
    {
        using (var fileStream = File.OpenRead(filePath))
        using (var fileContent = new StreamContent(fileStream))
        {
            fileContent.Headers.ContentType = new MediaTypeHeaderValue("application/octet-stream");

            using (var response = await httpClient.PostAsync("https://api.assemblyai.com/v2/upload", fileContent))
            {
                response.EnsureSuccessStatusCode();
                var jsonDoc = await response.Content.ReadFromJsonAsync<JsonDocument>();
                return jsonDoc.RootElement.GetProperty("upload_url").GetString();
            }
        }
    }

    static async Task<Transcript> CreateTranscriptAsync(string audioUrl, HttpClient httpClient)
    {
        var data = new {
            audio_url = audioUrl,
            speech_models = new[] { "universal-3-pro", "universal-2" },
            language_detection = true,
            summarization = true,
            summary_model = "informative",
            summary_type = "bullets"
        };

        var content = new StringContent(JsonSerializer.Serialize(data), Encoding.UTF8, "application/json");

        using (var response = await httpClient.PostAsync("https://api.assemblyai.com/v2/transcript", content))
        {
            response.EnsureSuccessStatusCode();
            return await response.Content.ReadFromJsonAsync<Transcript>();
        }
    }

    static async Task<Transcript> WaitForTranscriptToProcess(Transcript transcript, HttpClient httpClient)
    {
        var pollingEndpoint = $"https://api.assemblyai.com/v2/transcript/{transcript.Id}";

        while (true)
        {
            var pollingResponse = await httpClient.GetAsync(pollingEndpoint);
            transcript = await pollingResponse.Content.ReadFromJsonAsync<Transcript>();

            if (transcript.Status == "completed")
            {
                return transcript;
            }
            else if (transcript.Status == "error")
            {
                throw new Exception($"Transcription failed: {transcript.Error}");
            }
            else
            {
                await Task.Delay(TimeSpan.FromSeconds(3));
            }
        }
    }

    public class Transcript
    {
        [JsonPropertyName("id")]
        public string Id { get; set; }

        [JsonPropertyName("status")]
        public string Status { get; set; }

        [JsonPropertyName("text")]
        public string Text { get; set; }

        [JsonPropertyName("summary")]
        public string Summary { get; set; }

        [JsonPropertyName("error")]
        public string Error { get; set; }
    }
}
```

  </Tab>
  <Tab language="ruby" title="Ruby">
  
  Enable Summarization by setting `summarization` to `true` in the JSON payload. Use `summary_model` and `summary_type` to change the summary format.

If you specify one of `summary_model` or `summary_type`, then you must specify the other.

The following example returns an informative summary in a bulleted list.

```ruby {23-25}
require 'net/http'
require 'json'

base_url = 'https://api.assemblyai.com'

headers = {
  'authorization' => '<YOUR_API_KEY>',
  'content-type' => 'application/json'
}

path = "/my_audio.mp3"
uri = URI("#{base_url}/v2/upload")
request = Net::HTTP::Post.new(uri, headers)
request.body = File.read(path)

http = Net::HTTP.new(uri.host, uri.port)
http.use_ssl = true
upload_response = http.request(request)
upload_url = JSON.parse(upload_response.body)["upload_url"]

data = {
    "audio_url" => upload_url, # You can also use a URL to an audio or video file on the web
    "speech_models" => ["universal-3-pro", "universal-2"],
    "language_detection" => true,
    "summarization" => true,
    "summary_model" => "informative",
    "summary_type" => "bullets"
}

uri = URI.parse("#{base_url}/v2/transcript")
http = Net::HTTP.new(uri.host, uri.port)
http.use_ssl = true

request = Net::HTTP::Post.new(uri.request_uri, headers)
request.body = data.to_json

response = http.request(request)
response_body = JSON.parse(response.body)

unless response.is_a?(Net::HTTPSuccess)
  raise "API request failed with status #{response.code}: #{response.body}"
end

transcript_id = response_body['id']
puts "Transcript ID: #{transcript_id}"

polling_endpoint = URI.parse("#{base_url}/v2/transcript/#{transcript_id}")

while true
  polling_http = Net::HTTP.new(polling_endpoint.host, polling_endpoint.port)
  polling_http.use_ssl = true
  polling_request = Net::HTTP::Get.new(polling_endpoint.request_uri, headers)
  polling_response = polling_http.request(polling_request)

  transcription_result = JSON.parse(polling_response.body)

  if transcription_result['status'] == 'completed'
    puts "Transcription text: #{transcription_result['summary']}"
    break
  elsif transcription_result['status'] == 'error'
    raise "Transcription failed: #{transcription_result['error']}"
  else
    sleep(3)
  end
end
```

  </Tab>
  <Tab language="php" title="PHP">
  
  Enable Summarization by setting `summarization` to `true` in the JSON payload. Use `summary_model` and `summary_type` to change the summary format.

If you specify one of `summary_model` or `summary_type`, then you must specify the other.

The following example returns an informative summary in a bulleted list.

```php {30-32}
<?php
$ch = curl_init();
curl_setopt($ch, CURLOPT_RETURNTRANSFER, true);

$base_url = "https://api.assemblyai.com";

$headers = array(
    "authorization: <YOUR_API_KEY>",
    "content-type: application/json"
);

$path = "./local_file.mp3";

$ch = curl_init();

curl_setopt($ch, CURLOPT_URL, $base_url . "/v2/upload");
curl_setopt($ch, CURLOPT_POST, 1);
curl_setopt($ch, CURLOPT_POSTFIELDS, file_get_contents($path));
curl_setopt($ch, CURLOPT_HTTPHEADER, $headers);
curl_setopt($ch, CURLOPT_RETURNTRANSFER, 1);

$response = curl_exec($ch);
$response_data = json_decode($response, true);
$upload_url = $response_data["upload_url"];

curl_close($ch);

$data = array(
    "audio_url" => $upload_url, // You can also use a URL to an audio or video file on the web
    "speech_models" => array("universal-3-pro", "universal-2"),
    "language_detection" => true,
    "summarization" => true,
    "summary_model" => "informative",
    "summary_type" => "bullets"
);

$url = $base_url . "/v2/transcript";
$curl = curl_init($url);

curl_setopt($curl, CURLOPT_POST, true);
curl_setopt($curl, CURLOPT_POSTFIELDS, json_encode($data));
curl_setopt($curl, CURLOPT_HTTPHEADER, $headers);
curl_setopt($curl, CURLOPT_RETURNTRANSFER, true);

$response = curl_exec($curl);

$response = json_decode($response, true);

curl_close($curl);

$transcript_id = $response['id'];
echo "Transcript ID: $transcript_id\n";

$polling_endpoint = $base_url . "/v2/transcript/" . $transcript_id;

while (true) {
    $polling_response = curl_init($polling_endpoint);

    curl_setopt($polling_response, CURLOPT_HTTPHEADER, $headers);
    curl_setopt($polling_response, CURLOPT_RETURNTRANSFER, true);

    $transcription_result = json_decode(curl_exec($polling_response), true);

    if ($transcription_result['status'] === "completed") {
        echo $transcription_result['summary'];
        break;
    } else if ($transcription_result['status'] === "error") {
        throw new Exception("Transcription failed: " . $transcription_result['error']);
    } else {
        sleep(3);
    }
}
```

  </Tab>
</Tabs>

### Example output

```plain
- Smoke from hundreds of wildfires in Canada is triggering air quality alerts throughout the US. Skylines from Maine to Maryland to Minnesota are gray and smoggy. In some places, the air quality warnings include the warning to stay inside.
- Air pollution levels in Baltimore are considered unhealthy. Exposure to high levels can lead to a host of health problems. With climate change, we are seeing more wildfires. Will we be seeing more of these kinds of wide ranging air quality consequences?
```

<Tip title="Custom Summaries Using LeMUR">
  If you want more control of the output format, see how to generate a [Custom
  summary using LLM Gateway](/docs/llm-gateway/apply-llms-to-audio-files).
</Tip>

## API reference

### Request

```bash {6-8}
curl https://api.assemblyai.com/v2/transcript \
--header "Authorization: <YOUR_API_KEY>" \
--header "Content-Type: application/json" \
--data '{
  "audio_url": "YOUR_AUDIO_URL",
  "summarization": true,
  "summary_model": "informative",
  "summary_type": "bullets"
}'
```

| Key             | Type    | Description                                                    |
| --------------- | ------- | -------------------------------------------------------------- |
| `summarization` | boolean | Enable Summarization.                                          |
| `summary_type`  | string  | [Summary type](#summary-types) to use for the transcription.   |
| `summary_model` | string  | [Summary model](#summary-models) to use for the transcription. |

### Response

<Markdown src="summarization-response.mdx" />

| Key       | Type   | Description                  |
| --------- | ------ | ---------------------------- |
| `summary` | string | A summary of the audio file. |

The response also includes the request parameters used to generate the transcript.

### Summary types

The summary type determines both the length and the format of the summary, for example as a bulleted list or a paragraph.

| Value               | Description                                                           | Example                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     |
| ------------------- | --------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| `bullets` (default) | A bulleted summary with the most important points.                    | - The human brain has nearly tripled in mass in two million years. <br /> - One of the main reasons that our brain got so big is because it got a new part, called the frontal lobe.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        |
| `bullets_verbose`   | A longer bullet point list summarizing the entire transcription text. | Dan Gilbert is a psychologist and a happiness expert. His talk is recorded live at Ted conference. He explains why the human brain has nearly tripled in size in 2 million years. He also explains the difference between winning the lottery and becoming a paraplegic.\n- In 1994, Pete Best said he's happier than he would have been with the Beatles. In the free choice paradigm, monet prints are ranked from the one they like the most to the one that they don't. People prefer the third one over the fourth one because it's a little better.\n- People synthesize happiness when they change their affective. Hedonic aesthetic to make up your mind and change your mind is the friend of natural happiness. But it's the enemy of synthetic happiness. The psychological immune system works best when we are stuck. This is the difference between dating and marriage. People don't know this about themselves and it can work to their disadvantage.\n- In a photography course at Harvard, 66% of students choose not to take the course where they have the opportunity to change their mind. Adam Smith said that some things are better than others. Dan Gilbert recorded at Ted, 2004 in Monterey, California, 2004. |
| `gist`              | A few words summarizing the entire transcription text.                | A big brain                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 |
| `headline`          | A single sentence summarizing the entire transcription text.          | The human brain has nearly tripled in mass in two million years.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            |
| `paragraph`         | A single paragraph summarizing the entire transcription text.         | The human brain has nearly tripled in mass in two million years. It went from the one-and-a-quarter-pound brain of our ancestor, habilis, to the almost three-pound meatloaf everybody here has between their ears.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         |

### Summary models

The summary model determines the style and tone of the summary.

| Value                   | When to use                                                                                | Supported summary type                                   | Required parameters                                                              |
| ----------------------- | ------------------------------------------------------------------------------------------ | -------------------------------------------------------- | -------------------------------------------------------------------------------- |
| `informative` (default) | Best for files with a single speaker, such as presentations or lectures.                   | `bullets`, `bullets_verbose`, `headline`, or `paragraph` | `punctuate` and `format_text` set to `true`                                      |
| `conversational`        | Best for any 2-person conversation, such as customer/agent or interview/interviewee calls. | `bullets`, `bullets_verbose`, `headline`, or `paragraph` | `punctuate`, `format_text`, and `speaker_labels` or `multichannel` set to `true` |
| `catchy`                | Best for creating video, podcast, or media titles.                                         | `headline`, or `gist`                                    | `punctuate` and `format_text` set to `true`                                      |

## Frequently asked questions

<Accordion title="How long does it take to generate a summarization output?" theme="dark" iconColor="white" >
  
The inference speed of the Summary model depends on the desired output length. However, a single batch can be processed in less than 1 second.

  </Accordion>

<Accordion title="Can I extract individual words and their corresponding speaker labels with Summarization?" theme="dark" iconColor="white" >
  
No. Summarization only generates a single abstractive summary of the entire audio file, and doesn't provide word-level information or speaker labels. If you need word-level information, consider using [Word-level timestamps](/docs/speech-to-text/pre-recorded-audio/word-level-timestamps) and [Speaker Diarization](/docs/speech-to-text/speaker-diarization) instead.

  </Accordion>
