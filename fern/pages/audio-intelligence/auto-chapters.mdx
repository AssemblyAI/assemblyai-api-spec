---
title: "Auto Chapters"
description: "Automatically summarize your audio into chapters"
---

import { LanguageTable } from "../../assets/components/LanguagesTable";

<AccordionGroup>

<Accordion title="Supported languages">
  <LanguageTable
    languages={[
      { name: "Global English", code: "en" },
      { name: "Australian English", code: "en_au" },
      { name: "British English", code: "en_uk" },
      { name: "US English", code: "en_us" },
    ]}
    columns={2}
  />
  <br />
</Accordion>

<Accordion title="Supported models">
  <LanguageTable
    languages={[
      { name: "Universal-3-Pro", code: "universal-3-pro" },
      { name: "Universal-2", code: "universal-2" },
    ]}
    columns={2}
  />
  <br />
</Accordion>

<Accordion title="Supported regions">
  US & EU <br />
</Accordion>

</AccordionGroup>

The Auto Chapters model summarizes audio data over time into chapters. Chapters makes it easy for users to navigate and find specific information.

Each chapter contains the following:

- Summary
- One-line gist
- Headline
- Start and end timestamps

<Warning title="Auto Chapters and Summarization">
  You can only enable one of the Auto Chapters and
  [Summarization](/docs/audio-intelligence/summarization) models in the same
  transcription.
</Warning>

## Quickstart

<Tabs groupId="language">
  <Tab language="python-sdk" title="Python SDK" default>
  
  Enable Auto Chapters by setting `auto_chapters` to `True` in the transcription config. `punctuate` must be enabled to use Auto Chapters (`punctuate` is enabled by default).

<Code src="../../snippets/audio-intelligence/auto-chapters/python-sdk.py" highlight={[8]} />
  </Tab>
  <Tab language="python" title="Python" default>
  
   Enable Auto Chapters by setting `auto_chapters` to `True` in the JSON payload.

<Code src="../../snippets/audio-intelligence/auto-chapters/python.py" highlight={[19]} />
  </Tab>
  <Tab language="javascript-sdk" title="JavaScript SDK">
  
  Enable Auto Chapters by setting `auto_chapters` to `true` in the transcription config. `punctuate` must be enabled to use Auto Chapters (`punctuate` is enabled by default).

<Code src="../../snippets/audio-intelligence/auto-chapters/javascript-sdk.js" highlight={[12]} />
  </Tab>
  <Tab language="javascript" title="JavaScript">
  
  Enable Auto Chapters by setting `auto_chapters` to `true` in the JSON payload.

<Code src="../../snippets/audio-intelligence/auto-chapters/javascript.js" highlight={[19]} />
  </Tab>
  <Tab language="csharp" title="C#">
  
  Enable Auto Chapters by setting `auto_chapters` to `true` in the JSON payload.

<Info>
  Most of these libraries are included by default, but on .NET Framework and
  Mono you need to reference the System.Net.Http library and install the
  [System.Net.Http.Json NuGet
  package](https://www.nuget.org/packages/System.Net.Http.Json).
</Info>

<Code src="../../snippets/audio-intelligence/auto-chapters/csharp.cs" highlight={[53]} />
  </Tab>
  <Tab language="ruby" title="Ruby">
  
  Enable Auto Chapters by setting `auto_chapters` to `true` in the JSON payload.

<Code src="../../snippets/audio-intelligence/auto-chapters/ruby.rb" highlight={[23]} />
  </Tab>
 <Tab language="php" title="PHP">
  
  Enable Auto Chapters by setting `auto_chapters` to `true` in the JSON payload.

<Code src="../../snippets/audio-intelligence/auto-chapters/php.php" highlight={[30]} />
  </Tab>
</Tabs>

### Example output

```plain
250-28840: Smoke from hundreds of wildfires in Canada is triggering air quality alerts across US
29610-280340: High particulate matter in wildfire smoke can lead to serious health problems
```

<Tip title="Auto Chapters Using LLM Gateway">
  Check out this cookbook [Creating Chapter
  Summaries](/docs/guides/input-text-chapters) for an example of how to use LLM
  Gateway to create chapter summaries.
</Tip>

## API reference

### Request

<Code
  src="../../snippets/audio-intelligence/auto-chapters/bash.sh"
  highlight={[6]}
/>

| Key             | Type    | Description           |
| --------------- | ------- | --------------------- |
| `auto_chapters` | boolean | Enable Auto Chapters. |

### Response

<Markdown src="auto-chapters-response.mdx" />

| Key                    | Type   | Description                                                                |
| ---------------------- | ------ | -------------------------------------------------------------------------- |
| `chapters`             | array  | An array of temporally sequential chapters for the audio file.             |
| `chapters[i].gist`     | string | An short summary in a few words of the content spoken in the i-th chapter. |
| `chapters[i].headline` | string | A single sentence summary of the content spoken during the i-th chapter.   |
| `chapters[i].summary`  | string | A one paragraph summary of the content spoken during the i-th chapter.     |
| `chapters[i].start`    | number | The starting time, in milliseconds, for the i-th chapter.                  |
| `chapters[i].end`      | number | The ending time, in milliseconds, for the i-th chapter.                    |

The response also includes the request parameters used to generate the transcript.

## Frequently asked questions

<Accordion
  title="Can I specify the number of chapters to be generated by the Auto Chapters model?"
  theme="dark"
  iconColor="white"
>

No, the number of chapters generated by the Auto Chapters model isn't configurable by the user. The model automatically segments the audio file into logical chapters as the topic of conversation changes.

</Accordion>

## Troubleshooting

<Accordion
  title="Why am I not getting any chapter predictions for my audio file?"
  theme="dark"
  iconColor="white"
>

One possible reason is that the audio file doesn't contain enough variety in topic or tone for the model to identify separate chapters. Another reason could be due to background noise or low-quality audio interfering with the model's analysis.

</Accordion>
