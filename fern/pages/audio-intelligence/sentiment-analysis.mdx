---
title: "Sentiment Analysis"
description: "Detect the sentiment of speech in your audio"
---

import { LanguageTable } from "../../assets/components/LanguagesTable";

<AccordionGroup>

<Accordion title="Supported languages">
  <LanguageTable
    languages={[
      { name: "Global English", code: "en" },
      { name: "Australian English", code: "en_au" },
      { name: "British English", code: "en_uk" },
      { name: "US English", code: "en_us" },
    ]}
    columns={2}
  />
  <br />
</Accordion>

<Accordion title="Supported models">
  <LanguageTable
    languages={[
      { name: "Universal-3-Pro", code: "universal-3-pro" },
      { name: "Universal-2", code: "universal-2" },
    ]}
    columns={2}
  />
  <br />
</Accordion>

<Accordion title="Supported regions">
  US & EU <br />
</Accordion>

</AccordionGroup>

The Sentiment Analysis model detects the sentiment of each spoken sentence in the transcript text. Use Sentiment Analysis to get a detailed analysis of the positive, negative, or neutral sentiment conveyed in the audio, along with a confidence score for each result.

## Quickstart

<Tabs groupId="language">
  <Tab language="python-sdk" title="Python SDK" default>
  
  Enable Sentiment Analysis by setting `sentiment_analysis` to `True` in the transcription config.

<Code src="../../snippets/audio-intelligence/sentiment-analysis/python-sdk-1.py" highlight={[8]} />
  </Tab>
  <Tab language="python" title="Python" default>
  
  Enable Sentiment Analysis by setting `sentiment_analysis` to `True` in the JSON payload.

<Code src="../../snippets/audio-intelligence/sentiment-analysis/python-1.py" highlight={[19]} />
  </Tab>
  <Tab language="javascript-sdk" title="JavaScript SDK">
  
  Enable Sentiment Analysis by setting `sentiment_analysis` to `true` in the transcription config.

<Code src="../../snippets/audio-intelligence/sentiment-analysis/javascript-sdk-1.js" highlight={[12]} />
  </Tab>
  <Tab language="javascript" title="JavaScript">
  
  Enable Sentiment Analysis by setting `sentiment_analysis` to `true` in the JSON payload.

<Code src="../../snippets/audio-intelligence/sentiment-analysis/javascript-1.js" highlight={[19]} />
  </Tab>
  <Tab language="csharp" title="C#">
  
  Enable Sentiment Analysis by setting `sentiment_analysis` to `true` in the JSON payload.

<Info>
  Most of these libraries are included by default, but on .NET Framework and
  Mono you need to reference the System.Net.Http library and install the
  [System.Net.Http.Json NuGet
  package](https://www.nuget.org/packages/System.Net.Http.Json).
</Info>

<Code src="../../snippets/audio-intelligence/sentiment-analysis/csharp-1.cs" highlight={[53]} />
  </Tab>
  <Tab language="ruby" title="Ruby">
  
  Enable Sentiment Analysis by setting `sentiment_analysis` to `true` in the JSON payload.

<Code src="../../snippets/audio-intelligence/sentiment-analysis/ruby-1.rb" highlight={[22]} />
  </Tab>
  <Tab language="php" title="PHP">
  
  Enable Sentiment Analysis by setting `sentiment_analysis` to `true` in the JSON payload.

<Code src="../../snippets/audio-intelligence/sentiment-analysis/php-1.php" highlight={[30]} />
  </Tab>
</Tabs>

### Example output

```plain
Smoke from hundreds of wildfires in Canada is triggering air quality alerts throughout the US.
NEGATIVE
0.8181032538414001
Timestamp: 250 - 6350
...
```

<Tip title="Sentiment Analysis Using LLM Gateway">
  Check out this cookbook [LLM Gateway for Customer Call Sentiment
  Analysis](/docs/guides/call-sentiment-analysis) for an example of how to use
  LLM Gateway to analyze the sentiment of a customer call.
</Tip>

## Add speaker labels to sentiments

<Tabs groupId="language">
  <Tab language="python-sdk" title="Python SDK" default>
  
  To add speaker labels to each sentiment analysis result, using [Speaker Diarization](/docs/speech-to-text/speaker-diarization), enable `speaker_labels` in the transcription config.

Each sentiment result will then have a `speaker` field that contains the speaker label.

<Code src="../../snippets/audio-intelligence/sentiment-analysis/python-sdk-2.py" highlight={[3]} />
  </Tab>
    <Tab language="python" title="Python" default>
  
  To add speaker labels to each sentiment analysis result, using [Speaker Diarization](/docs/speech-to-text/speaker-diarization), enable `speaker_labels` in the JSON payload.

Each sentiment result will then have a `speaker` field that contains the speaker label.

<Code src="../../snippets/audio-intelligence/sentiment-analysis/python-2.py" highlight={[4]} />
  </Tab>
  <Tab language="javascript-sdk" title="JavaScript SDK">
  
  To add speaker labels to each sentiment analysis result, using [Speaker Diarization](/docs/speech-to-text/speaker-diarization), enable `speaker_labels` in the transcription config.

Each sentiment result will then have a `speaker` field that contains the speaker label.

<Code src="../../snippets/audio-intelligence/sentiment-analysis/javascript-sdk-2.js" highlight={[4]} />
  </Tab>
    <Tab language="javascript" title="JavaScript" default>
  
  To add speaker labels to each sentiment analysis result, using [Speaker Diarization](/docs/speech-to-text/speaker-diarization), enable `speaker_labels` in the JSON payload.

Each sentiment result will then have a `speaker` field that contains the speaker label.

<Code src="../../snippets/audio-intelligence/sentiment-analysis/javascript-2.js" highlight={[4]} />
  </Tab>
    <Tab language="csharp" title="C#" default>
  
  To add speaker labels to each sentiment analysis result, using [Speaker Diarization](/docs/speech-to-text/speaker-diarization), enable `speaker_labels` in the JSON payload.

Each sentiment result will then have a `speaker` field that contains the speaker label.

<Code src="../../snippets/audio-intelligence/sentiment-analysis/csharp-2.cs" highlight={[5,12,33-34]} />
  </Tab>
  <Tab language="ruby" title="Ruby" default>
  
  To add speaker labels to each sentiment analysis result, using [Speaker Diarization](/docs/speech-to-text/speaker-diarization), enable `speaker_labels` in the JSON payload.

Each sentiment result will then have a `speaker` field that contains the speaker label.

<Code src="../../snippets/audio-intelligence/sentiment-analysis/ruby-2.rb" highlight={[4]} />
  </Tab>
    <Tab language="php" title="PHP" default>
  
  To add speaker labels to each sentiment analysis result, using [Speaker Diarization](/docs/speech-to-text/speaker-diarization), enable `speaker_labels` in the JSON payload.

Each sentiment result will then have a `speaker` field that contains the speaker label.

<Code src="../../snippets/audio-intelligence/sentiment-analysis/php-2.php" highlight={[4]} />
  </Tab>
</Tabs>

## API reference

### Request

<Code
  src="../../snippets/audio-intelligence/sentiment-analysis/bash.sh"
  highlight={[6]}
/>

| Key                  | Type    | Description                |
| -------------------- | ------- | -------------------------- |
| `sentiment_analysis` | boolean | Enable Sentiment Analysis. |

### Response

<Markdown src="sentiment-analysis-response.mdx" />

| Key                                        | Type           | Description                                                                                                                |
| ------------------------------------------ | -------------- | -------------------------------------------------------------------------------------------------------------------------- |
| `sentiment_analysis_results`               | array          | A temporal sequence of Sentiment Analysis results for the audio file, one element for each sentence in the file.           |
| `sentiment_analysis_results[i].text`       | string         | The transcript of the i-th sentence.                                                                                       |
| `sentiment_analysis_results[i].start`      | number         | The starting time, in milliseconds, of the i-th sentence.                                                                  |
| `sentiment_analysis_results[i].end`        | number         | The ending time, in milliseconds, of the i-th sentence.                                                                    |
| `sentiment_analysis_results[i].sentiment`  | string         | The detected sentiment for the i-th sentence, one of `POSITIVE`, `NEUTRAL`, `NEGATIVE`.                                    |
| `sentiment_analysis_results[i].confidence` | number         | The confidence score for the detected sentiment of the i-th sentence, from 0 to 1.                                         |
| `sentiment_analysis_results[i].speaker`    | string or null | The speaker of the i-th sentence if [Speaker Diarization](/docs/speech-to-text/speaker-diarization) is enabled, else null. |

## Frequently asked questions

<Accordion title="What if the model predicts the wrong sentiment label for a sentence?" theme="dark" iconColor="white" >
  
The Sentiment Analysis model is based on the interpretation of the transcript and may not always accurately capture the intended sentiment of the speaker. It's recommended to take into account the context of the transcript and to validate the sentiment analysis results with human judgment when possible.

  </Accordion>

<Accordion title="What if the transcript contains sensitive or offensive content?" theme="dark" iconColor="white" >
  
The [Content Moderation model](/docs/audio-intelligence/content-moderation) can be used to identify and filter out sensitive or offensive content from the transcript.

  </Accordion>

<Accordion title="What if the sentiment analysis results aren't consistent with my expectations?" theme="dark" iconColor="white" >
  
It's important to ensure that the audio being analyzed is relevant to your use case. Additionally, it's recommended to take into account the context of the transcript and to evaluate the confidence score for each sentiment label.

  </Accordion>

<Accordion title="What if the sentiment analysis is taking too long to process?" theme="dark" iconColor="white" >
  
The Sentiment Analysis model is designed to be fast and efficient, but processing times may vary depending on the size of the audio file and the complexity of the language used. If you experience longer processing times than expected, don't hesitate to contact our support team.

  </Accordion>
