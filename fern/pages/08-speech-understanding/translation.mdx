---
title: "Translation"
description: "Translate your transcripts from one language to another"
hidden: true
---

import { LanguageTable } from "../../assets/components/LanguagesTable";

<AccordionGroup>

<Accordion title="Supported languages">
  <LanguageTable
    languages={[
      { name: "Global English", code: "en" },
      { name: "Australian English", code: "en_au" },
      { name: "British English", code: "en_uk" },
      { name: "US English", code: "en_us" },
      { name: "Spanish", code: "es" },
      { name: "French", code: "fr" },
      { name: "German", code: "de" },
      { name: "Italian", code: "it" },
      { name: "Portuguese", code: "pt" },
      { name: "Dutch", code: "nl" },
      { name: "Hindi", code: "hi" },
      { name: "Japanese", code: "ja" },
      { name: "Chinese", code: "zh" },
      { name: "Finnish", code: "fi" },
      { name: "Korean", code: "ko" },
      { name: "Polish", code: "pl" },
      { name: "Russian", code: "ru" },
      { name: "Turkish", code: "tr" },
      { name: "Ukrainian", code: "uk" },
      { name: "Vietnamese", code: "vi" },
      { name: "Afrikaans", code: "af" },
      { name: "Albanian", code: "sq" },
      { name: "Amharic", code: "am" },
      { name: "Arabic", code: "ar" },
      { name: "Armenian", code: "hy" },
      { name: "Assamese", code: "as" },
      { name: "Azerbaijani", code: "az" },
      { name: "Bashkir", code: "ba" },
      { name: "Basque", code: "eu" },
      { name: "Belarusian", code: "be" },
      { name: "Bengali", code: "bn" },
      { name: "Bosnian", code: "bs" },
      { name: "Breton", code: "br" },
      { name: "Bulgarian", code: "bg" },
      { name: "Catalan", code: "ca" },
      { name: "Croatian", code: "hr" },
      { name: "Czech", code: "cs" },
      { name: "Danish", code: "da" },
      { name: "Estonian", code: "et" },
      { name: "Faroese", code: "fo" },
      { name: "Galician", code: "gl" },
      { name: "Georgian", code: "ka" },
      { name: "Greek", code: "el" },
      { name: "Gujarati", code: "gu" },
      { name: "Haitian", code: "ht" },
      { name: "Hausa", code: "ha" },
      { name: "Hawaiian", code: "haw" },
      { name: "Hebrew", code: "he" },
      { name: "Hungarian", code: "hu" },
      { name: "Icelandic", code: "is" },
      { name: "Indonesian", code: "id" },
      { name: "Javanese", code: "jw" },
      { name: "Kannada", code: "kn" },
      { name: "Kazakh", code: "kk" },
      { name: "Lao", code: "lo" },
      { name: "Latin", code: "la" },
      { name: "Latvian", code: "lv" },
      { name: "Lingala", code: "ln" },
      { name: "Lithuanian", code: "lt" },
      { name: "Luxembourgish", code: "lb" },
      { name: "Macedonian", code: "mk" },
      { name: "Malagasy", code: "mg" },
      { name: "Malay", code: "ms" },
      { name: "Malayalam", code: "ml" },
      { name: "Maltese", code: "mt" },
      { name: "Maori", code: "mi" },
      { name: "Marathi", code: "mr" },
      { name: "Mongolian", code: "mn" },
      { name: "Nepali", code: "ne" },
      { name: "Norwegian", code: "no" },
      { name: "Norwegian Nynorsk", code: "nn" },
      { name: "Occitan", code: "oc" },
      { name: "Panjabi", code: "pa" },
      { name: "Pashto", code: "ps" },
      { name: "Persian", code: "fa" },
      { name: "Romanian", code: "ro" },
      { name: "Sanskrit", code: "sa" },
      { name: "Serbian", code: "sr" },
      { name: "Shona", code: "sn" },
      { name: "Sindhi", code: "sd" },
      { name: "Sinhala", code: "si" },
      { name: "Slovak", code: "sk" },
      { name: "Slovenian", code: "sl" },
      { name: "Somali", code: "so" },
      { name: "Sundanese", code: "su" },
      { name: "Swahili", code: "sw" },
      { name: "Swedish", code: "sv" },
      { name: "Tagalog", code: "tl" },
      { name: "Tajik", code: "tg" },
      { name: "Tamil", code: "ta" },
      { name: "Tatar", code: "tt" },
      { name: "Telugu", code: "te" },
      { name: "Turkmen", code: "tk" },
      { name: "Urdu", code: "ur" },
      { name: "Uzbek", code: "uz" },
      { name: "Welsh", code: "cy" },
      { name: "Yiddish", code: "yi" },
      { name: "Yoruba", code: "yo" }
    ]}
    columns={2}
  />
  <br />
</Accordion>

<Accordion title="Supported models">
  <LanguageTable
    languages={[
      { name: "Universal-3-Pro", code: "universal-pro" },
      { name: "Universal-3", code: "universal" },
    ]}
    columns={2}
  />
  <br />
</Accordion>

<Accordion title="Supported regions">
  US only <br />
</Accordion>

</AccordionGroup>

## Overview

The Translation feature automatically converts your transcribed audio content from one language to another, enabling you to reach global audiences without manual translation work. You can translate transcripts into over 100 languages with a single API request.

**Key capabilities:**
- Translate to multiple target languages simultaneously
- Choose between formal and informal translation styles
- Translate during transcription or add translations to existing transcripts
- Get full-text translations that preserve the original meaning and context

**Common use cases:**
- Creating multilingual subtitles for video content
- Translating customer support calls for international teams
- Localizing podcast episodes for different markets
- Making educational content accessible in multiple languages
- Generating multilingual meeting summaries

## Quickstart

There are two ways to use Translation:

1. **Transcribe and translate in one request** - Best when you're starting a new transcription and want to automatically translate the transcript text as part of that process
2. **Transcribe and translate in separate requests** - Best when you already have text that you would like to translate or for more complicated workflows where you want to separate the transcription and translation tasks

### Method 1: Transcribe and translate in one request

This method is ideal when you're starting fresh and want both transcription and translation in a single workflow.

<Tabs groupId="language">
<Tab language="python" title="Python" default>

```python
import requests
import time

base_url = "https://api.assemblyai.com"

headers = {
  "authorization": "YOUR_API_KEY"
}

# Need to transcribe a local file? Learn more here: https://www.assemblyai.com/docs/getting-started/transcribe-an-audio-file
audio_url = "https://assembly.ai/wildfires.mp3"

# Configure transcription with translation
data = {
  "audio_url": audio_url,
  "speech_understanding": {
    "request": {
      "translation": {
        "target_languages": ["es", "de"],  # Translate to Spanish and German
        "formal": True  # Use formal language style
      }
    }
  }
}

# Submit transcription request
response = requests.post(base_url + "/v2/transcript", headers=headers, json=data)
transcript_id = response.json()["id"]
polling_endpoint = base_url + f"/v2/transcript/{transcript_id}"

# Poll transcription results
while True:
  transcript = requests.get(polling_endpoint, headers=headers).json()

  if transcript["status"] == "completed":
    break

  elif transcript["status"] == "error":
    raise RuntimeError(f"Transcription failed: {transcript['error']}")

  else:
    time.sleep(3)

# Access and display results
print("\n--- Original Transcript ---")
print(transcript['text'][:200] + "...")

print("\n--- Translations ---")
for language_code, translated_text in transcript['translated_texts'].items():
  print(f"\n{language_code.upper()}:")
  print(translated_text[:200] + "...")
```

</Tab>
<Tab language="python" title="Python SDK">

```python
import assemblyai as aai

aai.settings.api_key = "YOUR_API_KEY"

transcriber = aai.Transcriber()

# Configure transcription with translation
config = aai.TranscriptionConfig(
  speech_understanding=aai.SpeechUnderstandingConfig(
    translation=aai.TranslationConfig(
      target_languages=['es', 'de'],  # Translate to Spanish and German
      formal=True  # Use formal language style
    )
  )
)

# Submit transcription request
transcript = transcriber.transcribe(
  "https://assembly.ai/wildfires.mp3",
  config=config
)

# Access and display results
print("\n--- Original Transcript ---")
print(transcript.text[:200] + "...")

print("\n--- Translations ---")
for language_code, translated_text in transcript.translated_texts.items():
  print(f"\n{language_code.upper()}:")
  print(translated_text[:200] + "...")
```

</Tab>
<Tab language="javascript" title="JavaScript" default>

```javascript
const fetch = require('node-fetch');

const baseUrl = 'https://api.assemblyai.com';
const headers = {
  authorization: 'YOUR_API_KEY'
};

// Need to transcribe a local file? Learn more here: https://www.assemblyai.com/docs/getting-started/transcribe-an-audio-file
const audioUrl = 'https://assembly.ai/wildfires.mp3';

// Configure transcription with translation
const data = {
  audio_url: audioUrl,
  speech_understanding: {
    request: {
      translation: {
        target_languages: ['es', 'de'],  // Translate to Spanish and German
        formal: true  // Use formal language style
      }
    }
  }
};

// Submit transcription request
async function transcribeAndTranslate() {
  const response = await fetch(`${baseUrl}/v2/transcript`, {
    method: 'POST',
    headers: {
      ...headers,
      'Content-Type': 'application/json'
    },
    body: JSON.stringify(data)
  });

  const transcript = await response.json();
  const transcriptId = transcript.id;
  const pollingEndpoint = `${baseUrl}/v2/transcript/${transcriptId}`;

  // Poll transcription results
  while (true) {
    const pollingResponse = await fetch(pollingEndpoint, { headers });
    const transcriptResult = await pollingResponse.json();

    if (transcriptResult.status === 'completed') {
      // Access and display results
      console.log('\n--- Original Transcript ---');
      console.log(transcriptResult.text.substring(0, 200) + '...');

      console.log('\n--- Translations ---');
      for (const [languageCode, translatedText] of Object.entries(transcriptResult.translated_texts)) {
        console.log(`\n${languageCode.toUpperCase()}:`);
        console.log(translatedText.substring(0, 200) + '...');
      }
      break;
    } else if (transcriptResult.status === 'error') {
      throw new Error(`Transcription failed: ${transcriptResult.error}`);
    } else {
      await new Promise(resolve => setTimeout(resolve, 3000));
    }
  }
}

transcribeAndTranslate();
```

</Tab>
<Tab language="typescript" title="JavaScript SDK">

```typescript
import { AssemblyAI } from 'assemblyai';

const client = new AssemblyAI({
  apiKey: 'YOUR_API_KEY'
});

// Configure transcription with translation
const config = {
  audio_url: 'https://assembly.ai/wildfires.mp3',
  speech_understanding: {
    request: {
      translation: {
        target_languages: ['es', 'de'],  // Translate to Spanish and German
        formal: true  // Use formal language style
      }
    }
  }
};

// Submit transcription request
const transcript = await client.transcripts.transcribe(config);

// Access and display results
console.log('\n--- Original Transcript ---');
console.log(transcript.text?.substring(0, 200) + '...');

console.log('\n--- Translations ---');
if (transcript.translated_texts) {
  for (const [languageCode, translatedText] of Object.entries(transcript.translated_texts)) {
    console.log(`\n${languageCode.toUpperCase()}:`);
    console.log(translatedText.substring(0, 200) + '...');
  }
}
```

</Tab>
</Tabs>

### Method 2: Transcribe and translate in separate requests

This method is useful when you already have text that you would like to translate or for more complicated workflows where you want to separate the transcription and translation tasks.

<Tabs groupId="language">
<Tab language="python" title="Python" default>

```python
import requests
import time

base_url = "https://api.assemblyai.com"

headers = {
  "authorization": ""
}

# Need to transcribe a local file? Learn more here: https://www.assemblyai.com/docs/getting-started/transcribe-an-audio-file
audio_url = "https://assembly.ai/wildfires.mp3"

# Submit transcription request (without translation)
data = {
  "audio_url": audio_url
}

# Transcribe file
response = requests.post(base_url + "/v2/transcript", headers=headers, json=data)
transcript_id = response.json()["id"]
polling_endpoint = base_url + f"/v2/transcript/{transcript_id}"

print(f"Transcription started. ID: {transcript_id}")

# Poll for transcription completion
while True:
  transcript = requests.get(polling_endpoint, headers=headers).json()

  if transcript["status"] == "completed":
    print("Transcription completed!")
    break

  elif transcript["status"] == "error":
    raise RuntimeError(f"Transcription failed: {transcript['error']}")

  else:
    print(f"Status: {transcript['status']}. Waiting...")
    time.sleep(3)

# Add translation configuration to the completed transcript
understanding_body = {
  "transcript_id": transcript_id,
  "speech_understanding": {
    "request": {
      "translation": {
      "target_languages": ["es", "de"],  # Translate to Spanish and German
      "formal": True  # Use formal language style
      }
    }
  }
}

print("Requesting translations...")

# Send to Speech Understanding API for translation
result = requests.post(
  "https://llm-gateway.assemblyai.com/v1/understanding",
  headers=headers,
  json=understanding_body
).json()

print("Translation completed!")

# Access and display results
print("\n--- Original Transcript ---")
print(result['text'][:200] + "...")

print("\n--- Translations ---")
for language_code, translated_text in result['translated_texts'].items():
  print(f"\n{language_code.upper()}:")
  print(translated_text[:200] + "...")
```

</Tab>

<Tab language="python-sdk" title="Python SDK">

```python
import assemblyai as aai

# Set your API key
aai.settings.api_key = "<YOUR_API_KEY>"

# Need to transcribe a local file? Learn more here: https://www.assemblyai.com/docs/getting-started/transcribe-an-audio-file
audio_url = "https://assembly.ai/wildfires.mp3"

# Configure and create transcriber
config = aai.TranscriptionConfig()

transcriber = aai.Transcriber(config=config)

print("Starting transcription...")

# Transcribe the audio
transcript = transcriber.transcribe(audio_url)

if transcript.status == aai.TranscriptStatus.error:
  raise RuntimeError(f"Transcription failed: {transcript.error}")

print("Transcription completed!")

# Request translation using Speech Understanding
print("Requesting translations...")

result = transcript.speech_understanding(
  translation={
    "target_languages": ["es", "de"],  # Translate to Spanish and German
    "formal": True  # Use formal language style
  }
)

print("Translation completed!")

# Access and display results
print("\n--- Original Transcript ---")
print(result.text[:200] + "...")

print("\n--- Translations ---")
for language_code, translated_text in result.translated_texts.items():
  print(f"\n{language_code.upper()}:")
  print(translated_text[:200] + "...")
```

</Tab>

<Tab language="javascript-http" title="JavaScript">

```javascript
const baseUrl = "https://api.assemblyai.com";

const headers = {
  "authorization": "<YOUR_API_KEY>",
  "content-type": "application/json"
};

// Need to transcribe a local file? Learn more here: https://www.assemblyai.com/docs/getting-started/transcribe-an-audio-file
const audioUrl = "https://assembly.ai/wildfires.mp3";

async function translateTranscript() {
  // Submit transcription request (without translation)
  const data = {
    audio_url: audioUrl
  };

  let response = await fetch(`${baseUrl}/v2/transcript`, {
    method: "POST",
    headers: headers,
    body: JSON.stringify(data)
  });

  const { id: transcriptId } = await response.json();
  const pollingEndpoint = `${baseUrl}/v2/transcript/${transcriptId}`;

  console.log(`Transcription started. ID: ${transcriptId}`);

  // Poll for transcription completion
  let transcript;
  while (true) {
    response = await fetch(pollingEndpoint, { headers });
    transcript = await response.json();

    if (transcript.status === "completed") {
      console.log("Transcription completed!");
      break;
    } else if (transcript.status === "error") {
      throw new Error(`Transcription failed: ${transcript.error}`);
    } else {
      console.log(`Status: ${transcript.status}. Waiting...`);
      await new Promise(resolve => setTimeout(resolve, 3000));
    }
  }

  // Add translation configuration to the completed transcript
  transcript.speech_understanding = {
    request: {
      translation: {
        target_languages: ["es", "de"],  // Translate to Spanish and German
        formal: true  // Use formal language style
      }
    }
  };

  // Enable translation
  const understandingBody = {
    transcript_id: transcriptId,
    speech_understanding: {
      request: {
        translation: {
        target_languages: ["es", "de"],  // Translate to Spanish and German
        formal: true  // Use formal language style
        }
      }
    }
  };

  console.log("Requesting translations...");

  // Send to Speech Understanding API for translation
  response = await fetch("https://llm-gateway.assemblyai.com/v1/understanding", {
    method: "POST",
    headers: headers,
    body: JSON.stringify(understandingBody)
  });

  const result = await response.json();
  console.log("Translation completed!");

  // Access and display results
  console.log("\n--- Original Transcript ---");
  console.log(result.text.substring(0, 200) + "...");

  console.log("\n--- Translations ---");
  for (const [languageCode, translatedText] of Object.entries(result.translated_texts)) {
    console.log(`\n${languageCode.toUpperCase()}:`);
    console.log(translatedText.substring(0, 200) + "...");
  }
}

translateTranscript().catch(console.error);
```

</Tab>

<Tab language="javascript-sdk" title="JavaScript SDK">

```javascript
import { AssemblyAI } from 'assemblyai';

// Set your API key
const client = new AssemblyAI({
  apiKey: "<YOUR_API_KEY>"
});

// Or use a publicly-accessible URL
const audioUrl = "https://assembly.ai/wildfires.mp3";

async function translateTranscript() {
  // Configure and transcribe the audio
  console.log("Starting transcription...");

  const transcript = await client.transcripts.transcribe({
    audio: audioUrl,
    speaker_labels: true  // Optional: enable speaker diarization
  });

  if (transcript.status === "error") {
    throw new Error(`Transcription failed: ${transcript.error}`);
  }

  console.log("Transcription completed!");

  // Request translation using Speech Understanding
  console.log("Requesting translations...");

  const result = await transcript.speechUnderstanding({
    translation: {
      target_languages: ["es", "de"],  // Translate to Spanish and German
      formal: true  // Use formal language style
    }
  });

  console.log("Translation completed!");

  // Access and display results
  console.log("\n--- Original Transcript ---");
  console.log(result.text.substring(0, 200) + "...");

  console.log("\n--- Translations ---");
  for (const [languageCode, translatedText] of Object.entries(result.translated_texts)) {
    console.log(`\n${languageCode.toUpperCase()}:`);
    console.log(translatedText.substring(0, 200) + "...");
  }
}

translateTranscript().catch(console.error);
```

</Tab>
</Tabs>

**Expected output:**
```
--- Original Transcript ---
Smoke from hundreds of wildfires in Canada is triggering air quality alerts throughout the US...

--- Translations ---

ES:
El humo de cientos de incendios forestales en Canadá está provocando alertas de calidad del aire...

DE:
Rauch von Hunderten von Waldbränden in Kanada löst in den gesamten USA Luftqualitätswarnungen aus...
```

## Output format

The Translation API returns translations in the `translated_texts` key of the response. This key contains an object where each property is a language code corresponding to one of your target languages, and the value is the full translated text.

**Example response structure:**

```json
{
  "id": "735d90b6-2e8b-4748-b75d-d02b78eb7811",
  "status": "completed",
  "text": "Smoke from hundreds of wildfires in Canada is triggering air quality alerts...",
  "translated_texts": {
    "es": "El humo de cientos de incendios forestales en Canadá está provocando alertas de calidad del aire...",
    "de": "Rauch von Hunderten von Waldbränden in Kanada löst in den gesamten USA Luftqualitätswarnungen aus..."
  },
  "speech_understanding": {
    "request": {
      "translation": {
        "formal": true,
        "target_languages": ["es", "de"]
      }
    },
    "response": {
      "translation": {
        "status": "success"
      }
    }
  }
}
```

## API reference

### Request

#### Method 1: Transcribe and translate in one request

When creating a new transcription, include the `speech_understanding` parameter directly in your transcription request:

```bash
curl -X POST \
  "https://api.assemblyai.com/v2/transcript" \
  -H "Authorization: YOUR_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "audio_url": "https://assembly.ai/wildfires.mp3",
    "speech_understanding": {
      "request": {
        "translation": {
          "target_languages": ["es", "de"],
          "formal": true
        }
      }
    }
  }'
```

#### Method 2: Add translation to existing transcripts

For existing transcripts, retrieve the completed transcript and send it to the Speech Understanding API:

```bash {6} maxLines=15
# Step 1: Get the completed transcript
transcript=$(curl -s -X GET \
  "https://api.assemblyai.com/v2/transcript/YOUR_TRANSCRIPT_ID" \
  -H "Authorization: YOUR_API_KEY")

# Step 2: Add translation and send to Speech Understanding API
curl -X POST \
  "https://llm-gateway.assemblyai.com/v1/understanding" \
  -H "Authorization: YOUR_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "transcript_id": "{transcript_id}",
    "speech_understanding": {
      "request": {
        "translation": {
          "target_languages": ["es", "de"],
          "formal": true
        }
      }
    }
  }'
```

| Key                                          | Type    | Required? | Description                                                                                                                      |
| -------------------------------------------- | ------- | --------- | -------------------------------------------------------------------------------------------------------------------------------- |
| `speech_understanding`                       | object  | Yes       | Container for speech understanding requests.                                                                                     |
| `speech_understanding.request`               | object  | Yes       | The understanding request configuration.                                                                                         |
| `speech_understanding.request.translation`   | object  | Yes       | Translation configuration.                                                                                                       |
| `translation.target_languages`               | array   | Yes       | Array of language codes to translate the transcript into. See the supported languages table for available language codes.        |
| `translation.formal`                         | boolean | No        | Whether to use formal language in translations. Defaults to `false`. When `true`, uses formal pronouns and grammatical forms.    |

### Response

The Translation API returns your original transcript response with an additional `translated_texts` key containing the translations.

```json
{
  "id": "735d90b6-2e8b-4748-b75d-d02b78eb7811",
  "status": "completed",
  "text": "Smoke from hundreds of wildfires in Canada is triggering air quality alerts throughout the US...",
  "translated_texts": {
    "es": "El humo de cientos de incendios forestales en Canadá está provocando alertas de calidad del aire en todo Estados Unidos...",
    "de": "Rauch von Hunderten von Waldbränden in Kanada löst in den gesamten USA Luftqualitätswarnungen aus..."
  },
  "speech_understanding": {
    "request": {
      "translation": {
        "formal": true,
        "target_languages": ["es", "de"]
      }
    },
    "response": {
      "translation": {
        "status": "success"
      }
    }
  }
}
```

| Key                                           | Type   | Description                                                                                                                          |
| --------------------------------------------- | ------ | ------------------------------------------------------------------------------------------------------------------------------------ |
| `translated_texts`                            | object | An object containing the translated texts, where each key is a language code and each value is the full translated transcript text. |
| `speech_understanding`                        | object | Container for speech understanding request and response information.                                                                 |
| `speech_understanding.request`                | object | The original translation request configuration that was submitted.                                                                   |
| `speech_understanding.request.translation`    | object | The translation parameters that were used.                                                                                           |
| `speech_understanding.response`               | object | The response information from the translation process.                                                                               |
| `speech_understanding.response.translation`   | object | Status information about the translation.                                                                                            |
| `speech_understanding.response.translation.status` | string | The status of the translation. Will be `"success"` when translation completes successfully.                                          |

#### Key differences from standard transcription

| Field | Standard Transcription | With Translation |
|-------|------------------------|------------------|
| `translated_texts` | Not present | Object with language codes as keys and translated texts as values |
| `speech_understanding` | Not present | Object containing the translation request and response details |

All other fields from the original transcript (`text`, `words`, `utterances`, `confidence`, etc.) remain unchanged.
