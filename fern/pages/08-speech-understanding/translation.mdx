---
title: "Translation"
description: "Translate your transcripts from one language to another"
hidden: true
---

Our Translation model lets you convert transcript text or spoken audio in one language to another language or languages of your choosing.

## Quickstart

There are two ways to use Translation:

1. **Transcribe and translate in one request** - Best when you're starting a new transcription and want to automatically translate the transcript text as part of that process
2. **Transcribe and identify in separate requests** - Best when you already have text that you would like to translate or for more complicated workflows where you want to separate the transcription and translation tasks

### Method 1: Transcribe and translate in one request

This method is ideal when you're starting fresh and want both transcription and translation in a single workflow.

<Tabs groupId="language">
<Tab language="python" title="Python" default>

```python
import requests
import time

base_url = "https://api.assemblyai.com"

headers = {
  "authorization": "<YOUR_API_KEY>"
}

## Use this section and comment out lines 17 and 18 to transcribe a local file
# with open("./my-audio.mp3", "rb") as f:
# response = requests.post(base_url + "/v2/upload",
# headers=headers,
# data=f)
# upload_url = response.json()["upload_url"]

# Or use a publicly-accessible URL:
upload_url = "https://assembly.ai/wildfires.mp3"

data = {
  "audio_url": upload_url,
  "speech_understanding": {
    "request": {
      "translation": {
        "target_languages": ["es"],
        "formal": True
      }
    }
    }
}

# transcribe file
response = requests.post(base_url + "/v2/transcript", headers=headers, json=data)

transcript_id = response.json()["id"]
polling_endpoint = base_url + f"/v2/transcript/{transcript_id}"

# poll for transcription results
while True:
  transcript = requests.get(polling_endpoint, headers=headers).json()

  if transcript["status"] == "completed":
    break

  elif transcript["status"] == "error":
    raise RuntimeError(f"Transcription failed: {transcript['error']}")

  else:
    time.sleep(3)

# Access the results and print the translated texts to the terminal
for language_code, text in transcript['translated_texts'].items():
  print(f'"{language_code}": "{text}"')
```

</Tab>
</Tabs>

### Method 2: Transcribe and translate in separate requests

This method is useful when you already have text that you would like to translate or for more complicated workflows where you want to separate the transcription and translation tasks

<Tabs groupId="language">
<Tab language="python" title="Python" default>

```python
import requests
import time

base_url = "https://api.assemblyai.com"

headers = {
  "authorization": "<YOUR_API_KEY>"
}

## Use this section and comment out lines 17 and 18 to transcribe a local file
# with open("./my-audio.mp3", "rb") as f:
# response = requests.post(base_url + "/v2/upload",
# headers=headers,
# data=f)
# upload_url = response.json()["upload_url"]

# Or use a publicly-accessible URL:
upload_url = "https://assembly.ai/wildfires.mp3"

data = {
  "audio_url": upload_url,
  "speaker_labels": True
}

# transcribe file
response = requests.post(base_url + "/v2/transcript", headers=headers, json=data)

transcript_id = response.json()["id"]
polling_endpoint = base_url + f"/v2/transcript/{transcript_id}"

# poll for transcription results
while True:
  transcript = requests.get(polling_endpoint, headers=headers).json()

  if transcript["status"] == "completed":
    break

  elif transcript["status"] == "error":
    raise RuntimeError(f"Transcription failed: {transcript['error']}")

  else:
    time.sleep(3)

# Add speaker identification request to the transcript
transcript["speech_understanding"] = {
  "request": {
    "speaker_identification": {
      "speaker_type": "name",
      "known_values": ["Michel Martin", "Peter DeCarlo"]  # Change these values to match the names of the speakers in your file
    }
  }
}

# Send the modified transcript to the Speech Understanding API
result = requests.post(
  "https://llm-gateway.assemblyai.com/v1/understanding",
  headers = headers,
  json = transcript
).json()

# Access the results and print utterances to the terminal
for utterance in result["utterances"]:
  print(f"{utterance['speaker']}: {utterance['text']}")
```

</Tab>
</Tabs>
