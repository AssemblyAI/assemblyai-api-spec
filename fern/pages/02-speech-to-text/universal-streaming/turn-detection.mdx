---
title: "Turn detection"
description: "Intelligent turn detection with Streaming Speech-to-Text"
---

### Overview

AssemblyAI's turn detection model uses a neural network to detect when someone has finished speaking. Unlike traditional voice activity detection that only listens for silence, our model understands the meaning and flow of speech to make better decisions about when a turn has ended.

The model has two ways to detect end-of-turn:
1. **Semantic detection** - The model predicts when speech naturally ends based on meaning and context
2. **Acoustic detection** - Traditional silence-based detection as a backup using VAD

When either method detects an end-of-turn, the model returns `end_of_turn=True` in the response.

This approach solves common voice agent problems:
- No more awkward long pauses waiting for silence thresholds
- No more cutting people off mid-sentence during natural pauses
- Better handling of "um" and thinking pauses
- Easily fine tune the model to your use case

### Quick start configurations

#### Aggressive

Ends turns very quickly, optimized for short responses and rapid back-and-forth.
```json
"end_of_turn_confidence_threshold": 0.5,
"min_end_of_turn_silence_when_confident": 160,
"max_turn_silence": 400
```
<Tip>Recommended use cases: Agent Assist, IVR replacements, Retail/E-commerce (order confirmations, delivery status), Telecom (outage reporting, yes/no checks)</Tip>


#### Balanced
Provides a natural middle ground, allowing enough pause for most conversational turns without feeling sluggish or overly eager. 
```json
"end_of_turn_confidence_threshold": 0.7,
"min_end_of_turn_silence_when_confident": 400,
"max_turn_silence": 1200
```
<Tip>Recommended use cases: Customer Support, Tech Support/SaaS, Financial Services (account inquiries, balance checks), Travel & Hospitality, Education, Government Services</Tip>

#### Conservative
Holds the floor longer, optimized for reflective or complex speech where users may pause to think before finishing.
```json
"end_of_turn_confidence_threshold": 0.9,
"min_end_of_turn_silence_when_confident": 800,
"max_turn_silence": 3600
```
<Tip>Recommended use cases: Healthcare, Mental Health Support, Sales & Consulting, Legal & Insurance, Language Learning</Tip>

These configurations are just starting points and can be fine-tuned based on your specific use case. Reach out to [support@assemblyai.com](mailto:support@assemblyai.com) for help.

### How it works

<Tabs>
<Tab title="Semantic Detection">

Triggers when the model is confident about end-of-turn and **all conditions are met**

| Parameter | Default | Description |
|-----------|---------|-------------|
| `end_of_turn_confidence_threshold` | `0.7` | Model confidence must be ≥ this value |
| `min_end_of_turn_silence_when_confident` | `160 ms` | Silence duration after VAD detects end of speech |
| Minimum speech duration | `80 ms` | User must speak at least one word _(internal)_ |
| Word finalization | Required | Last word must be finalized _(internal)_ |

</Tab>
<Tab title="Acoustic Detection">

Triggers when the model is not confident (fallback to silence-based) and **all conditions are met**

| Parameter | Default | Description |
|-----------|---------|-------------|
| `end_of_turn_confidence_threshold` | `0.7` | Model confidence must be < this value |
| `max_turn_silence` | `2400 ms` | Maximum silence duration after VAD detects end of speech |
| Minimum speech duration | `80 ms` | User must speak at least one word _(internal)_ |
| Word finalization | Required | Last word must be finalized _(internal)_ |

</Tab>
</Tabs>

**To disable semantic detection:** Set `end_of_turn_confidence_threshold = 1` to use only acoustic detection.

The turn detection model uses a neural network to detect when someone has finished speaking. It has two ways to detect end-of-turn:

<Steps>
<Step>
### Semantic Detection

Triggers when **all** conditions are met:

#### Model confidence threshold

- Model predicts semantic end-of-turn confidence greater than `end_of_turn_confidence_threshold`
- Default: `0.7` (user configurable)

#### Minimum silence duration

- After the end of speech detected by VAD, `min_end_of_turn_silence_when_confident` milliseconds must pass
- Default: `160 ms` (user configurable)

#### Minimum speech duration

- The user must speak for at least `80 ms` since the last end-of-turn (ensures at least one word)
- Set to `80 ms` (internal)

#### Word finalized

- Last word in `turn.words` has been finalized
- Internal configuration

</Step>
<Step>

### Acoustic Detection

Triggers when **all** conditions are met:

#### Model confidence threshold

- Model predicts semantic end-of-turn confidence **less than** `end_of_turn_confidence_threshold`
- Default: `0.7` (user configurable)

#### Maximum silence duration

- After the end of speech detected by VAD, `max_turn_silence` milliseconds must pass
- Default: `2400 ms` (user configurable)

#### Minimum speech duration

- The user must speak for at least `80 ms` since the last end-of-turn (ensures at least one word)
- Set to `80 ms` (internal)

#### Word finalized

- Last word in `turn.words` has been finalized
- Internal configuration

</Step>
</Steps>

### Disable turn detection

To disable model-based turn detection, set `end_of_turn_confidence_threshold` to 1. This will stop the model from predicting end-of-turns and will only use silence-based detection.
If you are using your own form of turn detection (such as VAD or a custom turn detection model), you can send a `ForceEndpoint` event to the server to force the end of a turn and receive the final turn transcript.

```python
ws.send(json.dumps({"type": "ForceEndpoint"}))
```

### Important notes

- Silence-based detection can override model-based detection even with high EOT confidence thresholds
- Word finalization always takes precedence — endpointing won't occur until the last word is finalized
- We define end-of-turn detection as the process of detecting the end of sustained speech activity, often called end-pointing in the Voice Agents context
