---
title: "Speech-to-Speech"
description: "Build real-time voice AI agents that listen and respond naturally"
---

Build voice-powered AI agents that have natural conversations with your users. Your agent listens to speech and responds with a natural-sounding voice—all in real-time.

<Note>
  This is an early stage product subject to change and should not be used for
  production usage.
</Note>

## How it works

```
┌─────────────┐                 ┌─────────────────┐                 ┌─────────────┐
│             │     Audio       │                 │      Audio      │             │
│    User     │  ────────────►  │   Voice Agent   │  ────────────►  │    User     │
│  (speaks)   │                 │                 │                 │   (hears)   │
└─────────────┘                 └─────────────────┘                 └─────────────┘
```

1. **User speaks** — Your app captures microphone audio and streams it to the agent
2. **Agent responds** — The agent processes the speech and generates a spoken response
3. **User hears** — Your app receives audio and plays it through the speaker

The entire flow happens in real-time with low latency.

---

## Quick Start

Get a voice agent up and running in 3 steps.

### Step 1: Get your API key

Grab your API key from your [AssemblyAI dashboard](https://www.assemblyai.com/app).

### Step 2: Create your agent

Create an agent by sending a POST request. Here's an example of a friendly assistant:

<Tabs>
<Tab title="cURL">
```bash
curl -X POST https://aaigentsv1.up.railway.app/agents \
  -H "Authorization: YOUR_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "agent_name": "friendly_assistant",
    "instructions": "You are a friendly and helpful assistant. Keep your responses concise and conversational. Be warm and personable.",
    "voice": "luna",
    "greeting": "Say hello and ask how you can help today."
  }'
```
</Tab>
<Tab title="Python">
```python
import requests

response = requests.post(
"https://aaigentsv1.up.railway.app/agents",
headers={
"Authorization": "YOUR_API_KEY",
"Content-Type": "application/json"
},
json={
"agent_name": "friendly_assistant",
"instructions": "You are a friendly and helpful assistant. Keep your responses concise and conversational. Be warm and personable.",
"voice": "luna",
"greeting": "Say hello and ask how you can help today."
}
)

print(response.json())

````
</Tab>
<Tab title="JavaScript">
```javascript
const response = await fetch("https://aaigentsv1.up.railway.app/agents", {
  method: "POST",
  headers: {
    "Authorization": "YOUR_API_KEY",
    "Content-Type": "application/json"
  },
  body: JSON.stringify({
    agent_name: "friendly_assistant",
    instructions: "You are a friendly and helpful assistant. Keep your responses concise and conversational. Be warm and personable.",
    voice: "luna",
    greeting: "Say hello and ask how you can help today."
  })
});

console.log(await response.json());
````

</Tab>
</Tabs>

### Step 3: Start a conversation

Connect to your agent via WebSocket and start talking:

```
wss://aaigentsv1.up.railway.app/ws/friendly_assistant
```

Once connected, send audio as binary WebSocket frames (PCM16, 16kHz, mono) and receive the agent's spoken responses back as audio.

<Accordion title="Full Python example">
```python
import asyncio
import json
import websockets
import sounddevice as sd
import numpy as np

async def voice_chat():
uri = "wss://aaigentsv1.up.railway.app/ws/friendly_assistant"
queue = asyncio.Queue(maxsize=100)
session_ready = False

    async with websockets.connect(uri, ping_interval=10, ping_timeout=20) as ws:
        print("Connected! Waiting for session...")

        # Send microphone audio to the agent
        async def send_audio():
            while True:
                data = await queue.get()
                if session_ready:
                    await ws.send(data)
                queue.task_done()

        asyncio.create_task(send_audio())
        loop = asyncio.get_running_loop()

        def mic_callback(indata, frames, time, status):
            if not queue.full():
                loop.call_soon_threadsafe(queue.put_nowait, bytes(indata))

        with sd.InputStream(samplerate=16000, channels=1, dtype='int16', callback=mic_callback), \
             sd.OutputStream(samplerate=16000, channels=1, dtype='int16') as speaker:

            while True:
                response = await ws.recv()

                # Play audio responses
                if isinstance(response, bytes) and len(response):
                    speaker.write(np.frombuffer(response, dtype=np.int16))

                # Handle JSON messages
                elif isinstance(response, str):
                    msg = json.loads(response)

                    if msg.get("type") == "session.created":
                        print("Session ready! Start speaking...")
                        session_ready = True

                    elif msg.get("type") == "conversation.item.done":
                        item = msg.get("item", {})
                        role = item.get("role")
                        text = item.get("content", [{}])[0].get("text", "")
                        print(f"[{role}]: {text}")

asyncio.run(voice_chat())

````

Install dependencies with:
```bash
pip install websockets sounddevice numpy
````

</Accordion>

That's it! You now have a working voice agent.

---

## Example agents

Here are some practical examples to inspire your own agents.

### Customer support agent

```json
{
  "agent_name": "support_agent",
  "instructions": "You are a customer support agent for a software company. Be helpful, patient, and empathetic. Ask clarifying questions to understand the customer's issue. If you can't solve a problem, offer to escalate to a human agent. Keep responses brief and focused.",
  "voice": "celeste",
  "greeting": "Thank the customer for calling and ask how you can help them today."
}
```

### Appointment scheduler

```json
{
  "agent_name": "appointment_scheduler",
  "instructions": "You are a friendly receptionist who helps schedule appointments. Collect the caller's name, preferred date and time, and reason for the appointment. Confirm all details before ending the call. Be efficient but warm.",
  "voice": "estelle",
  "greeting": "Welcome the caller and ask if they'd like to schedule an appointment."
}
```

### Virtual concierge

```json
{
  "agent_name": "hotel_concierge",
  "instructions": "You are a luxury hotel concierge. Be warm, professional, and knowledgeable. Help guests with restaurant recommendations, local attractions, transportation, and any requests. Anticipate needs and offer personalized suggestions.",
  "voice": "orion",
  "greeting": "Welcome the guest and ask how you can make their stay more enjoyable."
}
```

---

## Choose a voice

Pick a voice that matches your agent's personality.

| Voice       | Style                               |
| ----------- | ----------------------------------- |
| `luna`      | Chill but excitable, gen-z optimist |
| `celeste`   | Warm, laid-back, fun-loving         |
| `orion`     | Older male, warm and happy          |
| `ursa`      | Young male, energetic               |
| `astra`     | Young female, wide-eyed and curious |
| `esther`    | Older female, loving and caring     |
| `estelle`   | Middle-aged female, sweet and kind  |
| `andromeda` | Young female, breathy and calm      |

---

## Add tools

Tools let your agent take actions—like checking a database, calling an API, or triggering a workflow.

Here's a simple example of an agent with a weather tool:

```json
{
  "agent_name": "weather_assistant",
  "instructions": "You help users check the weather. When they ask about weather, use the get_weather tool to look it up.",
  "voice": "luna",
  "tools": [
    {
      "name": "get_weather",
      "description": "Get the current weather for a city",
      "parameters": {
        "type": "object",
        "properties": {
          "city": {
            "type": "string",
            "description": "The city name"
          }
        },
        "required": ["city"]
      }
    }
  ]
}
```

When a user asks "What's the weather in Tokyo?", the agent sends your client a `tool.call` event:

```json
{
  "type": "tool.call",
  "call_id": "call_abc123",
  "name": "get_weather",
  "arguments": { "city": "Tokyo" }
}
```

Your client executes the function and sends back the result:

```json
{
  "type": "tool.result",
  "call_id": "call_abc123",
  "result": "{\"temperature\": \"72°F\", \"conditions\": \"sunny\"}"
}
```

The agent then speaks the weather information to the user.

---

## Agent configuration

Full list of options when creating an agent.

| Field                   | Type   | Default  | Description                                         |
| ----------------------- | ------ | -------- | --------------------------------------------------- |
| `agent_name`            | string | required | Unique identifier (letters, numbers, underscores)   |
| `instructions`          | string | -        | Personality and behavior guidelines                 |
| `voice`                 | string | `"luna"` | Voice to use for responses                          |
| `greeting`              | string | -        | What the agent says when a conversation starts      |
| `temperature`           | float  | `0.8`    | Response creativity (0.0 = focused, 1.0 = creative) |
| `max_tokens`            | int    | `4096`   | Maximum response length                             |
| `language`              | string | `"en"`   | Language code                                       |
| `tools`                 | array  | -        | Tool definitions (see above)                        |
| `audio_in_sample_rate`  | int    | `16000`  | Input audio sample rate in Hz                       |
| `audio_out_sample_rate` | int    | `16000`  | Output audio sample rate in Hz                      |

---

## WebSocket events

When connected to an agent, you'll receive these events:

### session.created

Sent when the connection is established and ready.

```json
{
  "type": "session.created",
  "session": {
    "id": "uuid",
    "agent_name": "my_agent"
  }
}
```

### conversation.item.done

Sent when a speaker finishes talking. Contains the transcript.

```json
{
  "type": "conversation.item.done",
  "item": {
    "role": "user",
    "content": [{ "type": "text", "text": "What's the weather like?" }]
  }
}
```

### conversation.item.interim

Sent during speech with partial transcripts. Useful for showing real-time captions.

```json
{
  "type": "conversation.item.interim",
  "item": {
    "role": "user",
    "content": [{ "type": "text", "text": "What's the wea..." }]
  }
}
```

### tool.call

Sent when the agent wants to use a tool. See [Add tools](#add-tools) for handling.

### Audio (binary)

The agent's spoken responses come as binary WebSocket frames containing PCM16 audio.

---

## Audio format

Both input and output audio use the same format:

- **Encoding**: PCM16 (16-bit signed integer, little-endian)
- **Sample rate**: 16,000 Hz (configurable)
- **Channels**: Mono

---

## REST API reference

<Accordion title="Manage agents">

**Base URL**: `https://aaigentsv1.up.railway.app`

All REST endpoints require an `Authorization: YOUR_API_KEY` header.

### Create or update agent

`POST /agents` — Create a new agent or update an existing one.

### List agents

`GET /agents` — List all your agents.

```json
{
  "agents": ["agent1", "agent2"],
  "count": 2
}
```

### Get agent

`GET /agents/{agent_name}` — Get an agent's configuration.

### Delete agent

`DELETE /agents/{agent_name}` — Delete an agent.

</Accordion>

<Accordion title="Conversation history">

### List conversations

`GET /agents/{agent_name}/conversations` — List all conversations for an agent.

```json
{
  "agent_name": "my_agent",
  "conversations": [
    {
      "conversation_id": "uuid",
      "created_at": "2025-12-18T13:00:00Z"
    }
  ],
  "count": 1
}
```

### Get conversation

`GET /agents/{agent_name}/conversations/{conversation_id}` — Get a specific conversation with all messages.

```json
{
  "conversation_id": "uuid",
  "agent_name": "my_agent",
  "items": [],
  "created_at": "2025-12-18T13:00:00Z"
}
```

</Accordion>

<Accordion title="Tool definition schema">

Tools follow JSON Schema format:

```json
{
  "name": "tool_name",
  "description": "What this tool does",
  "parameters": {
    "type": "object",
    "properties": {
      "param_name": {
        "type": "string",
        "description": "What this parameter is for"
      }
    },
    "required": ["param_name"]
  }
}
```

**Supported parameter types**: `string`, `number`, `boolean`, `array`, `object`

</Accordion>
