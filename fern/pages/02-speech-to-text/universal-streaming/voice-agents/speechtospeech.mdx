---
title: "Speech-to-Speech"
description: "Speech-to-speech API docs"
---

Real-time voice AI over WebSocket with speech-to-text, language model processing, and text-to-speech.

---

## Endpoint

```
wss://aaigents.up.railway.app/ws
```

Connect to establish a voice agent session.

---

## Client Events

### session.update

Initialize or update session configuration.

**Request**

```json
{
  "type": "session.update",
  "session": {
    "instructions": "You are a helpful voice assistant.",
    "temperature": 0.8,
    "max_tokens": 4096,
    "llm": {
      "model": "llama-4-scout-17b-16e-instruct"
    },
    "tools": [],
    "audio": {
      "input": {
        "format": {
          "type": "audio/pcm",
          "rate": 16000
        },
        "language": "multi",
        "turn_detection": {
          "type": "assemblyai"
        }
      },
      "output": {
        "format": {
          "type": "audio/pcm",
          "rate": 24000
        },
        "voice": "rex",
        "speed": 1
      }
    }
  }
}
```

**Properties**

| Property | Type | Required | Description |
|----------|------|----------|-------------|
| `type` | string | Yes | Event type: `"session.update"` |
| `session` | object | Yes | Session configuration |
| `session.instructions` | string | No | System instructions for AI (default: elementary teacher prompt) |
| `session.temperature` | number | No | LLM temperature 0-1 (default: `0.8`) |
| `session.max_tokens` | number | No | Max output tokens (default: `4096`) |
| `session.llm` | object | No | LLM configuration |
| `session.llm.model` | string | No | Model name (default: `"llama-4-scout-17b-16e-instruct"`) |
| `session.tools` | array | No | Function calling tools (default: `[]`) |
| `session.audio` | object | No | Audio configuration |
| `session.audio.input` | object | No | Input audio settings |
| `session.audio.input.format` | object | No | Audio format |
| `session.audio.input.format.type` | string | No | Format type (default: `"audio/pcm"`) |
| `session.audio.input.format.rate` | number | No | Sample rate in Hz (default: `16000`) |
| `session.audio.input.language` | string | No | Language code or `"multi"` for auto-detect (default: `"multi"`) |
| `session.audio.input.turn_detection` | object | No | VAD configuration |
| `session.audio.input.turn_detection.type` | string | No | VAD provider (default: `"assemblyai"`) |
| `session.audio.output` | object | No | Output audio settings |
| `session.audio.output.format` | object | No | Audio format |
| `session.audio.output.format.type` | string | No | Format type (default: `"audio/pcm"`) |
| `session.audio.output.format.rate` | number | No | Sample rate in Hz (default: `24000`) |
| `session.audio.output.voice` | string | No | Voice ID (default: `"rex"`) |
| `session.audio.output.speed` | number | No | Speech speed multiplier (default: `1`) |

### Audio Stream

Send raw PCM audio as binary WebSocket frames.

**Format**
- Encoding: PCM16 (16-bit signed integer, little-endian)
- Sample Rate: Must match `audio.input.format.rate`
- Channels: 1 (mono)
- Recommended chunk size: 4096 samples

---

## Server Events

### session.updated

Confirmation of session configuration.

**Response**

```json
{
  "type": "session.updated",
  "session": {
    "id": "session_abc123def456",
    "llm": {
      "model": "llama-4-scout-17b-16e-instruct"
    },
    "instructions": "You are a helpful voice assistant.",
    "tools": [],
    "tool_choice": "auto",
    "max_output_tokens": 4096,
    "temperature": 0.8,
    "audio": {
      "input": {
        "format": {
          "type": "audio/pcm",
          "rate": 16000
        },
        "language": "multi",
        "turn_detection": {
          "type": "assemblyai"
        }
      },
      "output": {
        "format": {
          "type": "audio/pcm",
          "rate": 24000
        },
        "voice": "rex",
        "speed": 1
      }
    }
  }
}
```

**Properties**

| Property | Type | Description |
|----------|------|-------------|
| `type` | string | Event type: `"session.updated"` |
| `session` | object | Complete session state |
| `session.id` | string | Unique session identifier |
| `session.llm` | object | LLM configuration |
| `session.instructions` | string | System instructions |
| `session.tools` | array | Available tools |
| `session.tool_choice` | string | Tool selection mode |
| `session.max_output_tokens` | number | Max output tokens |
| `session.temperature` | number | LLM temperature |
| `session.audio` | object | Audio configuration (mirrors request) |

### conversation.item.done

Notification when a conversation turn completes.

**Response**

```json
{
  "type": "conversation.item.done",
  "event_id": "evt_789xyz",
  "previous_item_id": null,
  "item": {
    "id": "msg_456def",
    "type": "message",
    "status": "completed",
    "role": "user",
    "content": [
      {
        "type": "input_text",
        "text": "What's the weather like?"
      }
    ]
  }
}
```

**Properties**

| Property | Type | Description |
|----------|------|-------------|
| `type` | string | Event type: `"conversation.item.done"` |
| `event_id` | string | Unique event identifier |
| `previous_item_id` | string \| null | Previous item ID in conversation |
| `item` | object | Conversation item |
| `item.id` | string | Item identifier |
| `item.type` | string | Item type: `"message"` |
| `item.status` | string | Status: `"completed"` |
| `item.role` | string | `"user"` or `"assistant"` |
| `item.content` | array | Content parts |
| `item.content[].type` | string | `"input_text"` (user) or `"text"` (assistant) |
| `item.content[].text` | string | Transcript text |

### tool_call

Function call request from AI agent.

**Response**

```json
{
  "type": "tool_call",
  "tool_call": {
    "id": "call_abc123",
    "type": "function",
    "function": {
      "name": "get_weather",
      "arguments": "{\"location\":\"San Francisco\"}"
    }
  }
}
```

**Properties**

| Property | Type | Description |
|----------|------|-------------|
| `type` | string | Event type: `"tool_call"` |
| `tool_call` | object | Tool call request |
| `tool_call.id` | string | Unique call identifier |
| `tool_call.type` | string | Type: `"function"` |
| `tool_call.function` | object | Function details |
| `tool_call.function.name` | string | Function name |
| `tool_call.function.arguments` | string | JSON-encoded arguments |

### Audio Stream

Raw PCM audio response as binary WebSocket frames.

**Format**
- Encoding: PCM16 (16-bit signed integer, little-endian)
- Sample Rate: Matches `audio.output.format.rate`
- Channels: 1 (mono)

---

## Tools / Function Calling

Define tools in `session.tools`:

**Tool Schema**

```json
{
  "type": "function",
  "function": {
    "name": "get_weather",
    "description": "Get current weather for a location",
    "parameters": {
      "type": "object",
      "properties": {
        "location": {
          "type": "string",
          "description": "City name"
        },
        "unit": {
          "type": "string",
          "enum": ["celsius", "fahrenheit"]
        }
      },
      "required": ["location"]
    }
  }
}
```

**Properties**

| Property | Type | Required | Description |
|----------|------|----------|-------------|
| `type` | string | Yes | Must be `"function"` |
| `function` | object | Yes | Function definition |
| `function.name` | string | Yes | Function name |
| `function.description` | string | Yes | Human-readable description |
| `function.parameters` | object | Yes | JSON Schema for parameters |
| `function.parameters.type` | string | Yes | Must be `"object"` |
| `function.parameters.properties` | object | Yes | Object defining each parameter |
| `function.parameters.properties.<param>` | object | Yes | Individual parameter definition |
| `function.parameters.properties.<param>.type` | string | Yes | JSON type: `"string"`, `"number"`, `"boolean"`, `"array"`, `"object"` |
| `function.parameters.properties.<param>.description` | string | No | Human-readable parameter description |
| `function.parameters.properties.<param>.enum` | array | No | Valid values for the parameter |
| `function.parameters.required` | array | No | List of required parameter names |

---

## Supported Languages

Values for `audio.input.language`:

| Code | Language |
|------|----------|
| `multi` | Auto-detect (default) |
| `en` | English |


---

## Available Voices

Values for `audio.output.voice` (Rime TTS):

| Voice ID | Description |
|----------|-------------|
| `rex` | Default male voice |

Additional voices available via Rime API.

---

## Examples


### Python

**Installation**

```bash
pip install websockets sounddevice numpy
```

**Code**

```python
import asyncio
import json
import websockets
import sounddevice as sd
import numpy as np

URI = "wss://aaigents.up.railway.app/ws"
INSTRUCTIONS = "You are a helpful voice assistant. Keep responses concise."

async def voice_chat():
    queue = asyncio.Queue(maxsize=100)
    session_ready = False

    async with websockets.connect(URI, ping_interval=10, ping_timeout=20) as ws:
        print(f"Connected to {URI}")

        # Task to send audio from queue to WebSocket
        async def sender():
            while True:
                data = await queue.get()
                if session_ready:
                    await ws.send(data)
                queue.task_done()

        sender_task = asyncio.create_task(sender())
        loop = asyncio.get_running_loop()

        # Microphone callback
        def mic_callback(indata, frames, time, status):
            if status.input_overflow:
                print("Audio buffer overflow!")
            pcm_bytes = bytes(indata)
            loop.call_soon_threadsafe(
                lambda: queue.full() or queue.put_nowait(pcm_bytes)
            )

        # Open audio streams
        with sd.InputStream(
            samplerate=16000, channels=1, dtype='int16', callback=mic_callback
        ), sd.OutputStream(samplerate=24000, channels=1, dtype='int16') as speaker:
            
            print("Waiting for session to be ready...")

            try:
                async for message in ws:
                    if isinstance(message, bytes):
                        # Play audio response
                        speaker.write(np.frombuffer(message, dtype=np.int16))
                    
                    else:
                        # Handle JSON events
                        data = json.loads(message)
                        event_type = data.get("type")
                        
                        if event_type == "session.created":
                            # Configure session
                            await ws.send(json.dumps({
                                "type": "session.update",
                                "session": {
                                    "instructions": INSTRUCTIONS,
                                    "llm": {
                                        "model": "llama-4-scout-17b-16e-instruct"
                                    },
                                    "audio": {
                                        "input": {
                                            "format": {"type": "audio/pcm", "rate": 16000},
                                            "language": "multi"
                                        },
                                        "output": {
                                            "format": {"type": "audio/pcm", "rate": 24000},
                                            "voice": "rex",
                                            "speed": 1
                                        }
                                    }
                                }
                            }))
                            print("Session created, configuring...")
                        
                        elif event_type == "session.updated":
                            session_ready = True
                            print("âœ“ Voice chat active. Press Ctrl+C to quit.")
                        
                        elif event_type == "conversation.item.done":
                            item = data.get("item", {})
                            role = item.get("role", "")
                            content = item.get("content", [])
                            if content:
                                text = content[0].get("text", "")
                                print(f"[{role}]: {text}")
                        
                        elif event_type == "tool_call":
                            tool_call = data.get("tool_call", {})
                            function_name = tool_call.get("function", {}).get("name")
                            print(f"ðŸ”§ Tool call: {function_name}")

            except KeyboardInterrupt:
                print("\nDisconnecting...")
            finally:
                sender_task.cancel()

if __name__ == "__main__":
    try:
        asyncio.run(voice_chat())
    except KeyboardInterrupt:
        print("Exited.")
```

