---
title: "Livekit"
description: "Livekit voice agent integration"
---

<Note>
  This guide assumes prior knowledge of LiveKit. If you haven't used LiveKit before and are unfamiliar with LiveKit, please check out our [Building a Voice Agent with LiveKit and AssemblyAI guide](https://www.assemblyai.com/docs/speech-to-text/livekit-intro-guide).
</Note>

## Overview

LiveKit is an open source platform for developers building realtime media applications. In this guide, we'll show you how to integrate AssemblyAI's streaming speech-to-text model into your Livekit voice agent using the Agents framework.

<Card 
    title="Livekit" 
    icon={<img src="https://assemblyaiassets.com/images/Livekit.svg" alt="Livekit logo"/>} 
    href="https://docs.livekit.io/agents/integrations/stt/assemblyai/"
>
    View Livekit's AssemblyAI STT plugin documentation.
</Card>

## Quick start

### Installation

Install the plugin from PyPI:

```bash
pip install "livekit-agents[assemblyai]"
```

### Authentication

The AssemblyAI plugin requires an [AssemblyAI API key](https://www.assemblyai.com/docs/api-reference/overview#authorization). Set `ASSEMBLYAI_API_KEY` in your `.env` file.

<Tip>
  You can obtain an AssemblyAI API key by signing up
  [here](https://www.assemblyai.com/dashboard/signup).
</Tip>

### Basic usage

Use AssemblyAI STT in an `AgentSession` or as a standalone transcription service:

```python
from livekit.plugins import assemblyai

session = AgentSession(
    stt = assemblyai.STT(
      end_of_turn_confidence_threshold=0.7,
      min_end_of_turn_silence_when_confident=160,
      max_turn_silence=2400,
    ),
    # ... llm, tts, etc.
    vad=silero.VAD.load(), # VAD Enabled for Interruptions
    turn_detection="stt", # Enable Turn Detection
)
```

## Configuration

### Turn Detection (Key Feature)

AssemblyAI's new turn detection model was built specifically for voice agents and you can tweak it to fit your use case. It processes both audio and linguistic information to determine an end of turn confidence score on every inference, and if that confidence score is past the set threshold, it triggers end of turn.

This custom model was designed to address 2 major issues with voice agents. With traditional VAD (voice activity detection) approaches based on silence alone, there are situations where the agent wouldn't wait for a user to finish their turn even if the audio data suggested it. Think of a situation like "My credit card number is____" - if someone is looking that up, traditional VAD may not wait for the user, where our turn detection model is far better in these situations.

Additionally, in situations where we are certain that the user is done speaking like "What is my credit score?", a high end of turn confidence is returned, greater than the threshold, and triggering end of turn, allowing for minimal turnaround latency in those scenarios.

```python
# STT-based turn detection (recommended)
turn_detection="stt"

stt=assemblyai.STT(
    end_of_turn_confidence_threshold=0.7,
    min_end_of_turn_silence_when_confident=160,  # in ms
    max_turn_silence=2400,  # in ms
)
```

**Parameter tuning:**
- **end_of_turn_confidence_threshold**: Raise or lower the threshold based on how confident you'd like us to be before triggering end of turn based on confidence score
- **min_end_of_turn_silence_when_confident**: Increase or decrease the amount of time we wait to trigger end of turn when confident
- **max_turn_silence**: Lower or raise the amount of time needed to trigger end of turn when end of turn isn't triggered by a high confidence score

<Tip>
  You can also set `turn_detection="vad"` if you'd like turn detection to be based on Silero VAD instead of our advanced turn detection model.
</Tip>

For more information, see our [Universal-Streaming end-of-turn detection guide](https://www.assemblyai.com/docs/speech-to-text/universal-streaming#end-of-turn-detection) and [message-by-message breakdown](https://www.assemblyai.com/docs/speech-to-text/universal-streaming-messages-guide).

### Parameters

<ParamField path="api_key" type="str">
  Your AssemblyAI API key.
</ParamField>

<ParamField path="sample_rate" type="int" default="16000">
  The sample rate of the audio stream
</ParamField>

<ParamField path="encoding" type="str" default="pcm_s16le">
  The encoding of the audio stream. Allowed values: `pcm_s16le`, `pcm_mulaw`
</ParamField>

<ParamField path="formatted_finals" type="bool" default="True">
  Whether to return formatted final transcripts. If enabled, formatted final
  transcripts will be emitted shortly following an end-of-turn detection.
</ParamField>

<ParamField path="end_of_turn_confidence_threshold" type="float" default="0.65">
  The confidence threshold to use when determining if the end of a turn has been
  reached.  
  In our API the default is 0.4, but the default in LiveKit is set to 0.65.
</ParamField>

<ParamField path="min_end_of_turn_silence_when_confident" type="int" default="480">
  The minimum amount of silence required to detect end of turn when confident.
</ParamField>

<ParamField path="max_turn_silence" type="int" default="700">
  The maximum amount of silence allowed in a turn before end of turn is triggered.
</ParamField>