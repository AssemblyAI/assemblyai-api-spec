---
title: "Model selection"
---

We use a combination of models to produce your results. With the `speech_models` parameter, you can list multiple speech models in priority order from left to right, allowing our system to automatically route your audio to the best available option. Visit [our Models page](/docs/getting-started/models) to learn more about our different models and <a href="https://www.assemblyai.com/pricing" target="_blank">our pricing page</a> for full pricing information.

**Model routing behavior:** The system uses the priority order to determine which model to use based on the request characteristics. For example, with `["universal-3-pro", "universal-2"]`, the system will try to use Universal-3-Pro first, but fall back to Universal-2 for any language not supported by Universal-3-Pro.

<Tip title="Identifying the Model Used in Your Request">
  The API returns a field called `speech_model_used` that tells you which
  specific model was actually used to process your request.
</Tip>

<Tabs>
<Tab language="python-sdk" title="Python SDK">

| Name                        | Parameter                         | Description                                                              |
| --------------------------- | --------------------------------- | ------------------------------------------------------------------------ |
| **Universal-2** (default)   | `speech_models=['universal-2']`   | Our fastest model with the broadest language coverage.                   |
| **Universal-3-Pro**         | `speech_models=['universal-3-pro']` | Our highest accuracy model with fine-tuning support and customization via prompting. |

</Tab>
<Tab language="javascript-sdk" title="JavaScript SDK">

| Name                        | Parameter                           | Description                                                              |
| --------------------------- | ----------------------------------- | ------------------------------------------------------------------------ |
| **Universal-2** (default)   | `speech_models: ['universal-2']`    | Our fastest model with the broadest language coverage.                   |
| **Universal-3-Pro**         | `speech_models: ['universal-3-pro']` | Our highest accuracy model with fine-tuning support and customization via prompting. |

</Tab>
<Tab language="api" title="API">

| Name                        | API Parameter                        | Description                                                              |
| --------------------------- | ------------------------------------ | ------------------------------------------------------------------------ |
| **Universal-2** (default)   | `"speech_models":["universal-2"]`    | Our fastest model with the broadest language coverage.                   |
| **Universal-3-Pro**         | `"speech_models": ["universal-3-pro"]` | Our highest accuracy model with fine-tuning support and customization via prompting. |

</Tab>
</Tabs>
<br />

<Tabs>
<Tab language="python-sdk" title="Python SDK" default>

You can change the model by setting `speech_models` in the transcription config:

```python highlight={14-15} maxLines=15
import assemblyai as aai

aai.settings.api_key = "<YOUR_API_KEY>"
# You can use a local filepath:
# audio_file = "./local_file.mp3"

# Or use a publicly-accessible URL:
audio_file = "https://assembly.ai/wildfires.mp3"

config = aai.TranscriptionConfig(
    speech_models=["universal-3-pro", "universal-2"],
    language_detection=True
)
transcript = aai.Transcriber(config=config).transcribe(audio_file)

if transcript.status == "error":
  raise RuntimeError(f"Transcription failed: {transcript.error}")

print(transcript.text)
```

</Tab>
<Tab language="python" title="Python">

You can change the model by setting the `speech_models` in the POST request body:

```python highlight={21} maxLines=15
import requests
import time

base_url = "https://api.assemblyai.com"

headers = {
    "authorization": "<YOUR_API_KEY>"
}

with open("./my-audio.mp3", "rb") as f:
  response = requests.post(base_url + "/v2/upload",
                          headers=headers,
                          data=f)

upload_url = response.json()["upload_url"]

data = {
    "audio_url": upload_url, # You can also use a URL to an audio or video file on the web
    "speech_models": ["universal-3-pro", "universal-2"],
    "language_detection": True
}

url = base_url + "/v2/transcript"
response = requests.post(url, json=data, headers=headers)

transcript_id = response.json()['id']
polling_endpoint = base_url + "/v2/transcript/" + transcript_id

while True:
  transcription_result = requests.get(polling_endpoint, headers=headers).json()

  if transcription_result['status'] == 'completed':
    print(transcription_result['text'])
    break

  elif transcription_result['status'] == 'error':
    raise RuntimeError(f"Transcription failed: {transcription_result['error']}")

  else:
    time.sleep(3)

```

</Tab>
<Tab language="javascript-sdk" title="JavaScript SDK" default>

You can change the model by setting the `speech_models` in the transcript parameters:

```javascript highlight={17} maxLines=15
import { AssemblyAI } from "assemblyai";

const client = new AssemblyAI({
  apiKey: "<YOUR_API_KEY>",
});

// You can use a local filepath:
// const audioFile = './local_file.mp3'

// Or use a publicly-accessible URL:
const audioFile = "https://assembly.ai/wildfires.mp3";

const params = {
  audio: audioFile,
  speech_models: ["universal-3-pro", "universal-2"],
  language_detection: true
};

const run = async () => {
  const transcript = await client.transcripts.transcribe(params);

  console.log(transcript.text);
};

run();
```

</Tab>
<Tab language="javascript" title="JavaScript">

You can change the model by setting the `speech_models` in the POST request body:

```javascript highlight={21} maxLines=15
import axios from "axios";
import fs from "fs-extra";

const baseUrl = "https://api.assemblyai.com";

const headers = {
  authorization: "<YOUR_API_KEY>",
};

const path = "./my-audio.mp3";
const audioData = await fs.readFile(path);
const uploadResponse = await axios.post(`${baseUrl}/v2/upload`, audioData, {
  headers,
});
const uploadUrl = uploadResponse.data.upload_url;

const data = {
  audio_url: uploadUrl, // You can also use a URL to an audio or video file on the web
  speech_models: ["universal-3-pro", "universal-2"],
  language_detection: true
};

const url = `${baseUrl}/v2/transcript`;
const response = await axios.post(url, data, { headers: headers });

const transcriptId = response.data.id;
const pollingEndpoint = `${baseUrl}/v2/transcript/${transcriptId}`;

while (true) {
  const pollingResponse = await axios.get(pollingEndpoint, {
    headers: headers,
  });
  const transcriptionResult = pollingResponse.data;

  if (transcriptionResult.status === "completed") {
    console.log(transcriptionResult.text);
    break;
  } else if (transcriptionResult.status === "error") {
    throw new Error(`Transcription failed: ${transcriptionResult.error}`);
  } else {
    await new Promise((resolve) => setTimeout(resolve, 3000));
  }
}
```

</Tab>
</Tabs>
