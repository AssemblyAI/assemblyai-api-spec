---
title: "Select the Speech Model"
---

We use a combination of models to produce your results. With the `speech_models` parameter, you can list multiple speech models in priority order, allowing our system to automatically route your audio to the best available option. You can visit our <a href="https://www.assemblyai.com/pricing" target="_blank">pricing page</a> for more information on our model tiers.

**Model routing behavior:** The system uses the priority order to determine which model to use based on the request characteristics. For example, with `["slam-1", "universal"]`, the system will try to use Slam-1 first, but fall back to Universal for non-English audio since Slam-1 only supports English.

<Tip title="Identifying the Model Used in Your Request">
  The API returns a field called `speech_model_used` that tells you which specific model was actually used to process your request.
</Tip>

<Tabs>
<Tab language="python" title="Python">

| Name                    |  Parameter               | Description                                                                           |
| ----------------------- | --------------------------- | ------------------------------------------------------------------------------------- |
| **Universal** (default) | `speech_models=['universal]` | Use our fastest, most robust models with the broadest [language support](/docs/speech-to-text/pre-recorded-audio/supported-languages).          |
| **Slam-1**      | `speech_models=['slam-1]`    | Use our most customizable model for your transcription (English only).                |

</Tab>
<Tab language="javascript" title="JavaScript">

| Name                    |  Parameter | Description                                                                           |
| ----------------------- | ------------- | ------------------------------------------------------------------------------------- |
| **Universal** (default) | `speech_models: ['universal']` | Use our fastest, most robust models with the broadest [language support](/docs/speech-to-text/pre-recorded-audio/supported-languages).          |
| **Slam-1**       | `speech_models: ['slam-1']`    | Use our most customizable model for your transcription (English only).                |

</Tab>
<Tab language="api" title="API">

| Name                    | API Parameter                | Description                                                                           |
| ----------------------- | ---------------------------- | ------------------------------------------------------------------------------------- |
| **Universal** (default) | `"speech_models":["universal"]` |  Use our fastest, most robust models with the broadest [language support](/docs/speech-to-text/pre-recorded-audio/supported-languages).          |
| **Slam-1**      | `"speech_models": ["slam-1"]`    | Use our most customizable model for your transcription (English only).                |

</Tab>
</Tabs>
<br />

<Tabs>
<Tab language="python-sdk" title="Python SDK" default>

You can change the model by setting `speech_models` in the transcription config:

```python highlight={12-14} maxLines=15
import assemblyai as aai

aai.settings.api_key = "<YOUR_API_KEY>"
# You can use a local filepath:
# audio_file = "./local_file.mp3"

# Or use a publicly-accessible URL:
audio_file = "https://assembly.ai/wildfires.mp3"

# If you don't include the `speech_models` parameter, AssemblyAI will use the default Universal model.
# To specify a different model—or multiple models, set the optional `speech_models` parameter as shown below.
config = aai.TranscriptionConfig(
    speech_models=["slam-1", "universal"]
)

transcript = aai.Transcriber(config=config).transcribe(audio_file)

if transcript.status == "error":
  raise RuntimeError(f"Transcription failed: {transcript.error}")

print(transcript.text)
```

</Tab>
<Tab language="python" title="Python">

You can change the model by setting the `speech_models` in the POST request body:

```python highlight={21} maxLines=15
import requests
import time

base_url = "https://api.assemblyai.com"

headers = {
    "authorization": "<YOUR_API_KEY>"
}

with open("./my-audio.mp3", "rb") as f:
  response = requests.post(base_url + "/v2/upload",
                          headers=headers,
                          data=f)

upload_url = response.json()["upload_url"]

data = {
    "audio_url": upload_url, # You can also use a URL to an audio or video file on the web
    # If you don't include the `speech_models` parameter, AssemblyAI will use the default Universal model.
    # To specify a different model—or multiple models, set the optional `speech_models` parameter as shown below.
    "speech_models":["slam-1", "universal"]
}

url = base_url + "/v2/transcript"
response = requests.post(url, json=data, headers=headers)

transcript_id = response.json()['id']
polling_endpoint = base_url + "/v2/transcript/" + transcript_id

while True:
  transcription_result = requests.get(polling_endpoint, headers=headers).json()

  if transcription_result['status'] == 'completed':
    print(transcription_result['text'])
    break

  elif transcription_result['status'] == 'error':
    raise RuntimeError(f"Transcription failed: {transcription_result['error']}")

  else:
    time.sleep(3)

```

</Tab>
<Tab language="javascript-sdk" title="JavaScript SDK" default>

You can change the model by setting the `speech_models` in the transcript parameters:

```javascript highlight={17} maxLines=15
import { AssemblyAI } from "assemblyai";

const client = new AssemblyAI({
  apiKey: "<YOUR_API_KEY>",
});

// You can use a local filepath:
// const audioFile = './local_file.mp3'

// Or use a publicly-accessible URL:
const audioFile = "https://assembly.ai/wildfires.mp3";

const params = {
  audio: audioFile,
  //If you don't include the `speech_models` parameter, AssemblyAI will use the default Universal model.
  //To specify a different model—or multiple models, set the optional `speech_models` parameter as shown below.
  speech_models: ["slam-1", "universal"]
};

const run = async () => {
  const transcript = await client.transcripts.transcribe(params);

  console.log(transcript.text);
};

run();
```

</Tab>
<Tab language="javascript" title="JavaScript">

You can change the model by setting the `speech_models` in the POST request body:

```javascript highlight={21} maxLines=15
import axios from "axios";
import fs from "fs-extra";

const baseUrl = "https://api.assemblyai.com";

const headers = {
  authorization: "<YOUR_API_KEY>",
};

const path = "./my-audio.mp3";
const audioData = await fs.readFile(path);
const uploadResponse = await axios.post(`${baseUrl}/v2/upload`, audioData, {
  headers,
});
const uploadUrl = uploadResponse.data.upload_url;

const data = {
  audio_url: uploadUrl, // You can also use a URL to an audio or video file on the web
  //If you don't include the `speech_models` parameter, AssemblyAI will use the default Universal model.
  //To specify a different model—or multiple models, set the optional `speech_models` parameter as shown below.
  speech_models: ["slam-1", "universal"]
};

const url = `${baseUrl}/v2/transcript`;
const response = await axios.post(url, data, { headers: headers });

const transcriptId = response.data.id;
const pollingEndpoint = `${baseUrl}/v2/transcript/${transcriptId}`;

while (true) {
  const pollingResponse = await axios.get(pollingEndpoint, {
    headers: headers,
  });
  const transcriptionResult = pollingResponse.data;

  if (transcriptionResult.status === "completed") {
    console.log(transcriptionResult.text);
    break;
  } else if (transcriptionResult.status === "error") {
    throw new Error(`Transcription failed: ${transcriptionResult.error}`);
  } else {
    await new Promise((resolve) => setTimeout(resolve, 3000));
  }
}
```

</Tab>
<Tab language="csharp" title="C#">

You can change the model by setting the `speech_models` in the POST request body:

```csharp highlight={71} maxLines=15
using System;
using System.IO;
using System.Net.Http;
using System.Net.Http.Headers;
using System.Net.Http.Json;
using System.Text;
using System.Text.Json;
using System.Text.Json.Serialization;
using System.Threading.Tasks;

public class Transcript
{
    public string Id { get; set; }
    public string Status { get; set; }
    public string Text { get; set; }
    public string Error { get; set; }
}

class Program
{
    static void Main(string[] args)
    {
        MainAsync(args).GetAwaiter().GetResult();
    }

    static async Task MainAsync(string[] args)
    {
        using (var httpClient = new HttpClient())
        {
            httpClient.DefaultRequestHeaders.Add("authorization", "<YOUR-API-KEY>");

            var localFilePath = "audio.mp3";

            Console.WriteLine("Uploading file...");
            var uploadUrl = await UploadFileAsync(localFilePath, httpClient);

            Console.WriteLine("Creating transcript with speech_models...");
            var transcript = await CreateTranscriptAsync(uploadUrl, httpClient);

            Console.WriteLine("Waiting for transcript...");
            transcript = await WaitForTranscriptToProcess(transcript, httpClient);

            Console.WriteLine("Transcription completed!");
            Console.WriteLine("----------------------------------");
            Console.WriteLine(transcript.Text);
        }
    }

    static async Task<string> UploadFileAsync(string filePath, HttpClient httpClient)
    {
        using (var fileStream = File.OpenRead(filePath))
        using (var content = new StreamContent(fileStream))
        {
            content.Headers.ContentType = new MediaTypeHeaderValue("application/octet-stream");

            var response = await httpClient.PostAsync("https://api.assemblyai.com/v2/upload", content);
            response.EnsureSuccessStatusCode();

            var jsonDoc = await response.Content.ReadFromJsonAsync<JsonDocument>();
            return jsonDoc.RootElement.GetProperty("upload_url").GetString();
        }
    }

    static async Task<Transcript> CreateTranscriptAsync(string audioUrl, HttpClient httpClient)
    {
        var data = new
        {
            audio_url = audioUrl,
            //If you don't include the `speech_models` parameter, AssemblyAI will use the default Universal model.
            //To specify a different model—or multiple models, set the optional `speech_models` parameter as shown below.
            speech_models = new[] { "slam-1", "universal" }
        };

        var content = new StringContent(JsonSerializer.Serialize(data), Encoding.UTF8, "application/json");

        using (var response = await httpClient.PostAsync("https://api.assemblyai.com/v2/transcript", content))
        {
            response.EnsureSuccessStatusCode();
            return await response.Content.ReadFromJsonAsync<Transcript>();
        }
    }

    static async Task<Transcript> WaitForTranscriptToProcess(Transcript transcript, HttpClient httpClient)
    {
        var pollingEndpoint = $"https://api.assemblyai.com/v2/transcript/{transcript.Id}";

        while (true)
        {
            var pollingResponse = await httpClient.GetAsync(pollingEndpoint);
            transcript = await pollingResponse.Content.ReadFromJsonAsync<Transcript>();

            switch (transcript.Status)
            {
                case "processing":
                case "queued":
                    Console.WriteLine($"Status: {transcript.Status}... waiting...");
                    await Task.Delay(TimeSpan.FromSeconds(3));
                    break;
                case "completed":
                    return transcript;
                case "error":
                    throw new Exception($"Transcription failed: {transcript.Error}");
                default:
                    throw new Exception("Unexpected transcript status.");
            }
        }
    }
}
```

</Tab>
<Tab language="ruby" title="Ruby">

You can change the model by setting the `speech_models` in the POST request body:

```ruby highlight={25} maxLines=15
require 'net/http'
require 'json'

base_url = 'https://api.assemblyai.com'

headers = {
  'authorization' => '<YOUR_API_KEY>',
  'content-type' => 'application/json'
}

path = "./my-audio.mp3"
uri = URI("#{base_url}/v2/upload")
request = Net::HTTP::Post.new(uri, headers)
request.body = File.read(path)

http = Net::HTTP.new(uri.host, uri.port)
http.use_ssl = true
upload_response = http.request(request)
upload_url = JSON.parse(upload_response.body)["upload_url"]

data = {
    "audio_url" => upload_url, # You can also use a URL to an audio or video file on the web
    # If you don't include the `speech_models` parameter, AssemblyAI will use the default Universal model.
    # To specify a different model—or multiple models, set the optional `speech_models` parameter as shown below.
   "speech_models" => ["slam-1", "universal"]
}

uri = URI.parse("#{base_url}/v2/transcript")
http = Net::HTTP.new(uri.host, uri.port)
http.use_ssl = true

request = Net::HTTP::Post.new(uri.request_uri, headers)
request.body = data.to_json

response = http.request(request)
response_body = JSON.parse(response.body)

unless response.is_a?(Net::HTTPSuccess)
  raise "API request failed with status #{response.code}: #{response.body}"
end

transcript_id = response_body['id']
puts "Transcript ID: #{transcript_id}"

polling_endpoint = URI.parse("#{base_url}/v2/transcript/#{transcript_id}")

while true
  polling_http = Net::HTTP.new(polling_endpoint.host, polling_endpoint.port)
  polling_http.use_ssl = true
  polling_request = Net::HTTP::Get.new(polling_endpoint.request_uri, headers)
  polling_response = polling_http.request(polling_request)

  transcription_result = JSON.parse(polling_response.body)

  if transcription_result['status'] == 'completed'
    puts "Transcription text: #{transcription_result['text']}"
    break
  elsif transcription_result['status'] == 'error'
    raise "Transcription failed: #{transcription_result['error']}"
  else
    puts 'Waiting for transcription to complete...'
    sleep(3)
  end
end
```

</Tab>
<Tab language="php" title="PHP">

You can change the model by setting the `speech_models` in the POST request body:

```php highlight={32} maxLines=15
<?php
$ch = curl_init();
curl_setopt($ch, CURLOPT_RETURNTRANSFER, true);

$base_url = "https://api.assemblyai.com";

$headers = array(
"authorization: <YOUR_API_KEY>",
"content-type: application/json"
);

$path = "./my-audio.mp3";

$ch = curl_init();

curl_setopt($ch, CURLOPT_URL, $base_url . "/v2/upload");
curl_setopt($ch, CURLOPT_POST, 1);
curl_setopt($ch, CURLOPT_POSTFIELDS, file_get_contents($path));
curl_setopt($ch, CURLOPT_HTTPHEADER, $headers);
curl_setopt($ch, CURLOPT_RETURNTRANSFER, 1);

$response = curl_exec($ch);
$response_data = json_decode($response, true);
$upload_url = $response_data["upload_url"];

curl_close($ch);

$data = array(
    "audio_url" => $upload_url, // You can also use a URL to an audio or video file on the web
    //If you don't include the `speech_models` parameter, AssemblyAI will use the default Universal model.
    //To specify a different model—or multiple models, set the optional `speech_models` parameter as shown below.
    "speech_models" => array("slam-1", "universal")
);

$url = $base_url . "/v2/transcript";
$curl = curl_init($url);

curl_setopt($curl, CURLOPT_POST, true);
curl_setopt($curl, CURLOPT_POSTFIELDS, json_encode($data));
curl_setopt($curl, CURLOPT_HTTPHEADER, $headers);
curl_setopt($curl, CURLOPT_RETURNTRANSFER, true);

$response = curl_exec($curl);

$response = json_decode($response, true);

curl_close($curl);

$transcript_id = $response['id'];
echo "Transcript ID: $transcript_id\n";

$polling_endpoint = $base_url . "/v2/transcript/" . $transcript_id;

while (true) {
$polling_response = curl_init($polling_endpoint);

    curl_setopt($polling_response, CURLOPT_HTTPHEADER, $headers);
    curl_setopt($polling_response, CURLOPT_RETURNTRANSFER, true);

    $transcription_result = json_decode(curl_exec($polling_response), true);

    if ($transcription_result['status'] === "completed") {
        echo $transcription_result['text'];
        break;
    } else if ($transcription_result['status'] === "error") {
        throw new Exception("Transcription failed: " . $transcription_result['error']);
    } else {
        sleep(3);
    }

}
```

</Tab>
</Tabs>
