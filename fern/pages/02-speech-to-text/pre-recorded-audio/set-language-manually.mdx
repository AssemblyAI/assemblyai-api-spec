---
title: "Set Language Manually"
---

If you already know the dominant language, you can use the `language_code` key to specify the language of the speech in your audio file.

<CodeBlocks>

```python title="Python SDK" highlight={10} maxLines=15
import assemblyai as aai

aai.settings.api_key = "<YOUR_API_KEY>"

# audio_file = "./local_file.mp3"
audio_file = "https://assembly.ai/wildfires.mp3"

config = aai.TranscriptionConfig(
    speech_models=["universal-3-pro", "universal-2"],
    language_code="es"
)

transcript = aai.Transcriber(config=config).transcribe(audio_file)

if transcript.status == "error":
  raise RuntimeError(f"Transcription failed: {transcript.error}")

print(transcript.text)
```

```python title="Python" highlight={20} maxLines=15
import requests
import time

base_url = "https://api.assemblyai.com"

headers = {
    "authorization": "<YOUR_API_KEY>"
}

with open("./my-audio.mp3", "rb") as f:
  response = requests.post(base_url + "/v2/upload",
                          headers=headers,
                          data=f)

upload_url = response.json()["upload_url"]

data = {
    "audio_url": upload_url, # You can also use a URL to an audio or video file on the web
    "speech_models": ["universal-3-pro", "universal-2"],
    "language_code": "es"
}

url = base_url + "/v2/transcript"
response = requests.post(url, json=data, headers=headers)

transcript_id = response.json()['id']
polling_endpoint = base_url + "/v2/transcript/" + transcript_id

while True:
  transcription_result = requests.get(polling_endpoint, headers=headers).json()

  if transcription_result['status'] == 'completed':
    print(f"Transcript ID:", transcript_id)
    break

  elif transcription_result['status'] == 'error':
    raise RuntimeError(f"Transcription failed: {transcription_result['error']}")

  else:
    time.sleep(3)

```

```javascript title="JavaScript SDK" highlight={13} maxLines=15
import { AssemblyAI } from "assemblyai";

const client = new AssemblyAI({
  apiKey: "<YOUR_API_KEY>",
});

// const audioFile = './local_file.mp3'
const audioFile = "https://assembly.ai/wildfires.mp3";

const params = {
  audio: audioFile,
  speech_models: ["universal-3-pro", "universal-2"],
  language_code: "es",
};

const run = async () => {
  const transcript = await client.transcripts.transcribe(params);

  console.log(transcript.text);
};

run();
```

```javascript title="JavaScript" highlight={20} maxLines=15
import axios from "axios";
import fs from "fs-extra";

const baseUrl = "https://api.assemblyai.com";

const headers = {
  authorization: "<YOUR_API_KEY>",
};

const path = "./my-audio.mp3";
const audioData = await fs.readFile(path);
const uploadResponse = await axios.post(`${baseUrl}/v2/upload`, audioData, {
  headers,
});
const uploadUrl = uploadResponse.data.upload_url;

const data = {
  audio_url: uploadUrl, // You can also use a URL to an audio or video file on the web
  speech_models: ["universal-3-pro", "universal-2"],
  language_code: "es",
};

const url = `${baseUrl}/v2/transcript`;
const response = await axios.post(url, data, { headers: headers });

const transcriptId = response.data.id;
const pollingEndpoint = `${baseUrl}/v2/transcript/${transcriptId}`;

while (true) {
  const pollingResponse = await axios.get(pollingEndpoint, {
    headers: headers,
  });
  const transcriptionResult = pollingResponse.data;

  if (transcriptionResult.status === "completed") {
    console.log(transcriptionResult.text);
    break;
  } else if (transcriptionResult.status === "error") {
    throw new Error(`Transcription failed: ${transcriptionResult.error}`);
  } else {
    await new Promise((resolve) => setTimeout(resolve, 3000));
  }
}
```

</CodeBlocks>

See the [Supported languages](#supported-languages) section below for all supported languages and their codes.

## Supported languages

AssemblyAI offers two different levels of speech-to-text models for pre-recorded audio: **Universal-3-Pro** and **Universal-2**. Check out the [Models](/docs/getting-started/models) page of our documentation to learn more about our different models and how to choose the best one for your use case.

### Universal-3-Pro

<iframe
  className="airtable-embed"
  src="https://airtable.com/embed/apptQjwE6ZsC2Zfoi/shr0akLmAjn8bE9RP?backgroundColor=green"
  width="100%"
  height="225"
  style={{ background: "transparent", border: "1px solid #ccc" }}
/>
<noscript>
  <BestLanguageTable />
</noscript>

### Universal-2

<iframe
  className="airtable-embed"
  src="https://airtable.com/embed/appAHNKtjqyFB83AF/shrhQFfUxq1PROjTf?backgroundColor=green"
  width="100%"
  height="533"
  style={{ background: "transparent", border: "1px solid #ccc" }}
/>
<noscript>
  <BestLanguageTable />
</noscript>

**Breakdown of Universal-2 language support**

<AccordionGroup>
  
  <Accordion title="High accuracy (≤ 10% WER)">
    English, Spanish, French, German, Indonesian, Italian, Japanese, Dutch, Polish, Portuguese, Russian, Turkish, Ukrainian, Catalan
  </Accordion>

<Accordion title="Good accuracy (>10% to ≤25% WER)">
  Arabic, Azerbaijani, Bulgarian, Bosnian, Mandarin Chinese, Czech, Danish,
  Greek, Estonian, Finnish, Filipino, Galician, Hindi, Croatian, Hungarian,
  Korean, Macedonian, Malay, Norwegian, Romanian, Slovak, Swedish, Swiss German, Thai,
  Urdu, Vietnamese
</Accordion>

<Accordion title="Moderate accuracy (>25% to ≤50% WER)">
  Afrikaans, Belarusian, Welsh, Persian (Farsi), Hebrew, Armenian, Icelandic,
  Kazakh, Lithuanian, Latvian, Māori, Marathi, Slovenian, Swahili, Tamil
</Accordion>

<Accordion title="Fair accuracy (>50% WER)">
  Amharic, Assamese, Bengali, Gujarati, Hausa, Javanese, Georgian, Khmer,
  Kannada, Luxembourgish, Lingala, Lao, Malayalam, Mongolian, Maltese, Burmese,
  Nepali, Occitan, Punjabi, Pashto, Sindhi, Shona, Somali, Serbian, Telugu,
  Tajik, Uzbek, Yoruba
</Accordion>

</AccordionGroup>
