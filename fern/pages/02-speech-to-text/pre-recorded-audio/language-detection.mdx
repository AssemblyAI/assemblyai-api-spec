---
title: "Language detection"
---

This page explains how to configure language settings for your transcription requests. By default, automatic language detection is enabled and will identify the dominant language in your audio. You can also set the language manually if you know it in advance.

## Supported languages

AssemblyAI offers two different levels of speech-to-text models for pre-recorded audio: **Universal-2** and **Universal-3-Pro**. Check out the [Models](/docs/getting-started/models) page of our documentation to learn more about our different models and how to choose the best one for your use case.

### Supported languages and features for Universal-2

<iframe
  className="airtable-embed"
  src="https://airtable.com/embed/appAHNKtjqyFB83AF/shrhQFfUxq1PROjTf?backgroundColor=green"
  width="100%"
  height="533"
  style={{ background: "transparent", border: "1px solid #ccc" }}
/>
<noscript>
  <BestLanguageTable />
</noscript>

#### Breakdown of Universal-2 language support

<AccordionGroup>
  
  <Accordion title="High accuracy (≤ 10% WER)">
    English, Spanish, French, German, Indonesian, Italian, Japanese, Dutch, Polish, Portuguese, Russian, Turkish, Ukrainian, Catalan
  </Accordion>

<Accordion title="Good accuracy (>10% to ≤25% WER)">
  Arabic, Azerbaijani, Bulgarian, Bosnian, Mandarin Chinese, Czech, Danish,
  Greek, Estonian, Finnish, Filipino, Galician, Hindi, Croatian, Hungarian,
  Korean, Macedonian, Malay, Norwegian, Romanian, Slovak, Swedish, Swiss German, Thai,
  Urdu, Vietnamese
</Accordion>

<Accordion title="Moderate accuracy (>25% to ≤50% WER)">
  Afrikaans, Belarusian, Welsh, Persian (Farsi), Hebrew, Armenian, Icelandic,
  Kazakh, Lithuanian, Latvian, Māori, Marathi, Slovenian, Swahili, Tamil
</Accordion>

<Accordion title="Fair accuracy (>50% WER)">
  Amharic, Assamese, Bengali, Gujarati, Hausa, Javanese, Georgian, Khmer,
  Kannada, Luxembourgish, Lingala, Lao, Malayalam, Mongolian, Maltese, Burmese,
  Nepali, Occitan, Punjabi, Pashto, Sindhi, Shona, Somali, Serbian, Telugu,
  Tajik, Uzbek, Yoruba
</Accordion>

</AccordionGroup>

### Supported languages and features for Universal-3-Pro

<iframe
  className="airtable-embed"
  src="https://airtable.com/embed/apptQjwE6ZsC2Zfoi/shr0akLmAjn8bE9RP?backgroundColor=green"
  width="100%"
  height="225"
  style={{ background: "transparent", border: "1px solid #ccc" }}
/>
<noscript>
  <BestLanguageTable />
</noscript>

## Automatic language detection

Automatic language detection is enabled by default. When enabled, the model identifies the dominant language in your audio and transcribes accordingly. Language detection requires at least 15 seconds of spoken audio to identify the language accurately.

<CodeBlocks>

```python title="Python SDK" for="python-sdk" highlight={8} maxLines=15
import assemblyai as aai

aai.settings.api_key = "<YOUR_API_KEY>"

# audio_file = "./local_file.mp3"
audio_file = "https://assembly.ai/wildfires.mp3"

config = aai.TranscriptionConfig(language_detection=True)

transcript = aai.Transcriber(config=config).transcribe(audio_file)

print(transcript.text)
print(transcript.json_response["language_code"])
```

```python title="Python" for="python" highlight={19} maxLines=15
import requests
import time

base_url = "https://api.assemblyai.com"

headers = {
    "authorization": "<YOUR_API_KEY>"
}

with open("./my-audio.mp3", "rb") as f:
  response = requests.post(base_url + "/v2/upload",
                          headers=headers,
                          data=f)

upload_url = response.json()["upload_url"]

data = {
    "audio_url": upload_url,
    "language_detection": True,
}

url = base_url + "/v2/transcript"
response = requests.post(url, json=data, headers=headers)

transcript_id = response.json()['id']
polling_endpoint = base_url + "/v2/transcript/" + transcript_id

while True:
  transcription_result = requests.get(polling_endpoint, headers=headers).json()

  if transcription_result['status'] == 'completed':
    print(f"Transcript ID:", transcript_id)
    print(f"Language Code:", transcription_result['language_code'])
    print(f"Text:", transcription_result['text'])
    break

  elif transcription_result['status'] == 'error':
    raise RuntimeError(f"Transcription failed: {transcription_result['error']}")

  else:
    time.sleep(3)

```

```javascript title="JavaScript SDK" for="javascript-sdk" highlight={12} maxLines=15
import { AssemblyAI } from "assemblyai";

const client = new AssemblyAI({
  apiKey: "<YOUR_API_KEY>",
});

// const audioFile = './local_file.mp3'
const audioFile = "https://assembly.ai/wildfires.mp3";

const params = {
  audio: audioFile,
  language_detection: true,
};

const run = async () => {
  const transcript = await client.transcripts.transcribe(params);

  console.log(transcript.text);
  console.log(transcript.language_code);
};

run();
```

```javascript title="JavaScript" for="javascript" highlight={19} maxLines=15
import axios from "axios";
import fs from "fs-extra";

const baseUrl = "https://api.assemblyai.com";

const headers = {
  authorization: "<YOUR_API_KEY>",
};

const path = "./my-audio.mp3";
const audioData = await fs.readFile(path);
const uploadResponse = await axios.post(`${baseUrl}/v2/upload`, audioData, {
  headers,
});
const uploadUrl = uploadResponse.data.upload_url;

const data = {
  audio_url: uploadUrl,
  language_detection: true,
};

const url = `${baseUrl}/v2/transcript`;
const response = await axios.post(url, data, { headers: headers });

const transcriptId = response.data.id;
const pollingEndpoint = `${baseUrl}/v2/transcript/${transcriptId}`;

while (true) {
  const pollingResponse = await axios.get(pollingEndpoint, {
    headers: headers,
  });
  const transcriptionResult = pollingResponse.data;

  if (transcriptionResult.status === "completed") {
    console.log(transcriptionResult.text);
    console.log(transcriptionResult.language_code);
    break;
  } else if (transcriptionResult.status === "error") {
    throw new Error(`Transcription failed: ${transcriptionResult.error}`);
  } else {
    await new Promise((resolve) => setTimeout(resolve, 3000));
  }
}
```

</CodeBlocks>

### Set a list of expected languages

If you're confident the audio is in one of a few languages, provide that list via `language_detection_options.expected_languages`. Detection is restricted to these candidates and the model will choose the language with the highest confidence from this list. This can eliminate scenarios where Automatic Language Detection selects an unexpected language for transcription.

- Use the [supported language codes](#supported-languages) (e.g., `"en"`, `"es"`, `"fr"`).
- If `expected_languages` is not specified, it is set to `["all"]` by default.

<CodeBlocks>

```python title="Python SDK" for="python-sdk" highlight={9} maxLines=15
import assemblyai as aai

aai.settings.api_key = "<YOUR_API_KEY>"

# audio_file = "./local_file.mp3"
audio_file = "https://assembly.ai/wildfires.mp3"

options = aai.LanguageDetectionOptions(
    expected_languages=["en", "es", "fr", "de"],
    fallback_language="auto"
)

config = aai.TranscriptionConfig(language_detection=True, language_detection_options=options)

transcript = aai.Transcriber(config=config).transcribe(audio_file)

print(transcript.text)
print(transcript.json_response["language_code"])
```

```python title="Python" for="python" highlight={21} maxLines=15
import requests
import time

base_url = "https://api.assemblyai.com"

headers = {
    "authorization": "<YOUR_API_KEY>"
}

with open("./my-audio.mp3", "rb") as f:
  response = requests.post(base_url + "/v2/upload",
                          headers=headers,
                          data=f)

upload_url = response.json()["upload_url"]

data = {
    "audio_url": upload_url,
    "language_detection": True,
    "language_detection_options": {
      "expected_languages": ["en", "es", "fr", "de"],
      "fallback_language": "auto"
  }
}

url = base_url + "/v2/transcript"
response = requests.post(url, json=data, headers=headers)

transcript_id = response.json()['id']
polling_endpoint = base_url + "/v2/transcript/" + transcript_id

while True:
  transcription_result = requests.get(polling_endpoint, headers=headers).json()

  if transcription_result['status'] == 'completed':
    print(f"Transcript ID:", transcript_id)
    print(f"Language Code:", transcription_result['language_code'])
    print(f"Text:", transcription_result['text'])
    break

  elif transcription_result['status'] == 'error':
    raise RuntimeError(f"Transcription failed: {transcription_result['error']}")

  else:
    time.sleep(3)

```

```javascript title="JavaScript SDK" for="javascript-sdk" highlight={14} maxLines=15
import { AssemblyAI } from "assemblyai";

const client = new AssemblyAI({
  apiKey: "<YOUR_API_KEY>",
});

// const audioFile = './local_file.mp3'
const audioFile = "https://assembly.ai/wildfires.mp3";

const params = {
  audio: audioFile,
  language_detection: true,
  language_detection_options: {
    expected_languages: ["en", "es", "fr", "de"],
    fallback_language: "auto",
  },
};

const run = async () => {
  const transcript = await client.transcripts.transcribe(params);

  console.log(transcript.text);
  console.log(transcript.language_code);
};

run();
```

```javascript title="JavaScript" for="javascript" highlight={21} maxLines=15
import axios from "axios";
import fs from "fs-extra";

const baseUrl = "https://api.assemblyai.com";

const headers = {
  authorization: "<YOUR_API_KEY>",
};

const path = "./my-audio.mp3";
const audioData = await fs.readFile(path);
const uploadResponse = await axios.post(`${baseUrl}/v2/upload`, audioData, {
  headers,
});
const uploadUrl = uploadResponse.data.upload_url;

const data = {
  audio_url: uploadUrl,
  language_detection: true,
  language_detection_options: {
    expected_languages: ["en", "es", "fr", "de"],
    fallback_language: "auto",
  },
};

const url = `${baseUrl}/v2/transcript`;
const response = await axios.post(url, data, { headers: headers });

const transcriptId = response.data.id;
const pollingEndpoint = `${baseUrl}/v2/transcript/${transcriptId}`;

while (true) {
  const pollingResponse = await axios.get(pollingEndpoint, {
    headers: headers,
  });
  const transcriptionResult = pollingResponse.data;

  if (transcriptionResult.status === "completed") {
    console.log(transcriptionResult.text);
    console.log(transcriptionResult.language_code);
    break;
  } else if (transcriptionResult.status === "error") {
    throw new Error(`Transcription failed: ${transcriptionResult.error}`);
  } else {
    await new Promise((resolve) => setTimeout(resolve, 3000));
  }
}
```

</CodeBlocks>

### Choose a fallback language

Control what language transcription should fall back to when detection cannot confidently select a language from the `expected_languages` list.

- Set `language_detection_options.fallback_language` to a specific language code (e.g., `"en"`).
- `fallback_language` must be one of the language codes in `expected_languages` or `"auto"`.
- When `fallback_language` is unspecified, it is set to `"auto"` by default. This tells our model to choose the fallback language from `expected_languages` with the highest confidence score.

<CodeBlocks>

```python title="Python SDK" for="python-sdk" highlight={10} maxLines=15
import assemblyai as aai

aai.settings.api_key = "<YOUR_API_KEY>"

# audio_file = "./local_file.mp3"
audio_file = "https://assembly.ai/wildfires.mp3"

options = aai.LanguageDetectionOptions(
    expected_languages=["en", "es", "fr", "de"],
    fallback_language="en"
)

config = aai.TranscriptionConfig(language_detection=True, language_detection_options=options)

transcript = aai.Transcriber(config=config).transcribe(audio_file)

print(transcript.text)
print(transcript.json_response["language_code"])
```

```javascript title="JavaScript SDK" for="javascript-sdk" highlight={15} maxLines=15
import { AssemblyAI } from "assemblyai";

const client = new AssemblyAI({
  apiKey: "<YOUR_API_KEY>",
});

// const audioFile = './local_file.mp3'
const audioFile = "https://assembly.ai/wildfires.mp3";

const params = {
  audio: audioFile,
  language_detection: true,
  language_detection_options: {
    expected_languages: ["en", "es", "fr", "de"],
    fallback_language: "en",
  },
};

const run = async () => {
  const transcript = await client.transcripts.transcribe(params);

  console.log(transcript.text);
  console.log(transcript.language_code);
};

run();
```

</CodeBlocks>

### Confidence score

If language detection is enabled, the API returns a confidence score for the detected language. The score ranges from 0.0 (low confidence) to 1.0 (high confidence).

<CodeBlocks>

```python title="Python SDK" for="python-sdk" highlight={8,13} maxLines=15
import assemblyai as aai

aai.settings.api_key = "<YOUR_API_KEY>"

# audio_file = "./local_file.mp3"
audio_file = "https://assembly.ai/wildfires.mp3"

config = aai.TranscriptionConfig(language_detection=True)

transcript = aai.Transcriber(config=config).transcribe(audio_file)

print(transcript.text)
print(transcript.json_response["language_confidence"])
```

```javascript title="JavaScript SDK" for="javascript-sdk" highlight={19} maxLines=15
import { AssemblyAI } from "assemblyai";

const client = new AssemblyAI({
  apiKey: "<YOUR_API_KEY>",
});

// const audioFile = './local_file.mp3'
const audioFile = "https://assembly.ai/wildfires.mp3";

const params = {
  audio: audioFile,
  language_detection: true,
};

const run = async () => {
  const transcript = await client.transcripts.transcribe(params);

  console.log(transcript.text);
  console.log(transcript.language_confidence);
};

run();
```

</CodeBlocks>

### Set a language confidence threshold

You can set the confidence threshold that must be reached if language detection is enabled. An error will be returned if the language confidence is below this threshold. Valid values are in the range [0,1] inclusive.

<CodeBlocks>

```python title="Python SDK" for="python-sdk" highlight={8,13} maxLines=15
import assemblyai as aai

aai.settings.api_key = "<YOUR_API_KEY>"

# audio_file = "./local_file.mp3"
audio_file = "https://assembly.ai/wildfires.mp3"

config = aai.TranscriptionConfig(language_detection=True, language_confidence_threshold=0.8)

transcript = aai.Transcriber(config=config).transcribe(audio_file)

if transcript.status == "error":
  raise RuntimeError(f"Transcription failed: {transcript.error}")
else:
  print(transcript.json_response["language_confidence"])
  print(transcript.text)
```

```javascript title="JavaScript SDK" for="javascript-sdk" highlight={13} maxLines=15
import { AssemblyAI } from "assemblyai";

const client = new AssemblyAI({
  apiKey: "<YOUR_API_KEY>",
});

// const audioFile = './local_file.mp3'
const audioFile = "https://assembly.ai/wildfires.mp3";

const params = {
  audio: audioFile,
  language_detection: true,
  language_confidence_threshold: 0.8,
};

const run = async () => {
  const transcript = await client.transcripts.transcribe(params);

  if (transcript.status === "error") {
    throw new Error(`Transcription failed: ${transcript.error}`);
  }

  console.log(transcript.text);
  console.log(transcript.language_confidence);
};

run();
```

</CodeBlocks>

## Set language manually

If you already know the dominant language, you can use the `language_code` parameter to specify the language of the speech in your audio file. If you don't include a `language_code` parameter in your request, it defaults to `en_us`.

<CodeBlocks>

```python title="Python SDK" highlight={8} maxLines=15
import assemblyai as aai

aai.settings.api_key = "<YOUR_API_KEY>"

# audio_file = "./local_file.mp3"
audio_file = "https://assembly.ai/wildfires.mp3"

config = aai.TranscriptionConfig(language_code="es")

transcript = aai.Transcriber(config=config).transcribe(audio_file)

if transcript.status == "error":
  raise RuntimeError(f"Transcription failed: {transcript.error}")

print(transcript.text)
```

```python title="Python" highlight={19} maxLines=15
import requests
import time

base_url = "https://api.assemblyai.com"

headers = {
    "authorization": "<YOUR_API_KEY>"
}

with open("./my-audio.mp3", "rb") as f:
  response = requests.post(base_url + "/v2/upload",
                          headers=headers,
                          data=f)

upload_url = response.json()["upload_url"]

data = {
    "audio_url": upload_url,
    "language_code": "es"
}

url = base_url + "/v2/transcript"
response = requests.post(url, json=data, headers=headers)

transcript_id = response.json()['id']
polling_endpoint = base_url + "/v2/transcript/" + transcript_id

while True:
  transcription_result = requests.get(polling_endpoint, headers=headers).json()

  if transcription_result['status'] == 'completed':
    print(f"Transcript ID:", transcript_id)
    break

  elif transcription_result['status'] == 'error':
    raise RuntimeError(f"Transcription failed: {transcription_result['error']}")

  else:
    time.sleep(3)

```

```javascript title="JavaScript SDK" highlight={12} maxLines=15
import { AssemblyAI } from "assemblyai";

const client = new AssemblyAI({
  apiKey: "<YOUR_API_KEY>",
});

// const audioFile = './local_file.mp3'
const audioFile = "https://assembly.ai/wildfires.mp3";

const params = {
  audio: audioFile,
  language_code: "es",
};

const run = async () => {
  const transcript = await client.transcripts.transcribe(params);

  console.log(transcript.text);
};

run();
```

```javascript title="JavaScript" highlight={19} maxLines=15
import axios from "axios";
import fs from "fs-extra";

const baseUrl = "https://api.assemblyai.com";

const headers = {
  authorization: "<YOUR_API_KEY>",
};

const path = "./my-audio.mp3";
const audioData = await fs.readFile(path);
const uploadResponse = await axios.post(`${baseUrl}/v2/upload`, audioData, {
  headers,
});
const uploadUrl = uploadResponse.data.upload_url;

const data = {
  audio_url: uploadUrl,
  language_code: "es",
};

const url = `${baseUrl}/v2/transcript`;
const response = await axios.post(url, data, { headers: headers });

const transcriptId = response.data.id;
const pollingEndpoint = `${baseUrl}/v2/transcript/${transcriptId}`;

while (true) {
  const pollingResponse = await axios.get(pollingEndpoint, {
    headers: headers,
  });
  const transcriptionResult = pollingResponse.data;

  if (transcriptionResult.status === "completed") {
    console.log(transcriptionResult.text);
    break;
  } else if (transcriptionResult.status === "error") {
    throw new Error(`Transcription failed: ${transcriptionResult.error}`);
  } else {
    await new Promise((resolve) => setTimeout(resolve, 3000));
  }
}
```

</CodeBlocks>

See the [Supported languages](#supported-languages) section above for all supported languages and their codes.
