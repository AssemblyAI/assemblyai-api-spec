---
title: 'Multichannel transcription'
description: 'Multichannel transcription in AssemblyAI Speech-to-Text API'
---

If you have a multichannel audio file with multiple speakers, you can transcribe each of them separately.

<Tabs groupId="language">
  <Tab language="python" title="Python" default>
To enable it, set `multichannel` to `True` in your transcription config.

```python {1}
config = aai.TranscriptionConfig(multichannel=True)

transcriber = aai.Transcriber(config=config)
transcript = transcriber.transcribe(audio_url)

print(transcript.json_response["audio_channels"])

print(transcript.utterances)
```

  </Tab>
  <Tab language="typescript" title="TypeScript">
To enable it, set `multichannel` to `true` in the transcription parameters.

```ts {3}
const params = {
  audio: audioUrl,
  multichannel: true
}

const transcript = await client.transcripts.transcribe(params)
console.log(transcript.utterances)
```

  </Tab>
  <Tab language="golang" title="Go">
To enable it, set `Multichannel` to `true` in the transcription parameters.

```go {2}
transcript, _ := client.Transcripts.TranscribeFromURL(ctx, audioURL, &aai.TranscriptOptionalParams{
    Multichannel: aai.Bool(true),
})
```

  </Tab>
  <Tab language="java" title="Java">
To enable it, set `multichannel` to `true` in the transcription parameters.

```java {2}
var params = TranscriptOptionalParams.builder()
                .multichannel(true)
                .build();

Transcript transcript = client.transcripts().transcribe(audioUrl, params);

System.out.println(transcript.getUtterances());
```

  </Tab>
  <Tab language="csharp" title="C#">
To enable it, set `Multichannel` to `true` in the transcription parameters.

```csharp {4}
var transcript = await client.Transcripts.TranscribeAsync(new TranscriptParams
{
    AudioUrl = audioUrl,
    Multichannel = true
});

foreach (var utterance in transcript.Utterances!)
{
    Console.WriteLine($"Speaker: {utterance.Speaker}, Word: {utterance.Text}");
}
```

  </Tab>
  <Tab language="ruby" title="Ruby">
To enable it, set `multichannel` to `true` in the transcription parameters.

```ruby {3}
transcript = client.transcripts.transcribe(
  audio_url: audio_url,
  multichannel: true
)

p transcript.utterances
```

  </Tab>
</Tabs>

<Note>

Multichannel audio increases the transcription time by approximately 25%.

The response includes an `audio_channels` property with the number of different channels, and an additional `utterances` property, containing a list of turn-by-turn utterances.

Each utterance contains channel information, starting at 1.

Additionally, each word in the `words` array contains the channel identifier.

</Note>