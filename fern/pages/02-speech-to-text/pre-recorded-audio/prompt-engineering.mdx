---
title: "Customizing transcription results using Prompt Engineering"
---

import { PromptGenerator } from "../../../assets/components/PromptGenerator";
import { PromptLibrary } from "../../../assets/components/PromptLibrary";


Use prompt engineering to control transcription style and improve accuracy for domain-specific terminology. This guide documents best practices for crafting effective prompts for Universal-3-Pro speech transcription.

## How prompting works

SpeechLLM prompting works more like **selecting modes and knobs** than open-ended instruction following. The model is trained primarily to transcribe, then fine-tuned to respond to common transcription instructions for style, speakers, and speech events.

### What prompts CAN do

| Capability | Description | Reliability |
|------------|-------------|-------------|
| **Add disfluencies** | Include um, uh, false starts, repetitions, stutters | High |
| **Format output** | Control punctuation, capitalization, number formatting | High |
| **Speaker attribution** | Mark speaker turns and add labels | High |
| **Preserve speech patterns** | Keep natural hesitations and self-corrections | High |
| **Audio event tags** | Mark laughter, music, applause, background sounds | Medium |
| **Code-switching** | Handle multilingual audio in same transcript | Medium |
| **Domain terminology** | Improve accuracy for medical, legal, technical terms | Medium |

### What prompts CANNOT reliably do

| Limitation | Why |
|------------|-----|
| **Invent correct spellings** | Unknown rare words need hotwords or context injection |
| **Resolve ambiguous audio** | The model transcribes what it hears, not what it infers |
| **Perfect proper nouns** | Names and brands may need a second-pass correction |
| **Translate content** | Code-switching preserves language, doesn't translate |

For consistent proper-noun accuracy or domain vocabulary, you'll usually need **context injection, hotwords/candidate lists, or a second-pass correction step**.

---

## Prompt generator

This prompt generator helps you create a starting prompt based on your selected transcription style. Paste a sample of your transcript and select your preferred style to get a customized prompt recommendation.

<PromptGenerator />

## Prompt library

Browse community-submitted prompts, vote on the ones that work best, and share your own.

<PromptLibrary />

---

## Prompt capabilities

Each capability below acts as a "knob" you can turn. Combine 3-5 capabilities maximum for best results.

### 1. Verbatim transcription and disfluencies

**What it does:** Preserves natural speech patterns including filler words, false starts, repetitions, and self-corrections.

**Reliability:** High

**Example prompts:**

```text
Include spoken filler words like "um," "uh," "you know," "like," plus repetitions
and false starts when clearly spoken.
```

```text
Preserve all disfluencies exactly as spoken including verbal hesitations,
restarts, and self-corrections (um, uh, I—I mean).
```

```text
Transcribe verbatim:
- Fillers: yes (um, uh, like, you know)
- Repetitions: yes (I I, the the the)
- Stutters: yes (th-that, b-but)
- False starts: yes (I was— I went)
- Colloquial: yes (gonna, wanna, gotta)
```

**Key insight from testing:** 71% of top-performing prompts explicitly mention "um/uh" versus only 2.4% of bottom-performing prompts. This is the single largest differentiator.

---

### 2. Output style and formatting

**What it does:** Controls punctuation, capitalization, and readability without changing words.

**Reliability:** High

**Example prompts:**

```text
Transcribe this audio with beautiful punctuation and formatting.
```

```text
Use expressive punctuation to reflect emotion and prosody.
```

```text
Use standard punctuation and sentence breaks for readability.
```

---

### 3. Entity accuracy and spelling

**What it does:** Improves accuracy for proper nouns, brands, technical terms, and domain vocabulary.

**Reliability:** Medium (works best with explicit examples)

**Example prompts:**

```text
Use standard spelling and the most contextually correct spelling of all words
including names, brands, drug names, medical terms, and proper nouns.
```

```text
Non-negotiable: Pharmaceutical accuracy required (omeprazole over omeprizole,
metformin over metforman).
```

```text
Preserve acronyms and capitalization (EBITDA over ebitda, API over A.P.I.).
```

**Why examples work:** The model learns **error patterns** from examples, not just specific words. When you show `(omeprazole over omeprizole)`, the model learns "fix vowel substitution errors in pharmaceutical terms" and applies this to ALL drugs.

---

### 4. Speaker attribution

**What it does:** Marks speaker turns and adds identifying labels.

**Reliability:** High

**Example prompts:**

```text
Mark speaker turns clearly.
```

```text
Tag speaker changes with context like name, role, or gender based on speech content.
```

```text
Label speakers by role when identifiable (Justice Roberts:, Petitioner's Counsel:).
```

**Caution:** Over-focusing on speaker labels at the expense of content capture can hurt overall quality. Always combine with verbatim instructions.

---

### 5. Audio event tags

**What it does:** Marks non-speech sounds like music, laughter, applause, and background noise.

**Reliability:** Medium

**Example prompts:**

```text
Preserve non-speech audio in tags to indicate when the audio occurred.
```

```text
Tag sounds: [laughter], [silence], [noise], [cough], [sigh].
```

```text
Include audio event markers for music, laughter, and applause.
```

**Caution:** Over-specifying tag formats can increase hallucinated markers. Use sparingly.

---

### 6. Code-switching and multilingual

**What it does:** Handles audio where speakers switch between languages.

**Reliability:** Medium

**Example prompts:**

```text
Transcribe in the original language mix (code-switching), preserving words
in the language they are spoken.
```

```text
Preserve natural code-switching between English and Spanish. Retain spoken
language as-is (correct "I was hablando con mi manager").
```

**Note:** Requires `language_detection: true` on your request. If a single language code is specified, the model will try to transcribe only that language.

---

### 7. Numbers and measurements

**What it does:** Controls how numbers, percentages, and measurements are formatted.

**Reliability:** Medium

**Example prompts:**

```text
Convert spoken numbers to digits.
```

```text
Use digits for numbers, percentages, and measurements.
```

```text
Format financial figures with standard notation (Q3 revenue over third quarter revenue).
```

---

### 8. Difficult audio handling

**What it does:** Provides guidance for unclear audio, overlapping speech, and interruptions.

**Reliability:** Medium (YMMV)

**Example prompts:**

```text
If unintelligible, write (unclear).
```

```text
Mark inaudible segments. Preserve overlapping speech and crosstalk.
```

```text
Include pause markers where the speaker hesitates significantly.
```

---

## Best practices

### Data-driven findings

Based on analysis of **15,000 prompts** across 15 audio files, comparing top 700 vs bottom 700 performing prompts:

| Metric | Top 700 | Bottom 700 | Insight |
|--------|---------|------------|---------|
| **Average length** | 57.6 words | 23.5 words | Longer prompts perform 2.5x better |
| **Mentions "um/uh"** | 71.0% | 2.4% | Explicit disfluency examples are critical |
| **Uses "preserve"** | 83.9% | 31.0% | Preservation language signals intent |
| **Uses "Mandatory"** | 93.1% | 59.3% | Authoritative language helps |
| **Avg verbatim score** | +467 | +40 | Top prompts add 11.7x more content |

### What helps

| Practice | Impact | Example |
|----------|--------|---------|
| **Explicit disfluency examples** | Massive | `(um, uh, I—I mean over cleaned speech)` |
| **Authoritative language** | High | `Mandatory:`, `Non-negotiable:`, `Required:` |
| **Contrast examples (X over Y)** | High | `(omeprazole over omeprizole)` |
| **50-70 word prompts** | High | Long enough for specificity, short enough to follow |
| **3-5 instructions maximum** | High | Prevents conflicting instructions |

### What hurts

| Anti-pattern | Impact | Why it fails |
|--------------|--------|--------------|
| **Prompts under 30 words** | Severe | Lack specificity for model to learn from |
| **Missing disfluency instructions** | Severe | Model defaults to clean transcription |
| **Format-only focus** | High | Speaker labels without content capture |
| **Negative language** | High | "Don't", "never", "avoid" confuse the model |
| **Conflicting instructions** | High | "Include disfluencies" + "clean grammar" |
| **Vague instructions** | Medium | "Be accurate" provides no error pattern |
| **Over-specified tag formats** | Medium | Can increase hallucinated markers |

### What doesn't hurt

These additions provide marginal benefit but won't degrade quality:

- Adding a short context line
- Adding a single formatting rule (digits for numbers)
- Adding speaker turn markers

---

## Domain-specific sample prompts

### Legal transcription

Best for: Court proceedings, depositions, legal hearings

```text
Mandatory: Transcribe legal proceedings with precise terminology intact.

Required: Preserve all disfluencies including verbal pauses, false starts, and
self-corrections (uh, um, I—I mean over cleaned speech).

Non-negotiable: Distinguish between speakers through clear attribution
(Justice Roberts: over generic labels).

Capture Latin legal phrases exactly as spoken (certiorari, habeas corpus,
amicus curiae).
```

**Why it works:** Combines authoritative language (Mandatory, Required, Non-negotiable), explicit disfluency examples with contrast format, speaker attribution guidance, and domain terminology.

---

### Medical transcription

Best for: Clinical consultations, medical dictation, patient encounters

```text
Mandatory: Preserve all clinical terminology exactly as spoken including drug
names, dosages, and diagnostic terms.

Required: Capture every hesitation, false start, and filler word (um, uh, ah)
as spoken.

Non-negotiable: Pharmaceutical accuracy (omeprazole over omeprizole,
metformin over metforman, hypertension over high blood pressure).

Label physician and patient speech clearly when identifiable.
```

**Why it works:** Prioritizes medical accuracy with explicit drug name examples showing error patterns, while preserving verbatim speech for documentation compliance.

---

### Financial/Earnings calls

Best for: Quarterly earnings calls, investor presentations, financial meetings

```text
Mandatory: Corporate earnings call transcription with precise financial
terminology.

Required: Preserve all speaker disfluencies including hesitations, false starts,
and filler words (um, uh, you know) exactly as spoken.

Non-negotiable: Financial term accuracy (EBITDA over ebitda, year-over-year
over y-o-y, basis points over bps).

Format numerical data with standard notation. Label executive speakers by role
when identifiable (CEO:, CFO:, Analyst:).
```

**Why it works:** Balances financial terminology precision with verbatim capture of executive speech patterns important for tone analysis.

---

### Software/Technical meetings

Best for: Engineering standups, code reviews, technical discussions

```text
Mandatory: Technical meeting transcription with multiple participants.

Required: Preserve all verbal disfluencies including hesitations, false starts,
and thinking sounds (um, uh, hmm, so) exactly as spoken.

Non-negotiable: Technical terminology accuracy (Kubernetes over kubernetties,
PostgreSQL over postgres, API over A.P.I.).

Mark speaker transitions explicitly. Capture self-corrections and restarts
(I was— I went, th-that).
```

**Why it works:** Preserves natural developer speech patterns while ensuring technical terms are spelled correctly.

---

### Code-switching (Bilingual)

Best for: Multilingual conversations, Spanglish, language mixing

```text
Mandatory: Transcribe verbatim, preserving natural code-switching between
English and Spanish.

Required: Retain spoken language as-is without translation
(correct "I was hablando con mi manager").

Non-negotiable: Preserve fillers, repetitions, and false starts across both
languages (eh, o sea— I mean, you know).

Resolve sound-alike errors using bilingual context (pero over perro,
meeting over mitin).
```

**Why it works:** Explicitly instructs preservation over translation, handles cross-language disfluencies, and addresses common bilingual transcription errors.

---

## How to build your prompt

### Step 1: Start with your base need

Choose your primary transcription goal:

| Goal | Base instruction |
|------|------------------|
| **Verbatim/disfluencies** | `Include spoken filler words, hesitations, plus repetitions and false starts when clearly spoken.` |
| **Clean/readable** | `Transcribe this audio with beautiful punctuation and formatting.` |
| **Entity accuracy** | `Use standard spelling and contextually correct spelling of all proper nouns.` |
| **Code-switching** | `Transcribe in the original language mix, preserving words in the language spoken.` |

### Step 2: Add authoritative language

Prefix each instruction with:
- `Non-negotiable:`
- `Mandatory:`
- `Required:`
- `Strict requirement:`

### Step 3: Add explicit examples

Use the contrast format for error patterns:

```text
(correct over incorrect, correct2 over incorrect2)
```

Examples by error type:

| Error type | Example |
|------------|---------|
| Vowel substitution | `(omeprazole over omeprizole)` |
| Sound-alike | `(CABG over cabbage)` |
| Technical terms | `(Kubernetes over kubernetties)` |
| Proper nouns | `(Salesforce over sales force)` |
| Disfluencies | `(um, uh, I—I mean over cleaned speech)` |

### Step 4: Keep it concise

- **Target:** 50-70 words
- **Maximum:** 3-5 instructions
- **Test:** If instructions could conflict, remove one

### Final prompt structure

```text
[Authoritative language]: [Specific instruction] + [Explicit examples]
[Authoritative language]: [Specific instruction] + [Explicit examples]
[Authoritative language]: [Specific instruction] + [Explicit examples]
```

---

## Prompt components that don't work

### Negative instructions

```text
❌ Don't write "omeprizole"
❌ Do NOT mess up medication names
❌ Never include filler words
❌ Avoid unclear speech
```

The word "not" and negative instructions confuse the model. Always use positive instructions with examples of what you WANT.

### Vague instructions without examples

```text
❌ Use correct medical terminology.
❌ Transcribe accurately.
❌ Be precise with drug names.
```

Without error patterns to learn from, these provide only marginal benefit.

### Context-only prompts

```text
❌ Context: Medical transcription
❌ This is a legal deposition
```

Context helps marginally but is not a substitute for explicit examples. Prioritize examples over context.

### Role priming

```text
❌ You are a medical transcriptionist
❌ Act as a court reporter
```

Role phrases provide minimal benefit. Use concrete instructions instead.

### Overly long prompts

```text
❌ You are a medical transcriptionist with 20 years of experience.
   Your job is to accurately transcribe medical dictation...
   [continues for 10+ lines with many instructions]
```

Long prompts with many instructions start to conflict. The model picks a mode and ignores the rest.

---

## Testing your prompts

1. **Identify target terms** - What words/phrases are being transcribed incorrectly?
2. **Find the error pattern** - Vowel substitution? Sound-alike? Phonetic spelling?
3. **Choose example terms** - Pick 2-3 common terms with the SAME error pattern
4. **Test and verify** - Listen to the audio to confirm correctness
5. **Measure success rate** - Test variations on sample files

---

## Quick reference

### Winning formula

```text
[Mandatory/Required/Non-negotiable]: [Specific instruction] (correct over incorrect)
```

### Must-haves for verbatim transcription

- ✅ Explicit disfluency examples (um, uh, false starts)
- ✅ Authoritative language (Mandatory, Required)
- ✅ Contrast format (correct over incorrect)
- ✅ 50-70 words total
- ✅ 3-5 instructions maximum

### Must-avoids

- ❌ Prompts under 30 words
- ❌ Negative language (don't, never, avoid)
- ❌ Conflicting instructions
- ❌ Vague instructions without examples
- ❌ Format-only focus without content capture
