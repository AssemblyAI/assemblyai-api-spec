---
title: "Universal-Streaming Early Access Guide"
hide-nav-links: true
description: "Transcribe live audio with Streaming Speech-to-Text"
---

<Note title="Universal-Streaming Early Access">
  This is an early access version of the Streaming API. It is subject to change.
</Note>

## Quickstart

To run this quickstart you will need:

- Python installed
- A valid API key

To run the quickstart:

<Steps>
    <Step>
    Create a new Python file (for example, `main.py`) and paste the code provided below inside.
    </Step>
    <Step>
    Insert your API key to line 10.
    </Step>
    <Step>
    Install the necessary libraries

    ```bash
    pip install websocket-client pyaudio
    ```

    </Step>
    <Step>
    Run with `python main.py`
    </Step>

</Steps>

<CodeBlocks>
```python title="Python"
import pyaudio
import websocket
import json
import threading
import time
from urllib.parse import urlencode
from datetime import datetime

# --- Configuration ---
YOUR_API_KEY = "<YOUR-API-KEY>"  # Replace with your actual API key

CONNECTION_PARAMS = {
    "sample_rate": 16000,
    "formatted_finals": True, # Request formatted final transcripts
}
API_ENDPOINT_BASE_URL = "wss://streaming.assemblyai.com/v3/ws"
API_ENDPOINT = f"{API_ENDPOINT_BASE_URL}?{urlencode(CONNECTION_PARAMS)}"

# Audio Configuration
FRAMES_PER_BUFFER = 800  # 50ms of audio (0.05s * 16000Hz)
SAMPLE_RATE = CONNECTION_PARAMS["sample_rate"]
CHANNELS = 1
FORMAT = pyaudio.paInt16

# Global variables for audio stream and websocket
audio = None
stream = None
ws_app = None
audio_thread = None
stop_event = threading.Event() # To signal the audio thread to stop

# --- WebSocket Event Handlers ---

def on_open(ws):
    """Called when the WebSocket connection is established."""
    print("WebSocket connection opened.")
    print(f"Connected to: {API_ENDPOINT}")

    # Start sending audio data in a separate thread
    def stream_audio():
        global stream
        print("Starting audio streaming...")
        while not stop_event.is_set():
            try:
                audio_data = stream.read(FRAMES_PER_BUFFER, exception_on_overflow=False)
                # Send audio data as binary message
                ws.send(audio_data, websocket.ABNF.OPCODE_BINARY)
            except Exception as e:
                print(f'Error streaming audio: {e}')
                # If stream read fails, likely means it's closed, stop the loop
                break
        print("Audio streaming stopped.")

    global audio_thread
    audio_thread = threading.Thread(target=stream_audio)
    audio_thread.daemon = True # Allow main thread to exit even if this thread is running
    audio_thread.start()

def on_message(ws, message):
    """Called when a message is received from the server."""
    try:
        data = json.loads(message)
        msg_type = data.get('type')

        if msg_type == 'Begin':
            session_id = data.get('id')
            expires_at = data.get('expires_at')
            print(f"\nSession began: ID={session_id}, ExpiresAt={datetime.fromtimestamp(expires_at)}")

        elif msg_type == 'Partial':
            text = data.get('text', '')
            if text:
                print(text, end='\r', flush=True)

        elif msg_type == 'Final':
            text = data.get('text', '')
            if text:
                print(' ' * 80, end='\r', flush=True)
                print(text, end='\r\n', flush=True)
            # You can also access other fields like 'words', 'confidence', etc.
            # print(f"Final Transcript received: {data}") # Uncomment for full details

        elif msg_type == 'Termination':
            audio_duration = data.get('audio_duration_seconds')
            session_duration = data.get('session_duration_seconds')
            print(f"\nSession Terminated: Audio Duration={audio_duration}s, Session Duration={session_duration}s")

    except json.JSONDecodeError:
        print(f"\nReceived non-JSON message: {message}")
    except Exception as e:
        print(f'\nError handling message: {e}')
        print(f"Message data: {message}") # Print raw message on error

def on_error(ws, error):
    """Called when a WebSocket error occurs."""
    print(f'\nWebSocket Error: {error}')
    # Attempt to signal stop on error
    stop_event.set()

def on_close(ws, close_status_code, close_msg):
    """Called when the WebSocket connection is closed."""
    print(f'\nWebSocket Disconnected: Status={close_status_code}, Msg={close_msg}')
    # Ensure audio resources are released
    global stream, audio
    stop_event.set() # Signal audio thread just in case it's still running

    if stream:
        if stream.is_active():
            stream.stop_stream()
        stream.close()
        stream = None
    if audio:
        audio.terminate()
        audio = None
    # Try to join the audio thread to ensure clean exit
    if audio_thread and audio_thread.is_alive():
         audio_thread.join(timeout=1.0)


# --- Main Execution ---

def run():
    global audio, stream, ws_app

    # Initialize PyAudio
    audio = pyaudio.PyAudio()

    # Open microphone stream
    try:
        stream = audio.open(
            input=True,
            frames_per_buffer=FRAMES_PER_BUFFER,
            channels=CHANNELS,
            format=FORMAT,
            rate=SAMPLE_RATE
        )
        print("Microphone stream opened successfully.")
        print("Speak into your microphone. Press Ctrl+C to stop.")
    except Exception as e:
        print(f"Error opening microphone stream: {e}")
        if audio:
            audio.terminate()
        return # Exit if microphone cannot be opened

    # Create WebSocketApp
    ws_app = websocket.WebSocketApp(
        API_ENDPOINT,
        header={'Authorization': YOUR_API_KEY},
        on_open=on_open,
        on_message=on_message,
        on_error=on_error,
        on_close=on_close
    )

    # Run WebSocketApp in a separate thread to allow main thread to catch KeyboardInterrupt
    ws_thread = threading.Thread(target=ws_app.run_forever)
    ws_thread.daemon = True
    ws_thread.start()

    try:
        # Keep main thread alive until interrupted
        while ws_thread.is_alive():
            time.sleep(0.1)
    except KeyboardInterrupt:
        print("\nCtrl+C received. Stopping...")
        stop_event.set() # Signal audio thread to stop

        # Send termination message to the server
        if ws_app and ws_app.sock and ws_app.sock.connected:
            try:
                terminate_message = {"type": "Terminate"}
                print(f"Sending termination message: {json.dumps(terminate_message)}")
                ws_app.send(json.dumps(terminate_message))
                # Give a moment for messages to process before forceful close
                time.sleep(0.5)
            except Exception as e:
                print(f"Error sending termination message: {e}")

        # Close the WebSocket connection (will trigger on_close)
        if ws_app:
            ws_app.close()

        # Wait for WebSocket thread to finish
        ws_thread.join(timeout=2.0)

    except Exception as e:
        print(f"\nAn unexpected error occurred: {e}")
        stop_event.set()
        if ws_app:
            ws_app.close()
        ws_thread.join(timeout=2.0)

    finally:
        # Final cleanup (already handled in on_close, but good as a fallback)
        if stream and stream.is_active():
            stream.stop_stream()
        if stream:
            stream.close()
        if audio:
            audio.terminate()
        print("Cleanup complete. Exiting.")

if __name__ == "__main__":
    run()
```
</CodeBlocks>

## Early Access Considerations

### Recommendations

- Use an audio chunk size of 50ms. Larger chunk sizes are workable, but may result in latency fluctuations.
- Sample rate of 16 kHz and encoding of pcm_s16le. 8 kHz is workable, but may result in latency fluctuations.
- Do not exceed your alloted session concurrency, otherwise experienced latency will not be representative of latency at launch.

### Known Issues
These are issues currently known to exist in the API and being worked on by our team.

- Partial transcripts may start with sub-words.
- Subsequent partials may contain the same text content.
- Transcript confidence scores may currently be unstable.
- The session `Begin` message's `expires_at` field returns current epoch time.
- Partial and final transcripts may return unexpected word-level timestamps.



## Reference

### Audio requirements

The audio format must conform to the following requirements:

- PCM16 or Mu-law encoding (See Specify the encoding)
- A sample rate that matches the value of the `sample_rate` parameter
- Single-channel
- 50 milliseconds of audio per message (recommended)


### Message types

You send:
<AccordionGroup>
<Accordion title="Audio data">
```json
"UklGRtjIAABXQVZFZ"
```

</Accordion>

<Accordion title="Endpointing config">
```json
{"type": "EndpointSilenceThreshold", "value_ms": 700}
```
</Accordion>

<Accordion title="Session termination">
```json
{"type": "Terminate"}
```
</Accordion>

</AccordionGroup>

You receive:

<AccordionGroup>

  <Accordion title="Session Begin">

    ```json
    {
        "type": "Begin",
        "id": "cfd280c7-5a9b-4dd6-8c05-235ccfa3c97f",
        "expires_at": 1745483367
    }
    ```

  </Accordion>
  <Accordion title="Partial Transcript">
    ```json
    {
        "confidence": 0.9656018614768982,
        "endpoint_confidence": 0.00015928121865727007,
        "order": 11,
        "start": 880,
        "end": 960,
        "text": "hello",
        "words":
        [
            {
                "start": 960,
                "end": 960,
                "confidence": 0.9656018614768982,
                "text": "hello"
            }
        ],
        "type": "Partial"
    }
    ```
  </Accordion>
  <Accordion title="Final Transcript">
    ```json
    {
        "confidence": 0.9826867580413818,
        "endpoint_confidence": 0.11108475923538208,
        "order": 24,
        "start": 960,
        "end": 2000,
        "text": "hello everybody",
        "words":
        [
            {
                "start": 960,
                "end": 960,
                "confidence": 0.9656018614768982,
                "text": "hello"
            },
            {
                "start": 1440,
                "end": 1440,
                "confidence": 0.9997717142105103,
                "text": "everybody"
            }
        ],
        "type": "Final",
        "formatted": False
    }
    ```
  </Accordion>
  <Accordion title="Session Termination">
    ```json
    {
        "type": "Termination",
        "audio_duration_seconds": 2000,
        "session_duration_seconds": 2000
    }
    ```
  </Accordion>
</AccordionGroup>
