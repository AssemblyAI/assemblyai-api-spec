from enum import Enum
from typing import Any, Dict, List, Optional, Union
from pydantic import BaseModel, ConfigDict, Field, model_validator


class ChatRole(str, Enum):
    """The role of the message sender."""

    assistant = "assistant"
    user = "user"
    system = "system"
    tool = "tool"


class ModelName(str, Enum):
    """Available models for chat completions."""

    # Anthropic Claude
    claude_sonnet_4_5 = "claude-sonnet-4-5-20250929"
    claude_sonnet_4 = "claude-sonnet-4-20250514"
    claude_opus_4 = "claude-opus-4-20250514"
    claude_haiku_4_5 = "claude-haiku-4-5-20251001"
    claude_haiku_3_5 = "claude-3-5-haiku-20241022"
    claude_haiku_3 = "claude-3-haiku-20240307"

    # OpenAI GPT
    gpt_5 = "gpt-5"
    gpt_5_nano = "gpt-5-nano"
    gpt_5_mini = "gpt-5-mini"
    gpt_4_1 = "gpt-4.1"
    gpt_oss_120b = "gpt-oss-120b"
    gpt_oss_20b = "gpt-oss-20b"

    # Google Gemini
    gemini_2_5_pro = "gemini-2.5-pro"
    gemini_2_5_flash = "gemini-2.5-flash"
    gemini_2_5_flash_lite = "gemini-2.5-flash-lite"
    gemini_3_pro_preview = "gemini-3-pro-preview"


class FinishReason(str, Enum):
    """The reason the model stopped generating tokens."""

    end_turn = "end_turn"
    stop = "stop"
    max_tokens = "max_tokens"


# Content types
class TextContent(BaseModel):
    """Text content part."""

    model_config = ConfigDict(extra="forbid")

    type: str = Field("text", description="Content type")
    text: str = Field(..., description="The text content")


# Tool calling models
class FunctionDescription(BaseModel):
    """Function description for tool calling."""

    model_config = ConfigDict(extra="forbid")

    description: Optional[str] = Field(None, description="Function description")
    name: str = Field(..., description="Function name")
    parameters: Dict[str, Any] = Field(
        ..., description="JSON Schema object for parameters"
    )


class Tool(BaseModel):
    """Tool definition."""

    model_config = ConfigDict(extra="forbid")

    type: str = Field("function", description="Tool type")
    function: FunctionDescription = Field(..., description="Function description")


class ToolChoiceFunction(BaseModel):
    """Tool choice function specification."""

    model_config = ConfigDict(extra="forbid")

    name: str = Field(..., description="Function name")


class ToolChoiceObject(BaseModel):
    """Tool choice object."""

    model_config = ConfigDict(extra="forbid")

    type: str = Field("function", description="Tool choice type")
    function: ToolChoiceFunction = Field(..., description="Function specification")


class Function(BaseModel):
    """Function call details."""

    model_config = ConfigDict(extra="forbid")

    arguments: str = Field(..., description="Function arguments as JSON string")
    name: str = Field(..., description="Function name")


class FunctionToolCall(BaseModel):
    """Function tool call."""

    model_config = ConfigDict(extra="forbid")

    function: Function = Field(..., description="Function call details")
    id: str = Field(..., description="Tool call ID")
    type: str = Field("function", description="Tool call type")


# Message models
class StandardMessage(BaseModel):
    """Standard chat message."""

    model_config = ConfigDict(extra="forbid")

    role: ChatRole = Field(..., description="The role of the message sender")
    content: Union[str, List[TextContent]] = Field(
        ..., description="The content of the message"
    )
    name: Optional[str] = Field(
        None, description="Optional name for the message sender"
    )


class ToolMessage(BaseModel):
    """Tool message."""

    model_config = ConfigDict(extra="forbid")

    role: str = Field("tool", description="Message role")
    content: str = Field(..., description="Tool response content")
    tool_call_id: str = Field(
        ..., description="ID of the tool call this is responding to"
    )
    name: Optional[str] = Field(None, description="Optional tool name")


# Union type for messages
Message = Union[StandardMessage, ToolMessage]


class ChatMessage(BaseModel):
    """A chat message (legacy model for backward compatibility)."""

    model_config = ConfigDict(extra="forbid")

    role: ChatRole = Field(..., description="The role of the message sender")
    content: str = Field(..., description="The content of the message")


class ChatChoice(BaseModel):
    """A chat completion choice."""

    model_config = ConfigDict(extra="forbid")

    message: Optional[Message] = Field(
        None, description="The message generated by the model"
    )
    finish_reason: Optional[str] = Field(
        None, description="The reason the model stopped generating"
    )
    tool_calls: Optional[List[FunctionToolCall]] = Field(
        None, description="Tool calls made by the model"
    )


class ChatRequest(BaseModel):
    """The original request parameters."""

    model_config = ConfigDict(extra="forbid")

    model: ModelName = Field(..., description="The model used for the completion")
    max_tokens: int = Field(..., description="Maximum number of tokens to generate")
    temperature: float = Field(..., description="Temperature for sampling")


class Usage(BaseModel):
    """Token usage information."""

    model_config = ConfigDict(extra="forbid")

    input_tokens: int = Field(..., description="Number of input tokens")
    output_tokens: int = Field(..., description="Number of output tokens")
    total_tokens: int = Field(..., description="Total number of tokens")


class ChatCompletionsResponse(BaseModel):
    """Response from chat completions endpoint."""

    model_config = ConfigDict(extra="forbid")

    request_id: str = Field(..., description="Unique identifier for the request")
    choices: List[ChatChoice] = Field(..., description="List of completion choices")
    request: Dict[str, Any] = Field(
        ..., description="The original request parameters (sans prompt/messages)"
    )
    usage: Usage = Field(..., description="Token usage information")
    response_time: Optional[int] = Field(None, description="Response time in nanoseconds")
    llm_status_code: Optional[int] = Field(None, description="Status code from the underlying LLM")


class ChatCompletionsRequest(BaseModel):
    """Request parameters for chat completions."""

    model_config = ConfigDict(extra="forbid")

    # Either messages or prompt is required
    messages: Optional[List[Message]] = Field(
        None, description="List of messages for the conversation"
    )
    prompt: Optional[str] = Field(
        None, description="Simple prompt (will be converted to messages)"
    )

    model: str = Field(..., description="The model to use for completion")

    # LLM Parameters
    max_tokens: Optional[int] = Field(
        None, description="Maximum number of tokens to generate", ge=1
    )
    temperature: Optional[float] = Field(
        None, description="Temperature for sampling", ge=0.0, le=2.0
    )

    # Tool calling
    tools: Optional[List[Tool]] = Field(
        None, description="Tools available for the model to call"
    )
    tool_choice: Optional[Union[str, ToolChoiceObject]] = Field(
        None, description="Tool choice strategy"
    )

    @model_validator(mode="after")
    def validate_messages_or_prompt(self):
        """Ensure either messages or prompt is provided, but not both."""
        if not self.messages and not self.prompt:
            raise ValueError("Either 'messages' or 'prompt' must be provided")
        if self.messages and self.prompt:
            raise ValueError("Cannot provide both 'messages' and 'prompt'")
        return self


# Speech Understanding Models (copied from transcript API)
class SpeakerType(str, Enum):
    """The type of speaker identification."""

    name = "name"
    role = "role"


class SpeakerIdentificationRequest(BaseModel):
    """Speaker identification request configuration."""

    model_config = ConfigDict(extra="forbid")

    speaker_type: SpeakerType = Field(
        ..., description="The type of speaker identification"
    )
    known_values: Optional[List[str]] = Field(
        None,
        description="Known values for speakers (required when speaker_type is 'role')",
    )


class SpeakerIdentificationResponse(BaseModel):
    """Speaker identification response."""

    model_config = ConfigDict(extra="forbid")

    mapping: Dict[str, str] = Field(
        ..., description="Mapping of original speakers to identified speakers"
    )
    status: str = Field(..., description="The status of speaker identification")


class TranslationRequest(BaseModel):
    """Translation request configuration."""

    model_config = ConfigDict(extra="forbid")

    target_languages: List[str] = Field(
        ..., description="List of target language codes"
    )
    formal: bool = Field(True, description="Whether to use formal language")
    match_original_utterance: bool = Field(
        False, description="Whether to match original utterance structure"
    )


class TranslationResponse(BaseModel):
    """Translation response."""

    model_config = ConfigDict(extra="forbid")

    status: str = Field(..., description="The status of translation")


class CustomFormattingRequest(BaseModel):
    """Custom formatting request configuration."""

    model_config = ConfigDict(extra="forbid")

    date: Optional[str] = Field(
        None, description="Date format pattern (e.g., 'mm/dd/yyyy')"
    )
    phone_number: Optional[str] = Field(
        None, description="Phone number format pattern (e.g., '(xxx)xxx-xxxx')"
    )
    email: Optional[str] = Field(
        None, description="Email format pattern (e.g., 'username@domain.com')"
    )
    formatted_utterances: bool = Field(True, description="Whether to format utterances")


class CustomFormattingResponse(BaseModel):
    """Custom formatting response."""

    model_config = ConfigDict(extra="forbid")

    mapping: Dict[str, str] = Field(
        ..., description="Mapping of original text to formatted text"
    )
    formatted_text: Optional[str] = Field(None, description="The formatted text")
    formatted_utterances: Optional[List[dict]] = Field(
        None, description="Formatted utterances"
    )
    status: str = Field(..., description="The status of custom formatting")


class SpeechUnderstandingRequest(BaseModel):
    """Speech understanding request configuration."""

    model_config = ConfigDict(extra="forbid")

    speaker_identification: Optional[SpeakerIdentificationRequest] = Field(
        None, description="Speaker identification request"
    )
    translation: Optional[TranslationRequest] = Field(
        None, description="Translation request"
    )
    custom_formatting: Optional[CustomFormattingRequest] = Field(
        None, description="Custom formatting request"
    )


class SpeechUnderstandingResponse(BaseModel):
    """Speech understanding response configuration."""

    model_config = ConfigDict(extra="forbid")

    speaker_identification: Optional[SpeakerIdentificationResponse] = Field(
        None, description="Speaker identification response"
    )
    translation: Optional[TranslationResponse] = Field(
        None, description="Translation response"
    )
    custom_formatting: Optional[CustomFormattingResponse] = Field(
        None, description="Custom formatting response"
    )


class SpeechUnderstanding(BaseModel):
    """Speech Understanding configuration with results."""

    model_config = ConfigDict(extra="forbid")

    request: SpeechUnderstandingRequest = Field(
        ..., description="The speech understanding request configuration"
    )
    response: Optional[SpeechUnderstandingResponse] = Field(
        None, description="The speech understanding response"
    )


class SpeechUnderstandingInput(BaseModel):
    """Speech Understanding input configuration for requests."""

    model_config = ConfigDict(extra="forbid")

    request: SpeechUnderstandingRequest = Field(
        ..., description="The speech understanding request configuration"
    )


# Utterance and Word models for understanding response
class TranscriptWord(BaseModel):
    """A word in the transcript."""

    model_config = ConfigDict(extra="forbid")

    speaker: str = Field(..., description="The speaker of the word")
    text: str = Field(..., description="The text of the word")
    start: int = Field(..., description="Start time in milliseconds")
    end: int = Field(..., description="End time in milliseconds")
    confidence: float = Field(..., description="Confidence score", ge=0.0, le=1.0)


class TranscriptUtterance(BaseModel):
    """An utterance in the transcript."""

    model_config = ConfigDict(extra="forbid")

    speaker: str = Field(..., description="The speaker of the utterance")
    text: str = Field(..., description="The text of the utterance")
    confidence: float = Field(..., description="Confidence score", ge=0.0, le=1.0)
    start: int = Field(..., description="Start time in milliseconds")
    end: int = Field(..., description="End time in milliseconds")
    words: List[TranscriptWord] = Field(..., description="Words in the utterance")


# Understanding endpoint models
class UnderstandingRequest(BaseModel):
    """Request for understanding endpoint."""

    model_config = ConfigDict(extra="forbid")

    transcript_id: str = Field(..., description="The transcript ID to process")
    speech_understanding: SpeechUnderstandingInput = Field(
        ..., description="Speech understanding configuration"
    )


class UnderstandingResponse(BaseModel):
    """Response from understanding endpoint."""

    model_config = ConfigDict(extra="forbid")

    speech_understanding: SpeechUnderstanding = Field(
        ..., description="Speech understanding results"
    )
    utterances: List[TranscriptUtterance] = Field(
        ..., description="Updated utterances with speech understanding applied"
    )
    request_id: str = Field(..., description="Unique identifier for the request")


class DeleteResponse(BaseModel):
    """Response from delete request endpoint."""

    model_config = ConfigDict(extra="forbid")

    success: bool = Field(..., description="Whether the deletion was successful")
    message: str = Field(..., description="Deletion status message")
    request_id: str = Field(..., description="The deleted request ID")
