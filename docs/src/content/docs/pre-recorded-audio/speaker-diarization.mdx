---
title: Speaker diarization
description: Identify who said what in your audio files
---

import { Tabs, TabItem, Aside } from "@astrojs/starlight/components";

Speaker diarization identifies who said what in your audio. Enable it by setting `speaker_labels` to `true` in your transcription request.

## Quickstart

<Tabs>
<TabItem label="Python SDK">

```python
import assemblyai as aai

aai.settings.api_key = "YOUR_API_KEY"

config = aai.TranscriptionConfig(speaker_labels=True)

transcript = aai.Transcriber().transcribe(
    "https://assembly.ai/wildfires.mp3",
    config=config,
)

for utterance in transcript.utterances:
    print(f"Speaker {utterance.speaker}: {utterance.text}")
```

</TabItem>
<TabItem label="JavaScript SDK">

```javascript
import { AssemblyAI } from "assemblyai";

const client = new AssemblyAI({ apiKey: "YOUR_API_KEY" });

const transcript = await client.transcripts.transcribe({
  audio_url: "https://assembly.ai/wildfires.mp3",
  speaker_labels: true,
});

for (const utterance of transcript.utterances) {
  console.log(`Speaker ${utterance.speaker}: ${utterance.text}`);
}
```

</TabItem>
</Tabs>

<Aside type="tip">
  Speaker labels are returned as `Speaker A`, `Speaker B`, etc. You can use the [Speaker Identification](/docs/speech-understanding/speaker-identification) feature for cross-file speaker matching.
</Aside>
