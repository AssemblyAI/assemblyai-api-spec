---
title: LLM Gateway
description: Apply LLMs to your audio data with AssemblyAI's LLM Gateway
---

import { Card, CardGrid, Aside } from "@astrojs/starlight/components";

LLM Gateway lets you apply large language models directly to your audio data through a familiar chat completions interface. Ask questions, extract insights, and build agentic workflows â€” all powered by your transcripts.

<Aside type="note">
  LLM Gateway replaces the legacy LeMUR API. See the [migration guide](/docs/llm-gateway/migration-from-lemur) for details.
</Aside>

## What you can do

<CardGrid>
  <Card title="Chat Completions" icon="comment">
    Use a familiar OpenAI-compatible interface to query your audio data.
  </Card>
  <Card title="Speech Understanding" icon="puzzle">
    Extract structured insights from audio with a single API call.
  </Card>
  <Card title="Tool Calling" icon="setting">
    Build agentic workflows that use your transcripts as context.
  </Card>
  <Card title="Structured Outputs" icon="document">
    Get JSON-formatted responses that match your schema.
  </Card>
</CardGrid>

## Quickstart

```bash
curl https://api.assemblyai.com/v2/llm-gateway/chat/completions \
  --header "Authorization: YOUR_API_KEY" \
  --header "Content-Type: application/json" \
  --data '{
    "model": "anthropic/claude-sonnet-4-20250514",
    "messages": [
      {
        "role": "user",
        "content": "Summarize this transcript",
        "transcript_ids": ["YOUR_TRANSCRIPT_ID"]
      }
    ]
  }'
```

## Next steps

- [Apply LLMs to audio files](/docs/llm-gateway/apply-llms-to-audio-files)
- [Ask questions about your audio](/docs/llm-gateway/ask-questions)
- [Build agentic workflows](/docs/llm-gateway/agentic-workflows)
- [View the API Reference](/docs/api-reference)
